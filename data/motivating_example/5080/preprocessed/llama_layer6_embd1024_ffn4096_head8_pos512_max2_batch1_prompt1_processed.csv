Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,1.696,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.568,3.2640000000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,1.696,4.96,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,3.0,0.0,64.0,32.0,2.048,7.008,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.592,9.6,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",6,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.112,11.712,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",7,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,13.76,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",8,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.112,15.872,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",9,128.0,0.0,256.0,0,0.0,256.0,256.0,129.0,6.0,0.9555555555555556,32.0,32.0,2.88,18.752,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",10,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,21.279999999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",11,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.4,23.679999999999996,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.08,25.759999999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,128.0,0.0,256.0,0,0.0,256.0,256.0,129.0,6.0,0.9555555555555556,32.0,32.0,2.88,28.639999999999997,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.4,31.039999999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",15,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.4,33.44,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",16,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,3.0,0.0,64.0,0.0,2.56,36.0,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(detail::TensorInfo<T1, T3>, detail::TensorInfo<const T1, T3>, detail::TensorInfo<const T2, T3>, int, int, T3, long)",17,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,4352.0,4096.0,4.8,40.8,0.0,0.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",18,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,3.008,43.808,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",19,515.0,0.0,1030.0,0,0.0,1030.0,1030.0,0.0,2.0,0.0,32.0,32.0,2.848,46.656,0.0,0.0,0.0,515.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",20,0.0,128.0,0.0,0,0.0,128.0,128.0,8.0,6.0,0.5714285714285714,320.0,256.0,2.88,49.536,0.0,128.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",21,288.0,0.0,576.0,0,0.0,576.0,576.0,0.0,10.0,0.0,512.0,512.0,2.56,52.096000000000004,0.0,0.0,0.0,288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",22,1664.0,2304.0,1280.0,0,0.0,3584.0,3584.0,0.0,8.0,0.0,512.0,512.0,2.912,55.008,0.0,256.0,1024.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",23,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,8.0,0.0,512.0,512.0,2.528,57.536,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",24,1536.0,2304.0,1024.0,0,0.0,3328.0,3328.0,0.0,8.0,0.0,512.0,512.0,2.976,60.512,0.0,256.0,1024.0,512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",25,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,8.0,0.0,512.0,512.0,2.464,62.976,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",26,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.72,65.696,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",27,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.488,69.184,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",28,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.912,72.096,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",29,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,74.72,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",30,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.008,77.728,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",31,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.688,80.416,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",32,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,10.08,90.496,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",33,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.448,98.94399999999999,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",34,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.512,107.45599999999999,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",35,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,110.55999999999999,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",36,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.136,113.69599999999998,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",37,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,4.096,117.79199999999999,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",38,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,120.89599999999999,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",39,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,123.48799999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",40,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,126.49599999999998,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",41,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.136,129.63199999999998,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",42,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.68,133.31199999999998,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",43,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,136.384,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",44,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,138.976,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",45,16384.0,1503744.0,0.0,0,0.0,1503744.0,1503744.0,8320.0,16.0,0.9980806142034548,12288.0,4096.0,20.064,159.04,1272832.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",46,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.704,167.744,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",47,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,170.336,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",48,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.688,173.024,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",49,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.52,176.544,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",50,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,178.976,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",51,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,181.6,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",52,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.104,184.704,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",53,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,187.264,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",54,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17145472.0,29216.0,23.616,210.88,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",55,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.944,213.82399999999998,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",56,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17154176.0,28864.0,24.416,238.23999999999998,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",57,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.688,240.92799999999997,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",58,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17834112.0,2048.0,22.752,263.67999999999995,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",59,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.528,266.20799999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",60,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.656,268.864,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",61,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,272.256,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",62,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,274.65599999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",63,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,277.24799999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",64,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,280.22399999999993,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",65,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,282.78399999999993,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",66,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.8,291.58399999999995,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",67,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.544,300.12799999999993,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",68,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,308.89599999999996,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",69,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,311.96799999999996,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",70,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.072,315.03999999999996,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",71,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,318.688,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",72,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,321.792,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",73,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.656,324.448,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",74,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.2,327.64799999999997,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",75,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,330.688,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",76,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,334.336,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",77,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,337.37600000000003,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",78,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.752,340.12800000000004,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",79,16384.0,1503744.0,0.0,0,0.0,1503744.0,1503744.0,8320.0,16.0,0.9980806142034548,12288.0,4096.0,20.192,360.32000000000005,1272832.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",80,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.48,368.80000000000007,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",81,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,371.4240000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",82,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,373.9840000000001,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",83,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,377.3760000000001,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",84,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,379.8080000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",85,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,382.3360000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",86,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.072,385.40800000000013,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",87,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.624,388.03200000000015,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",88,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17140224.0,29568.0,22.816,410.8480000000001,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",89,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.912,413.7600000000001,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",90,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17145216.0,28896.0,24.256,438.0160000000001,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",91,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,440.60800000000006,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",92,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17832832.0,2048.0,23.424,464.03200000000004,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",93,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.528,466.56000000000006,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",94,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,469.0880000000001,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",95,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.552,472.6400000000001,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",96,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,475.0400000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",97,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,477.6000000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",98,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.04,480.6400000000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",99,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,483.2320000000001,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",100,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.448,491.68000000000006,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",101,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.672,500.3520000000001,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",102,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.864,509.21600000000007,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",103,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,512.2560000000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",104,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.072,515.3280000000001,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",105,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,518.9760000000001,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",106,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,522.0160000000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",107,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.688,524.7040000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",108,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.2,527.9040000000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",109,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.072,530.9760000000001,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",110,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.776,534.7520000000001,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",111,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,537.792,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",112,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,540.384,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",113,16384.0,1503744.0,0.0,0,0.0,1503744.0,1503744.0,8320.0,16.0,0.9980806142034548,12288.0,4096.0,20.224,560.6080000000001,1272832.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",114,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.864,569.4720000000001,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",115,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,572.0640000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",116,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.624,574.6880000000001,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",117,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.456,578.1440000000001,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",118,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,580.5120000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",119,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,583.0720000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",120,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,586.0160000000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",121,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,588.6080000000001,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",122,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17164928.0,30144.0,23.136,611.744,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",123,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,3.136,614.88,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",124,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17154560.0,30080.0,23.744,638.624,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",125,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.656,641.28,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",126,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17839360.0,2048.0,22.88,664.16,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",127,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,666.752,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",128,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.688,669.4399999999999,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",129,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,672.832,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",130,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.528,675.36,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",131,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,677.92,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",132,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,680.8639999999999,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",133,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,683.4239999999999,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",134,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.704,692.1279999999998,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",135,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.448,700.5759999999998,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",136,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.48,709.0559999999998,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",137,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,712.1279999999998,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",138,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.072,715.1999999999998,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",139,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.776,718.9759999999998,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",140,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,722.0159999999997,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",141,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.688,724.7039999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",142,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,727.7759999999997,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",143,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.168,730.9439999999997,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",144,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.616,734.5599999999997,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",145,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,737.6319999999997,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",146,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,740.2239999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",147,16384.0,1503744.0,0.0,0,0.0,1503744.0,1503744.0,8320.0,16.0,0.9980806142034548,12288.0,4096.0,20.128,760.3519999999997,1272832.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",148,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.544,768.8959999999997,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",149,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,771.4879999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",150,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.592,774.0799999999997,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",151,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.424,777.5039999999997,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",152,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,779.9039999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",153,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,782.4639999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",154,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,785.4079999999996,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",155,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,787.9679999999995,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",156,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17135872.0,29504.0,23.008,810.9759999999995,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",157,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.912,813.8879999999996,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",158,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17141632.0,29728.0,22.784,836.6719999999996,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",159,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,839.2639999999996,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",160,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17837184.0,2048.0,23.2,862.4639999999996,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",161,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,865.0559999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",162,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,867.6159999999995,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",163,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.424,871.0399999999995,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",164,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,873.4719999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",165,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.688,876.1599999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",166,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,879.1359999999995,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",167,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.624,881.7599999999995,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",168,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.704,890.4639999999995,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",169,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.736,899.1999999999995,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",170,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.832,908.0319999999995,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",171,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,911.0719999999994,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",172,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,914.1119999999994,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",173,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,917.7599999999994,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",174,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.168,920.9279999999994,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",175,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.656,923.5839999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",176,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,926.5919999999994,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",177,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,929.6319999999994,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",178,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,933.2799999999994,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",179,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,936.3199999999994,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",180,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,938.9119999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",181,16384.0,1503744.0,0.0,0,0.0,1503744.0,1503744.0,8320.0,16.0,0.9980806142034548,12288.0,4096.0,20.192,959.1039999999994,1272832.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",182,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.416,967.5199999999994,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",183,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,970.0799999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",184,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,972.6399999999993,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",185,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.488,976.1279999999994,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",186,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,978.5279999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",187,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,981.0559999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",188,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,983.9999999999993,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",189,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,986.5919999999993,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",190,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17151872.0,28896.0,24.064,1010.6559999999993,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",191,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.88,1013.5359999999993,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",192,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17151872.0,28896.0,23.04,1036.5759999999993,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",193,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,1039.1679999999994,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",194,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17833216.0,2048.0,23.136,1062.3039999999994,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",195,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,1064.8959999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",196,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,1067.4559999999994,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",197,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.424,1070.8799999999994,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",198,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,1073.3119999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",199,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,1075.8719999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",200,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,1078.8479999999995,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",201,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,1081.4399999999996,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",202,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,1090.2079999999996,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",203,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.864,1099.0719999999997,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",204,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.576,1107.6479999999997,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",205,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,1110.7199999999996,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",206,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.136,1113.8559999999995,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",207,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.712,1117.5679999999995,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",208,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,1120.6079999999995,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",209,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,1123.1679999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",210,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,1126.2399999999993,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",211,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.136,1129.3759999999993,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",212,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.712,1133.0879999999993,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",213,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,1136.1279999999992,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",214,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.656,1138.7839999999992,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",215,16352.0,1503660.0,0.0,0,0.0,1503660.0,1503660.0,8323.0,16.0,0.9980813047127953,12288.0,4096.0,20.16,1158.9439999999993,1272815.0,198141.0,16352.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",216,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,1167.7119999999993,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",217,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,1170.2719999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",218,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,1172.7999999999993,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",219,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.456,1176.2559999999992,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",220,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,1178.6239999999991,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",221,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,1181.2159999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",222,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,1184.1919999999993,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",223,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,1186.7839999999994,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",224,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17136768.0,29152.0,22.272,1209.0559999999994,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",225,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.88,1211.9359999999995,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",226,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17155712.0,29120.0,23.776,1235.7119999999995,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",227,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.528,1238.2399999999996,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",228,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17832704.0,2048.0,23.04,1261.2799999999995,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",229,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,1263.8399999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",230,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.592,1266.4319999999996,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",231,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,1269.8239999999996,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",232,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,1272.2239999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",233,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,1274.8159999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",234,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,1277.7599999999998,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",235,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,1280.3199999999997,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",236,33088000.0,65856000.0,576000.0,0,0.0,66432000.0,66432000.0,88000.0,2056000.0,0.041044776119402986,132889024.0,178496.0,148.544,1428.8639999999998,256000.0,0.0,32800000.0,288000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",237,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,1430.9119999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",238,258.0,0.0,516.0,0,0.0,516.0,516.0,0.0,4.0,0.0,64.0,64.0,2.528,1433.4399999999998,0.0,0.0,0.0,258.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",239,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,1436.032,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",240,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,128000.0,128000.0,2.688,1438.72,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",241,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.112,1440.832,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",242,48128.0,0.0,96256.0,0,0.0,96256.0,96256.0,512.0,1512.0,0.25296442687747034,129024.0,8192.0,3.936,1444.768,0.0,0.0,0.0,48128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",243,27648.0,0.0,55296.0,0,0.0,55296.0,55296.0,2112.0,8610.0,0.1969781757134863,527360.0,0.0,4.704,1449.472,0.0,0.0,0.0,27648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",244,16320.0,0.0,32640.0,0,0.0,32640.0,32640.0,512.0,1512.0,0.25296442687747034,129024.0,8192.0,4.064,1453.536,0.0,0.0,0.0,16320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",245,33792.0,0.0,67584.0,0,0.0,67584.0,67584.0,2112.0,8802.0,0.19351291918636612,527360.0,0.0,4.768,1458.304,0.0,0.0,0.0,33792.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",246,16132.0,0.0,32264.0,0,0.0,32264.0,32264.0,512.0,1512.0,0.25296442687747034,129024.0,8192.0,3.968,1462.2720000000002,0.0,0.0,0.0,16132.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",247,28672.0,0.0,57344.0,0,0.0,57344.0,57344.0,2112.0,8642.0,0.19639204017109912,527360.0,0.0,4.992,1467.2640000000001,0.0,0.0,0.0,28672.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",248,16129.0,0.0,32258.0,0,0.0,32258.0,32258.0,512.0,1512.0,0.25296442687747034,129024.0,8192.0,3.936,1471.2,0.0,0.0,0.0,16129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",249,31744.0,0.0,63488.0,0,0.0,63488.0,63488.0,2112.0,8738.0,0.19465437788018433,527360.0,32.0,4.8,1476.0,0.0,0.0,0.0,31744.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",250,352.0,0.0,704.0,0,0.0,704.0,704.0,0.0,3.0,0.0,1056.0,128.0,3.168,1479.168,0.0,0.0,0.0,352.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",251,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.048,1481.216,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",252,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,11.0,0.9829984544049459,128.0,0.0,4.288,1485.504,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",253,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.176,1487.6799999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",254,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,11.0,0.9829984544049459,128.0,0.0,4.416,1492.0959999999998,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 1>(detail::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, detail::TensorInfo<T1, T2>, T2, detail::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",255,40292.0,0.0,80584.0,0,0.0,80584.0,80584.0,7257.0,2108.0,0.7749065670048051,131808.0,1568.0,5.888,1497.9839999999997,0.0,0.0,0.0,40292.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::radixSortKVInPlace<(int)-2, (int)-1, 32, 4, float, long, unsigned int>(detail::TensorInfo<T5, T7>, T7, T7, T7, detail::TensorInfo<T6, T7>, T7, bool)",256,64.0,0.0,128.0,0,0.0,128.0,128.0,458.0,8.0,0.9828326180257511,640.0,0.0,6.112,1504.0959999999998,0.0,0.0,0.0,64.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",257,64000.0,0.0,128000.0,0,0.0,128000.0,128000.0,0.0,3000.0,0.0,130016.0,8000.0,4.0,1508.0959999999998,0.0,0.0,0.0,64000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",258,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,768.0,0.0,160000.0,0.0,2.944,1511.0399999999997,0.0,0.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"native::<unnamed>::fill_reverse_indices_kernel(long *, int, detail::IntDivider<unsigned int>)",259,128768.0,0.0,257536.0,0,0.0,257536.0,257536.0,0.0,1000.0,0.0,0.0,256000.0,2.56,1513.5999999999997,0.0,0.0,0.0,128768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",260,387235.0,0.0,774470.0,0,0.0,774470.0,774470.0,64512.0,1000.0,0.9847356209549396,128000.0,0.0,3.968,1517.5679999999998,0.0,0.0,0.0,387235.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",261,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,2.592,1520.1599999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",262,29568.0,0.0,59136.0,0,0.0,59136.0,59136.0,10414.0,4264.0,0.7094972067039106,407680.0,306400.0,14.752,1534.9119999999998,0.0,0.0,0.0,29568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",263,14400.0,0.0,28800.0,0,0.0,28800.0,28800.0,3418.0,4272.0,0.4444733420026008,407552.0,390144.0,13.216,1548.1279999999997,0.0,0.0,0.0,14400.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",264,15744.0,0.0,31488.0,0,0.0,31488.0,31488.0,4798.0,4224.0,0.5318111283529151,405504.0,390656.0,14.048,1562.1759999999997,0.0,0.0,0.0,15744.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",265,15744.0,0.0,31488.0,0,0.0,31488.0,31488.0,4798.0,4223.0,0.5318700809222924,405504.0,326880.0,13.952,1576.1279999999997,0.0,0.0,0.0,15744.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",266,524494.0,1061280.0,152988.0,0,0.0,1214268.0,1214268.0,132.0,1312.0,0.09141274238227147,242688.0,128000.0,18.24,1594.3679999999997,133280.0,32000.0,448000.0,76494.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<float, 1>>(T1, int)",267,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,0.0,416.0,2.112,1596.4799999999998,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<float, std::plus<float>>::Policy900, const float *, float *, at_cuda_detail::ScanTileState<float, 1>, std::plus<float>, at_cuda_detail::NullType, unsigned int, float, 0>(T2, T3, T4, int, T5, T6, T7)",268,2177.0,85371.0,4354.0,0,0.0,89725.0,89725.0,4349.0,2053.0,0.6793189628241174,136128.0,129024.0,3.968,1600.4479999999999,85371.0,0.0,0.0,2177.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",269,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,512.0,0.0,128000.0,31808.0,2.592,1603.04,0.0,0.0,0.0,256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::unrolled_elementwise_kernel<native::FillFunctor<bool>, std::array<char *, 1>, 16, TrivialOffsetCalculator<0, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithoutCast, memory::StoreWithoutCast>(int, T1, T2, T4, T5, T6, T7)",270,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.016,1605.056,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",271,68096.0,0.0,136192.0,0,0.0,136192.0,136192.0,0.0,3000.0,0.0,288000.0,12288.0,9.024,1614.08,0.0,0.0,0.0,68096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",272,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,768.0,0.0,160000.0,0.0,2.88,1616.96,0.0,0.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",273,524497.0,1061280.0,152994.0,0,0.0,1214274.0,1214274.0,132.0,1312.0,0.09141274238227147,272128.0,128000.0,18.688,1635.6480000000001,133280.0,32000.0,448000.0,76497.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",274,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,251.0,0.19808306709265175,128000.0,32.0,9.664,1645.3120000000001,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",275,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.592,1647.9040000000002,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",276,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,251.0,0.19808306709265175,128000.0,32.0,9.696,1657.6000000000001,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",277,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.56,1660.16,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",278,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.56,1662.72,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",279,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.52,1666.24,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",280,1536.0,36576.0,3072.0,0,0.0,39648.0,39648.0,62.0,251.0,0.19808306709265175,128000.0,32.0,9.888,1676.128,36576.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",281,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.56,1678.6879999999999,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",282,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.496,1681.184,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",283,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.264,1684.4479999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",284,448000.0,640000.0,320000.0,0,0.0,960000.0,960000.0,0.0,1000.0,0.0,0.0,128000.0,2.784,1687.232,0.0,64000.0,288000.0,160000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",285,196945.0,327680.0,66210.0,0,0.0,393890.0,393890.0,0.0,768.0,0.0,256000.0,0.0,3.744,1690.9759999999999,0.0,0.0,163840.0,33105.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",286,18048.0,0.0,36096.0,0,0.0,36096.0,36096.0,124.0,251.0,0.33066666666666666,128000.0,32.0,12.992,1703.9679999999998,0.0,0.0,0.0,18048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",287,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.464,1706.4319999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",288,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.4,1708.8319999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",289,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.56,1711.3919999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",290,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.464,1713.8559999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",291,258.0,0.0,516.0,0,0.0,516.0,516.0,0.0,4.0,0.0,64.0,64.0,2.496,1716.3519999999999,0.0,0.0,0.0,258.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",292,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.016,1718.368,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",293,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.112,1720.48,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",294,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.528,1723.008,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",295,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.048,1725.056,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithoutCast, memory::StoreWithoutCast>(int, T1, T2, T4, T5, T6, T7)",296,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,3.0,0.0,64.0,32.0,2.368,1727.424,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",297,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.528,1729.952,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",298,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.464,1732.416,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",299,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,3.04,1735.456,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",300,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,3.232,1738.6879999999999,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",301,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.4,1741.088,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",302,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.464,1743.552,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",303,130.0,0.0,260.0,0,0.0,260.0,260.0,0.0,3.0,0.0,64.0,32.0,3.296,1746.848,0.0,0.0,0.0,130.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",304,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.048,1748.896,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",305,128.0,0.0,256.0,0,0.0,256.0,256.0,129.0,6.0,0.9555555555555556,32.0,32.0,2.944,1751.84,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",306,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.4,1754.24,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",307,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.56,1756.8,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",308,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,0.0,2.528,1759.328,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(detail::TensorInfo<T1, T3>, detail::TensorInfo<const T1, T3>, detail::TensorInfo<const T2, T3>, int, int, T3, long)",309,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,4352.0,4096.0,3.456,1762.7839999999999,0.0,0.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",310,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.752,1765.5359999999998,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",311,6.0,0.0,12.0,0,0.0,12.0,12.0,0.0,2.0,0.0,32.0,32.0,3.392,1768.9279999999999,0.0,0.0,0.0,6.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",312,515.0,0.0,1030.0,0,0.0,1030.0,1030.0,0.0,2.0,0.0,32.0,32.0,3.008,1771.936,0.0,0.0,0.0,515.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",313,0.0,128.0,0.0,0,0.0,128.0,128.0,8.0,6.0,0.5714285714285714,320.0,256.0,2.624,1774.56,0.0,128.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",314,288.0,0.0,576.0,0,0.0,576.0,576.0,0.0,10.0,0.0,512.0,512.0,2.496,1777.056,0.0,0.0,0.0,288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",315,1664.0,2308.0,1280.0,0,0.0,3588.0,3588.0,0.0,8.0,0.0,512.0,512.0,2.976,1780.0320000000002,4.0,256.0,1024.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",316,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,8.0,0.0,512.0,512.0,2.464,1782.496,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",317,1536.0,2304.0,1024.0,0,0.0,3328.0,3328.0,0.0,8.0,0.0,512.0,512.0,3.072,1785.568,0.0,256.0,1024.0,512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",318,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,8.0,0.0,512.0,512.0,2.464,1788.032,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",319,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.592,1790.624,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",320,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.456,1794.08,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",321,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,1796.48,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",322,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,1799.04,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",323,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.008,1802.048,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",324,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,1804.64,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",325,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.544,1813.1840000000002,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",326,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.96,1822.1440000000002,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",327,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.576,1830.7200000000003,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",328,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.2,1833.9200000000003,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",329,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.136,1837.0560000000003,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",330,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,1840.7040000000002,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",331,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,1843.8400000000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",332,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,1846.4,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",333,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,1849.536,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",334,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.008,1852.544,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",335,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,1856.192,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",336,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,1859.232,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",337,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,1861.792,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",338,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.592,1864.384,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",339,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.592,1866.976,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",340,16128.0,1503590.0,0.0,0,0.0,1503590.0,1503590.0,8335.0,16.0,0.9980840617890073,20480.0,4096.0,20.448,1887.4240000000002,1273208.0,198126.0,16128.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",341,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.736,1896.1600000000003,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",342,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,1898.7200000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",343,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.688,1901.4080000000004,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",344,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.456,1904.8640000000003,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",345,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.528,1907.3920000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",346,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.688,1910.0800000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",347,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.136,1913.2160000000003,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",348,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.528,1915.7440000000004,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",349,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17147136.0,29504.0,24.0,1939.7440000000004,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",350,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.944,1942.6880000000003,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",351,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17149184.0,29088.0,24.192,1966.8800000000003,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",352,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.624,1969.5040000000004,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",353,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17837312.0,2048.0,22.72,1992.2240000000004,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",354,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,1994.7840000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",355,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.72,1997.5040000000004,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",356,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.456,2000.9600000000003,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",357,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,2003.3920000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",358,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,2005.9840000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",359,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,2008.9600000000005,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",360,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.752,2011.7120000000004,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",361,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.512,2020.2240000000004,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",362,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,2028.9920000000004,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",363,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,2037.7600000000004,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",364,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,2.944,2040.7040000000004,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",365,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,2043.7440000000004,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",366,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,2047.3920000000003,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",367,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,2050.4320000000002,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",368,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,2053.0240000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",369,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,2056.1600000000003,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",370,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.072,2059.2320000000004,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",371,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.68,2062.9120000000003,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",372,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,2065.9840000000004,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",373,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.656,2068.6400000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",374,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.624,2071.264,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",375,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.656,2073.92,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",376,16288.0,1504006.0,0.0,0,0.0,1504006.0,1504006.0,8329.0,16.0,0.9980826842420611,20480.0,4096.0,20.384,2094.304,1273293.0,198137.0,16288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",377,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.448,2102.752,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",378,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,2105.344,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",379,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,2107.904,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",380,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.424,2111.328,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",381,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,2113.728,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",382,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,2116.288,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",383,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,2119.232,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",384,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.624,2121.8559999999998,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",385,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17146880.0,29472.0,22.144,2143.9999999999995,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",386,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.976,2146.9759999999997,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",387,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17144448.0,29088.0,23.008,2169.9839999999995,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",388,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,2172.5759999999996,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",389,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17839232.0,2048.0,22.784,2195.3599999999997,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",390,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,2197.9519999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",391,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,2200.5119999999997,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",392,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.456,2203.968,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",393,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,2206.368,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",394,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,2208.96,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",395,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,2211.904,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",396,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.656,2214.56,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",397,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.512,2223.072,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",398,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.416,2231.4880000000003,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",399,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.48,2239.9680000000003,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",400,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,2243.1040000000003,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",401,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,2246.1440000000002,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",402,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.776,2249.92,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",403,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,2252.992,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",404,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,2255.5840000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",405,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,2258.688,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",406,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.2,2261.888,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",407,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.68,2265.5679999999998,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",408,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.168,2268.736,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",409,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,2271.296,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",410,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.752,2274.048,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",411,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.56,2276.6079999999997,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",412,16352.0,1504172.0,0.0,0,0.0,1504172.0,1504172.0,8323.0,16.0,0.9980813047127953,20480.0,4096.0,20.48,2297.0879999999997,1273327.0,198141.0,16352.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",413,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,2305.8559999999998,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",414,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.656,2308.5119999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",415,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.624,2311.1359999999995,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",416,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,2314.5279999999993,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",417,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,2316.8959999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",418,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,2319.4879999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",419,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,2322.4319999999993,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",420,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,2325.0239999999994,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",421,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17149952.0,28608.0,23.52,2348.5439999999994,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",422,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.88,2351.4239999999995,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",423,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17160608.0,29056.0,23.168,2374.5919999999996,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",424,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.656,2377.2479999999996,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",425,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17833472.0,2048.0,23.68,2400.9279999999994,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",426,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,2403.5199999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",427,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.592,2406.1119999999996,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",428,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.584,2409.6959999999995,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",429,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,2412.1279999999992,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",430,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,2414.687999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",431,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.104,2417.791999999999,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",432,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,2420.351999999999,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",433,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,2429.119999999999,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",434,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.64,2437.759999999999,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",435,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.544,2446.3039999999987,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",436,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,2449.3439999999987,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",437,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.104,2452.4479999999985,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",438,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.744,2456.1919999999986,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",439,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.168,2459.3599999999988,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",440,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,2461.951999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",441,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.2,2465.1519999999987,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",442,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,2468.1919999999986,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",443,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,2471.839999999999,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",444,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,2474.8799999999987,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",445,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,2477.471999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",446,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.56,2480.031999999999,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",447,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.592,2482.623999999999,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",448,16384.0,1504260.0,0.0,0,0.0,1504260.0,1504260.0,8320.0,16.0,0.9980806142034548,20480.0,4096.0,20.16,2502.7839999999987,1273344.0,198148.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",449,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.448,2511.2319999999986,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",450,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.656,2513.8879999999986,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",451,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,2516.4479999999985,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",452,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.424,2519.8719999999985,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",453,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,2522.3039999999983,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",454,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,2524.8959999999984,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",455,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,2527.8719999999985,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",456,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.688,2530.5599999999986,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",457,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17137664.0,29184.0,23.072,2553.6319999999987,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",458,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.912,2556.5439999999985,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",459,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17149312.0,30080.0,23.072,2579.6159999999986,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",460,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,2582.2079999999987,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",461,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17839360.0,2048.0,22.592,2604.799999999999,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",462,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,2607.391999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",463,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.592,2609.983999999999,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",464,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.552,2613.535999999999,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",465,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,2615.967999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",466,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,2618.559999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",467,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.04,2621.599999999999,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",468,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,2624.159999999999,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",469,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,2632.927999999999,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",470,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.608,2641.535999999999,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",471,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.8,2650.3359999999993,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",472,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.2,2653.535999999999,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",473,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,2.976,2656.5119999999993,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",474,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.712,2660.2239999999993,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",475,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,2663.263999999999,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",476,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,2665.8559999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",477,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,2668.959999999999,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",478,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.168,2672.1279999999992,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",479,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,2675.7759999999994,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",480,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,2678.879999999999,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",481,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.528,2681.407999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",482,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.624,2684.031999999999,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",483,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.688,2686.719999999999,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",484,16384.0,1504256.0,0.0,0,0.0,1504256.0,1504256.0,8320.0,16.0,0.9980806142034548,20480.0,4096.0,20.288,2707.007999999999,1273344.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",485,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.864,2715.871999999999,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",486,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,2718.4959999999987,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",487,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.656,2721.1519999999987,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",488,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,2724.5439999999985,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",489,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,2727.0079999999984,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",490,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,2729.6319999999982,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",491,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,2732.575999999998,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",492,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.688,2735.2639999999983,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",493,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17142784.0,29440.0,23.232,2758.4959999999983,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",494,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.976,2761.4719999999984,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",495,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17136512.0,29024.0,23.456,2784.9279999999985,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",496,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,2787.5199999999986,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",497,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17840128.0,2048.0,22.816,2810.3359999999984,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",498,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,2812.8959999999984,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",499,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,2815.4559999999983,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",500,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,2818.847999999998,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",501,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,2821.279999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",502,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,2823.935999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",503,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,2826.911999999998,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",504,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,2829.503999999998,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",505,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.544,2838.047999999998,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",506,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.416,2846.463999999998,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",507,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.864,2855.327999999998,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",508,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,2858.463999999998,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",509,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.2,2861.663999999998,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",510,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,2865.311999999998,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",511,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,2868.351999999998,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",512,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.688,2871.039999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",513,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,2874.1119999999983,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",514,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,2877.151999999998,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",515,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,2880.7999999999984,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",516,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,2.976,2883.7759999999985,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",517,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,2886.3679999999986,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",518,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.592,2888.9599999999987,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",519,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.592,2891.5519999999988,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",520,16384.0,1504256.0,0.0,0,0.0,1504256.0,1504256.0,8320.0,16.0,0.9980806142034548,20480.0,4096.0,20.192,2911.743999999999,1273344.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",521,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.48,2920.223999999999,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",522,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.656,2922.8799999999987,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",523,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,2925.4079999999985,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",524,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,2928.7999999999984,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",525,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,2931.231999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",526,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,2933.791999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",527,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,2936.735999999998,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",528,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,2939.327999999998,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",529,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17138176.0,30112.0,22.496,2961.8239999999983,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",530,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.88,2964.7039999999984,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",531,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17151968.0,29312.0,23.584,2988.287999999998,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",532,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,2990.8799999999983,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",533,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17837568.0,2048.0,23.072,3013.9519999999984,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",534,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.656,3016.6079999999984,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",535,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.592,3019.1999999999985,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",536,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,3022.5919999999983,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",537,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.496,3025.0879999999984,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",538,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,3027.7439999999983,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",539,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,3030.7199999999984,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",540,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,3033.2799999999984,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",541,33088000.0,65856000.0,576000.0,0,0.0,66432000.0,66432000.0,88000.0,2056000.0,0.041044776119402986,132919808.0,181344.0,148.544,3181.8239999999983,256000.0,0.0,32800000.0,288000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",542,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,3183.871999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",543,258.0,0.0,516.0,0,0.0,516.0,516.0,0.0,5.0,0.0,64.0,64.0,2.496,3186.367999999998,0.0,0.0,0.0,258.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",544,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.432,3188.799999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",545,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,128000.0,128000.0,2.688,3191.487999999998,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",546,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,3193.535999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",547,48128.0,0.0,96256.0,0,0.0,96256.0,96256.0,512.0,1512.0,0.25296442687747034,129024.0,8192.0,3.904,3197.439999999998,0.0,0.0,0.0,48128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",548,27648.0,0.0,55296.0,0,0.0,55296.0,55296.0,2112.0,8610.0,0.1969781757134863,527360.0,0.0,4.672,3202.111999999998,0.0,0.0,0.0,27648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",549,16326.0,0.0,32652.0,0,0.0,32652.0,32652.0,512.0,1512.0,0.25296442687747034,129024.0,8192.0,4.096,3206.207999999998,0.0,0.0,0.0,16326.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",550,33792.0,0.0,67584.0,0,0.0,67584.0,67584.0,2112.0,8802.0,0.19351291918636612,527360.0,0.0,4.768,3210.975999999998,0.0,0.0,0.0,33792.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",551,16131.0,0.0,32262.0,0,0.0,32262.0,32262.0,512.0,1512.0,0.25296442687747034,129024.0,8192.0,3.872,3214.8479999999977,0.0,0.0,0.0,16131.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",552,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,2112.0,8770.0,0.19408197022606138,527360.0,0.0,4.64,3219.4879999999976,0.0,0.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",553,16129.0,0.0,32258.0,0,0.0,32258.0,32258.0,512.0,1512.0,0.25296442687747034,129024.0,8192.0,4.256,3223.7439999999974,0.0,0.0,0.0,16129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",554,30720.0,0.0,61440.0,0,0.0,61440.0,61440.0,2112.0,8706.0,0.19523017193566278,527360.0,32.0,4.768,3228.5119999999974,0.0,0.0,0.0,30720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",555,352.0,0.0,704.0,0,0.0,704.0,704.0,0.0,3.0,0.0,1056.0,128.0,3.136,3231.6479999999974,0.0,0.0,0.0,352.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",556,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.048,3233.695999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",557,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,11.0,0.9829984544049459,128.0,0.0,4.224,3237.9199999999973,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",558,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.048,3239.967999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",559,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,11.0,0.9829984544049459,128.0,0.0,4.32,3244.2879999999973,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 1>(detail::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, detail::TensorInfo<T1, T2>, T2, detail::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",560,40292.0,0.0,80584.0,0,0.0,80584.0,80584.0,8241.0,2106.0,0.796462742824007,131808.0,1696.0,5.888,3250.175999999997,0.0,0.0,0.0,40292.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::radixSortKVInPlace<(int)-2, (int)-1, 32, 4, float, long, unsigned int>(detail::TensorInfo<T5, T7>, T7, T7, T7, detail::TensorInfo<T6, T7>, T7, bool)",561,64.0,0.0,128.0,0,0.0,128.0,128.0,458.0,8.0,0.9828326180257511,640.0,0.0,5.952,3256.1279999999974,0.0,0.0,0.0,64.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",562,64000.0,0.0,128000.0,0,0.0,128000.0,128000.0,0.0,3000.0,0.0,130016.0,8000.0,4.096,3260.2239999999974,0.0,0.0,0.0,64000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",563,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,768.0,0.0,160000.0,0.0,2.88,3263.1039999999975,0.0,0.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"native::<unnamed>::fill_reverse_indices_kernel(long *, int, detail::IntDivider<unsigned int>)",564,128768.0,0.0,257536.0,0,0.0,257536.0,257536.0,0.0,1000.0,0.0,0.0,256000.0,2.496,3265.5999999999976,0.0,0.0,0.0,128768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",565,387237.0,0.0,774474.0,0,0.0,774474.0,774474.0,64512.0,1000.0,0.9847356209549396,128000.0,0.0,3.904,3269.5039999999976,0.0,0.0,0.0,387237.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",566,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,2.72,3272.2239999999974,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",567,29568.0,0.0,59136.0,0,0.0,59136.0,59136.0,10414.0,4264.0,0.7094972067039106,407552.0,301120.0,14.816,3287.0399999999972,0.0,0.0,0.0,29568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",568,14400.0,0.0,28800.0,0,0.0,28800.0,28800.0,3418.0,4262.0,0.44505208333333335,407552.0,390144.0,13.152,3300.1919999999973,0.0,0.0,0.0,14400.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",569,15744.0,0.0,31488.0,0,0.0,31488.0,31488.0,4798.0,4257.0,0.5298729983434567,405504.0,390144.0,14.272,3314.463999999997,0.0,0.0,0.0,15744.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",570,15744.0,0.0,31488.0,0,0.0,31488.0,31488.0,4798.0,4240.0,0.5308696614295199,405504.0,325600.0,14.24,3328.703999999997,0.0,0.0,0.0,15744.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",571,524494.0,1061280.0,152988.0,0,0.0,1214268.0,1214268.0,132.0,1312.0,0.09141274238227147,265984.0,128000.0,18.848,3347.551999999997,133280.0,32000.0,448000.0,76494.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<float, 1>>(T1, int)",572,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,0.0,416.0,2.048,3349.5999999999967,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<float, std::plus<float>>::Policy900, const float *, float *, at_cuda_detail::ScanTileState<float, 1>, std::plus<float>, at_cuda_detail::NullType, unsigned int, float, 0>(T2, T3, T4, int, T5, T6, T7)",573,2177.0,85371.0,4354.0,0,0.0,89725.0,89725.0,4349.0,2053.0,0.6793189628241174,135840.0,129024.0,4.16,3353.7599999999966,85371.0,0.0,0.0,2177.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",574,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,512.0,0.0,128000.0,31808.0,2.688,3356.4479999999967,0.0,0.0,0.0,256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::unrolled_elementwise_kernel<native::FillFunctor<bool>, std::array<char *, 1>, 16, TrivialOffsetCalculator<0, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithoutCast, memory::StoreWithoutCast>(int, T1, T2, T4, T5, T6, T7)",575,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.016,3358.4639999999968,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",576,68096.0,0.0,136192.0,0,0.0,136192.0,136192.0,0.0,3000.0,0.0,288000.0,12832.0,8.928,3367.3919999999966,0.0,0.0,0.0,68096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",577,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,768.0,0.0,160000.0,0.0,2.944,3370.3359999999966,0.0,0.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",578,524497.0,1061280.0,152994.0,0,0.0,1214274.0,1214274.0,132.0,1312.0,0.09141274238227147,253184.0,128000.0,18.528,3388.8639999999964,133280.0,32000.0,448000.0,76497.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",579,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,251.0,0.19808306709265175,128000.0,32.0,9.76,3398.6239999999966,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",580,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.464,3401.0879999999966,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",581,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,251.0,0.19808306709265175,128000.0,32.0,9.792,3410.8799999999965,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",582,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.464,3413.3439999999964,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",583,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.528,3415.871999999996,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",584,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.232,3419.103999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",585,1536.0,36576.0,3072.0,0,0.0,39648.0,39648.0,62.0,251.0,0.19808306709265175,128000.0,32.0,9.888,3428.991999999996,36576.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",586,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.4,3431.391999999996,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",587,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.592,3433.9839999999963,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",588,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.2,3437.183999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",589,448000.0,640000.0,320000.0,0,0.0,960000.0,960000.0,0.0,1000.0,0.0,0.0,128000.0,2.848,3440.031999999996,0.0,64000.0,288000.0,160000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",590,196945.0,327680.0,66210.0,0,0.0,393890.0,393890.0,0.0,768.0,0.0,256000.0,0.0,3.744,3443.775999999996,0.0,0.0,163840.0,33105.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",591,18048.0,0.0,36096.0,0,0.0,36096.0,36096.0,124.0,251.0,0.33066666666666666,128000.0,32.0,12.8,3456.5759999999964,0.0,0.0,0.0,18048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",592,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.496,3459.0719999999965,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",593,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.464,3461.5359999999964,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",594,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.432,3463.967999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",595,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.464,3466.431999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",596,258.0,0.0,516.0,0,0.0,516.0,516.0,0.0,5.0,0.0,64.0,64.0,2.496,3468.9279999999962,0.0,0.0,0.0,258.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",597,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.048,3470.975999999996,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",598,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.048,3473.023999999996,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",599,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.592,3475.615999999996,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",600,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.048,3477.6639999999957,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",601,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,3.0,0.0,64.0,32.0,2.464,3480.1279999999956,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",602,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.528,3482.6559999999954,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",603,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.464,3485.1199999999953,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",604,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,3.04,3488.1599999999953,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",605,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,3.2,3491.359999999995,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",606,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.368,3493.727999999995,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
