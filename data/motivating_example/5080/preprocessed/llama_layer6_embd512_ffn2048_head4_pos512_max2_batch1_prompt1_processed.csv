Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,1.696,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.6,3.2960000000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,1.664,4.96,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,3.0,0.0,64.0,32.0,2.016,6.976,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.592,9.568,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",6,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,11.616,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",7,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,13.664,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",8,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.144,15.808,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",9,128.0,0.0,256.0,0,0.0,256.0,256.0,129.0,6.0,0.9555555555555556,32.0,32.0,3.072,18.88,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",10,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,21.407999999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",11,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.432,23.839999999999996,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.08,25.919999999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,128.0,0.0,256.0,0,0.0,256.0,256.0,129.0,6.0,0.9555555555555556,32.0,32.0,3.04,28.959999999999994,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.4,31.359999999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",15,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.496,33.855999999999995,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",16,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,3.0,0.0,64.0,0.0,2.592,36.44799999999999,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(detail::TensorInfo<T1, T3>, detail::TensorInfo<const T1, T3>, detail::TensorInfo<const T2, T3>, int, int, T3, long)",17,1024.0,0.0,2048.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,2176.0,2048.0,4.352,40.8,0.0,0.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",18,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.912,43.711999999999996,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",19,515.0,0.0,1030.0,0,0.0,1030.0,1030.0,0.0,2.0,0.0,32.0,32.0,2.752,46.464,0.0,0.0,0.0,515.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",20,0.0,128.0,0.0,0,0.0,128.0,128.0,8.0,6.0,0.5714285714285714,320.0,256.0,2.72,49.184,0.0,128.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",21,288.0,0.0,576.0,0,0.0,576.0,576.0,0.0,10.0,0.0,512.0,512.0,2.496,51.68,0.0,0.0,0.0,288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",22,1664.0,2304.0,1280.0,0,0.0,3584.0,3584.0,0.0,8.0,0.0,512.0,512.0,3.008,54.688,0.0,256.0,1024.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",23,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,8.0,0.0,512.0,512.0,2.56,57.248000000000005,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",24,1536.0,2304.0,1024.0,0,0.0,3328.0,3328.0,0.0,8.0,0.0,512.0,512.0,2.944,60.19200000000001,0.0,256.0,1024.0,512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",25,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,8.0,0.0,512.0,512.0,2.464,62.656000000000006,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",26,128.0,512.0,256.0,0,0.0,768.0,768.0,0.0,32.0,0.0,2048.0,2048.0,2.624,65.28,0.0,512.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",27,384.0,1633.0,768.0,0,0.0,2401.0,2401.0,10.0,5.0,0.6666666666666666,2048.0,32.0,3.488,68.768,1632.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",28,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,71.2,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",29,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.72,73.92,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",30,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,2112.0,2048.0,3.104,77.024,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",31,0.0,512.0,0.0,0,0.0,512.0,512.0,0.0,48.0,0.0,4096.0,2048.0,2.528,79.552,0.0,512.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 2, 2, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",32,278528.0,581120.0,32768.0,0,0.0,613888.0,613888.0,11776.0,9472.0,0.5542168674698795,1179648.0,2048.0,5.312,84.864,24064.0,32768.0,262144.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 2, 2, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",33,278528.0,581120.0,32768.0,0,0.0,613888.0,613888.0,11776.0,9472.0,0.5542168674698795,1179648.0,2048.0,5.28,90.144,24064.0,32768.0,262144.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 2, 2, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",34,278528.0,581120.0,32768.0,0,0.0,613888.0,613888.0,11776.0,9472.0,0.5542168674698795,1179648.0,2048.0,5.376,95.52000000000001,24064.0,32768.0,262144.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",35,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,3072.0,2048.0,3.04,98.56000000000002,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",36,384.0,256.0,768.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,1024.0,1024.0,3.2,101.76000000000002,256.0,0.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",37,173056.0,0.0,346112.0,0,0.0,346112.0,346112.0,0.0,32.0,0.0,2048.0,2048.0,3.744,105.50400000000002,0.0,0.0,0.0,173056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",38,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,3072.0,2048.0,3.584,109.08800000000002,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",39,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,4096.0,2048.0,2.688,111.77600000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",40,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,3072.0,2048.0,3.04,114.81600000000003,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",41,384.0,256.0,768.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,1024.0,1024.0,3.104,117.92000000000003,256.0,0.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",42,173056.0,0.0,346112.0,0,0.0,346112.0,346112.0,0.0,32.0,0.0,2048.0,2048.0,3.2,121.12000000000003,0.0,0.0,0.0,173056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",43,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,3072.0,2048.0,3.072,124.19200000000004,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",44,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,4096.0,2048.0,2.56,126.75200000000004,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",45,8192.0,751872.0,0.0,0,0.0,751872.0,751872.0,4160.0,8.0,0.9980806142034548,6144.0,2048.0,20.128,146.88000000000005,636416.0,99072.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 2, 2, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",46,278528.0,581120.0,32768.0,0,0.0,613888.0,613888.0,11776.0,9472.0,0.5542168674698795,1179648.0,2048.0,5.312,152.19200000000006,24064.0,32768.0,262144.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",47,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,4096.0,2048.0,2.656,154.84800000000007,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",48,128.0,512.0,256.0,0,0.0,768.0,768.0,0.0,32.0,0.0,2048.0,2048.0,2.56,157.40800000000007,0.0,512.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",49,384.0,1633.0,768.0,0,0.0,2401.0,2401.0,10.0,5.0,0.6666666666666666,2048.0,32.0,3.328,160.73600000000008,1632.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",50,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,163.20000000000007,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",51,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,165.82400000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",52,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,2112.0,2048.0,3.104,168.92800000000008,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",53,0.0,512.0,0.0,0,0.0,512.0,512.0,0.0,48.0,0.0,4096.0,2048.0,2.56,171.48800000000008,0.0,512.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",54,1069056.0,2117632.0,36864.0,0,0.0,2154496.0,2154496.0,5632.0,66048.0,0.07857142857142857,4366336.0,16384.0,8.416,179.90400000000008,16384.0,0.0,1050624.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",55,22528.0,43008.0,4096.0,0,0.0,47104.0,47104.0,0.0,32.0,0.0,8192.0,8192.0,3.072,182.97600000000008,2048.0,0.0,20480.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",56,1069056.0,2117632.0,36864.0,0,0.0,2154496.0,2154496.0,5632.0,66048.0,0.07857142857142857,4366336.0,16384.0,7.872,190.84800000000007,16384.0,0.0,1050624.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",57,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,16384.0,8192.0,2.624,193.47200000000007,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",58,1082368.0,2114560.0,66560.0,0,0.0,2181120.0,2181120.0,8704.0,66048.0,0.11643835616438356,4456448.0,1024.0,9.152,202.62400000000005,16384.0,0.0,1049088.0,33280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",59,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,4096.0,2048.0,2.56,205.18400000000005,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",60,128.0,512.0,256.0,0,0.0,768.0,768.0,0.0,32.0,0.0,2048.0,2048.0,2.624,207.80800000000005,0.0,512.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",61,384.0,1633.0,768.0,0,0.0,2401.0,2401.0,10.0,5.0,0.6666666666666666,2048.0,32.0,3.36,211.16800000000006,1632.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",62,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,213.60000000000005,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",63,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,216.16000000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",64,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,2112.0,2048.0,2.976,219.13600000000005,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",65,0.0,512.0,0.0,0,0.0,512.0,512.0,0.0,48.0,0.0,4096.0,2048.0,2.528,221.66400000000004,0.0,512.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 2, 2, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",66,278528.0,581120.0,32768.0,0,0.0,613888.0,613888.0,11776.0,9472.0,0.5542168674698795,1179648.0,2048.0,5.28,226.94400000000005,24064.0,32768.0,262144.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 2, 2, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",67,278528.0,581120.0,32768.0,0,0.0,613888.0,613888.0,11776.0,9472.0,0.5542168674698795,1179648.0,2048.0,5.216,232.16000000000005,24064.0,32768.0,262144.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 2, 2, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",68,278528.0,581120.0,32768.0,0,0.0,613888.0,613888.0,11776.0,9472.0,0.5542168674698795,1179648.0,2048.0,5.568,237.72800000000007,24064.0,32768.0,262144.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",69,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,3072.0,2048.0,3.104,240.83200000000008,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",70,384.0,256.0,768.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,1024.0,1024.0,3.04,243.87200000000007,256.0,0.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",71,173056.0,0.0,346112.0,0,0.0,346112.0,346112.0,0.0,32.0,0.0,2048.0,2048.0,3.328,247.20000000000007,0.0,0.0,0.0,173056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",72,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,3072.0,2048.0,3.008,250.20800000000008,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",73,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,4096.0,2048.0,2.56,252.7680000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",74,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,3072.0,2048.0,3.072,255.8400000000001,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",75,384.0,256.0,768.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,1024.0,1024.0,3.008,258.84800000000007,256.0,0.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",76,173056.0,0.0,346112.0,0,0.0,346112.0,346112.0,0.0,32.0,0.0,2048.0,2048.0,3.264,262.1120000000001,0.0,0.0,0.0,173056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",77,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,3072.0,2048.0,3.04,265.1520000000001,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",78,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,4096.0,2048.0,2.528,267.6800000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",79,8192.0,751872.0,0.0,0,0.0,751872.0,751872.0,4160.0,8.0,0.9980806142034548,6144.0,2048.0,20.096,287.7760000000001,636416.0,99072.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 2, 2, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",80,278528.0,581120.0,32768.0,0,0.0,613888.0,613888.0,11776.0,9472.0,0.5542168674698795,1179648.0,2048.0,5.44,293.2160000000001,24064.0,32768.0,262144.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",81,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,4096.0,2048.0,2.656,295.8720000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",82,128.0,512.0,256.0,0,0.0,768.0,768.0,0.0,32.0,0.0,2048.0,2048.0,2.528,298.40000000000015,0.0,512.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",83,384.0,1633.0,768.0,0,0.0,2401.0,2401.0,10.0,5.0,0.6666666666666666,2048.0,32.0,3.296,301.69600000000014,1632.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",84,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,304.16000000000014,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",85,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,306.78400000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",86,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,2112.0,2048.0,2.976,309.76000000000016,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",87,0.0,512.0,0.0,0,0.0,512.0,512.0,0.0,48.0,0.0,4096.0,2048.0,2.656,312.41600000000017,0.0,512.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",88,1069056.0,2117632.0,36864.0,0,0.0,2154496.0,2154496.0,5632.0,66048.0,0.07857142857142857,4366336.0,16384.0,7.744,320.1600000000002,16384.0,0.0,1050624.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",89,22528.0,43008.0,4096.0,0,0.0,47104.0,47104.0,0.0,32.0,0.0,8192.0,8192.0,3.008,323.1680000000002,2048.0,0.0,20480.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",90,1069056.0,2117632.0,36864.0,0,0.0,2154496.0,2154496.0,5632.0,66048.0,0.07857142857142857,4366336.0,16384.0,7.808,330.97600000000017,16384.0,0.0,1050624.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",91,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,16384.0,8192.0,2.56,333.5360000000002,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",92,1082368.0,2114560.0,66560.0,0,0.0,2181120.0,2181120.0,8704.0,66048.0,0.11643835616438356,4456448.0,1024.0,9.632,343.1680000000002,16384.0,0.0,1049088.0,33280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",93,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,4096.0,2048.0,2.528,345.6960000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",94,128.0,512.0,256.0,0,0.0,768.0,768.0,0.0,32.0,0.0,2048.0,2048.0,2.528,348.2240000000002,0.0,512.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",95,384.0,1633.0,768.0,0,0.0,2401.0,2401.0,10.0,5.0,0.6666666666666666,2048.0,32.0,3.328,351.5520000000002,1632.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",96,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,353.95200000000017,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",97,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,356.51200000000017,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",98,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,2112.0,2048.0,3.008,359.52000000000015,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",99,0.0,512.0,0.0,0,0.0,512.0,512.0,0.0,48.0,0.0,4096.0,2048.0,2.592,362.11200000000014,0.0,512.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 2, 2, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",100,278528.0,581120.0,32768.0,0,0.0,613888.0,613888.0,11776.0,9472.0,0.5542168674698795,1179648.0,2048.0,5.216,367.32800000000015,24064.0,32768.0,262144.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 2, 2, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",101,278528.0,581120.0,32768.0,0,0.0,613888.0,613888.0,11776.0,9472.0,0.5542168674698795,1179648.0,2048.0,5.248,372.57600000000014,24064.0,32768.0,262144.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 2, 2, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",102,278528.0,581120.0,32768.0,0,0.0,613888.0,613888.0,11776.0,9472.0,0.5542168674698795,1179648.0,2048.0,5.152,377.7280000000001,24064.0,32768.0,262144.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",103,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,3072.0,2048.0,3.04,380.76800000000014,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",104,384.0,256.0,768.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,1024.0,1024.0,3.136,383.90400000000017,256.0,0.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",105,173056.0,0.0,346112.0,0,0.0,346112.0,346112.0,0.0,32.0,0.0,2048.0,2048.0,3.2,387.10400000000016,0.0,0.0,0.0,173056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",106,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,3072.0,2048.0,3.072,390.17600000000016,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",107,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,4096.0,2048.0,2.528,392.7040000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",108,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,3072.0,2048.0,3.168,395.8720000000002,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",109,384.0,256.0,768.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,1024.0,1024.0,3.104,398.97600000000017,256.0,0.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",110,173056.0,0.0,346112.0,0,0.0,346112.0,346112.0,0.0,32.0,0.0,2048.0,2048.0,3.168,402.1440000000002,0.0,0.0,0.0,173056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",111,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,3072.0,2048.0,2.976,405.1200000000002,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",112,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,4096.0,2048.0,2.528,407.6480000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",113,8192.0,751872.0,0.0,0,0.0,751872.0,751872.0,4160.0,8.0,0.9980806142034548,6144.0,2048.0,20.096,427.7440000000002,636416.0,99072.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 2, 2, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",114,278528.0,581120.0,32768.0,0,0.0,613888.0,613888.0,11776.0,9472.0,0.5542168674698795,1179648.0,2048.0,5.44,433.1840000000002,24064.0,32768.0,262144.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",115,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,4096.0,2048.0,2.624,435.8080000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",116,128.0,512.0,256.0,0,0.0,768.0,768.0,0.0,32.0,0.0,2048.0,2048.0,2.528,438.33600000000024,0.0,512.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",117,384.0,1633.0,768.0,0,0.0,2401.0,2401.0,10.0,5.0,0.6666666666666666,2048.0,32.0,3.36,441.69600000000025,1632.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",118,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,444.09600000000023,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",119,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,446.72000000000025,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",120,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,2112.0,2048.0,3.04,449.7600000000003,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",121,0.0,512.0,0.0,0,0.0,512.0,512.0,0.0,48.0,0.0,4096.0,2048.0,2.528,452.2880000000003,0.0,512.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",122,1069056.0,2117632.0,36864.0,0,0.0,2154496.0,2154496.0,5632.0,66048.0,0.07857142857142857,4366336.0,16384.0,8.0,460.2880000000003,16384.0,0.0,1050624.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",123,22528.0,43008.0,4096.0,0,0.0,47104.0,47104.0,0.0,32.0,0.0,8192.0,8192.0,2.848,463.1360000000003,2048.0,0.0,20480.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",124,1069056.0,2117632.0,36864.0,0,0.0,2154496.0,2154496.0,5632.0,66048.0,0.07857142857142857,4366336.0,16384.0,8.032,471.1680000000003,16384.0,0.0,1050624.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",125,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,16384.0,8192.0,2.56,473.7280000000003,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",126,1082368.0,2114560.0,66560.0,0,0.0,2181120.0,2181120.0,8704.0,66048.0,0.11643835616438356,4456448.0,1024.0,8.64,482.3680000000003,16384.0,0.0,1049088.0,33280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",127,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,4096.0,2048.0,2.656,485.0240000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",128,128.0,512.0,256.0,0,0.0,768.0,768.0,0.0,32.0,0.0,2048.0,2048.0,2.528,487.5520000000003,0.0,512.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",129,384.0,1633.0,768.0,0,0.0,2401.0,2401.0,10.0,5.0,0.6666666666666666,2048.0,32.0,3.328,490.8800000000003,1632.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",130,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,493.28000000000026,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",131,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,495.87200000000024,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",132,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,2112.0,2048.0,3.04,498.91200000000026,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",133,0.0,512.0,0.0,0,0.0,512.0,512.0,0.0,48.0,0.0,4096.0,2048.0,2.496,501.40800000000024,0.0,512.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 2, 2, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",134,278528.0,581120.0,32768.0,0,0.0,613888.0,613888.0,11776.0,9472.0,0.5542168674698795,1179648.0,2048.0,5.568,506.9760000000002,24064.0,32768.0,262144.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 2, 2, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",135,278528.0,581120.0,32768.0,0,0.0,613888.0,613888.0,11776.0,9472.0,0.5542168674698795,1179648.0,2048.0,5.184,512.1600000000002,24064.0,32768.0,262144.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 2, 2, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",136,278528.0,581120.0,32768.0,0,0.0,613888.0,613888.0,11776.0,9472.0,0.5542168674698795,1179648.0,2048.0,5.216,517.3760000000002,24064.0,32768.0,262144.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",137,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,3072.0,2048.0,3.104,520.4800000000002,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",138,384.0,256.0,768.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,1024.0,1024.0,3.04,523.5200000000002,256.0,0.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",139,173056.0,0.0,346112.0,0,0.0,346112.0,346112.0,0.0,32.0,0.0,2048.0,2048.0,3.2,526.7200000000003,0.0,0.0,0.0,173056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",140,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,3072.0,2048.0,3.104,529.8240000000003,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",141,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,4096.0,2048.0,2.528,532.3520000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",142,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,3072.0,2048.0,3.072,535.4240000000003,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",143,384.0,256.0,768.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,1024.0,1024.0,3.168,538.5920000000003,256.0,0.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",144,173056.0,0.0,346112.0,0,0.0,346112.0,346112.0,0.0,32.0,0.0,2048.0,2048.0,3.168,541.7600000000003,0.0,0.0,0.0,173056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",145,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,3072.0,2048.0,3.072,544.8320000000003,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",146,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,4096.0,2048.0,2.56,547.3920000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",147,8192.0,751872.0,0.0,0,0.0,751872.0,751872.0,4160.0,8.0,0.9980806142034548,6144.0,2048.0,20.224,567.6160000000003,636416.0,99072.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 2, 2, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",148,278528.0,581120.0,32768.0,0,0.0,613888.0,613888.0,11776.0,9472.0,0.5542168674698795,1179648.0,2048.0,5.248,572.8640000000004,24064.0,32768.0,262144.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",149,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,4096.0,2048.0,2.56,575.4240000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",150,128.0,512.0,256.0,0,0.0,768.0,768.0,0.0,32.0,0.0,2048.0,2048.0,2.496,577.9200000000003,0.0,512.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",151,384.0,1633.0,768.0,0,0.0,2401.0,2401.0,10.0,5.0,0.6666666666666666,2048.0,32.0,3.328,581.2480000000003,1632.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",152,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,583.6160000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",153,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,586.2080000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",154,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,2112.0,2048.0,3.008,589.2160000000003,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",155,0.0,512.0,0.0,0,0.0,512.0,512.0,0.0,48.0,0.0,4096.0,2048.0,2.528,591.7440000000004,0.0,512.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",156,1069056.0,2117632.0,36864.0,0,0.0,2154496.0,2154496.0,5632.0,66048.0,0.07857142857142857,4366336.0,16384.0,7.776,599.5200000000003,16384.0,0.0,1050624.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",157,22528.0,43008.0,4096.0,0,0.0,47104.0,47104.0,0.0,32.0,0.0,8192.0,8192.0,2.912,602.4320000000004,2048.0,0.0,20480.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",158,1069056.0,2117632.0,36864.0,0,0.0,2154496.0,2154496.0,5632.0,66048.0,0.07857142857142857,4366336.0,16384.0,8.096,610.5280000000004,16384.0,0.0,1050624.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",159,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,16384.0,8192.0,2.592,613.1200000000003,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",160,1082368.0,2114560.0,66560.0,0,0.0,2181120.0,2181120.0,8704.0,66048.0,0.11643835616438356,4456448.0,1024.0,9.088,622.2080000000003,16384.0,0.0,1049088.0,33280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",161,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,4096.0,2048.0,2.528,624.7360000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",162,128.0,512.0,256.0,0,0.0,768.0,768.0,0.0,32.0,0.0,2048.0,2048.0,2.528,627.2640000000004,0.0,512.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",163,384.0,1633.0,768.0,0,0.0,2401.0,2401.0,10.0,5.0,0.6666666666666666,2048.0,32.0,3.424,630.6880000000003,1632.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",164,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,633.1200000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",165,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,635.7760000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",166,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,2112.0,2048.0,2.912,638.6880000000003,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",167,0.0,512.0,0.0,0,0.0,512.0,512.0,0.0,48.0,0.0,4096.0,2048.0,2.56,641.2480000000003,0.0,512.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 2, 2, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",168,278528.0,581120.0,32768.0,0,0.0,613888.0,613888.0,11776.0,9472.0,0.5542168674698795,1179648.0,2048.0,5.344,646.5920000000003,24064.0,32768.0,262144.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 2, 2, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",169,278528.0,581120.0,32768.0,0,0.0,613888.0,613888.0,11776.0,9472.0,0.5542168674698795,1179648.0,2048.0,5.568,652.1600000000003,24064.0,32768.0,262144.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 2, 2, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",170,278528.0,581120.0,32768.0,0,0.0,613888.0,613888.0,11776.0,9472.0,0.5542168674698795,1179648.0,2048.0,5.44,657.6000000000004,24064.0,32768.0,262144.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",171,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,3072.0,2048.0,3.168,660.7680000000004,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",172,384.0,256.0,768.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,1024.0,1024.0,3.04,663.8080000000003,256.0,0.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",173,173056.0,0.0,346112.0,0,0.0,346112.0,346112.0,0.0,32.0,0.0,2048.0,2048.0,3.2,667.0080000000004,0.0,0.0,0.0,173056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",174,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,3072.0,2048.0,3.296,670.3040000000004,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",175,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,4096.0,2048.0,2.56,672.8640000000004,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",176,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,3072.0,2048.0,3.04,675.9040000000003,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",177,384.0,256.0,768.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,1024.0,1024.0,3.04,678.9440000000003,256.0,0.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",178,173056.0,0.0,346112.0,0,0.0,346112.0,346112.0,0.0,32.0,0.0,2048.0,2048.0,3.2,682.1440000000003,0.0,0.0,0.0,173056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",179,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,3072.0,2048.0,3.04,685.1840000000003,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",180,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,4096.0,2048.0,2.592,687.7760000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",181,8192.0,751872.0,0.0,0,0.0,751872.0,751872.0,4160.0,8.0,0.9980806142034548,6144.0,2048.0,20.224,708.0000000000003,636416.0,99072.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 2, 2, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",182,278528.0,581120.0,32768.0,0,0.0,613888.0,613888.0,11776.0,9472.0,0.5542168674698795,1179648.0,2048.0,5.12,713.1200000000003,24064.0,32768.0,262144.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",183,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,4096.0,2048.0,2.592,715.7120000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",184,128.0,512.0,256.0,0,0.0,768.0,768.0,0.0,32.0,0.0,2048.0,2048.0,2.528,718.2400000000004,0.0,512.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",185,384.0,1633.0,768.0,0,0.0,2401.0,2401.0,10.0,5.0,0.6666666666666666,2048.0,32.0,3.392,721.6320000000004,1632.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",186,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,724.0320000000004,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",187,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,726.6560000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",188,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,2112.0,2048.0,3.008,729.6640000000004,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",189,0.0,512.0,0.0,0,0.0,512.0,512.0,0.0,48.0,0.0,4096.0,2048.0,2.528,732.1920000000005,0.0,512.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",190,1069056.0,2117632.0,36864.0,0,0.0,2154496.0,2154496.0,5632.0,66048.0,0.07857142857142857,4366336.0,16384.0,8.0,740.1920000000005,16384.0,0.0,1050624.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",191,22528.0,43008.0,4096.0,0,0.0,47104.0,47104.0,0.0,32.0,0.0,8192.0,8192.0,2.912,743.1040000000005,2048.0,0.0,20480.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",192,1069056.0,2117632.0,36864.0,0,0.0,2154496.0,2154496.0,5632.0,66048.0,0.07857142857142857,4366336.0,16384.0,7.968,751.0720000000005,16384.0,0.0,1050624.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",193,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,16384.0,8192.0,2.56,753.6320000000004,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",194,1082368.0,2114560.0,66560.0,0,0.0,2181120.0,2181120.0,8704.0,66048.0,0.11643835616438356,4456448.0,1024.0,9.056,762.6880000000004,16384.0,0.0,1049088.0,33280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",195,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,4096.0,2048.0,2.528,765.2160000000005,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",196,128.0,512.0,256.0,0,0.0,768.0,768.0,0.0,32.0,0.0,2048.0,2048.0,2.528,767.7440000000005,0.0,512.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",197,384.0,1633.0,768.0,0,0.0,2401.0,2401.0,10.0,5.0,0.6666666666666666,2048.0,32.0,3.328,771.0720000000005,1632.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",198,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,773.4720000000004,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",199,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,776.1280000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",200,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,2112.0,2048.0,2.944,779.0720000000003,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",201,0.0,512.0,0.0,0,0.0,512.0,512.0,0.0,48.0,0.0,4096.0,2048.0,2.56,781.6320000000003,0.0,512.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 2, 2, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",202,278528.0,581120.0,32768.0,0,0.0,613888.0,613888.0,11776.0,9472.0,0.5542168674698795,1179648.0,2048.0,5.28,786.9120000000003,24064.0,32768.0,262144.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 2, 2, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",203,278528.0,581120.0,32768.0,0,0.0,613888.0,613888.0,11776.0,9472.0,0.5542168674698795,1179648.0,2048.0,5.216,792.1280000000003,24064.0,32768.0,262144.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 2, 2, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",204,278528.0,581120.0,32768.0,0,0.0,613888.0,613888.0,11776.0,9472.0,0.5542168674698795,1179648.0,2048.0,5.344,797.4720000000003,24064.0,32768.0,262144.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",205,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,3072.0,2048.0,3.104,800.5760000000004,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",206,384.0,256.0,768.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,1024.0,1024.0,3.2,803.7760000000004,256.0,0.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",207,173056.0,0.0,346112.0,0,0.0,346112.0,346112.0,0.0,32.0,0.0,2048.0,2048.0,3.264,807.0400000000004,0.0,0.0,0.0,173056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",208,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,3072.0,2048.0,3.04,810.0800000000004,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",209,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,4096.0,2048.0,2.688,812.7680000000004,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",210,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,3072.0,2048.0,3.04,815.8080000000003,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",211,384.0,256.0,768.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,1024.0,1024.0,3.104,818.9120000000004,256.0,0.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",212,173056.0,0.0,346112.0,0,0.0,346112.0,346112.0,0.0,32.0,0.0,2048.0,2048.0,3.2,822.1120000000004,0.0,0.0,0.0,173056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",213,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,3072.0,2048.0,3.04,825.1520000000004,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",214,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,4096.0,2048.0,2.528,827.6800000000004,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",215,8192.0,751872.0,0.0,0,0.0,751872.0,751872.0,4160.0,8.0,0.9980806142034548,6144.0,2048.0,20.16,847.8400000000004,636416.0,99072.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 2, 2, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",216,278528.0,581120.0,32768.0,0,0.0,613888.0,613888.0,11776.0,9472.0,0.5542168674698795,1179648.0,2048.0,5.216,853.0560000000004,24064.0,32768.0,262144.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",217,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,4096.0,2048.0,2.592,855.6480000000004,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",218,128.0,512.0,256.0,0,0.0,768.0,768.0,0.0,32.0,0.0,2048.0,2048.0,2.496,858.1440000000003,0.0,512.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",219,384.0,1633.0,768.0,0,0.0,2401.0,2401.0,10.0,5.0,0.6666666666666666,2048.0,32.0,3.296,861.4400000000004,1632.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",220,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,863.8400000000004,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",221,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.72,866.5600000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",222,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,2112.0,2048.0,2.976,869.5360000000004,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",223,0.0,512.0,0.0,0,0.0,512.0,512.0,0.0,48.0,0.0,4096.0,2048.0,2.592,872.1280000000004,0.0,512.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",224,1069056.0,2117632.0,36864.0,0,0.0,2154496.0,2154496.0,5632.0,66048.0,0.07857142857142857,4366336.0,16384.0,8.48,880.6080000000004,16384.0,0.0,1050624.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",225,22528.0,43008.0,4096.0,0,0.0,47104.0,47104.0,0.0,32.0,0.0,8192.0,8192.0,2.944,883.5520000000004,2048.0,0.0,20480.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",226,1069056.0,2117632.0,36864.0,0,0.0,2154496.0,2154496.0,5632.0,66048.0,0.07857142857142857,4366336.0,16384.0,7.808,891.3600000000004,16384.0,0.0,1050624.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",227,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,16384.0,8192.0,2.56,893.9200000000003,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",228,1082368.0,2114560.0,66560.0,0,0.0,2181120.0,2181120.0,8704.0,66048.0,0.11643835616438356,4456448.0,1024.0,8.896,902.8160000000003,16384.0,0.0,1049088.0,33280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",229,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,4096.0,2048.0,2.528,905.3440000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",230,128.0,512.0,256.0,0,0.0,768.0,768.0,0.0,32.0,0.0,2048.0,2048.0,2.624,907.9680000000003,0.0,512.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",231,384.0,1633.0,768.0,0,0.0,2401.0,2401.0,10.0,5.0,0.6666666666666666,2048.0,32.0,3.328,911.2960000000003,1632.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",232,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.528,913.8240000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",233,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,916.4480000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",234,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,2112.0,2048.0,2.976,919.4240000000003,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",235,0.0,512.0,0.0,0,0.0,512.0,512.0,0.0,48.0,0.0,4096.0,2048.0,2.528,921.9520000000003,0.0,512.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",236,16704000.0,33088000.0,576000.0,0,0.0,33664000.0,33664000.0,88000.0,1032000.0,0.07857142857142857,66122496.0,191808.0,75.392,997.3440000000003,256000.0,0.0,16416000.0,288000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",237,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.112,999.4560000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",238,258.0,0.0,516.0,0,0.0,516.0,516.0,0.0,4.0,0.0,64.0,64.0,2.528,1001.9840000000003,0.0,0.0,0.0,258.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",239,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.432,1004.4160000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",240,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,128000.0,128000.0,2.752,1007.1680000000002,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",241,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.112,1009.2800000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",242,48128.0,0.0,96256.0,0,0.0,96256.0,96256.0,512.0,1512.0,0.25296442687747034,129024.0,8192.0,4.064,1013.3440000000002,0.0,0.0,0.0,48128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",243,27648.0,0.0,55296.0,0,0.0,55296.0,55296.0,2112.0,8610.0,0.1969781757134863,527360.0,0.0,4.96,1018.3040000000002,0.0,0.0,0.0,27648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",244,22200.0,0.0,44400.0,0,0.0,44400.0,44400.0,512.0,1512.0,0.25296442687747034,129024.0,8192.0,3.936,1022.2400000000002,0.0,0.0,0.0,22200.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",245,27648.0,0.0,55296.0,0,0.0,55296.0,55296.0,2112.0,8610.0,0.1969781757134863,527360.0,0.0,4.768,1027.0080000000003,0.0,0.0,0.0,27648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",246,16130.0,0.0,32260.0,0,0.0,32260.0,32260.0,512.0,1512.0,0.25296442687747034,129024.0,8192.0,3.936,1030.9440000000002,0.0,0.0,0.0,16130.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",247,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,2112.0,8770.0,0.19408197022606138,527360.0,0.0,4.96,1035.9040000000002,0.0,0.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",248,16129.0,0.0,32258.0,0,0.0,32258.0,32258.0,512.0,1512.0,0.25296442687747034,129024.0,8192.0,4.064,1039.9680000000003,0.0,0.0,0.0,16129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",249,31744.0,0.0,63488.0,0,0.0,63488.0,63488.0,2112.0,8738.0,0.19465437788018433,527360.0,32.0,4.736,1044.7040000000004,0.0,0.0,0.0,31744.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",250,352.0,0.0,704.0,0,0.0,704.0,704.0,0.0,3.0,0.0,1056.0,128.0,2.976,1047.6800000000005,0.0,0.0,0.0,352.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",251,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.08,1049.7600000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",252,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,11.0,0.9829984544049459,128.0,0.0,4.32,1054.0800000000004,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",253,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.048,1056.1280000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",254,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,11.0,0.9829984544049459,128.0,0.0,4.288,1060.4160000000004,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 1>(detail::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, detail::TensorInfo<T1, T2>, T2, detail::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",255,40292.0,0.0,80584.0,0,0.0,80584.0,80584.0,7913.0,2106.0,0.7897993811757661,131808.0,1664.0,5.92,1066.3360000000005,0.0,0.0,0.0,40292.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::radixSortKVInPlace<(int)-2, (int)-1, 32, 4, float, long, unsigned int>(detail::TensorInfo<T5, T7>, T7, T7, T7, detail::TensorInfo<T6, T7>, T7, bool)",256,64.0,0.0,128.0,0,0.0,128.0,128.0,458.0,8.0,0.9828326180257511,640.0,0.0,5.984,1072.3200000000004,0.0,0.0,0.0,64.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",257,64000.0,0.0,128000.0,0,0.0,128000.0,128000.0,0.0,3000.0,0.0,130016.0,8000.0,4.096,1076.4160000000004,0.0,0.0,0.0,64000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",258,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,768.0,0.0,160000.0,0.0,2.944,1079.3600000000004,0.0,0.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"native::<unnamed>::fill_reverse_indices_kernel(long *, int, detail::IntDivider<unsigned int>)",259,128768.0,0.0,257536.0,0,0.0,257536.0,257536.0,0.0,1000.0,0.0,0.0,256000.0,2.464,1081.8240000000003,0.0,0.0,0.0,128768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",260,387282.0,0.0,774564.0,0,0.0,774564.0,774564.0,64512.0,1000.0,0.9847356209549396,128000.0,0.0,3.936,1085.7600000000002,0.0,0.0,0.0,387282.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",261,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,2.624,1088.3840000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",262,29568.0,0.0,59136.0,0,0.0,59136.0,59136.0,10414.0,4264.0,0.7094972067039106,407552.0,308512.0,14.72,1103.1040000000003,0.0,0.0,0.0,29568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",263,14400.0,0.0,28800.0,0,0.0,28800.0,28800.0,3418.0,4262.0,0.44505208333333335,407552.0,390272.0,13.088,1116.1920000000002,0.0,0.0,0.0,14400.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",264,15744.0,0.0,31488.0,0,0.0,31488.0,31488.0,4798.0,4228.0,0.5315754487037447,405504.0,316192.0,14.144,1130.3360000000002,0.0,0.0,0.0,15744.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",265,15744.0,0.0,31488.0,0,0.0,31488.0,31488.0,4798.0,4226.0,0.5316932624113475,405504.0,349792.0,14.336,1144.6720000000003,0.0,0.0,0.0,15744.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",266,524494.0,1061280.0,152988.0,0,0.0,1214268.0,1214268.0,132.0,1312.0,0.09141274238227147,253824.0,128000.0,18.592,1163.2640000000004,133280.0,32000.0,448000.0,76494.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<float, 1>>(T1, int)",267,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,0.0,416.0,2.08,1165.3440000000003,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<float, std::plus<float>>::Policy900, const float *, float *, at_cuda_detail::ScanTileState<float, 1>, std::plus<float>, at_cuda_detail::NullType, unsigned int, float, 0>(T2, T3, T4, int, T5, T6, T7)",268,2177.0,85371.0,4354.0,0,0.0,89725.0,89725.0,4349.0,2053.0,0.6793189628241174,135296.0,129024.0,3.968,1169.3120000000004,85371.0,0.0,0.0,2177.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",269,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,512.0,0.0,128000.0,31808.0,2.624,1171.9360000000004,0.0,0.0,0.0,256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::unrolled_elementwise_kernel<native::FillFunctor<bool>, std::array<char *, 1>, 16, TrivialOffsetCalculator<0, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithoutCast, memory::StoreWithoutCast>(int, T1, T2, T4, T5, T6, T7)",270,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.016,1173.9520000000005,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",271,68096.0,0.0,136192.0,0,0.0,136192.0,136192.0,0.0,3000.0,0.0,288000.0,12576.0,8.992,1182.9440000000004,0.0,0.0,0.0,68096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",272,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,768.0,0.0,160000.0,0.0,2.88,1185.8240000000005,0.0,0.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",273,524496.0,1061280.0,152992.0,0,0.0,1214272.0,1214272.0,132.0,1312.0,0.09141274238227147,252928.0,128000.0,18.304,1204.1280000000006,133280.0,32000.0,448000.0,76496.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",274,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,251.0,0.19808306709265175,128000.0,32.0,9.664,1213.7920000000006,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",275,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.464,1216.2560000000005,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",276,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,251.0,0.19808306709265175,128000.0,32.0,9.824,1226.0800000000006,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",277,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.528,1228.6080000000006,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",278,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.592,1231.2000000000007,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",279,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.232,1234.4320000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",280,1536.0,36576.0,3072.0,0,0.0,39648.0,39648.0,62.0,251.0,0.19808306709265175,128000.0,32.0,9.696,1244.1280000000006,36576.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",281,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.432,1246.5600000000006,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",282,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.4,1248.9600000000007,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",283,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.168,1252.1280000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",284,448000.0,640000.0,320000.0,0,0.0,960000.0,960000.0,0.0,1000.0,0.0,0.0,128000.0,2.784,1254.9120000000007,0.0,64000.0,288000.0,160000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",285,196944.0,327680.0,66208.0,0,0.0,393888.0,393888.0,0.0,768.0,0.0,256000.0,0.0,3.712,1258.6240000000007,0.0,0.0,163840.0,33104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",286,18048.0,0.0,36096.0,0,0.0,36096.0,36096.0,124.0,251.0,0.33066666666666666,128000.0,32.0,12.896,1271.5200000000007,0.0,0.0,0.0,18048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",287,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.4,1273.9200000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",288,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.432,1276.3520000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",289,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.432,1278.7840000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",290,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.432,1281.2160000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",291,258.0,0.0,516.0,0,0.0,516.0,516.0,0.0,4.0,0.0,64.0,64.0,2.528,1283.7440000000008,0.0,0.0,0.0,258.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",292,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.016,1285.760000000001,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",293,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.048,1287.808000000001,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",294,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.688,1290.496000000001,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",295,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.016,1292.512000000001,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithoutCast, memory::StoreWithoutCast>(int, T1, T2, T4, T5, T6, T7)",296,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,3.0,0.0,64.0,32.0,2.4,1294.9120000000012,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",297,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.496,1297.4080000000013,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",298,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.4,1299.8080000000014,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",299,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,3.072,1302.8800000000012,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",300,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,3.2,1306.0800000000013,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",301,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.496,1308.5760000000014,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",302,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.432,1311.0080000000014,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",303,130.0,0.0,260.0,0,0.0,260.0,260.0,0.0,3.0,0.0,64.0,32.0,3.296,1314.3040000000015,0.0,0.0,0.0,130.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",304,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.112,1316.4160000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",305,128.0,0.0,256.0,0,0.0,256.0,256.0,129.0,6.0,0.9555555555555556,32.0,32.0,2.912,1319.3280000000016,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",306,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.432,1321.7600000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",307,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.56,1324.3200000000015,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",308,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,0.0,2.496,1326.8160000000016,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(detail::TensorInfo<T1, T3>, detail::TensorInfo<const T1, T3>, detail::TensorInfo<const T2, T3>, int, int, T3, long)",309,1024.0,0.0,2048.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,2176.0,2048.0,3.552,1330.3680000000015,0.0,0.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",310,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.88,1333.2480000000016,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",311,6.0,0.0,12.0,0,0.0,12.0,12.0,0.0,2.0,0.0,32.0,32.0,3.392,1336.6400000000017,0.0,0.0,0.0,6.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",312,515.0,0.0,1030.0,0,0.0,1030.0,1030.0,0.0,2.0,0.0,32.0,32.0,2.752,1339.3920000000016,0.0,0.0,0.0,515.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",313,0.0,128.0,0.0,0,0.0,128.0,128.0,8.0,6.0,0.5714285714285714,320.0,256.0,2.592,1341.9840000000017,0.0,128.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",314,288.0,0.0,576.0,0,0.0,576.0,576.0,0.0,10.0,0.0,512.0,512.0,2.496,1344.4800000000018,0.0,0.0,0.0,288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",315,1664.0,2308.0,1280.0,0,0.0,3588.0,3588.0,0.0,8.0,0.0,512.0,512.0,2.944,1347.4240000000018,4.0,256.0,1024.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",316,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,8.0,0.0,512.0,512.0,2.432,1349.8560000000018,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",317,1536.0,2304.0,1024.0,0,0.0,3328.0,3328.0,0.0,8.0,0.0,512.0,512.0,2.944,1352.8000000000018,0.0,256.0,1024.0,512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",318,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,8.0,0.0,512.0,512.0,2.432,1355.2320000000018,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",319,128.0,512.0,256.0,0,0.0,768.0,768.0,0.0,32.0,0.0,2048.0,2048.0,2.528,1357.7600000000018,0.0,512.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",320,384.0,1633.0,768.0,0,0.0,2401.0,2401.0,10.0,5.0,0.6666666666666666,2048.0,32.0,3.392,1361.1520000000019,1632.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",321,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.528,1363.6800000000019,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",322,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,1366.304000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",323,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,2112.0,2048.0,3.008,1369.312000000002,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",324,0.0,512.0,0.0,0,0.0,512.0,512.0,0.0,48.0,0.0,4096.0,2048.0,2.496,1371.808000000002,0.0,512.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 2, 2, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",325,278528.0,581120.0,32768.0,0,0.0,613888.0,613888.0,11776.0,9472.0,0.5542168674698795,1179648.0,2048.0,5.376,1377.184000000002,24064.0,32768.0,262144.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 2, 2, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",326,278528.0,581120.0,32768.0,0,0.0,613888.0,613888.0,11776.0,9472.0,0.5542168674698795,1179648.0,2048.0,5.152,1382.336000000002,24064.0,32768.0,262144.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 2, 2, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",327,278528.0,581120.0,32768.0,0,0.0,613888.0,613888.0,11776.0,9472.0,0.5542168674698795,1179648.0,2048.0,5.28,1387.616000000002,24064.0,32768.0,262144.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",328,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,3072.0,2048.0,3.104,1390.720000000002,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",329,384.0,256.0,768.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,1024.0,1024.0,3.04,1393.760000000002,256.0,0.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",330,173056.0,0.0,346112.0,0,0.0,346112.0,346112.0,0.0,32.0,0.0,2048.0,2048.0,3.2,1396.960000000002,0.0,0.0,0.0,173056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",331,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,3072.0,2048.0,3.136,1400.096000000002,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",332,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,4096.0,2048.0,2.592,1402.6880000000021,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",333,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,3072.0,2048.0,3.136,1405.8240000000021,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",334,384.0,256.0,768.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,1024.0,1024.0,3.008,1408.8320000000022,256.0,0.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",335,173056.0,0.0,346112.0,0,0.0,346112.0,346112.0,0.0,32.0,0.0,2048.0,2048.0,3.168,1412.000000000002,0.0,0.0,0.0,173056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",336,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,3072.0,2048.0,3.072,1415.072000000002,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",337,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,4096.0,2048.0,2.56,1417.6320000000019,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",338,768.0,0.0,1536.0,0,0.0,1536.0,1536.0,0.0,40.0,0.0,4096.0,4096.0,2.592,1420.224000000002,0.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",339,768.0,0.0,1536.0,0,0.0,1536.0,1536.0,0.0,40.0,0.0,4096.0,4096.0,2.688,1422.912000000002,0.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",340,8192.0,752128.0,0.0,0,0.0,752128.0,752128.0,4160.0,8.0,0.9980806142034548,10240.0,2048.0,20.352,1443.2640000000022,636672.0,99072.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 2, 2, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",341,278528.0,581120.0,32768.0,0,0.0,613888.0,613888.0,11776.0,9472.0,0.5542168674698795,1179648.0,2048.0,5.184,1448.4480000000021,24064.0,32768.0,262144.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",342,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,4096.0,2048.0,2.592,1451.0400000000022,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",343,128.0,512.0,256.0,0,0.0,768.0,768.0,0.0,32.0,0.0,2048.0,2048.0,2.496,1453.5360000000023,0.0,512.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",344,384.0,1633.0,768.0,0,0.0,2401.0,2401.0,10.0,5.0,0.6666666666666666,2048.0,32.0,3.36,1456.8960000000022,1632.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",345,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,1459.2960000000023,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",346,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.688,1461.9840000000024,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",347,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,2112.0,2048.0,2.976,1464.9600000000025,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",348,0.0,512.0,0.0,0,0.0,512.0,512.0,0.0,48.0,0.0,4096.0,2048.0,2.56,1467.5200000000025,0.0,512.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",349,1069056.0,2117632.0,36864.0,0,0.0,2154496.0,2154496.0,5632.0,66048.0,0.07857142857142857,4366336.0,16384.0,7.968,1475.4880000000026,16384.0,0.0,1050624.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",350,22528.0,43008.0,4096.0,0,0.0,47104.0,47104.0,0.0,32.0,0.0,8192.0,8192.0,2.88,1478.3680000000027,2048.0,0.0,20480.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",351,1069056.0,2117632.0,36864.0,0,0.0,2154496.0,2154496.0,5632.0,66048.0,0.07857142857142857,4366336.0,16384.0,7.968,1486.3360000000027,16384.0,0.0,1050624.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",352,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,16384.0,8192.0,2.592,1488.9280000000028,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",353,1082368.0,2114560.0,66560.0,0,0.0,2181120.0,2181120.0,8704.0,66048.0,0.11643835616438356,4456448.0,1024.0,8.896,1497.8240000000028,16384.0,0.0,1049088.0,33280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",354,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,4096.0,2048.0,2.56,1500.3840000000027,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",355,128.0,512.0,256.0,0,0.0,768.0,768.0,0.0,32.0,0.0,2048.0,2048.0,2.528,1502.9120000000028,0.0,512.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",356,384.0,1633.0,768.0,0,0.0,2401.0,2401.0,10.0,5.0,0.6666666666666666,2048.0,32.0,3.328,1506.2400000000027,1632.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",357,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.56,1508.8000000000027,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",358,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,1511.4240000000027,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",359,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,2112.0,2048.0,3.04,1514.4640000000027,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",360,0.0,512.0,0.0,0,0.0,512.0,512.0,0.0,48.0,0.0,4096.0,2048.0,2.656,1517.1200000000026,0.0,512.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 2, 2, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",361,278528.0,581120.0,32768.0,0,0.0,613888.0,613888.0,11776.0,9472.0,0.5542168674698795,1179648.0,2048.0,5.152,1522.2720000000027,24064.0,32768.0,262144.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 2, 2, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",362,278528.0,581120.0,32768.0,0,0.0,613888.0,613888.0,11776.0,9472.0,0.5542168674698795,1179648.0,2048.0,5.312,1527.5840000000026,24064.0,32768.0,262144.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 2, 2, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",363,278528.0,581120.0,32768.0,0,0.0,613888.0,613888.0,11776.0,9472.0,0.5542168674698795,1179648.0,2048.0,5.408,1532.9920000000025,24064.0,32768.0,262144.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",364,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,3072.0,2048.0,3.008,1536.0000000000025,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",365,384.0,256.0,768.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,1024.0,1024.0,3.008,1539.0080000000025,256.0,0.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",366,173056.0,0.0,346112.0,0,0.0,346112.0,346112.0,0.0,32.0,0.0,2048.0,2048.0,3.264,1542.2720000000024,0.0,0.0,0.0,173056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",367,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,3072.0,2048.0,3.072,1545.3440000000023,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",368,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,4096.0,2048.0,2.592,1547.9360000000024,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",369,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,3072.0,2048.0,3.136,1551.0720000000024,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",370,384.0,256.0,768.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,1024.0,1024.0,3.072,1554.1440000000023,256.0,0.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",371,173056.0,0.0,346112.0,0,0.0,346112.0,346112.0,0.0,32.0,0.0,2048.0,2048.0,3.232,1557.3760000000023,0.0,0.0,0.0,173056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",372,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,3072.0,2048.0,3.072,1560.4480000000021,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",373,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,4096.0,2048.0,2.56,1563.008000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",374,768.0,0.0,1536.0,0,0.0,1536.0,1536.0,0.0,40.0,0.0,4096.0,4096.0,2.688,1565.6960000000022,0.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",375,768.0,0.0,1536.0,0,0.0,1536.0,1536.0,0.0,40.0,0.0,4096.0,4096.0,2.56,1568.2560000000021,0.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",376,8192.0,752128.0,0.0,0,0.0,752128.0,752128.0,4160.0,8.0,0.9980806142034548,10240.0,2048.0,20.384,1588.6400000000021,636672.0,99072.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 2, 2, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",377,278528.0,581120.0,32768.0,0,0.0,613888.0,613888.0,11776.0,9472.0,0.5542168674698795,1179648.0,2048.0,5.248,1593.8880000000022,24064.0,32768.0,262144.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",378,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,4096.0,2048.0,2.56,1596.4480000000021,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",379,128.0,512.0,256.0,0,0.0,768.0,768.0,0.0,32.0,0.0,2048.0,2048.0,2.56,1599.008000000002,0.0,512.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",380,384.0,1633.0,768.0,0,0.0,2401.0,2401.0,10.0,5.0,0.6666666666666666,2048.0,32.0,3.424,1602.432000000002,1632.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",381,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.528,1604.960000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",382,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,1607.520000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",383,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,2112.0,2048.0,2.944,1610.464000000002,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",384,0.0,512.0,0.0,0,0.0,512.0,512.0,0.0,48.0,0.0,4096.0,2048.0,2.56,1613.024000000002,0.0,512.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",385,1069056.0,2117632.0,36864.0,0,0.0,2154496.0,2154496.0,5632.0,66048.0,0.07857142857142857,4366336.0,16384.0,7.776,1620.800000000002,16384.0,0.0,1050624.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",386,22528.0,43008.0,4096.0,0,0.0,47104.0,47104.0,0.0,32.0,0.0,8192.0,8192.0,3.04,1623.840000000002,2048.0,0.0,20480.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",387,1069056.0,2117632.0,36864.0,0,0.0,2154496.0,2154496.0,5632.0,66048.0,0.07857142857142857,4366336.0,16384.0,8.0,1631.840000000002,16384.0,0.0,1050624.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",388,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,16384.0,8192.0,2.56,1634.400000000002,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",389,1082368.0,2114560.0,66560.0,0,0.0,2181120.0,2181120.0,8704.0,66048.0,0.11643835616438356,4456448.0,1024.0,9.12,1643.5200000000018,16384.0,0.0,1049088.0,33280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",390,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,4096.0,2048.0,2.56,1646.0800000000017,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",391,128.0,512.0,256.0,0,0.0,768.0,768.0,0.0,32.0,0.0,2048.0,2048.0,2.528,1648.6080000000018,0.0,512.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",392,384.0,1633.0,768.0,0,0.0,2401.0,2401.0,10.0,5.0,0.6666666666666666,2048.0,32.0,3.392,1652.0000000000018,1632.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",393,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,1654.400000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",394,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,1656.992000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",395,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,2112.0,2048.0,2.976,1659.9680000000021,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",396,0.0,512.0,0.0,0,0.0,512.0,512.0,0.0,48.0,0.0,4096.0,2048.0,2.528,1662.4960000000021,0.0,512.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 2, 2, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",397,278528.0,581120.0,32768.0,0,0.0,613888.0,613888.0,11776.0,9472.0,0.5542168674698795,1179648.0,2048.0,5.376,1667.8720000000021,24064.0,32768.0,262144.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 2, 2, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",398,278528.0,581120.0,32768.0,0,0.0,613888.0,613888.0,11776.0,9472.0,0.5542168674698795,1179648.0,2048.0,5.216,1673.088000000002,24064.0,32768.0,262144.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 2, 2, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",399,278528.0,581120.0,32768.0,0,0.0,613888.0,613888.0,11776.0,9472.0,0.5542168674698795,1179648.0,2048.0,5.28,1678.368000000002,24064.0,32768.0,262144.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",400,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,3072.0,2048.0,3.04,1681.408000000002,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",401,384.0,256.0,768.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,1024.0,1024.0,3.04,1684.448000000002,256.0,0.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",402,173056.0,0.0,346112.0,0,0.0,346112.0,346112.0,0.0,32.0,0.0,2048.0,2048.0,3.2,1687.648000000002,0.0,0.0,0.0,173056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",403,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,3072.0,2048.0,3.136,1690.784000000002,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",404,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,4096.0,2048.0,2.56,1693.3440000000019,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",405,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,3072.0,2048.0,3.04,1696.3840000000018,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",406,384.0,256.0,768.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,1024.0,1024.0,3.104,1699.4880000000019,256.0,0.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",407,173056.0,0.0,346112.0,0,0.0,346112.0,346112.0,0.0,32.0,0.0,2048.0,2048.0,3.2,1702.688000000002,0.0,0.0,0.0,173056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",408,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,3072.0,2048.0,3.072,1705.7600000000018,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",409,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,4096.0,2048.0,2.656,1708.4160000000018,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",410,768.0,0.0,1536.0,0,0.0,1536.0,1536.0,0.0,40.0,0.0,4096.0,4096.0,2.592,1711.0080000000019,0.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",411,768.0,0.0,1536.0,0,0.0,1536.0,1536.0,0.0,40.0,0.0,4096.0,4096.0,2.592,1713.600000000002,0.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",412,8192.0,752128.0,0.0,0,0.0,752128.0,752128.0,4160.0,8.0,0.9980806142034548,10240.0,2048.0,20.256,1733.856000000002,636672.0,99072.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 2, 2, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",413,278528.0,581120.0,32768.0,0,0.0,613888.0,613888.0,11776.0,9472.0,0.5542168674698795,1179648.0,2048.0,5.408,1739.264000000002,24064.0,32768.0,262144.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",414,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,4096.0,2048.0,2.56,1741.824000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",415,128.0,512.0,256.0,0,0.0,768.0,768.0,0.0,32.0,0.0,2048.0,2048.0,2.528,1744.352000000002,0.0,512.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",416,384.0,1633.0,768.0,0,0.0,2401.0,2401.0,10.0,5.0,0.6666666666666666,2048.0,32.0,3.424,1747.7760000000019,1632.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",417,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,1750.208000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",418,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,1752.832000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",419,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,2112.0,2048.0,3.008,1755.840000000002,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",420,0.0,512.0,0.0,0,0.0,512.0,512.0,0.0,48.0,0.0,4096.0,2048.0,2.56,1758.400000000002,0.0,512.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",421,1069056.0,2117632.0,36864.0,0,0.0,2154496.0,2154496.0,5632.0,66048.0,0.07857142857142857,4366336.0,16384.0,7.776,1766.176000000002,16384.0,0.0,1050624.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",422,22528.0,43008.0,4096.0,0,0.0,47104.0,47104.0,0.0,32.0,0.0,8192.0,8192.0,2.912,1769.088000000002,2048.0,0.0,20480.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",423,1069056.0,2117632.0,36864.0,0,0.0,2154496.0,2154496.0,5632.0,66048.0,0.07857142857142857,4366336.0,16384.0,7.968,1777.056000000002,16384.0,0.0,1050624.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",424,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,16384.0,8192.0,2.592,1779.6480000000022,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",425,1082368.0,2114560.0,66560.0,0,0.0,2181120.0,2181120.0,8704.0,66048.0,0.11643835616438356,4456448.0,1024.0,8.704,1788.3520000000021,16384.0,0.0,1049088.0,33280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",426,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,4096.0,2048.0,2.56,1790.912000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",427,128.0,512.0,256.0,0,0.0,768.0,768.0,0.0,32.0,0.0,2048.0,2048.0,2.656,1793.568000000002,0.0,512.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",428,384.0,1633.0,768.0,0,0.0,2401.0,2401.0,10.0,5.0,0.6666666666666666,2048.0,32.0,3.328,1796.896000000002,1632.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",429,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,1799.328000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",430,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,1801.9200000000021,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",431,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,2112.0,2048.0,3.136,1805.056000000002,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",432,0.0,512.0,0.0,0,0.0,512.0,512.0,0.0,48.0,0.0,4096.0,2048.0,2.56,1807.616000000002,0.0,512.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 2, 2, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",433,278528.0,581120.0,32768.0,0,0.0,613888.0,613888.0,11776.0,9472.0,0.5542168674698795,1179648.0,2048.0,5.248,1812.864000000002,24064.0,32768.0,262144.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 2, 2, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",434,278528.0,581120.0,32768.0,0,0.0,613888.0,613888.0,11776.0,9472.0,0.5542168674698795,1179648.0,2048.0,5.376,1818.240000000002,24064.0,32768.0,262144.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 2, 2, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",435,278528.0,581120.0,32768.0,0,0.0,613888.0,613888.0,11776.0,9472.0,0.5542168674698795,1179648.0,2048.0,5.28,1823.520000000002,24064.0,32768.0,262144.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",436,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,3072.0,2048.0,3.072,1826.592000000002,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",437,384.0,256.0,768.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,1024.0,1024.0,3.136,1829.7280000000019,256.0,0.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",438,173056.0,0.0,346112.0,0,0.0,346112.0,346112.0,0.0,32.0,0.0,2048.0,2048.0,3.232,1832.9600000000019,0.0,0.0,0.0,173056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",439,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,3072.0,2048.0,3.04,1836.0000000000018,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",440,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,4096.0,2048.0,2.592,1838.592000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",441,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,3072.0,2048.0,3.04,1841.6320000000019,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",442,384.0,256.0,768.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,1024.0,1024.0,3.04,1844.6720000000018,256.0,0.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",443,173056.0,0.0,346112.0,0,0.0,346112.0,346112.0,0.0,32.0,0.0,2048.0,2048.0,3.2,1847.872000000002,0.0,0.0,0.0,173056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",444,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,3072.0,2048.0,3.04,1850.9120000000019,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",445,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,4096.0,2048.0,2.592,1853.504000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",446,768.0,0.0,1536.0,0,0.0,1536.0,1536.0,0.0,40.0,0.0,4096.0,4096.0,2.592,1856.096000000002,0.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",447,768.0,0.0,1536.0,0,0.0,1536.0,1536.0,0.0,40.0,0.0,4096.0,4096.0,2.592,1858.6880000000021,0.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",448,8192.0,752128.0,0.0,0,0.0,752128.0,752128.0,4160.0,8.0,0.9980806142034548,10240.0,2048.0,20.48,1879.1680000000022,636672.0,99072.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 2, 2, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",449,278528.0,581120.0,32768.0,0,0.0,613888.0,613888.0,11776.0,9472.0,0.5542168674698795,1179648.0,2048.0,5.248,1884.4160000000022,24064.0,32768.0,262144.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",450,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,4096.0,2048.0,2.56,1886.9760000000022,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",451,128.0,512.0,256.0,0,0.0,768.0,768.0,0.0,32.0,0.0,2048.0,2048.0,2.528,1889.5040000000022,0.0,512.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",452,384.0,1633.0,768.0,0,0.0,2401.0,2401.0,10.0,5.0,0.6666666666666666,2048.0,32.0,3.392,1892.8960000000022,1632.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",453,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,1895.3280000000022,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",454,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,1897.9840000000022,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",455,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,2112.0,2048.0,2.976,1900.9600000000023,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",456,0.0,512.0,0.0,0,0.0,512.0,512.0,0.0,48.0,0.0,4096.0,2048.0,2.56,1903.5200000000023,0.0,512.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",457,1069056.0,2117632.0,36864.0,0,0.0,2154496.0,2154496.0,5632.0,66048.0,0.07857142857142857,4366336.0,16384.0,7.84,1911.3600000000022,16384.0,0.0,1050624.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",458,22528.0,43008.0,4096.0,0,0.0,47104.0,47104.0,0.0,32.0,0.0,8192.0,8192.0,2.912,1914.2720000000022,2048.0,0.0,20480.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",459,1069056.0,2117632.0,36864.0,0,0.0,2154496.0,2154496.0,5632.0,66048.0,0.07857142857142857,4366336.0,16384.0,7.776,1922.0480000000023,16384.0,0.0,1050624.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",460,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,16384.0,8192.0,2.56,1924.6080000000022,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",461,1082368.0,2114560.0,66560.0,0,0.0,2181120.0,2181120.0,8704.0,66048.0,0.11643835616438356,4456448.0,1024.0,8.864,1933.4720000000023,16384.0,0.0,1049088.0,33280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",462,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,4096.0,2048.0,2.656,1936.1280000000022,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",463,128.0,512.0,256.0,0,0.0,768.0,768.0,0.0,32.0,0.0,2048.0,2048.0,2.56,1938.6880000000021,0.0,512.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",464,384.0,1633.0,768.0,0,0.0,2401.0,2401.0,10.0,5.0,0.6666666666666666,2048.0,32.0,3.36,1942.048000000002,1632.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",465,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,1944.4480000000021,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",466,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.752,1947.200000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",467,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,2112.0,2048.0,3.04,1950.240000000002,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",468,0.0,512.0,0.0,0,0.0,512.0,512.0,0.0,48.0,0.0,4096.0,2048.0,2.624,1952.864000000002,0.0,512.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 2, 2, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",469,278528.0,581120.0,32768.0,0,0.0,613888.0,613888.0,11776.0,9472.0,0.5542168674698795,1179648.0,2048.0,5.408,1958.272000000002,24064.0,32768.0,262144.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 2, 2, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",470,278528.0,581120.0,32768.0,0,0.0,613888.0,613888.0,11776.0,9472.0,0.5542168674698795,1179648.0,2048.0,5.28,1963.552000000002,24064.0,32768.0,262144.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 2, 2, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",471,278528.0,581120.0,32768.0,0,0.0,613888.0,613888.0,11776.0,9472.0,0.5542168674698795,1179648.0,2048.0,5.216,1968.7680000000018,24064.0,32768.0,262144.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",472,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,3072.0,2048.0,3.072,1971.8400000000017,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",473,384.0,256.0,768.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,1024.0,1024.0,3.008,1974.8480000000018,256.0,0.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",474,173056.0,0.0,346112.0,0,0.0,346112.0,346112.0,0.0,32.0,0.0,2048.0,2048.0,3.232,1978.0800000000017,0.0,0.0,0.0,173056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",475,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,3072.0,2048.0,3.072,1981.1520000000016,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",476,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,4096.0,2048.0,2.72,1983.8720000000017,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",477,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,3072.0,2048.0,3.136,1987.0080000000016,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",478,384.0,256.0,768.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,1024.0,1024.0,3.04,1990.0480000000016,256.0,0.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",479,173056.0,0.0,346112.0,0,0.0,346112.0,346112.0,0.0,32.0,0.0,2048.0,2048.0,3.232,1993.2800000000016,0.0,0.0,0.0,173056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",480,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,3072.0,2048.0,3.072,1996.3520000000015,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",481,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,4096.0,2048.0,2.72,1999.0720000000015,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",482,768.0,0.0,1536.0,0,0.0,1536.0,1536.0,0.0,40.0,0.0,4096.0,4096.0,2.592,2001.6640000000016,0.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",483,768.0,0.0,1536.0,0,0.0,1536.0,1536.0,0.0,40.0,0.0,4096.0,4096.0,2.624,2004.2880000000016,0.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",484,8192.0,752128.0,0.0,0,0.0,752128.0,752128.0,4160.0,8.0,0.9980806142034548,10240.0,2048.0,20.544,2024.8320000000017,636672.0,99072.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 2, 2, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",485,278528.0,581120.0,32768.0,0,0.0,613888.0,613888.0,11776.0,9472.0,0.5542168674698795,1179648.0,2048.0,5.152,2029.9840000000017,24064.0,32768.0,262144.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",486,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,4096.0,2048.0,2.72,2032.7040000000018,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",487,128.0,512.0,256.0,0,0.0,768.0,768.0,0.0,32.0,0.0,2048.0,2048.0,2.592,2035.2960000000019,0.0,512.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",488,384.0,1633.0,768.0,0,0.0,2401.0,2401.0,10.0,5.0,0.6666666666666666,2048.0,32.0,3.456,2038.7520000000018,1632.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",489,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,2041.1840000000018,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",490,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,2043.8080000000018,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",491,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,2112.0,2048.0,3.008,2046.8160000000018,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",492,0.0,512.0,0.0,0,0.0,512.0,512.0,0.0,48.0,0.0,4096.0,2048.0,2.528,2049.344000000002,0.0,512.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",493,1069056.0,2117632.0,36864.0,0,0.0,2154496.0,2154496.0,5632.0,66048.0,0.07857142857142857,4366336.0,16384.0,7.744,2057.088000000002,16384.0,0.0,1050624.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",494,22528.0,43008.0,4096.0,0,0.0,47104.0,47104.0,0.0,32.0,0.0,8192.0,8192.0,2.88,2059.968000000002,2048.0,0.0,20480.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",495,1069056.0,2117632.0,36864.0,0,0.0,2154496.0,2154496.0,5632.0,66048.0,0.07857142857142857,4366336.0,16384.0,7.776,2067.744000000002,16384.0,0.0,1050624.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",496,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,16384.0,8192.0,2.592,2070.336000000002,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",497,1082368.0,2114560.0,66560.0,0,0.0,2181120.0,2181120.0,8704.0,66048.0,0.11643835616438356,4456448.0,1024.0,9.12,2079.456000000002,16384.0,0.0,1049088.0,33280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",498,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,4096.0,2048.0,2.56,2082.016000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",499,128.0,512.0,256.0,0,0.0,768.0,768.0,0.0,32.0,0.0,2048.0,2048.0,2.56,2084.576000000002,0.0,512.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",500,384.0,1633.0,768.0,0,0.0,2401.0,2401.0,10.0,5.0,0.6666666666666666,2048.0,32.0,3.456,2088.032000000002,1632.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",501,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,2090.4640000000018,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",502,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.688,2093.152000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",503,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,2112.0,2048.0,2.976,2096.128000000002,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",504,0.0,512.0,0.0,0,0.0,512.0,512.0,0.0,48.0,0.0,4096.0,2048.0,2.624,2098.7520000000018,0.0,512.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 2, 2, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",505,278528.0,581120.0,32768.0,0,0.0,613888.0,613888.0,11776.0,9472.0,0.5542168674698795,1179648.0,2048.0,5.312,2104.0640000000017,24064.0,32768.0,262144.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 2, 2, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",506,278528.0,581120.0,32768.0,0,0.0,613888.0,613888.0,11776.0,9472.0,0.5542168674698795,1179648.0,2048.0,5.248,2109.3120000000017,24064.0,32768.0,262144.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 2, 2, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",507,278528.0,581120.0,32768.0,0,0.0,613888.0,613888.0,11776.0,9472.0,0.5542168674698795,1179648.0,2048.0,5.344,2114.6560000000018,24064.0,32768.0,262144.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",508,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,3072.0,2048.0,3.168,2117.824000000002,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",509,384.0,256.0,768.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,1024.0,1024.0,3.008,2120.8320000000017,256.0,0.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",510,173056.0,0.0,346112.0,0,0.0,346112.0,346112.0,0.0,32.0,0.0,2048.0,2048.0,3.264,2124.096000000002,0.0,0.0,0.0,173056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",511,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,3072.0,2048.0,3.072,2127.168000000002,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",512,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,4096.0,2048.0,2.688,2129.856000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",513,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,3072.0,2048.0,3.072,2132.928000000002,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",514,384.0,256.0,768.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,1024.0,1024.0,3.072,2136.0000000000023,256.0,0.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",515,173056.0,0.0,346112.0,0,0.0,346112.0,346112.0,0.0,32.0,0.0,2048.0,2048.0,3.232,2139.2320000000022,0.0,0.0,0.0,173056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",516,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,3072.0,2048.0,3.04,2142.272000000002,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",517,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,4096.0,2048.0,2.688,2144.9600000000023,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",518,768.0,0.0,1536.0,0,0.0,1536.0,1536.0,0.0,40.0,0.0,4096.0,4096.0,2.656,2147.6160000000023,0.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",519,768.0,0.0,1536.0,0,0.0,1536.0,1536.0,0.0,40.0,0.0,4096.0,4096.0,2.592,2150.2080000000024,0.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",520,8192.0,752128.0,0.0,0,0.0,752128.0,752128.0,4160.0,8.0,0.9980806142034548,10240.0,2048.0,20.192,2170.4000000000024,636672.0,99072.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 2, 2, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",521,278528.0,581120.0,32768.0,0,0.0,613888.0,613888.0,11776.0,9472.0,0.5542168674698795,1179648.0,2048.0,5.152,2175.5520000000024,24064.0,32768.0,262144.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",522,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,4096.0,2048.0,2.656,2178.2080000000024,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",523,128.0,512.0,256.0,0,0.0,768.0,768.0,0.0,32.0,0.0,2048.0,2048.0,2.528,2180.736000000002,0.0,512.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",524,384.0,1633.0,768.0,0,0.0,2401.0,2401.0,10.0,5.0,0.6666666666666666,2048.0,32.0,3.36,2184.0960000000023,1632.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",525,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,2186.528000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",526,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,2189.184000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",527,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,2112.0,2048.0,3.168,2192.352000000002,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",528,0.0,512.0,0.0,0,0.0,512.0,512.0,0.0,48.0,0.0,4096.0,2048.0,2.72,2195.072000000002,0.0,512.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",529,1069056.0,2117632.0,36864.0,0,0.0,2154496.0,2154496.0,5632.0,66048.0,0.07857142857142857,4366336.0,16384.0,7.744,2202.816000000002,16384.0,0.0,1050624.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",530,22528.0,43008.0,4096.0,0,0.0,47104.0,47104.0,0.0,32.0,0.0,8192.0,8192.0,2.912,2205.728000000002,2048.0,0.0,20480.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",531,1069056.0,2117632.0,36864.0,0,0.0,2154496.0,2154496.0,5632.0,66048.0,0.07857142857142857,4366336.0,16384.0,7.904,2213.632000000002,16384.0,0.0,1050624.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",532,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,16384.0,8192.0,2.848,2216.480000000002,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",533,1082368.0,2114560.0,66560.0,0,0.0,2181120.0,2181120.0,8704.0,66048.0,0.11643835616438356,4456448.0,1024.0,8.928,2225.4080000000017,16384.0,0.0,1049088.0,33280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",534,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,48.0,0.0,4096.0,2048.0,2.592,2228.000000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",535,128.0,512.0,256.0,0,0.0,768.0,768.0,0.0,32.0,0.0,2048.0,2048.0,2.592,2230.592000000002,0.0,512.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",536,384.0,1633.0,768.0,0,0.0,2401.0,2401.0,10.0,5.0,0.6666666666666666,2048.0,32.0,3.424,2234.016000000002,1632.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",537,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,2236.4480000000017,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",538,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,2239.1040000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",539,1024.0,512.0,2048.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,2112.0,2048.0,3.008,2242.1120000000014,0.0,512.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",540,0.0,512.0,0.0,0,0.0,512.0,512.0,0.0,48.0,0.0,4096.0,2048.0,2.688,2244.8000000000015,0.0,512.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",541,16704000.0,33088000.0,576000.0,0,0.0,33664000.0,33664000.0,88000.0,1032000.0,0.07857142857142857,66050176.0,194816.0,75.584,2320.3840000000014,256000.0,0.0,16416000.0,288000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",542,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.112,2322.4960000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",543,258.0,0.0,516.0,0,0.0,516.0,516.0,0.0,5.0,0.0,64.0,64.0,2.528,2325.0240000000013,0.0,0.0,0.0,258.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",544,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.464,2327.488000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",545,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,128000.0,128000.0,2.624,2330.112000000001,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",546,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,2332.1600000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",547,48128.0,0.0,96256.0,0,0.0,96256.0,96256.0,512.0,1512.0,0.25296442687747034,129024.0,8192.0,3.904,2336.0640000000008,0.0,0.0,0.0,48128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",548,27648.0,0.0,55296.0,0,0.0,55296.0,55296.0,2112.0,8610.0,0.1969781757134863,527360.0,0.0,4.704,2340.768000000001,0.0,0.0,0.0,27648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",549,22137.0,0.0,44274.0,0,0.0,44274.0,44274.0,512.0,1512.0,0.25296442687747034,129024.0,8192.0,4.0,2344.768000000001,0.0,0.0,0.0,22137.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",550,27648.0,0.0,55296.0,0,0.0,55296.0,55296.0,2112.0,8610.0,0.1969781757134863,527360.0,0.0,4.8,2349.568000000001,0.0,0.0,0.0,27648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",551,16132.0,0.0,32264.0,0,0.0,32264.0,32264.0,512.0,1512.0,0.25296442687747034,129024.0,8192.0,4.0,2353.568000000001,0.0,0.0,0.0,16132.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",552,28672.0,0.0,57344.0,0,0.0,57344.0,57344.0,2112.0,8642.0,0.19639204017109912,527360.0,0.0,4.768,2358.336000000001,0.0,0.0,0.0,28672.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",553,16129.0,0.0,32258.0,0,0.0,32258.0,32258.0,512.0,1512.0,0.25296442687747034,129024.0,8192.0,4.128,2362.4640000000013,0.0,0.0,0.0,16129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",554,27648.0,0.0,55296.0,0,0.0,55296.0,55296.0,2112.0,8610.0,0.1969781757134863,527360.0,32.0,4.768,2367.2320000000013,0.0,0.0,0.0,27648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",555,352.0,0.0,704.0,0,0.0,704.0,704.0,0.0,3.0,0.0,1056.0,128.0,2.944,2370.1760000000013,0.0,0.0,0.0,352.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",556,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.048,2372.224000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",557,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,11.0,0.9829984544049459,128.0,0.0,4.256,2376.480000000001,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",558,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.048,2378.5280000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",559,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,11.0,0.9829984544049459,128.0,0.0,4.32,2382.848000000001,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 1>(detail::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, detail::TensorInfo<T1, T2>, T2, detail::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",560,40292.0,0.0,80584.0,0,0.0,80584.0,80584.0,5822.0,2106.0,0.734359233097881,131808.0,1824.0,6.048,2388.8960000000006,0.0,0.0,0.0,40292.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::radixSortKVInPlace<(int)-2, (int)-1, 32, 4, float, long, unsigned int>(detail::TensorInfo<T5, T7>, T7, T7, T7, detail::TensorInfo<T6, T7>, T7, bool)",561,64.0,0.0,128.0,0,0.0,128.0,128.0,458.0,8.0,0.9828326180257511,640.0,0.0,5.984,2394.8800000000006,0.0,0.0,0.0,64.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",562,64000.0,0.0,128000.0,0,0.0,128000.0,128000.0,0.0,3000.0,0.0,130016.0,8000.0,4.096,2398.9760000000006,0.0,0.0,0.0,64000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",563,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,768.0,0.0,160000.0,0.0,2.848,2401.8240000000005,0.0,0.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"native::<unnamed>::fill_reverse_indices_kernel(long *, int, detail::IntDivider<unsigned int>)",564,128768.0,0.0,257536.0,0,0.0,257536.0,257536.0,0.0,1000.0,0.0,0.0,256000.0,2.496,2404.3200000000006,0.0,0.0,0.0,128768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",565,387287.0,0.0,774574.0,0,0.0,774574.0,774574.0,64512.0,1000.0,0.9847356209549396,128000.0,0.0,3.968,2408.2880000000005,0.0,0.0,0.0,387287.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",566,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,2.592,2410.8800000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",567,29568.0,0.0,59136.0,0,0.0,59136.0,59136.0,10414.0,4261.0,0.7096422487223168,407552.0,308224.0,14.656,2425.5360000000005,0.0,0.0,0.0,29568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",568,14400.0,0.0,28800.0,0,0.0,28800.0,28800.0,3418.0,4267.0,0.44476252439817826,407552.0,390144.0,13.184,2438.7200000000007,0.0,0.0,0.0,14400.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",569,15744.0,0.0,31488.0,0,0.0,31488.0,31488.0,4798.0,4243.0,0.530693507355381,405632.0,303040.0,14.208,2452.928000000001,0.0,0.0,0.0,15744.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",570,15744.0,0.0,31488.0,0,0.0,31488.0,31488.0,4798.0,4232.0,0.5313399778516058,405504.0,363200.0,14.08,2467.0080000000007,0.0,0.0,0.0,15744.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",571,524494.0,1061280.0,152988.0,0,0.0,1214268.0,1214268.0,132.0,1312.0,0.09141274238227147,252544.0,128000.0,18.272,2485.2800000000007,133280.0,32000.0,448000.0,76494.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<float, 1>>(T1, int)",572,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,0.0,416.0,2.048,2487.3280000000004,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<float, std::plus<float>>::Policy900, const float *, float *, at_cuda_detail::ScanTileState<float, 1>, std::plus<float>, at_cuda_detail::NullType, unsigned int, float, 0>(T2, T3, T4, int, T5, T6, T7)",573,2177.0,85371.0,4354.0,0,0.0,89725.0,89725.0,4349.0,2053.0,0.6793189628241174,135584.0,129024.0,4.288,2491.6160000000004,85371.0,0.0,0.0,2177.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",574,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,512.0,0.0,128000.0,31808.0,2.656,2494.2720000000004,0.0,0.0,0.0,256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::unrolled_elementwise_kernel<native::FillFunctor<bool>, std::array<char *, 1>, 16, TrivialOffsetCalculator<0, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithoutCast, memory::StoreWithoutCast>(int, T1, T2, T4, T5, T6, T7)",575,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.048,2496.32,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",576,68096.0,0.0,136192.0,0,0.0,136192.0,136192.0,0.0,3000.0,0.0,288000.0,12672.0,9.056,2505.376,0.0,0.0,0.0,68096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",577,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,768.0,0.0,160000.0,0.0,2.88,2508.2560000000003,0.0,0.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",578,524496.0,1061280.0,152992.0,0,0.0,1214272.0,1214272.0,132.0,1312.0,0.09141274238227147,253824.0,128000.0,18.336,2526.592,133280.0,32000.0,448000.0,76496.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",579,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,251.0,0.19808306709265175,128000.0,32.0,9.76,2536.3520000000003,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",580,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.432,2538.784,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",581,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,251.0,0.19808306709265175,128000.0,32.0,9.728,2548.512,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",582,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.432,2550.944,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",583,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.464,2553.408,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",584,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.168,2556.576,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",585,1536.0,36576.0,3072.0,0,0.0,39648.0,39648.0,62.0,251.0,0.19808306709265175,128000.0,32.0,9.536,2566.112,36576.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",586,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.4,2568.512,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",587,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.432,2570.944,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",588,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.2,2574.144,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",589,448000.0,640000.0,320000.0,0,0.0,960000.0,960000.0,0.0,1000.0,0.0,0.0,128000.0,2.848,2576.9919999999997,0.0,64000.0,288000.0,160000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",590,196944.0,327680.0,66208.0,0,0.0,393888.0,393888.0,0.0,768.0,0.0,256000.0,0.0,3.84,2580.832,0.0,0.0,163840.0,33104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",591,18048.0,0.0,36096.0,0,0.0,36096.0,36096.0,124.0,251.0,0.33066666666666666,128000.0,32.0,12.928,2593.7599999999998,0.0,0.0,0.0,18048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",592,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.464,2596.2239999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",593,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.464,2598.6879999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",594,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.4,2601.0879999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",595,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.528,2603.6159999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",596,258.0,0.0,516.0,0,0.0,516.0,516.0,0.0,5.0,0.0,64.0,64.0,2.496,2606.1119999999996,0.0,0.0,0.0,258.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",597,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.048,2608.1599999999994,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",598,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.048,2610.207999999999,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",599,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.56,2612.767999999999,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",600,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.048,2614.815999999999,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",601,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,3.0,0.0,64.0,32.0,2.56,2617.375999999999,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",602,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.528,2619.9039999999986,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",603,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.464,2622.3679999999986,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",604,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,3.008,2625.3759999999984,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",605,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,3.232,2628.6079999999984,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",606,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.464,2631.0719999999983,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
