Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,1.728,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.568,3.2960000000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,1.664,4.96,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,3.0,0.0,64.0,32.0,2.048,7.008,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.592,9.6,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",6,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,11.648,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",7,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,13.696,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",8,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.048,15.744,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",9,128.0,0.0,256.0,0,0.0,256.0,256.0,129.0,6.0,0.9555555555555556,32.0,32.0,3.008,18.752,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",10,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.496,21.247999999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",11,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.432,23.679999999999996,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.176,25.855999999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,128.0,0.0,256.0,0,0.0,256.0,256.0,129.0,6.0,0.9555555555555556,32.0,32.0,2.848,28.703999999999994,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,31.231999999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",15,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.464,33.69599999999999,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",16,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,3.0,0.0,64.0,0.0,2.592,36.28799999999999,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(detail::TensorInfo<T1, T3>, detail::TensorInfo<const T1, T3>, detail::TensorInfo<const T2, T3>, int, int, T3, long)",17,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,4352.0,4096.0,4.864,41.15199999999999,0.0,0.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",18,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.848,43.999999999999986,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",19,515.0,0.0,1030.0,0,0.0,1030.0,1030.0,0.0,2.0,0.0,32.0,32.0,2.72,46.719999999999985,0.0,0.0,0.0,515.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",20,0.0,128.0,0.0,0,0.0,128.0,128.0,8.0,6.0,0.5714285714285714,320.0,256.0,3.104,49.823999999999984,0.0,128.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",21,288.0,0.0,576.0,0,0.0,576.0,576.0,0.0,10.0,0.0,512.0,512.0,2.496,52.319999999999986,0.0,0.0,0.0,288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",22,1664.0,2304.0,1280.0,0,0.0,3584.0,3584.0,0.0,8.0,0.0,512.0,512.0,3.04,55.359999999999985,0.0,256.0,1024.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",23,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,8.0,0.0,512.0,512.0,2.56,57.91999999999999,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",24,1536.0,2304.0,1024.0,0,0.0,3328.0,3328.0,0.0,8.0,0.0,512.0,512.0,2.912,60.83199999999999,0.0,256.0,1024.0,512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",25,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,8.0,0.0,512.0,512.0,2.496,63.32799999999999,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",26,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.688,66.01599999999999,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",27,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.456,69.472,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",28,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.528,72.0,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",29,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,74.656,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",30,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,77.632,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",31,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,80.224,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",32,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,9.76,89.98400000000001,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",33,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.608,98.59200000000001,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",34,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.512,107.10400000000001,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",35,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,110.14400000000002,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",36,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.104,113.24800000000002,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",37,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.744,116.99200000000002,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",38,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,120.03200000000002,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",39,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,122.59200000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",40,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,125.66400000000003,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",41,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.008,128.67200000000003,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",42,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,132.32000000000002,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",43,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,135.39200000000002,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",44,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,137.98400000000004,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",45,16384.0,1503744.0,0.0,0,0.0,1503744.0,1503744.0,8320.0,16.0,0.9980806142034548,12288.0,4096.0,20.224,158.20800000000003,1272832.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",46,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.48,166.68800000000002,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",47,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.752,169.44000000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",48,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,172.00000000000003,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",49,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.456,175.45600000000002,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",50,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,177.888,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",51,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,180.512,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",52,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.072,183.584,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",53,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,186.144,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",54,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17142400.0,29536.0,24.128,210.272,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",55,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,3.104,213.376,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",56,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17153408.0,29024.0,24.416,237.792,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",57,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.848,240.64000000000001,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",58,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17836800.0,2048.0,22.912,263.552,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",59,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,266.144,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",60,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.752,268.896,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",61,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.36,272.25600000000003,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",62,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,274.656,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",63,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,277.28000000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",64,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,280.25600000000003,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",65,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,282.848,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",66,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.8,291.648,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",67,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.576,300.22400000000005,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",68,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.544,308.76800000000003,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",69,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.2,311.968,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",70,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.072,315.04,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",71,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,318.68800000000005,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",72,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,321.72800000000007,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",73,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,324.32000000000005,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",74,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,327.36000000000007,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",75,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,330.4000000000001,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",76,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.68,334.0800000000001,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",77,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,337.2160000000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",78,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.688,339.9040000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",79,16384.0,1503744.0,0.0,0,0.0,1503744.0,1503744.0,8320.0,16.0,0.9980806142034548,12288.0,4096.0,20.256,360.1600000000001,1272832.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",80,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.864,369.02400000000006,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",81,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,371.61600000000004,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",82,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,374.14400000000006,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",83,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,377.53600000000006,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",84,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,379.9680000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",85,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,382.5920000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",86,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.008,385.6000000000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",87,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.688,388.28800000000007,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",88,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17139968.0,31104.0,23.52,411.80800000000005,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",89,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,3.232,415.0400000000001,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",90,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17148544.0,29344.0,22.976,438.0160000000001,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",91,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.752,440.7680000000001,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",92,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17833344.0,2048.0,23.616,464.38400000000007,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",93,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,467.0080000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",94,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,469.5360000000001,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",95,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.424,472.9600000000001,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",96,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.496,475.4560000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",97,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,478.0800000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",98,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,481.0560000000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",99,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.656,483.7120000000001,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",100,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.832,492.5440000000001,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",101,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.832,501.3760000000001,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",102,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.576,509.9520000000001,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",103,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,512.9920000000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",104,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.008,516.0000000000001,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",105,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.744,519.7440000000001,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",106,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.2,522.9440000000002,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",107,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,525.5360000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",108,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,528.5760000000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",109,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.008,531.5840000000002,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",110,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,535.2320000000002,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",111,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,538.3360000000002,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",112,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.656,540.9920000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",113,16384.0,1503744.0,0.0,0,0.0,1503744.0,1503744.0,8320.0,16.0,0.9980806142034548,12288.0,4096.0,20.192,561.1840000000002,1272832.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",114,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.832,570.0160000000002,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",115,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,572.6080000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",116,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,575.1680000000001,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",117,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.456,578.6240000000001,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",118,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,581.0560000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",119,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,583.6800000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",120,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,586.6560000000002,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",121,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,589.2480000000002,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",122,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17154432.0,28768.0,23.008,612.2560000000002,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",123,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.912,615.1680000000002,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",124,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17153664.0,28992.0,22.816,637.9840000000003,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",125,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.72,640.7040000000003,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",126,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17846272.0,2048.0,23.2,663.9040000000003,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",127,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.656,666.5600000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",128,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,669.0880000000003,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",129,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,672.4800000000004,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",130,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,674.9440000000004,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",131,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,677.5360000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",132,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,680.5120000000004,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",133,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,683.1040000000004,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",134,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.576,691.6800000000004,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",135,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.544,700.2240000000004,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",136,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.48,708.7040000000004,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",137,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,711.7760000000004,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",138,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.136,714.9120000000004,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",139,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,718.5600000000004,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",140,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,721.6320000000004,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",141,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,724.2240000000004,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",142,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,727.2640000000004,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",143,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,730.3040000000003,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",144,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,733.9520000000003,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",145,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,737.0560000000004,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",146,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,739.6480000000004,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",147,16384.0,1503744.0,0.0,0,0.0,1503744.0,1503744.0,8320.0,16.0,0.9980806142034548,12288.0,4096.0,20.064,759.7120000000003,1272832.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",148,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.928,768.6400000000003,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",149,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.72,771.3600000000004,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",150,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.592,773.9520000000003,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",151,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,777.3440000000004,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",152,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,779.7440000000004,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",153,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,782.4000000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",154,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.008,785.4080000000004,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",155,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.656,788.0640000000003,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",156,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17138944.0,29024.0,22.656,810.7200000000003,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",157,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,3.072,813.7920000000003,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",158,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17143680.0,31360.0,23.968,837.7600000000002,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",159,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,840.3520000000002,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",160,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17834752.0,2048.0,22.976,863.3280000000002,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",161,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.72,866.0480000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",162,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,868.6080000000002,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",163,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.36,871.9680000000002,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",164,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,874.4320000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",165,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,877.0560000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",166,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.008,880.0640000000003,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",167,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.624,882.6880000000003,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",168,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,9.152,891.8400000000004,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",169,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.48,900.3200000000004,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",170,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.608,908.9280000000003,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",171,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,911.9680000000003,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",172,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,915.0080000000003,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",173,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.712,918.7200000000003,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",174,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,921.7600000000002,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",175,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,924.3840000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",176,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,927.5200000000002,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",177,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,930.5600000000002,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",178,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,934.2080000000002,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",179,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.232,937.4400000000002,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",180,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,940.0640000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",181,16384.0,1503744.0,0.0,0,0.0,1503744.0,1503744.0,8320.0,16.0,0.9980806142034548,12288.0,4096.0,20.16,960.2240000000002,1272832.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",182,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.544,968.7680000000001,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",183,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,971.3600000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",184,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,973.8880000000001,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",185,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,977.2800000000002,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",186,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.56,979.8400000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",187,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,982.4320000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",188,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.104,985.5360000000002,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",189,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.624,988.1600000000002,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",190,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17168256.0,28480.0,23.744,1011.9040000000002,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",191,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,3.008,1014.9120000000003,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",192,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17148544.0,28832.0,23.616,1038.5280000000002,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",193,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.624,1041.1520000000003,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",194,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17830912.0,2048.0,23.52,1064.6720000000003,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",195,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,1067.2960000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",196,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,1069.8560000000002,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",197,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.552,1073.4080000000001,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",198,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,1075.8400000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",199,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.72,1078.5600000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",200,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,1081.5360000000003,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",201,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.624,1084.1600000000003,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",202,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.704,1092.8640000000003,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",203,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.992,1101.8560000000002,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",204,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.512,1110.3680000000002,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",205,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,1113.5040000000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",206,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,1116.544,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",207,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.712,1120.256,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",208,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,1123.296,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",209,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,1125.92,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",210,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,1129.056,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",211,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,1132.096,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",212,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.712,1135.808,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",213,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,1138.816,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",214,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,1141.44,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",215,16384.0,1503744.0,0.0,0,0.0,1503744.0,1503744.0,8320.0,16.0,0.9980806142034548,12288.0,4096.0,20.192,1161.632,1272832.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",216,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.864,1170.496,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",217,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.688,1173.1840000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",218,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,1175.7120000000002,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",219,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.36,1179.0720000000001,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",220,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,1181.5040000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",221,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.816,1184.3200000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",222,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,1187.2960000000003,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",223,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.624,1189.9200000000003,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",224,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17135200.0,29248.0,22.368,1212.2880000000002,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",225,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.912,1215.2000000000003,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",226,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17153792.0,29024.0,23.84,1239.0400000000002,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",227,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,1241.6320000000003,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",228,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17836800.0,2048.0,23.136,1264.7680000000003,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",229,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,1267.3600000000004,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",230,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.656,1270.0160000000003,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",231,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.36,1273.3760000000002,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",232,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.56,1275.9360000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",233,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,1278.5280000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",234,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.104,1281.6320000000003,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",235,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.752,1284.3840000000002,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",236,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.544,1292.9280000000003,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",237,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.672,1301.6000000000004,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",238,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.928,1310.5280000000005,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",239,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,1313.6320000000005,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",240,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.072,1316.7040000000004,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",241,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,1320.3520000000003,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",242,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,1323.3920000000003,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",243,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,1326.0160000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",244,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.264,1329.2800000000002,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",245,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.072,1332.352,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",246,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,1336.0,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",247,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,1339.04,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",248,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,1341.664,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",249,16352.0,1503660.0,0.0,0,0.0,1503660.0,1503660.0,8323.0,16.0,0.9980813047127953,12288.0,4096.0,20.128,1361.792,1272815.0,198141.0,16352.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",250,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.448,1370.24,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",251,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,1372.864,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",252,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.624,1375.488,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",253,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,1378.88,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",254,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,1381.344,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",255,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,1384.0,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",256,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.072,1387.072,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",257,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,1389.6319999999998,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",258,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17155424.0,29600.0,22.912,1412.5439999999999,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",259,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.944,1415.4879999999998,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",260,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17153408.0,28672.0,23.008,1438.4959999999999,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",261,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.56,1441.0559999999998,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",262,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17843840.0,2048.0,23.392,1464.4479999999999,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",263,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.752,1467.1999999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",264,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,1469.7279999999998,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",265,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.36,1473.0879999999997,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",266,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,1475.4559999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",267,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,1478.0799999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",268,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,1481.0559999999998,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",269,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,1483.648,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",270,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.832,1492.48,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",271,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.736,1501.2160000000001,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",272,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.512,1509.728,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",273,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,1512.768,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",274,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.008,1515.776,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",275,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,1519.424,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",276,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,1522.4959999999999,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",277,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,1525.088,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",278,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,1528.096,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",279,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.104,1531.2,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",280,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.616,1534.816,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",281,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.232,1538.048,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",282,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,1540.672,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",283,16384.0,1503744.0,0.0,0,0.0,1503744.0,1503744.0,8320.0,16.0,0.9980806142034548,12288.0,4096.0,20.16,1560.832,1272832.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",284,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.544,1569.3760000000002,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",285,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,1571.9680000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",286,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.656,1574.6240000000003,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",287,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.424,1578.0480000000002,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",288,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,1580.4800000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",289,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,1583.0720000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",290,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,1586.0480000000005,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",291,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,1588.6400000000006,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",292,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17146880.0,28928.0,22.816,1611.4560000000006,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",293,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.912,1614.3680000000006,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",294,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17141760.0,29248.0,22.336,1636.7040000000006,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",295,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,1639.2960000000007,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",296,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17828480.0,2048.0,23.328,1662.6240000000007,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",297,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,1665.2160000000008,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",298,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.592,1667.808000000001,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",299,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.36,1671.1680000000008,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",300,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,1673.6000000000008,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",301,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,1676.2240000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",302,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.008,1679.2320000000009,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",303,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.624,1681.856000000001,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",304,33088000.0,65856000.0,576000.0,0,0.0,66432000.0,66432000.0,88000.0,2056000.0,0.041044776119402986,132912480.0,180384.0,148.416,1830.2720000000008,256000.0,0.0,32800000.0,288000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",305,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,1832.3200000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",306,258.0,0.0,516.0,0,0.0,516.0,516.0,0.0,4.0,0.0,64.0,64.0,2.624,1834.9440000000009,0.0,0.0,0.0,258.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",307,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.464,1837.4080000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",308,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,128000.0,128000.0,2.816,1840.2240000000008,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",309,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.112,1842.336000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",310,48128.0,0.0,96256.0,0,0.0,96256.0,96256.0,512.0,1512.0,0.25296442687747034,129024.0,8192.0,3.968,1846.304000000001,0.0,0.0,0.0,48128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",311,27648.0,0.0,55296.0,0,0.0,55296.0,55296.0,2112.0,8610.0,0.1969781757134863,527360.0,0.0,4.864,1851.168000000001,0.0,0.0,0.0,27648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",312,16341.0,0.0,32682.0,0,0.0,32682.0,32682.0,512.0,1512.0,0.25296442687747034,129024.0,8192.0,4.064,1855.232000000001,0.0,0.0,0.0,16341.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",313,33792.0,0.0,67584.0,0,0.0,67584.0,67584.0,2112.0,8802.0,0.19351291918636612,527360.0,0.0,4.576,1859.8080000000011,0.0,0.0,0.0,33792.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",314,16134.0,0.0,32268.0,0,0.0,32268.0,32268.0,512.0,1512.0,0.25296442687747034,129024.0,8192.0,3.968,1863.7760000000012,0.0,0.0,0.0,16134.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",315,27648.0,0.0,55296.0,0,0.0,55296.0,55296.0,2112.0,8610.0,0.1969781757134863,527360.0,0.0,4.8,1868.5760000000012,0.0,0.0,0.0,27648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",316,16129.0,0.0,32258.0,0,0.0,32258.0,32258.0,512.0,1512.0,0.25296442687747034,129024.0,8192.0,3.936,1872.512000000001,0.0,0.0,0.0,16129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",317,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,2112.0,8770.0,0.19408197022606138,527360.0,32.0,4.736,1877.2480000000012,0.0,0.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",318,352.0,0.0,704.0,0,0.0,704.0,704.0,0.0,3.0,0.0,1056.0,128.0,3.104,1880.3520000000012,0.0,0.0,0.0,352.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",319,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.016,1882.3680000000013,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",320,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,11.0,0.9829984544049459,128.0,0.0,4.288,1886.6560000000013,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",321,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.08,1888.7360000000012,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",322,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,11.0,0.9829984544049459,128.0,0.0,4.224,1892.9600000000012,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 1>(detail::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, detail::TensorInfo<T1, T2>, T2, detail::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",323,40292.0,0.0,80584.0,0,0.0,80584.0,80584.0,7134.0,2108.0,0.7719108418091323,131808.0,1696.0,5.952,1898.9120000000012,0.0,0.0,0.0,40292.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::radixSortKVInPlace<(int)-2, (int)-1, 32, 4, float, long, unsigned int>(detail::TensorInfo<T5, T7>, T7, T7, T7, detail::TensorInfo<T6, T7>, T7, bool)",324,64.0,0.0,128.0,0,0.0,128.0,128.0,458.0,8.0,0.9828326180257511,640.0,0.0,6.048,1904.9600000000012,0.0,0.0,0.0,64.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",325,64000.0,0.0,128000.0,0,0.0,128000.0,128000.0,0.0,3000.0,0.0,130016.0,8000.0,4.288,1909.2480000000012,0.0,0.0,0.0,64000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",326,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,768.0,0.0,160000.0,0.0,2.944,1912.1920000000011,0.0,0.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"native::<unnamed>::fill_reverse_indices_kernel(long *, int, detail::IntDivider<unsigned int>)",327,128768.0,0.0,257536.0,0,0.0,257536.0,257536.0,0.0,1000.0,0.0,0.0,256000.0,2.56,1914.752000000001,0.0,0.0,0.0,128768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",328,387236.0,0.0,774472.0,0,0.0,774472.0,774472.0,64512.0,1000.0,0.9847356209549396,128000.0,0.0,4.128,1918.880000000001,0.0,0.0,0.0,387236.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",329,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,2.624,1921.504000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",330,29568.0,0.0,59136.0,0,0.0,59136.0,59136.0,10414.0,4256.0,0.7098841172460805,407552.0,305088.0,14.912,1936.416000000001,0.0,0.0,0.0,29568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",331,14400.0,0.0,28800.0,0,0.0,28800.0,28800.0,3418.0,4278.0,0.4441268191268191,407552.0,390144.0,13.344,1949.7600000000011,0.0,0.0,0.0,14400.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",332,15744.0,0.0,31488.0,0,0.0,31488.0,31488.0,4798.0,4208.0,0.5327559404841217,405504.0,390272.0,14.72,1964.4800000000012,0.0,0.0,0.0,15744.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",333,15744.0,0.0,31488.0,0,0.0,31488.0,31488.0,4798.0,4230.0,0.5314576871953921,405504.0,327008.0,14.144,1978.6240000000012,0.0,0.0,0.0,15744.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",334,524494.0,1061280.0,152988.0,0,0.0,1214268.0,1214268.0,132.0,1312.0,0.09141274238227147,255616.0,128000.0,18.72,1997.3440000000012,133280.0,32000.0,448000.0,76494.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<float, 1>>(T1, int)",335,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,0.0,416.0,2.08,1999.4240000000011,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<float, std::plus<float>>::Policy900, const float *, float *, at_cuda_detail::ScanTileState<float, 1>, std::plus<float>, at_cuda_detail::NullType, unsigned int, float, 0>(T2, T3, T4, int, T5, T6, T7)",336,2177.0,85371.0,4354.0,0,0.0,89725.0,89725.0,4349.0,2053.0,0.6793189628241174,136128.0,129024.0,3.968,2003.3920000000012,85371.0,0.0,0.0,2177.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",337,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,512.0,0.0,128000.0,31808.0,2.72,2006.1120000000012,0.0,0.0,0.0,256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::unrolled_elementwise_kernel<native::FillFunctor<bool>, std::array<char *, 1>, 16, TrivialOffsetCalculator<0, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithoutCast, memory::StoreWithoutCast>(int, T1, T2, T4, T5, T6, T7)",338,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.016,2008.1280000000013,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",339,68096.0,0.0,136192.0,0,0.0,136192.0,136192.0,0.0,3000.0,0.0,288000.0,12416.0,9.312,2017.4400000000012,0.0,0.0,0.0,68096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",340,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,768.0,0.0,160000.0,0.0,2.88,2020.3200000000013,0.0,0.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",341,524497.0,1061280.0,152994.0,0,0.0,1214274.0,1214274.0,132.0,1312.0,0.09141274238227147,246912.0,128000.0,18.528,2038.8480000000013,133280.0,32000.0,448000.0,76497.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",342,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,251.0,0.19808306709265175,128000.0,32.0,9.696,2048.5440000000012,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",343,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.528,2051.072000000001,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",344,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,251.0,0.19808306709265175,128000.0,32.0,9.824,2060.896000000001,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",345,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.432,2063.328000000001,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",346,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.624,2065.9520000000007,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",347,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.232,2069.1840000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",348,1536.0,36576.0,3072.0,0,0.0,39648.0,39648.0,62.0,251.0,0.19808306709265175,128000.0,32.0,9.728,2078.9120000000007,36576.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",349,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.4,2081.312000000001,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",350,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.496,2083.808000000001,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",351,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.168,2086.976000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",352,448000.0,640000.0,320000.0,0,0.0,960000.0,960000.0,0.0,1000.0,0.0,0.0,128000.0,2.784,2089.760000000001,0.0,64000.0,288000.0,160000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",353,196945.0,327680.0,66210.0,0,0.0,393890.0,393890.0,0.0,768.0,0.0,256000.0,0.0,3.808,2093.568000000001,0.0,0.0,163840.0,33105.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",354,18048.0,0.0,36096.0,0,0.0,36096.0,36096.0,124.0,251.0,0.33066666666666666,128000.0,32.0,13.184,2106.7520000000013,0.0,0.0,0.0,18048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",355,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.4,2109.1520000000014,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",356,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.464,2111.6160000000013,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",357,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.4,2114.0160000000014,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",358,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.464,2116.4800000000014,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",359,258.0,0.0,516.0,0,0.0,516.0,516.0,0.0,4.0,0.0,64.0,64.0,2.496,2118.9760000000015,0.0,0.0,0.0,258.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",360,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.08,2121.0560000000014,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",361,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.112,2123.1680000000015,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",362,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.56,2125.7280000000014,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",363,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.016,2127.7440000000015,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithoutCast, memory::StoreWithoutCast>(int, T1, T2, T4, T5, T6, T7)",364,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,3.0,0.0,64.0,32.0,2.432,2130.1760000000013,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",365,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.624,2132.800000000001,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",366,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.4,2135.200000000001,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",367,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,3.104,2138.304000000001,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",368,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,3.2,2141.504000000001,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",369,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.464,2143.9680000000008,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",370,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.4,2146.368000000001,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",371,130.0,0.0,260.0,0,0.0,260.0,260.0,0.0,3.0,0.0,64.0,32.0,3.36,2149.728000000001,0.0,0.0,0.0,130.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",372,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.048,2151.7760000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",373,128.0,0.0,256.0,0,0.0,256.0,256.0,129.0,6.0,0.9555555555555556,32.0,32.0,2.88,2154.656000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",374,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,2157.248000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",375,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.4,2159.648000000001,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",376,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,0.0,2.528,2162.176000000001,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(detail::TensorInfo<T1, T3>, detail::TensorInfo<const T1, T3>, detail::TensorInfo<const T2, T3>, int, int, T3, long)",377,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,4352.0,4096.0,3.072,2165.248000000001,0.0,0.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",378,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.848,2168.096000000001,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",379,6.0,0.0,12.0,0,0.0,12.0,12.0,0.0,2.0,0.0,32.0,32.0,3.36,2171.456000000001,0.0,0.0,0.0,6.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",380,515.0,0.0,1030.0,0,0.0,1030.0,1030.0,0.0,2.0,0.0,32.0,32.0,2.752,2174.208000000001,0.0,0.0,0.0,515.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",381,0.0,128.0,0.0,0,0.0,128.0,128.0,8.0,6.0,0.5714285714285714,320.0,256.0,2.56,2176.768000000001,0.0,128.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",382,288.0,0.0,576.0,0,0.0,576.0,576.0,0.0,10.0,0.0,512.0,512.0,2.464,2179.232000000001,0.0,0.0,0.0,288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",383,1664.0,2308.0,1280.0,0,0.0,3588.0,3588.0,0.0,8.0,0.0,512.0,512.0,2.944,2182.176000000001,4.0,256.0,1024.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",384,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,8.0,0.0,512.0,512.0,2.496,2184.672000000001,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",385,1536.0,2304.0,1024.0,0,0.0,3328.0,3328.0,0.0,8.0,0.0,512.0,512.0,2.912,2187.5840000000007,0.0,256.0,1024.0,512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",386,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,8.0,0.0,512.0,512.0,2.464,2190.0480000000007,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",387,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,2192.5760000000005,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",388,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.36,2195.9360000000006,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",389,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,2198.3360000000007,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",390,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,2200.928000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",391,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,2203.8720000000008,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",392,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.624,2206.4960000000005,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",393,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,2215.2640000000006,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",394,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.608,2223.8720000000008,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",395,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.8,2232.672000000001,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",396,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,2235.744000000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",397,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.008,2238.752000000001,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",398,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,2242.400000000001,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",399,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,2245.472000000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",400,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,2248.064000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",401,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,2251.1360000000013,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",402,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,2254.1760000000013,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",403,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,2257.8240000000014,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",404,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.2,2261.0240000000013,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",405,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,2263.648000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",406,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.656,2266.304000000001,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",407,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.56,2268.864000000001,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",408,16128.0,1503586.0,0.0,0,0.0,1503586.0,1503586.0,8332.0,16.0,0.9980833732630571,20480.0,4096.0,20.48,2289.344000000001,1273208.0,198122.0,16128.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",409,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.832,2298.176000000001,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",410,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,2300.8000000000006,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",411,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,2303.3600000000006,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",412,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.36,2306.7200000000007,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",413,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,2309.120000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",414,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.752,2311.8720000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",415,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,2314.8160000000007,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",416,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,2317.408000000001,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",417,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17141120.0,28928.0,24.096,2341.504000000001,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",418,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.944,2344.448000000001,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",419,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17154336.0,28928.0,23.872,2368.3200000000006,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",420,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,2370.9120000000007,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",421,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17828480.0,2048.0,22.688,2393.600000000001,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",422,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,2396.192000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",423,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,2398.752000000001,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",424,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.36,2402.112000000001,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",425,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,2404.480000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",426,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,2407.072000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",427,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,2410.048000000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",428,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.624,2412.672000000001,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",429,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.864,2421.536000000001,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",430,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.864,2430.400000000001,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",431,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.544,2438.944000000001,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",432,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,2442.016000000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",433,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.072,2445.088000000001,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",434,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,2448.7360000000012,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",435,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,2451.776000000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",436,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,2454.400000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",437,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.2,2457.600000000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",438,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.008,2460.6080000000006,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",439,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,2464.2560000000008,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",440,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.168,2467.424000000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",441,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,2469.984000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",442,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.528,2472.5120000000006,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",443,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.592,2475.1040000000007,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",444,16384.0,1504264.0,0.0,0,0.0,1504264.0,1504264.0,8320.0,16.0,0.9980806142034548,20480.0,4096.0,20.448,2495.5520000000006,1273344.0,198152.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",445,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.8,2504.3520000000008,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",446,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,2506.9760000000006,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",447,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.656,2509.6320000000005,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",448,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,2513.0240000000003,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",449,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,2515.4240000000004,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",450,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,2518.0480000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",451,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.04,2521.088,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",452,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.624,2523.712,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",453,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17143936.0,29312.0,22.4,2546.112,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",454,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.912,2549.024,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",455,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17156480.0,29344.0,23.168,2572.192,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",456,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.752,2574.944,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",457,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17844480.0,2048.0,22.848,2597.792,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",458,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,2600.384,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",459,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.624,2603.008,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",460,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.456,2606.464,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",461,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,2608.864,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",462,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.688,2611.552,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",463,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,2614.5280000000002,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",464,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,2617.1200000000003,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",465,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.736,2625.856,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",466,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,2634.6240000000003,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",467,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.864,2643.4880000000003,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",468,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,2646.5600000000004,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",469,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.008,2649.568,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",470,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.616,2653.184,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",471,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,2656.224,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",472,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.752,2658.976,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",473,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,2662.08,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",474,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,2665.12,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",475,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.712,2668.832,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",476,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,2671.904,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",477,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,2674.464,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",478,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.56,2677.024,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",479,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.592,2679.616,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",480,16384.0,1504258.0,0.0,0,0.0,1504258.0,1504258.0,8320.0,16.0,0.9980806142034548,20480.0,4096.0,20.32,2699.936,1273344.0,198146.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",481,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,2708.704,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",482,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.656,2711.36,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",483,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.72,2714.08,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",484,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,2717.4719999999998,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",485,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.336,2719.8079999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",486,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,2722.3999999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",487,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,2725.3759999999997,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",488,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.656,2728.0319999999997,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",489,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17148288.0,29440.0,23.008,2751.0399999999995,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",490,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.976,2754.0159999999996,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",491,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17153536.0,28960.0,23.168,2777.1839999999997,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",492,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,2779.776,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",493,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17835776.0,2048.0,22.72,2802.4959999999996,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",494,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.688,2805.1839999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",495,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,2807.7439999999997,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",496,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.36,2811.104,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",497,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.496,2813.6,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",498,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,2816.2239999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",499,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.136,2819.3599999999997,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",500,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,2821.9199999999996,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",501,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.512,2830.432,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",502,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.448,2838.8799999999997,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",503,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.448,2847.3279999999995,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",504,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,2850.3679999999995,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",505,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.008,2853.3759999999993,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",506,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,2857.0239999999994,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",507,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,2860.1279999999992,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",508,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,2862.7199999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",509,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,2865.7599999999993,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",510,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,2868.7999999999993,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",511,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.872,2872.671999999999,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",512,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.264,2875.9359999999992,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",513,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,2878.5279999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",514,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.56,2881.0879999999993,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",515,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.528,2883.615999999999,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",516,16384.0,1504256.0,0.0,0,0.0,1504256.0,1504256.0,8320.0,16.0,0.9980806142034548,20480.0,4096.0,20.384,2903.999999999999,1273344.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",517,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.544,2912.543999999999,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",518,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,2915.135999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",519,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.624,2917.759999999999,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",520,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,2921.1519999999987,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",521,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,2923.5839999999985,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",522,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,2926.2079999999983,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",523,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.008,2929.215999999998,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",524,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,2931.807999999998,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",525,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17142144.0,29280.0,23.68,2955.487999999998,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",526,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.976,2958.463999999998,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",527,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17149856.0,29120.0,23.328,2981.791999999998,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",528,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,2984.383999999998,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",529,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17833984.0,2048.0,23.008,3007.391999999998,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",530,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,3009.983999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",531,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,3012.543999999998,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",532,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.36,3015.903999999998,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",533,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,3018.335999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",534,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,3020.927999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",535,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.04,3023.967999999998,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",536,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,3026.559999999998,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",537,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.64,3035.199999999998,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",538,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.8,3043.999999999998,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",539,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.608,3052.6079999999984,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",540,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,3055.711999999998,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",541,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.104,3058.815999999998,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",542,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.68,3062.495999999998,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",543,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,3065.5999999999976,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",544,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,3068.2239999999974,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",545,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,3071.2639999999974,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",546,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.104,3074.367999999997,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",547,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.68,3078.047999999997,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",548,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,3081.087999999997,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",549,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.688,3083.775999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",550,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.56,3086.335999999997,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",551,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.56,3088.895999999997,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",552,16384.0,1504262.0,0.0,0,0.0,1504262.0,1504262.0,8320.0,16.0,0.9980806142034548,20480.0,4096.0,20.16,3109.055999999997,1273344.0,198150.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",553,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.8,3117.855999999997,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",554,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,3120.447999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",555,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,3123.007999999997,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",556,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.424,3126.431999999997,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",557,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,3128.863999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",558,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,3131.455999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",559,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.072,3134.527999999997,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",560,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,3137.119999999997,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",561,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17142784.0,29248.0,24.0,3161.119999999997,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",562,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.944,3164.063999999997,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",563,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17147648.0,29344.0,23.904,3187.967999999997,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",564,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,3190.559999999997,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",565,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17834240.0,2048.0,22.944,3213.503999999997,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",566,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,3216.0959999999973,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",567,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.624,3218.719999999997,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",568,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,3222.111999999997,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",569,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.496,3224.607999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",570,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,3227.231999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",571,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,3230.207999999997,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",572,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,3232.767999999997,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",573,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.576,3241.343999999997,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",574,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.864,3250.207999999997,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",575,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.416,3258.623999999997,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",576,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,3261.695999999997,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",577,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.008,3264.703999999997,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",578,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,3268.351999999997,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",579,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,3271.4239999999972,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",580,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,3273.983999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",581,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,3277.0559999999973,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",582,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.008,3280.063999999997,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",583,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,3283.7119999999973,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",584,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,3286.751999999997,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",585,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,3289.375999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",586,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.592,3291.967999999997,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",587,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.528,3294.495999999997,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",588,16352.0,1504176.0,0.0,0,0.0,1504176.0,1504176.0,8323.0,16.0,0.9980813047127953,20480.0,4096.0,20.128,3314.623999999997,1273327.0,198145.0,16352.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",589,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.608,3323.2319999999972,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",590,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.688,3325.9199999999973,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",591,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.592,3328.5119999999974,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",592,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.424,3331.9359999999974,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",593,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,3334.3359999999975,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",594,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,3336.9599999999973,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",595,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,3339.9039999999973,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",596,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.688,3342.5919999999974,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",597,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17143040.0,29056.0,22.304,3364.8959999999975,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",598,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,3.2,3368.0959999999973,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",599,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17138816.0,28992.0,22.976,3391.0719999999974,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",600,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.816,3393.887999999997,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",601,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17841280.0,2048.0,23.136,3417.023999999997,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",602,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,3419.647999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",603,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,3422.1759999999967,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",604,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,3425.5679999999966,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",605,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,3427.9999999999964,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",606,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,3430.5919999999965,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",607,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.104,3433.6959999999963,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",608,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.656,3436.351999999996,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",609,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,3445.1199999999963,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",610,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,3453.8879999999963,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",611,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.512,3462.3999999999965,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",612,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,3465.4399999999964,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",613,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.008,3468.4479999999962,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",614,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.616,3472.063999999996,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",615,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,3475.199999999996,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",616,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,3477.7919999999963,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",617,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.168,3480.9599999999964,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",618,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.168,3484.1279999999965,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",619,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,3487.7759999999967,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",620,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,3490.9119999999966,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",621,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,3493.5359999999964,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",622,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.624,3496.159999999996,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",623,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.56,3498.719999999996,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",624,16384.0,1504260.0,0.0,0,0.0,1504260.0,1504260.0,8320.0,16.0,0.9980806142034548,20480.0,4096.0,20.096,3518.815999999996,1273344.0,198148.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",625,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.576,3527.391999999996,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",626,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,3530.015999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",627,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,3532.543999999996,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",628,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,3535.9359999999956,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",629,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.56,3538.4959999999955,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",630,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.688,3541.1839999999956,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",631,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.072,3544.2559999999958,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",632,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.656,3546.9119999999957,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",633,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17149568.0,29856.0,22.784,3569.695999999996,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",634,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.912,3572.6079999999956,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",635,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17145600.0,29152.0,23.072,3595.6799999999957,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",636,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.56,3598.2399999999957,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",637,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17833728.0,2048.0,22.944,3621.1839999999956,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",638,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,3623.8079999999954,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",639,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,3626.3359999999952,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",640,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,3629.727999999995,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",641,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,3632.095999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",642,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,3634.687999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",643,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,3637.663999999995,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",644,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.656,3640.319999999995,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",645,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.8,3649.1199999999953,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",646,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.864,3657.9839999999954,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",647,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.896,3666.8799999999956,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",648,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,3669.9519999999957,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",649,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.008,3672.9599999999955,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",650,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,3676.6079999999956,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",651,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,3679.7119999999954,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",652,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,3682.3039999999955,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",653,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,3685.4079999999954,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",654,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,3688.4479999999953,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",655,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,3692.0959999999955,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",656,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,3695.1999999999953,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",657,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,3697.7919999999954,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",658,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.592,3700.3839999999955,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",659,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.56,3702.9439999999954,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",660,16384.0,1504264.0,0.0,0,0.0,1504264.0,1504264.0,8320.0,16.0,0.9980806142034548,20480.0,4096.0,20.128,3723.0719999999956,1273344.0,198152.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",661,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.608,3731.6799999999957,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",662,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.688,3734.367999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",663,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.624,3736.9919999999956,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",664,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.36,3740.3519999999958,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",665,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,3742.751999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",666,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,3745.343999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",667,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.04,3748.383999999996,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",668,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.624,3751.0079999999957,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",669,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17146880.0,29568.0,22.272,3773.2799999999957,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",670,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.912,3776.1919999999955,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",671,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17141632.0,28896.0,23.232,3799.4239999999954,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",672,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.688,3802.1119999999955,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",673,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17832192.0,2048.0,23.2,3825.3119999999954,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",674,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,3827.9039999999954,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",675,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,3830.4639999999954,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",676,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,3833.855999999995,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",677,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.56,3836.415999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",678,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,3838.975999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",679,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,3841.951999999995,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",680,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.624,3844.575999999995,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",681,33088000.0,65856000.0,576000.0,0,0.0,66432000.0,66432000.0,88000.0,2056000.0,0.041044776119402986,132884192.0,184032.0,148.32,3992.895999999995,256000.0,0.0,32800000.0,288000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",682,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.08,3994.975999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",683,258.0,0.0,516.0,0,0.0,516.0,516.0,0.0,5.0,0.0,64.0,64.0,2.56,3997.535999999995,0.0,0.0,0.0,258.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",684,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.4,3999.935999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",685,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,128000.0,128000.0,2.624,4002.559999999995,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",686,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,4004.6079999999947,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",687,48128.0,0.0,96256.0,0,0.0,96256.0,96256.0,512.0,1512.0,0.25296442687747034,129024.0,8192.0,4.0,4008.6079999999947,0.0,0.0,0.0,48128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",688,27648.0,0.0,55296.0,0,0.0,55296.0,55296.0,2112.0,8610.0,0.1969781757134863,527360.0,0.0,4.768,4013.3759999999947,0.0,0.0,0.0,27648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",689,16321.0,0.0,32642.0,0,0.0,32642.0,32642.0,512.0,1512.0,0.25296442687747034,129024.0,8192.0,3.904,4017.2799999999947,0.0,0.0,0.0,16321.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",690,33792.0,0.0,67584.0,0,0.0,67584.0,67584.0,2112.0,8802.0,0.19351291918636612,527360.0,0.0,4.736,4022.0159999999946,0.0,0.0,0.0,33792.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",691,16131.0,0.0,32262.0,0,0.0,32262.0,32262.0,512.0,1512.0,0.25296442687747034,129024.0,8192.0,4.064,4026.0799999999945,0.0,0.0,0.0,16131.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",692,28672.0,0.0,57344.0,0,0.0,57344.0,57344.0,2112.0,8642.0,0.19639204017109912,527360.0,0.0,4.896,4030.9759999999947,0.0,0.0,0.0,28672.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",693,16129.0,0.0,32258.0,0,0.0,32258.0,32258.0,512.0,1512.0,0.25296442687747034,129024.0,8192.0,3.872,4034.8479999999945,0.0,0.0,0.0,16129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",694,27648.0,0.0,55296.0,0,0.0,55296.0,55296.0,2112.0,8610.0,0.1969781757134863,527360.0,32.0,4.768,4039.6159999999945,0.0,0.0,0.0,27648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",695,352.0,0.0,704.0,0,0.0,704.0,704.0,0.0,3.0,0.0,1056.0,128.0,3.328,4042.9439999999945,0.0,0.0,0.0,352.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",696,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.112,4045.0559999999946,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",697,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,11.0,0.9829984544049459,128.0,0.0,4.32,4049.3759999999947,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",698,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.08,4051.4559999999947,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",699,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,11.0,0.9829984544049459,128.0,0.0,4.224,4055.679999999995,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 1>(detail::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, detail::TensorInfo<T1, T2>, T2, detail::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",700,40292.0,0.0,80584.0,0,0.0,80584.0,80584.0,6642.0,2098.0,0.759954233409611,131808.0,1632.0,5.888,4061.5679999999948,0.0,0.0,0.0,40292.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::radixSortKVInPlace<(int)-2, (int)-1, 32, 4, float, long, unsigned int>(detail::TensorInfo<T5, T7>, T7, T7, T7, detail::TensorInfo<T6, T7>, T7, bool)",701,64.0,0.0,128.0,0,0.0,128.0,128.0,458.0,8.0,0.9828326180257511,640.0,0.0,5.984,4067.5519999999947,0.0,0.0,0.0,64.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",702,64000.0,0.0,128000.0,0,0.0,128000.0,128000.0,0.0,3000.0,0.0,130016.0,8000.0,4.0,4071.5519999999947,0.0,0.0,0.0,64000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",703,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,768.0,0.0,160000.0,0.0,2.88,4074.431999999995,0.0,0.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"native::<unnamed>::fill_reverse_indices_kernel(long *, int, detail::IntDivider<unsigned int>)",704,128768.0,0.0,257536.0,0,0.0,257536.0,257536.0,0.0,1000.0,0.0,0.0,256000.0,2.464,4076.8959999999947,0.0,0.0,0.0,128768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",705,387236.0,0.0,774472.0,0,0.0,774472.0,774472.0,64512.0,1000.0,0.9847356209549396,128000.0,0.0,3.936,4080.831999999995,0.0,0.0,0.0,387236.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",706,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,2.656,4083.487999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",707,29568.0,0.0,59136.0,0,0.0,59136.0,59136.0,10414.0,4240.0,0.7106592056776306,407552.0,306976.0,14.912,4098.399999999995,0.0,0.0,0.0,29568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",708,14400.0,0.0,28800.0,0,0.0,28800.0,28800.0,3418.0,4264.0,0.4449362145274668,407552.0,390144.0,13.12,4111.519999999995,0.0,0.0,0.0,14400.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",709,15744.0,0.0,31488.0,0,0.0,31488.0,31488.0,4798.0,4232.0,0.5313399778516058,405504.0,390144.0,14.176,4125.695999999995,0.0,0.0,0.0,15744.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",710,15744.0,0.0,31488.0,0,0.0,31488.0,31488.0,4798.0,4236.0,0.5311047155191498,405504.0,327296.0,14.304,4139.999999999995,0.0,0.0,0.0,15744.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",711,524494.0,1061280.0,152988.0,0,0.0,1214268.0,1214268.0,132.0,1312.0,0.09141274238227147,238464.0,128000.0,18.656,4158.655999999995,133280.0,32000.0,448000.0,76494.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<float, 1>>(T1, int)",712,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,0.0,416.0,2.048,4160.703999999995,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<float, std::plus<float>>::Policy900, const float *, float *, at_cuda_detail::ScanTileState<float, 1>, std::plus<float>, at_cuda_detail::NullType, unsigned int, float, 0>(T2, T3, T4, int, T5, T6, T7)",713,2177.0,85371.0,4354.0,0,0.0,89725.0,89725.0,4349.0,2053.0,0.6793189628241174,136128.0,129024.0,4.288,4164.991999999995,85371.0,0.0,0.0,2177.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",714,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,512.0,0.0,128000.0,31808.0,2.592,4167.583999999994,0.0,0.0,0.0,256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::unrolled_elementwise_kernel<native::FillFunctor<bool>, std::array<char *, 1>, 16, TrivialOffsetCalculator<0, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithoutCast, memory::StoreWithoutCast>(int, T1, T2, T4, T5, T6, T7)",715,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.048,4169.631999999994,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",716,68096.0,0.0,136192.0,0,0.0,136192.0,136192.0,0.0,3000.0,0.0,288000.0,12416.0,9.152,4178.783999999994,0.0,0.0,0.0,68096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",717,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,768.0,0.0,160000.0,0.0,2.816,4181.599999999994,0.0,0.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",718,524497.0,1061280.0,152994.0,0,0.0,1214274.0,1214274.0,132.0,1312.0,0.09141274238227147,276992.0,128000.0,18.496,4200.095999999994,133280.0,32000.0,448000.0,76497.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",719,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,251.0,0.19808306709265175,128000.0,32.0,9.728,4209.823999999994,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",720,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.464,4212.287999999994,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",721,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,251.0,0.19808306709265175,128000.0,32.0,9.696,4221.983999999994,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",722,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.56,4224.543999999994,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",723,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.56,4227.103999999995,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",724,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.2,4230.303999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",725,1536.0,36576.0,3072.0,0,0.0,39648.0,39648.0,62.0,251.0,0.19808306709265175,128000.0,32.0,9.536,4239.839999999995,36576.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",726,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.592,4242.431999999994,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",727,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.432,4244.863999999994,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",728,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.2,4248.063999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",729,448000.0,640000.0,320000.0,0,0.0,960000.0,960000.0,0.0,1000.0,0.0,0.0,128000.0,2.784,4250.847999999994,0.0,64000.0,288000.0,160000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",730,196945.0,327680.0,66210.0,0,0.0,393890.0,393890.0,0.0,768.0,0.0,256000.0,0.0,3.776,4254.623999999993,0.0,0.0,163840.0,33105.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",731,18048.0,0.0,36096.0,0,0.0,36096.0,36096.0,124.0,251.0,0.33066666666666666,128000.0,32.0,12.992,4267.615999999994,0.0,0.0,0.0,18048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",732,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.432,4270.047999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",733,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.336,4272.383999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",734,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.4,4274.783999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",735,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.56,4277.343999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",736,258.0,0.0,516.0,0,0.0,516.0,516.0,0.0,5.0,0.0,64.0,64.0,2.496,4279.839999999994,0.0,0.0,0.0,258.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",737,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.048,4281.887999999994,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",738,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.048,4283.935999999993,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",739,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.496,4286.431999999993,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",740,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.176,4288.607999999994,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",741,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,3.0,0.0,64.0,32.0,2.432,4291.039999999994,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",742,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.496,4293.535999999994,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",743,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.4,4295.935999999993,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",744,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,3.072,4299.007999999993,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",745,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,3.168,4302.175999999993,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",746,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.496,4304.671999999993,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
