Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,1.696,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.568,3.2640000000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,1.632,4.896,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,3.0,0.0,64.0,32.0,2.016,6.912,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.624,9.536,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",6,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.112,11.648,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",7,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.144,13.792,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",8,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.112,15.904,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",9,128.0,0.0,256.0,0,0.0,256.0,256.0,129.0,6.0,0.9555555555555556,32.0,32.0,2.88,18.784,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",10,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,21.311999999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",11,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.528,23.839999999999996,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.048,25.887999999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,128.0,0.0,256.0,0,0.0,256.0,256.0,129.0,6.0,0.9555555555555556,32.0,32.0,2.848,28.735999999999997,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.464,31.199999999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",15,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.432,33.632,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",16,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,3.0,0.0,64.0,0.0,2.656,36.288,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(detail::TensorInfo<T1, T3>, detail::TensorInfo<const T1, T3>, detail::TensorInfo<const T2, T3>, int, int, T3, long)",17,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,4352.0,4096.0,4.736,41.023999999999994,0.0,0.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",18,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,3.008,44.032,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",19,515.0,0.0,1030.0,0,0.0,1030.0,1030.0,0.0,2.0,0.0,32.0,32.0,2.752,46.784,0.0,0.0,0.0,515.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",20,0.0,128.0,0.0,0,0.0,128.0,128.0,8.0,6.0,0.5714285714285714,320.0,256.0,2.72,49.504,0.0,128.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",21,288.0,0.0,576.0,0,0.0,576.0,576.0,0.0,10.0,0.0,512.0,512.0,2.464,51.967999999999996,0.0,0.0,0.0,288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",22,1664.0,2304.0,1280.0,0,0.0,3584.0,3584.0,0.0,8.0,0.0,512.0,512.0,3.104,55.071999999999996,0.0,256.0,1024.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",23,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,8.0,0.0,512.0,512.0,2.56,57.632,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",24,1536.0,2304.0,1024.0,0,0.0,3328.0,3328.0,0.0,8.0,0.0,512.0,512.0,2.976,60.608,0.0,256.0,1024.0,512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",25,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,8.0,0.0,512.0,512.0,2.496,63.104,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",26,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.624,65.728,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",27,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.488,69.216,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",28,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,71.616,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",29,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,74.272,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",30,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,77.21600000000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",31,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.752,79.968,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",32,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,10.048,90.016,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",33,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.832,98.84800000000001,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",34,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.672,107.52000000000001,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",35,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,110.528,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",36,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.136,113.664,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",37,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,117.312,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",38,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,120.352,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",39,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,122.912,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",40,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.168,126.08000000000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",41,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,129.12,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",42,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.68,132.8,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",43,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.168,135.96800000000002,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",44,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,138.56000000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",45,16320.0,1503576.0,0.0,0,0.0,1503576.0,1503576.0,8323.0,16.0,0.9980813047127953,12288.0,4096.0,20.16,158.72000000000003,1272798.0,198138.0,16320.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",46,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,167.48800000000003,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",47,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.688,170.17600000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",48,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,172.73600000000002,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",49,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.488,176.22400000000002,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",50,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,178.68800000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",51,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.688,181.376,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",52,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,184.352,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",53,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,186.912,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",54,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17148032.0,28864.0,23.776,210.68800000000002,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",55,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,3.168,213.85600000000002,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",56,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17154944.0,29760.0,24.576,238.43200000000002,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",57,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,241.02400000000003,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",58,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17830528.0,2048.0,22.752,263.776,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",59,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.656,266.432,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",60,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.624,269.05600000000004,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",61,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.424,272.48,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",62,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,274.88,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",63,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,277.504,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",64,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,280.44800000000004,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",65,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,283.00800000000004,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",66,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.48,291.48800000000006,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",67,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,9.088,300.5760000000001,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",68,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.512,309.0880000000001,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",69,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,312.1280000000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",70,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.008,315.1360000000001,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",71,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.68,318.8160000000001,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",72,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,321.82400000000007,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",73,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,324.41600000000005,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",74,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,327.4560000000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",75,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,330.4960000000001,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",76,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,334.1440000000001,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",77,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,337.2160000000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",78,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,339.8080000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",79,16384.0,1503744.0,0.0,0,0.0,1503744.0,1503744.0,8320.0,16.0,0.9980806142034548,12288.0,4096.0,20.128,359.9360000000001,1272832.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",80,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.64,368.5760000000001,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",81,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,371.2000000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",82,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.592,373.7920000000001,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",83,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,377.1840000000001,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",84,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,379.5520000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",85,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,382.1120000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",86,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.168,385.2800000000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",87,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,387.8400000000001,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",88,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17147648.0,28800.0,23.168,411.0080000000001,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",89,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.912,413.9200000000001,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",90,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17149952.0,30240.0,23.424,437.34400000000005,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",91,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.72,440.0640000000001,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",92,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17832064.0,2048.0,23.68,463.7440000000001,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",93,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,466.33600000000007,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",94,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.496,468.83200000000005,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",95,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,472.22400000000005,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",96,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,474.59200000000004,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",97,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,477.15200000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",98,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.136,480.28800000000007,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",99,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,482.88000000000005,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",100,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.8,491.68000000000006,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",101,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.384,500.0640000000001,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",102,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.832,508.8960000000001,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",103,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,511.9680000000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",104,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,2.976,514.9440000000001,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",105,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,518.5920000000001,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",106,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,521.6640000000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",107,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,524.2560000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",108,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,527.296,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",109,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.008,530.3040000000001,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",110,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,533.9520000000001,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",111,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,536.9920000000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",112,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.528,539.5200000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",113,16384.0,1503744.0,0.0,0,0.0,1503744.0,1503744.0,8320.0,16.0,0.9980806142034548,12288.0,4096.0,20.128,559.6480000000001,1272832.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",114,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.672,568.3200000000002,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",115,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,570.8800000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",116,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,573.44,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",117,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.456,576.8960000000001,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",118,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,579.296,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",119,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,581.856,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",120,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,584.8,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",121,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,587.3599999999999,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",122,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17156608.0,28736.0,23.52,610.8799999999999,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",123,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.912,613.7919999999999,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",124,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17163392.0,30048.0,22.784,636.5759999999999,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",125,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,639.1679999999999,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",126,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17837696.0,2048.0,23.36,662.5279999999999,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",127,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,665.0879999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",128,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,667.6159999999999,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",129,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,671.0079999999999,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",130,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,673.4399999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",131,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.496,675.9359999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",132,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.008,678.944,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",133,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.624,681.568,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",134,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.416,689.984,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",135,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.864,698.8480000000001,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",136,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.8,707.648,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",137,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,710.688,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",138,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,713.728,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",139,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.616,717.3439999999999,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",140,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,720.4159999999999,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",141,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,723.0079999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",142,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,726.0479999999999,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",143,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,729.0879999999999,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",144,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.68,732.7679999999998,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",145,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,735.7759999999998,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",146,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,738.3359999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",147,16384.0,1503744.0,0.0,0,0.0,1503744.0,1503744.0,8320.0,16.0,0.9980806142034548,12288.0,4096.0,20.096,758.4319999999998,1272832.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",148,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,9.088,767.5199999999998,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",149,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,770.0799999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",150,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,772.6399999999996,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",151,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.456,776.0959999999997,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",152,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,778.4639999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",153,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,780.9919999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",154,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.008,783.9999999999998,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",155,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.656,786.6559999999997,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",156,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17141504.0,29152.0,22.752,809.4079999999997,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",157,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.944,812.3519999999996,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",158,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17145216.0,29696.0,23.04,835.3919999999996,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",159,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.688,838.0799999999996,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",160,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17833344.0,2048.0,23.072,861.1519999999996,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",161,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,863.7119999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",162,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,866.2719999999995,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",163,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,869.6639999999995,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",164,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,872.0639999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",165,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,874.6239999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",166,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,877.5999999999995,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",167,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,880.1599999999994,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",168,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,9.024,889.1839999999994,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",169,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.608,897.7919999999993,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",170,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.544,906.3359999999993,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",171,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,909.3439999999994,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",172,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,912.3839999999993,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",173,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.616,915.9999999999993,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",174,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,919.0079999999994,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",175,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.528,921.5359999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",176,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,924.5439999999994,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",177,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.104,927.6479999999995,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",178,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,931.2959999999995,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",179,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,934.3999999999995,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",180,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,936.9599999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",181,16384.0,1503744.0,0.0,0,0.0,1503744.0,1503744.0,8320.0,16.0,0.9980806142034548,12288.0,4096.0,20.128,957.0879999999995,1272832.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",182,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.736,965.8239999999995,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",183,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,968.4159999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",184,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.688,971.1039999999995,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",185,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,974.4959999999995,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",186,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,976.8959999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",187,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,979.4239999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",188,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,982.3999999999995,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",189,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,984.9919999999995,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",190,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17153920.0,29888.0,23.936,1008.9279999999995,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",191,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,3.04,1011.9679999999995,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",192,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17142464.0,28704.0,23.84,1035.8079999999995,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",193,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.528,1038.3359999999996,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",194,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17843456.0,2048.0,23.136,1061.4719999999995,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",195,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,1064.0319999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",196,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,1066.5919999999994,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",197,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.424,1070.0159999999994,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",198,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,1072.4159999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",199,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,1074.9759999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",200,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.008,1077.9839999999995,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",201,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.784,1080.7679999999996,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",202,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.416,1089.1839999999995,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",203,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.928,1098.1119999999996,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",204,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.896,1107.0079999999996,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",205,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,1110.0799999999995,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",206,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.008,1113.0879999999995,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",207,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,1116.7359999999994,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",208,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,1119.7759999999994,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",209,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,1122.3359999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",210,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,1125.4079999999992,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",211,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.072,1128.479999999999,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",212,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.616,1132.095999999999,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",213,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,1135.231999999999,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",214,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.656,1137.887999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",215,16384.0,1503744.0,0.0,0,0.0,1503744.0,1503744.0,8320.0,16.0,0.9980806142034548,12288.0,4096.0,20.16,1158.047999999999,1272832.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",216,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.416,1166.463999999999,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",217,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,1169.087999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",218,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,1171.647999999999,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",219,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,1175.039999999999,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",220,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,1177.503999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",221,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,1180.063999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",222,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,1183.039999999999,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",223,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,1185.6319999999992,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",224,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17140416.0,29184.0,22.304,1207.9359999999992,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",225,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.912,1210.8479999999993,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",226,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17145344.0,28672.0,23.968,1234.8159999999993,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",227,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,1237.4079999999994,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",228,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17836672.0,2048.0,23.04,1260.4479999999994,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",229,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,1263.0079999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",230,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,1265.5679999999993,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",231,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,1268.9599999999994,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",232,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,1271.3599999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",233,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,1273.8879999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",234,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.008,1276.8959999999995,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",235,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.528,1279.4239999999995,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",236,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.448,1287.8719999999996,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",237,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,1296.6399999999996,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",238,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,9.088,1305.7279999999996,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",239,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,1308.7679999999996,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",240,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.168,1311.9359999999995,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",241,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,1315.5839999999994,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",242,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.168,1318.7519999999993,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",243,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,1321.3759999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",244,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.232,1324.6079999999993,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",245,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,1327.6479999999992,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",246,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,1331.2959999999991,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",247,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.2,1334.4959999999992,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",248,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,1337.0559999999991,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",249,16352.0,1503660.0,0.0,0,0.0,1503660.0,1503660.0,8323.0,16.0,0.9980813047127953,12288.0,4096.0,20.128,1357.183999999999,1272815.0,198141.0,16352.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",250,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,1365.951999999999,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",251,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,1368.5439999999992,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",252,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.688,1371.2319999999993,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",253,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.552,1374.7839999999992,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",254,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.496,1377.2799999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",255,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,1379.8719999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",256,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.008,1382.8799999999994,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",257,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,1385.4719999999995,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",258,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17159008.0,28736.0,22.88,1408.3519999999996,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",259,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.944,1411.2959999999996,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",260,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17150208.0,28576.0,22.976,1434.2719999999995,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",261,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,1436.8639999999996,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",262,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17840256.0,2048.0,23.488,1460.3519999999996,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",263,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,1462.9119999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",264,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.72,1465.6319999999996,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",265,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,1469.0239999999997,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",266,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,1471.4559999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",267,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,1473.9839999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",268,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,1476.9599999999998,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",269,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,1479.552,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",270,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.576,1488.128,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",271,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.608,1496.7359999999999,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",272,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.576,1505.312,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",273,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,1508.416,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",274,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,1511.456,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",275,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.584,1515.04,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",276,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,1518.1119999999999,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",277,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,1520.6719999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",278,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,1523.8079999999998,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",279,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,1526.8479999999997,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",280,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,1530.4959999999996,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",281,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,1533.5679999999995,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",282,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,1536.1279999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",283,16384.0,1503744.0,0.0,0,0.0,1503744.0,1503744.0,8320.0,16.0,0.9980806142034548,12288.0,4096.0,20.128,1556.2559999999994,1272832.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",284,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,9.152,1565.4079999999994,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",285,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.656,1568.0639999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",286,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,1570.6239999999993,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",287,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,1574.0159999999994,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",288,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,1576.4799999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",289,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,1579.0719999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",290,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.072,1582.1439999999993,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",291,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,1584.7039999999993,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",292,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17144704.0,29728.0,22.944,1607.6479999999992,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",293,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.976,1610.6239999999993,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",294,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17145856.0,28768.0,22.752,1633.3759999999993,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",295,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,1635.9679999999994,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",296,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17848704.0,2048.0,23.264,1659.2319999999993,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",297,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,1661.7919999999992,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",298,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,1664.3199999999993,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",299,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.456,1667.7759999999992,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",300,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,1670.2079999999992,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",301,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,1672.7679999999991,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",302,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,1675.7439999999992,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",303,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,1678.3359999999993,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",304,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,9.152,1687.4879999999994,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",305,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.48,1695.9679999999994,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",306,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.608,1704.5759999999993,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",307,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,1707.7119999999993,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",308,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,1710.7519999999993,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",309,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.616,1714.3679999999993,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",310,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,1717.4399999999991,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",311,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,1719.999999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",312,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,1723.1039999999991,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",313,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,1726.143999999999,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",314,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.68,1729.8239999999992,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",315,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,1732.9279999999992,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",316,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,1735.4879999999991,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",317,16384.0,1503744.0,0.0,0,0.0,1503744.0,1503744.0,8320.0,16.0,0.9980806142034548,12288.0,4096.0,20.096,1755.5839999999992,1272832.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",318,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.864,1764.4479999999992,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",319,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,1767.0399999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",320,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,1769.5999999999992,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",321,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.424,1773.0239999999992,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",322,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.528,1775.5519999999992,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",323,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,1778.0799999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",324,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.072,1781.1519999999991,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",325,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,1783.7439999999992,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",326,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17144192.0,28672.0,23.008,1806.7519999999993,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",327,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,3.008,1809.7599999999993,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",328,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17149952.0,28768.0,23.456,1833.2159999999992,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",329,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.624,1835.8399999999992,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",330,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17828992.0,2048.0,22.976,1858.8159999999993,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",331,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,1861.3759999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",332,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,1863.9359999999992,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",333,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,1867.3279999999993,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",334,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,1869.7279999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",335,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,1872.3199999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",336,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.88,1875.1999999999996,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",337,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.656,1877.8559999999995,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",338,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.704,1886.5599999999995,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",339,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,9.088,1895.6479999999995,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",340,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.928,1904.5759999999996,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",341,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.2,1907.7759999999996,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",342,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,1910.8159999999996,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",343,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,1914.4639999999995,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",344,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,1917.5359999999994,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",345,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,1920.0959999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",346,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,1923.1679999999992,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",347,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.008,1926.1759999999992,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",348,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,1929.8239999999992,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",349,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,1932.8639999999991,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",350,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,1935.423999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",351,16384.0,1503744.0,0.0,0,0.0,1503744.0,1503744.0,8320.0,16.0,0.9980806142034548,12288.0,4096.0,20.32,1955.743999999999,1272832.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",352,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.512,1964.255999999999,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",353,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,1966.815999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",354,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.624,1969.439999999999,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",355,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,1972.831999999999,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",356,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,1975.231999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",357,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,1977.791999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",358,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.072,1980.863999999999,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",359,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,1983.4239999999988,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",360,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17146240.0,29952.0,22.88,2006.303999999999,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",361,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,3.008,2009.311999999999,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",362,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17144320.0,29120.0,23.2,2032.511999999999,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",363,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,2035.1039999999991,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",364,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17832192.0,2048.0,23.328,2058.4319999999993,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",365,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,2061.0239999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",366,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.656,2063.6799999999994,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",367,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.584,2067.263999999999,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",368,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,2069.6639999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",369,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,2072.2239999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",370,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.072,2075.2959999999994,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",371,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,2077.8879999999995,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",372,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.448,2086.3359999999993,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",373,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.576,2094.9119999999994,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",374,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.896,2103.8079999999995,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",375,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.296,2107.1039999999994,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",376,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.008,2110.111999999999,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",377,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.808,2113.919999999999,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",378,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,2116.959999999999,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",379,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,2119.519999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",380,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,2122.623999999999,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",381,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,2.976,2125.599999999999,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",382,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.84,2129.439999999999,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",383,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,2132.543999999999,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",384,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,2135.103999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",385,16384.0,1503744.0,0.0,0,0.0,1503744.0,1503744.0,8320.0,16.0,0.9980806142034548,12288.0,4096.0,20.16,2155.2639999999988,1272832.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",386,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.704,2163.967999999999,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",387,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,2166.527999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",388,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,2169.087999999999,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",389,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,2172.4799999999987,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",390,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,2174.9119999999984,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",391,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,2177.5679999999984,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",392,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,2180.5119999999984,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",393,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.624,2183.135999999998,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",394,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17148032.0,29152.0,22.88,2206.0159999999983,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",395,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.944,2208.959999999998,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",396,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17156736.0,29600.0,23.2,2232.159999999998,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",397,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.688,2234.847999999998,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",398,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17846784.0,2048.0,23.488,2258.335999999998,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",399,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,2260.927999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",400,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.592,2263.519999999998,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",401,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.456,2266.9759999999983,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",402,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,2269.407999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",403,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,2271.967999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",404,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,2274.943999999998,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",405,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,2277.5359999999982,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",406,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.736,2286.271999999998,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",407,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.896,2295.1679999999983,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",408,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.832,2303.999999999998,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",409,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.2,2307.199999999998,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",410,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.168,2310.367999999998,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",411,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,2314.0159999999983,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",412,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,2317.0879999999984,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",413,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,2319.6799999999985,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",414,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,2322.7839999999983,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",415,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,2325.8239999999983,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",416,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.584,2329.407999999998,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",417,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,2332.447999999998,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",418,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,2335.007999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",419,16384.0,1503744.0,0.0,0,0.0,1503744.0,1503744.0,8320.0,16.0,0.9980806142034548,12288.0,4096.0,20.16,2355.167999999998,1272832.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",420,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,9.12,2364.2879999999977,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",421,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,2366.8479999999977,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",422,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.656,2369.5039999999976,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",423,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,2372.8959999999975,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",424,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.496,2375.3919999999976,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",425,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,2377.9839999999976,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",426,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.072,2381.0559999999978,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",427,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,2383.647999999998,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",428,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17145600.0,29760.0,22.944,2406.591999999998,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",429,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.944,2409.535999999998,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",430,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17151616.0,29728.0,22.752,2432.2879999999977,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",431,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.72,2435.0079999999975,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",432,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17833856.0,2048.0,23.104,2458.1119999999974,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",433,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,2460.6719999999973,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",434,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,2463.2319999999972,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",435,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.52,2466.751999999997,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",436,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,2469.215999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",437,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,2471.743999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",438,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.104,2474.847999999997,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",439,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.752,2477.5999999999967,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",440,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.896,2486.495999999997,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",441,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.832,2495.327999999997,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",442,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.384,2503.711999999997,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",443,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,2506.8159999999966,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",444,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.136,2509.9519999999966,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",445,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,2513.5999999999967,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",446,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,2516.7039999999965,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",447,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,2519.3279999999963,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",448,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,2522.3999999999965,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",449,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.072,2525.4719999999966,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",450,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,2529.1199999999967,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",451,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,2532.1599999999967,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",452,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,2534.7199999999966,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",453,16384.0,1503744.0,0.0,0,0.0,1503744.0,1503744.0,8320.0,16.0,0.9980806142034548,12288.0,4096.0,20.064,2554.7839999999965,1272832.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",454,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.384,2563.1679999999965,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",455,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,2565.7599999999966,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",456,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.624,2568.3839999999964,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",457,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.424,2571.8079999999964,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",458,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.496,2574.3039999999964,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",459,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,2576.9279999999962,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",460,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.136,2580.063999999996,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",461,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.688,2582.7519999999963,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",462,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17145216.0,30176.0,24.896,2607.6479999999965,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",463,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.912,2610.5599999999963,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",464,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17150336.0,28960.0,24.064,2634.623999999996,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",465,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.72,2637.343999999996,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",466,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17834624.0,2048.0,23.136,2660.479999999996,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",467,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,2663.039999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",468,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,2665.5679999999957,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",469,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.52,2669.0879999999956,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",470,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,2671.4879999999957,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",471,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,2674.0479999999957,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",472,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.008,2677.0559999999955,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",473,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,2679.6479999999956,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",474,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.608,2688.2559999999958,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",475,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.896,2697.151999999996,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",476,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.576,2705.727999999996,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",477,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,2708.799999999996,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",478,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,2.944,2711.743999999996,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",479,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.68,2715.423999999996,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",480,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,2718.4319999999957,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",481,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,2721.023999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",482,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,2724.0639999999958,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",483,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.008,2727.0719999999956,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",484,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.68,2730.7519999999954,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",485,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,2733.7919999999954,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",486,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,2736.3519999999953,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",487,16384.0,1503744.0,0.0,0,0.0,1503744.0,1503744.0,8320.0,16.0,0.9980806142034548,12288.0,4096.0,20.224,2756.5759999999955,1272832.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",488,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.48,2765.0559999999955,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",489,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,2767.6479999999956,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",490,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.72,2770.3679999999954,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",491,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.456,2773.8239999999955,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",492,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,2776.2239999999956,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",493,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,2778.7839999999956,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",494,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.04,2781.8239999999955,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",495,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,2784.4159999999956,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",496,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17138432.0,28992.0,22.304,2806.7199999999957,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",497,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,3.04,2809.7599999999957,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",498,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17155456.0,30112.0,24.864,2834.6239999999957,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",499,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,2837.215999999996,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",500,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17837696.0,2048.0,23.136,2860.3519999999958,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",501,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,2862.943999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",502,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.656,2865.599999999996,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",503,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,2868.9919999999956,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",504,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.528,2871.5199999999954,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",505,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,2874.0799999999954,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",506,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.008,2877.087999999995,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",507,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,2879.6799999999953,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",508,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.672,2888.3519999999953,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",509,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.832,2897.183999999995,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",510,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.928,2906.111999999995,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",511,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,2909.151999999995,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",512,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,2912.191999999995,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",513,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.68,2915.871999999995,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",514,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,2918.911999999995,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",515,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,2921.4719999999948,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",516,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,2924.5759999999946,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",517,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.072,2927.6479999999947,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",518,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,2931.295999999995,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",519,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,2934.367999999995,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",520,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.688,2937.055999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",521,16352.0,1503660.0,0.0,0,0.0,1503660.0,1503660.0,8323.0,16.0,0.9980813047127953,12288.0,4096.0,20.16,2957.215999999995,1272815.0,198141.0,16352.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",522,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.896,2966.111999999995,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",523,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,2968.671999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",524,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.592,2971.263999999995,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",525,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,2974.655999999995,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",526,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,2977.055999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",527,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,2979.615999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",528,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.04,2982.655999999995,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",529,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.528,2985.1839999999947,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",530,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17142016.0,28832.0,23.104,3008.2879999999946,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",531,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.912,3011.1999999999944,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",532,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17146880.0,28832.0,23.168,3034.3679999999945,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",533,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.688,3037.0559999999946,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",534,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17844864.0,2048.0,23.232,3060.2879999999946,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",535,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,3062.8799999999947,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",536,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.688,3065.5679999999948,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",537,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.552,3069.119999999995,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",538,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,3071.487999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",539,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,3074.079999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",540,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.008,3077.0879999999947,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",541,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,3079.6479999999947,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",542,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.832,3088.4799999999946,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",543,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.416,3096.8959999999947,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",544,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.416,3105.311999999995,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",545,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,3108.4159999999947,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",546,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,2.976,3111.391999999995,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",547,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,3115.039999999995,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",548,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,3118.079999999995,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",549,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,3120.639999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",550,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,3123.711999999995,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",551,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.136,3126.847999999995,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",552,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,3130.495999999995,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",553,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.2,3133.695999999995,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",554,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,3136.287999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",555,16352.0,1503660.0,0.0,0,0.0,1503660.0,1503660.0,8323.0,16.0,0.9980813047127953,12288.0,4096.0,20.256,3156.543999999995,1272815.0,198141.0,16352.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",556,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,9.184,3165.727999999995,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",557,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,3168.287999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",558,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,3170.847999999995,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",559,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,3174.239999999995,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",560,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,3176.7039999999947,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",561,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.688,3179.391999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",562,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.072,3182.463999999995,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",563,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,3185.055999999995,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",564,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17146240.0,29312.0,22.368,3207.423999999995,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",565,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,3.008,3210.431999999995,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",566,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17142528.0,29408.0,22.912,3233.3439999999946,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",567,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,3235.9359999999947,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",568,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17834240.0,2048.0,23.616,3259.5519999999947,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",569,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,3262.1119999999946,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",570,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.592,3264.7039999999947,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",571,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.424,3268.1279999999947,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",572,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,3270.5599999999945,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",573,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,3273.1199999999944,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",574,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.008,3276.1279999999942,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",575,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.752,3278.879999999994,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",576,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,3287.647999999994,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",577,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.416,3296.0639999999944,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",578,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.8,3304.8639999999946,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",579,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,3307.9999999999945,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",580,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.008,3311.0079999999944,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",581,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.616,3314.6239999999943,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",582,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.168,3317.7919999999945,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",583,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,3320.3839999999946,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",584,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,3323.4239999999945,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",585,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,2.976,3326.3999999999946,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",586,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.744,3330.143999999995,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",587,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,3333.1839999999947,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",588,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.784,3335.967999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",589,16384.0,1503744.0,0.0,0,0.0,1503744.0,1503744.0,8320.0,16.0,0.9980806142034548,12288.0,4096.0,20.128,3356.095999999995,1272832.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",590,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,3364.863999999995,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",591,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,3367.423999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",592,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.624,3370.0479999999948,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",593,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,3373.4399999999946,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",594,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,3375.8399999999947,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",595,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,3378.3999999999946,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",596,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,3381.3759999999947,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",597,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,3383.9359999999947,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",598,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17148256.0,28640.0,22.048,3405.9839999999945,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",599,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.944,3408.9279999999944,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",600,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17149824.0,28896.0,23.68,3432.6079999999943,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",601,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.656,3435.263999999994,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",602,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17833344.0,2048.0,22.816,3458.079999999994,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",603,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,3460.671999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",604,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,3463.199999999994,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",605,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,3466.5919999999937,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",606,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,3469.0239999999935,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",607,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,3471.5839999999935,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",608,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,3474.5599999999936,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",609,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,3477.1519999999937,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",610,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.736,3485.8879999999936,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",611,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.832,3494.7199999999934,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",612,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.544,3503.2639999999933,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",613,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,3506.3039999999933,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",614,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,2.976,3509.2799999999934,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",615,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.744,3513.0239999999935,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",616,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,3516.0639999999935,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",617,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,3518.6559999999936,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",618,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,3521.7599999999934,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",619,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.136,3524.8959999999934,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",620,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.68,3528.575999999993,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",621,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,3531.711999999993,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",622,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,3534.271999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",623,16384.0,1503744.0,0.0,0,0.0,1503744.0,1503744.0,8320.0,16.0,0.9980806142034548,12288.0,4096.0,20.16,3554.431999999993,1272832.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",624,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.576,3563.007999999993,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",625,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,3565.599999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",626,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,3568.159999999993,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",627,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,3571.551999999993,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",628,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,3574.015999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",629,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,3576.5759999999927,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",630,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,3579.551999999993,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",631,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.624,3582.1759999999927,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",632,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17146560.0,29440.0,22.976,3605.1519999999928,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",633,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,3.072,3608.223999999993,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",634,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17144832.0,28992.0,23.36,3631.583999999993,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",635,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.624,3634.207999999993,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",636,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17835648.0,2048.0,23.36,3657.567999999993,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",637,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,3660.159999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",638,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,3662.719999999993,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",639,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.424,3666.143999999993,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",640,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,3668.543999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",641,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,3671.103999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",642,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.008,3674.111999999993,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",643,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,3676.6719999999927,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",644,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.576,3685.2479999999928,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",645,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.416,3693.663999999993,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",646,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,9.024,3702.687999999993,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",647,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,3705.7919999999926,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",648,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,2.976,3708.7679999999928,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",649,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.68,3712.4479999999926,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",650,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,3715.4879999999926,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",651,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,3718.0479999999925,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",652,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,3721.0879999999925,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",653,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,2.976,3724.0639999999926,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",654,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,3727.7119999999927,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",655,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,3730.7519999999927,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",656,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.528,3733.2799999999925,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",657,16352.0,1503660.0,0.0,0,0.0,1503660.0,1503660.0,8323.0,16.0,0.9980813047127953,12288.0,4096.0,20.16,3753.4399999999923,1272815.0,198141.0,16352.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",658,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.928,3762.367999999992,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",659,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,3764.9599999999923,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",660,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.624,3767.583999999992,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",661,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.328,3770.911999999992,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",662,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,3773.311999999992,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",663,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,3775.871999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",664,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,3778.847999999992,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",665,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.656,3781.503999999992,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",666,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17147520.0,28992.0,22.72,3804.223999999992,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",667,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.944,3807.167999999992,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",668,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17154432.0,29376.0,22.816,3829.9839999999917,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",669,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.56,3832.5439999999917,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",670,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17833728.0,2048.0,22.976,3855.519999999992,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",671,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,3858.0799999999917,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",672,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.496,3860.575999999992,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",673,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,3863.9679999999917,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",674,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,3866.3679999999918,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",675,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,3868.8959999999915,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",676,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,3871.8399999999915,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",677,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,3874.3999999999915,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",678,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.704,3883.1039999999916,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",679,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.544,3891.6479999999915,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",680,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.64,3900.2879999999914,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",681,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.2,3903.487999999991,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",682,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,3906.527999999991,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",683,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,3910.1759999999913,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",684,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,3913.2479999999914,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",685,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,3915.871999999991,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",686,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,3918.9439999999913,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",687,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,3921.9839999999913,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",688,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,3925.6319999999914,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",689,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.168,3928.7999999999915,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",690,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,3931.3919999999916,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",691,16384.0,1503744.0,0.0,0,0.0,1503744.0,1503744.0,8320.0,16.0,0.9980806142034548,12288.0,4096.0,20.096,3951.4879999999916,1272832.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",692,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,3960.2559999999917,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",693,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,3962.8479999999918,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",694,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,3965.4079999999917,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",695,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.456,3968.863999999992,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",696,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,3971.231999999992,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",697,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,3973.7919999999917,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",698,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.072,3976.863999999992,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",699,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.688,3979.551999999992,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",700,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17148416.0,29152.0,22.368,4001.919999999992,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",701,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.976,4004.895999999992,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",702,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17151360.0,28864.0,22.464,4027.359999999992,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",703,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,4029.951999999992,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",704,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17835264.0,2048.0,22.688,4052.639999999992,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",705,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.656,4055.295999999992,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",706,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,4057.823999999992,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",707,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.36,4061.183999999992,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",708,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,4063.583999999992,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",709,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,4066.175999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",710,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.104,4069.279999999992,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",711,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.624,4071.903999999992,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",712,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.896,4080.799999999992,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",713,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.96,4089.759999999992,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",714,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,4098.527999999992,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",715,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,4101.535999999992,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",716,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,4104.575999999992,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",717,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,4108.223999999992,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",718,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.2,4111.423999999992,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",719,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.656,4114.079999999992,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",720,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,4117.215999999992,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",721,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.168,4120.383999999992,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",722,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,4124.031999999992,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",723,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.168,4127.199999999992,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",724,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,4129.791999999991,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",725,16384.0,1503744.0,0.0,0,0.0,1503744.0,1503744.0,8320.0,16.0,0.9980806142034548,12288.0,4096.0,20.192,4149.983999999991,1272832.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",726,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,4158.751999999991,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",727,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,4161.311999999992,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",728,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,4163.839999999992,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",729,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,4167.231999999992,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",730,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.336,4169.567999999992,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",731,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,4172.159999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",732,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.072,4175.231999999992,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",733,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,4177.791999999992,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",734,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17148928.0,29248.0,24.32,4202.111999999992,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",735,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.944,4205.055999999992,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",736,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17151712.0,29280.0,23.904,4228.959999999993,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",737,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,4231.551999999992,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",738,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17831936.0,2048.0,23.328,4254.879999999993,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",739,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,4257.439999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",740,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,4259.999999999994,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",741,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.424,4263.423999999994,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",742,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,4265.791999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",743,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,4268.383999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",744,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.008,4271.3919999999935,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",745,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,4273.983999999993,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",746,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.544,4282.527999999993,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",747,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,9.216,4291.743999999993,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",748,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.576,4300.319999999993,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",749,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,4303.3919999999935,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",750,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.008,4306.399999999993,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",751,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.744,4310.143999999993,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",752,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,4313.215999999993,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",753,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.784,4315.999999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",754,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,4319.039999999993,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",755,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.008,4322.0479999999925,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",756,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,4325.695999999993,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",757,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,4328.735999999993,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",758,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,4331.295999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",759,16384.0,1503744.0,0.0,0,0.0,1503744.0,1503744.0,8320.0,16.0,0.9980806142034548,12288.0,4096.0,20.128,4351.423999999993,1272832.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",760,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.512,4359.935999999992,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",761,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,4362.495999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",762,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,4365.055999999993,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",763,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,4368.447999999993,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",764,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,4370.847999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",765,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.496,4373.343999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",766,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,4376.319999999992,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",767,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.688,4379.0079999999925,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",768,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17137920.0,29920.0,22.592,4401.599999999992,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",769,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.944,4404.543999999993,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",770,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17153024.0,28640.0,23.648,4428.191999999993,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",771,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.56,4430.751999999993,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",772,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17832448.0,2048.0,22.976,4453.727999999993,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",773,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,4456.287999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",774,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,4458.815999999993,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",775,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,4462.207999999993,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",776,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.528,4464.7359999999935,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",777,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.496,4467.231999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",778,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.136,4470.367999999994,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",779,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.784,4473.151999999994,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",780,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.832,4481.983999999994,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",781,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.448,4490.431999999994,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",782,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,9.12,4499.551999999994,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",783,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,4502.687999999995,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",784,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,2.976,4505.663999999994,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",785,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,4509.311999999994,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",786,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,4512.351999999994,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",787,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,4514.911999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",788,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.168,4518.0799999999945,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",789,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.104,4521.183999999995,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",790,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,4524.831999999995,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",791,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,4527.903999999995,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",792,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.656,4530.559999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",793,16384.0,1503744.0,0.0,0,0.0,1503744.0,1503744.0,8320.0,16.0,0.9980806142034548,12288.0,4096.0,20.16,4550.719999999995,1272832.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",794,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.736,4559.455999999995,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",795,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.528,4561.983999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",796,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,4564.543999999995,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",797,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.584,4568.127999999995,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",798,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.496,4570.623999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",799,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,4573.183999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",800,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,4576.127999999996,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",801,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,4578.719999999996,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",802,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17150880.0,29376.0,23.392,4602.1119999999955,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",803,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.912,4605.023999999996,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",804,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17150720.0,28608.0,23.616,4628.639999999996,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",805,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,4631.231999999995,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",806,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17838464.0,2048.0,23.392,4654.623999999995,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",807,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,4657.183999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",808,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.592,4659.775999999995,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",809,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.424,4663.199999999995,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",810,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.496,4665.695999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",811,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.688,4668.3839999999955,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",812,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.04,4671.423999999995,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",813,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,4673.983999999996,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",814,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.832,4682.815999999996,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",815,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,4691.583999999996,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",816,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.416,4699.999999999996,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",817,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,4703.0719999999965,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",818,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.008,4706.079999999996,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",819,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,4709.727999999996,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",820,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,4712.767999999996,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",821,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,4715.327999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",822,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,4718.367999999997,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",823,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.008,4721.375999999997,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",824,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,4725.023999999997,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",825,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,4728.063999999997,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",826,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,4730.655999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",827,16384.0,1503744.0,0.0,0,0.0,1503744.0,1503744.0,8320.0,16.0,0.9980806142034548,12288.0,4096.0,20.128,4750.783999999996,1272832.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",828,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.8,4759.583999999996,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",829,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,4762.143999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",830,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,4764.671999999997,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",831,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,4768.063999999997,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",832,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.496,4770.559999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",833,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,4773.119999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",834,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.072,4776.191999999997,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",835,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.752,4778.943999999998,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",836,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17139072.0,29664.0,22.976,4801.919999999997,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",837,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.944,4804.863999999998,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",838,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17143168.0,29632.0,22.72,4827.583999999998,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",839,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,4830.175999999998,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",840,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17834624.0,2048.0,23.136,4853.311999999998,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",841,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,4855.8719999999985,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",842,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.592,4858.463999999998,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",843,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.456,4861.919999999998,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",844,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,4864.287999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",845,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,4866.847999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",846,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,4869.823999999999,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",847,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,4872.415999999998,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",848,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,4881.183999999998,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",849,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.48,4889.663999999998,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",850,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.512,4898.175999999998,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",851,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,4901.1839999999975,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",852,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,4904.223999999997,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",853,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.808,4908.031999999997,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",854,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,4911.039999999997,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",855,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,4913.599999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",856,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,4916.639999999998,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",857,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,4919.679999999998,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",858,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.616,4923.295999999998,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",859,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,4926.3359999999975,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",860,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,4928.895999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",861,16384.0,1503744.0,0.0,0,0.0,1503744.0,1503744.0,8320.0,16.0,0.9980806142034548,12288.0,4096.0,20.288,4949.1839999999975,1272832.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",862,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.576,4957.7599999999975,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",863,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,4960.351999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",864,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.688,4963.039999999997,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",865,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,4966.431999999997,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",866,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,4968.863999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",867,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.496,4971.359999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",868,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,4974.335999999997,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",869,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.688,4977.023999999997,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",870,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17151232.0,29024.0,22.592,4999.615999999996,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",871,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,3.04,5002.655999999996,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",872,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17154688.0,29440.0,23.648,5026.303999999996,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",873,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.56,5028.863999999997,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",874,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17828608.0,2048.0,22.976,5051.8399999999965,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",875,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,5054.399999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",876,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.624,5057.023999999997,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",877,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.488,5060.511999999997,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",878,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,5062.879999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",879,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,5065.471999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",880,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,5068.415999999997,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",881,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,5071.007999999997,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",882,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.64,5079.647999999997,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",883,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.512,5088.159999999997,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",884,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.512,5096.671999999997,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",885,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,5099.679999999997,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",886,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.008,5102.6879999999965,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",887,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,5106.335999999997,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",888,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,5109.407999999997,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",889,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,5111.967999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",890,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,5115.1039999999975,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",891,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.072,5118.175999999998,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",892,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.616,5121.791999999998,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",893,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,5124.863999999998,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",894,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,5127.455999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",895,16384.0,1503744.0,0.0,0,0.0,1503744.0,1503744.0,8320.0,16.0,0.9980806142034548,12288.0,4096.0,20.224,5147.679999999998,1272832.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",896,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.48,5156.159999999997,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",897,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,5158.7199999999975,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",898,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,5161.247999999998,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",899,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.488,5164.735999999998,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",900,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,5167.135999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",901,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,5169.7599999999975,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",902,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,5172.703999999998,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",903,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,5175.295999999998,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",904,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17137280.0,29184.0,22.432,5197.727999999997,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",905,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,3.072,5200.799999999997,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",906,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17143808.0,30048.0,22.976,5223.775999999997,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",907,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,5226.367999999997,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",908,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17827712.0,2048.0,23.392,5249.759999999997,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",909,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,5252.319999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",910,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,5254.879999999997,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",911,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.424,5258.303999999997,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",912,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,5260.671999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",913,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,5263.263999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",914,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.04,5266.303999999997,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",915,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,5268.863999999998,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",916,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,5277.631999999998,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",917,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.48,5286.111999999997,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",918,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.704,5294.815999999997,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",919,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,5297.855999999997,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",920,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,5300.895999999997,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",921,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.68,5304.575999999997,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",922,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,5307.679999999998,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",923,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.528,5310.207999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",924,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,5313.247999999998,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",925,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.104,5316.351999999998,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",926,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,5319.999999999998,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",927,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,5323.071999999998,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",928,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,5325.695999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",929,16384.0,1503744.0,0.0,0,0.0,1503744.0,1503744.0,8320.0,16.0,0.9980806142034548,12288.0,4096.0,20.32,5346.015999999998,1272832.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",930,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.48,5354.495999999997,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",931,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.688,5357.1839999999975,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",932,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.656,5359.839999999997,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",933,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,5363.231999999997,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",934,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,5365.663999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",935,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,5368.223999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",936,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,5371.167999999998,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",937,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,5373.7599999999975,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",938,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17149568.0,29056.0,23.488,5397.247999999998,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",939,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.912,5400.159999999998,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",940,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17151232.0,28864.0,22.784,5422.943999999998,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",941,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,5425.535999999997,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",942,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17836928.0,2048.0,22.784,5448.319999999997,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",943,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,5450.879999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",944,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,5453.407999999998,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",945,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.456,5456.863999999998,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",946,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,5459.263999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",947,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,5461.823999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",948,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,5464.767999999998,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",949,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,5467.359999999998,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",950,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.8,5476.159999999998,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",951,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.96,5485.119999999998,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",952,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.896,5494.015999999998,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",953,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.168,5497.1839999999975,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",954,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,2.976,5500.159999999997,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",955,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,5503.807999999997,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",956,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,5506.815999999997,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",957,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.528,5509.343999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",958,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,5512.351999999997,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",959,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,5515.391999999997,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",960,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,5519.039999999997,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",961,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,5522.079999999997,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",962,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,5524.639999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",963,16352.0,1503660.0,0.0,0,0.0,1503660.0,1503660.0,8323.0,16.0,0.9980813047127953,12288.0,4096.0,20.096,5544.735999999997,1272815.0,198141.0,16352.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",964,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.864,5553.599999999997,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",965,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.752,5556.351999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",966,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,5558.879999999997,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",967,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.424,5562.303999999997,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",968,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,5564.671999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",969,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,5567.199999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",970,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,5570.175999999998,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",971,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.624,5572.799999999997,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",972,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17145856.0,28832.0,22.368,5595.167999999998,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",973,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,3.008,5598.175999999998,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",974,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17144704.0,29184.0,22.88,5621.055999999998,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",975,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.656,5623.711999999998,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",976,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17840000.0,2048.0,23.008,5646.7199999999975,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",977,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,5649.279999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",978,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.656,5651.935999999998,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",979,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.36,5655.295999999998,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",980,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,5657.727999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",981,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,5660.383999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",982,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,5663.359999999997,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",983,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,5665.951999999997,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",984,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.736,5674.6879999999965,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",985,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.608,5683.295999999997,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",986,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.448,5691.743999999997,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",987,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,5694.879999999997,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",988,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.072,5697.9519999999975,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",989,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.616,5701.5679999999975,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",990,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,5704.671999999998,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",991,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,5707.231999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",992,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,5710.239999999998,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",993,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.104,5713.343999999998,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",994,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,5716.991999999998,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",995,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,5720.031999999998,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",996,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.688,5722.719999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",997,16320.0,1503576.0,0.0,0,0.0,1503576.0,1503576.0,8323.0,16.0,0.9980813047127953,12288.0,4096.0,20.256,5742.975999999999,1272798.0,198138.0,16320.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",998,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.832,5751.807999999999,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",999,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,5754.3679999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1000,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,5756.928,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1001,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.488,5760.416,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1002,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.496,5762.912,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1003,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,5765.472000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1004,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,5768.448,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1005,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,5771.008000000001,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1006,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17149568.0,29120.0,24.096,5795.104,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1007,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,3.04,5798.144,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1008,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17148032.0,29120.0,23.872,5822.0160000000005,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1009,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,5824.608,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1010,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17833728.0,2048.0,23.776,5848.384,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1011,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,5851.008,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1012,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,5853.568,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1013,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.456,5857.024,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1014,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,5859.424,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1015,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,5861.984,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1016,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,5864.96,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1017,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,5867.552,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1018,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.672,5876.223999999999,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1019,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.544,5884.767999999999,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1020,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.832,5893.599999999999,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1021,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,5896.639999999999,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1022,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.104,5899.744,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1023,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,5903.392,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1024,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,5906.4,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1025,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,5909.023999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1026,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,5912.128,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1027,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,5915.168,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1028,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,5918.816,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1029,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.168,5921.9839999999995,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1030,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.688,5924.672,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",1031,16384.0,1503744.0,0.0,0,0.0,1503744.0,1503744.0,8320.0,16.0,0.9980806142034548,12288.0,4096.0,20.16,5944.831999999999,1272832.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1032,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,5953.599999999999,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1033,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,5956.223999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1034,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.592,5958.815999999999,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1035,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.328,5962.143999999999,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1036,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,5964.512,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1037,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,5967.04,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1038,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.072,5970.112,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1039,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,5972.704,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1040,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17137408.0,29120.0,22.336,5995.04,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1041,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.976,5998.016,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1042,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17153024.0,29600.0,24.256,6022.272,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1043,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.624,6024.896,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1044,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17832704.0,2048.0,23.232,6048.128,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1045,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,6050.688,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1046,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,6053.216,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1047,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,6056.608,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1048,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,6058.976000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1049,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,6061.504000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1050,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.04,6064.544000000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1051,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.72,6067.264000000001,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1052,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.448,6075.712000000001,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1053,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.512,6084.224000000001,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1054,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.928,6093.152000000001,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1055,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,6096.288000000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1056,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.008,6099.296000000001,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1057,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.776,6103.072000000001,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1058,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,6106.176000000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1059,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,6108.736000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1060,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.2,6111.9360000000015,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1061,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.008,6114.944000000001,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1062,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.68,6118.624000000002,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1063,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,6121.696000000002,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1064,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.528,6124.224000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",1065,16384.0,1503744.0,0.0,0,0.0,1503744.0,1503744.0,8320.0,16.0,0.9980806142034548,12288.0,4096.0,20.416,6144.640000000002,1272832.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1066,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,6153.408000000002,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1067,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,6155.968000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1068,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.624,6158.592000000002,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1069,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.424,6162.016000000002,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1070,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,6164.384000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1071,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,6166.944000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1072,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,6169.888000000004,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1073,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,6172.480000000003,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1074,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17156864.0,28544.0,22.464,6194.944000000003,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1075,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.912,6197.856000000003,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1076,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17149184.0,28640.0,23.328,6221.184000000004,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1077,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.688,6223.872000000004,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1078,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17834880.0,2048.0,23.616,6247.488000000004,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1079,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,6250.048000000004,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1080,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,6252.608000000005,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1081,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,6256.000000000005,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1082,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,6258.400000000004,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1083,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,6260.928000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1084,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.04,6263.968000000004,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1085,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,6266.528000000005,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1086,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.48,6275.008000000004,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1087,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.48,6283.488000000004,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1088,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.352,6291.840000000004,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1089,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,6294.976000000004,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1090,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,6298.016000000004,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1091,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.616,6301.632000000004,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1092,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.2,6304.832000000004,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1093,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,6307.424000000004,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1094,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,6310.464000000004,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1095,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.008,6313.472000000003,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1096,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.584,6317.056000000003,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1097,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,6320.128000000003,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1098,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,6322.688000000004,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",1099,16384.0,1503744.0,0.0,0,0.0,1503744.0,1503744.0,8320.0,16.0,0.9980806142034548,12288.0,4096.0,20.32,6343.008000000003,1272832.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1100,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.8,6351.808000000004,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1101,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,6354.368000000004,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1102,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,6356.896000000004,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1103,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.552,6360.448000000004,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1104,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,6362.848000000004,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1105,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,6365.408000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1106,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,6368.352000000004,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1107,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,6370.912000000005,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1108,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17145856.0,29472.0,23.296,6394.208000000005,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1109,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.944,6397.1520000000055,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1110,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17135008.0,29536.0,22.72,6419.872000000006,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1111,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,6422.464000000005,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1112,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17828608.0,2048.0,23.488,6445.952000000006,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1113,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.752,6448.704000000006,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1114,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.592,6451.296000000006,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1115,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.36,6454.656000000005,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1116,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,6457.120000000005,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1117,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,6459.680000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1118,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,6462.656000000005,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1119,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,6465.248000000005,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1120,33088000.0,65856000.0,576000.0,0,0.0,66432000.0,66432000.0,88000.0,2056000.0,0.041044776119402986,132904352.0,182592.0,147.776,6613.024000000005,256000.0,0.0,32800000.0,288000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1121,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,6615.072000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1122,258.0,0.0,516.0,0,0.0,516.0,516.0,0.0,4.0,0.0,64.0,64.0,2.624,6617.6960000000045,0.0,0.0,0.0,258.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",1123,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.4,6620.096000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",1124,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,128000.0,128000.0,2.688,6622.784000000004,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",1125,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,6624.832000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",1126,48128.0,0.0,96256.0,0,0.0,96256.0,96256.0,512.0,1512.0,0.25296442687747034,129024.0,8192.0,4.0,6628.832000000004,0.0,0.0,0.0,48128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",1127,27648.0,0.0,55296.0,0,0.0,55296.0,55296.0,2112.0,8610.0,0.1969781757134863,527360.0,0.0,4.672,6633.5040000000035,0.0,0.0,0.0,27648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",1128,16348.0,0.0,32696.0,0,0.0,32696.0,32696.0,512.0,1512.0,0.25296442687747034,129024.0,8192.0,3.936,6637.440000000003,0.0,0.0,0.0,16348.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",1129,33792.0,0.0,67584.0,0,0.0,67584.0,67584.0,2112.0,8802.0,0.19351291918636612,527360.0,0.0,4.8,6642.240000000003,0.0,0.0,0.0,33792.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",1130,16131.0,0.0,32262.0,0,0.0,32262.0,32262.0,512.0,1512.0,0.25296442687747034,129024.0,8192.0,3.808,6646.048000000003,0.0,0.0,0.0,16131.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",1131,29696.0,0.0,59392.0,0,0.0,59392.0,59392.0,2112.0,8674.0,0.19580938253291302,527360.0,0.0,4.704,6650.752000000003,0.0,0.0,0.0,29696.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",1132,16129.0,0.0,32258.0,0,0.0,32258.0,32258.0,512.0,1512.0,0.25296442687747034,129024.0,8192.0,3.936,6654.688000000003,0.0,0.0,0.0,16129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",1133,27648.0,0.0,55296.0,0,0.0,55296.0,55296.0,2112.0,8610.0,0.1969781757134863,527360.0,32.0,4.864,6659.552000000002,0.0,0.0,0.0,27648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",1134,352.0,0.0,704.0,0,0.0,704.0,704.0,0.0,3.0,0.0,1056.0,128.0,3.008,6662.560000000002,0.0,0.0,0.0,352.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",1135,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.048,6664.608000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",1136,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,11.0,0.9829984544049459,128.0,0.0,4.32,6668.928000000002,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",1137,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.144,6671.072000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",1138,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,11.0,0.9829984544049459,128.0,0.0,4.416,6675.488000000002,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 1>(detail::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, detail::TensorInfo<T1, T2>, T2, detail::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",1139,40292.0,0.0,80584.0,0,0.0,80584.0,80584.0,9061.0,2108.0,0.8112633181126332,131808.0,1824.0,6.24,6681.728000000002,0.0,0.0,0.0,40292.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::radixSortKVInPlace<(int)-2, (int)-1, 32, 4, float, long, unsigned int>(detail::TensorInfo<T5, T7>, T7, T7, T7, detail::TensorInfo<T6, T7>, T7, bool)",1140,64.0,0.0,128.0,0,0.0,128.0,128.0,458.0,8.0,0.9828326180257511,640.0,0.0,5.984,6687.712000000002,0.0,0.0,0.0,64.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1141,64000.0,0.0,128000.0,0,0.0,128000.0,128000.0,0.0,3000.0,0.0,130016.0,8000.0,3.936,6691.648000000002,0.0,0.0,0.0,64000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",1142,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,768.0,0.0,160000.0,0.0,2.944,6694.592000000002,0.0,0.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"native::<unnamed>::fill_reverse_indices_kernel(long *, int, detail::IntDivider<unsigned int>)",1143,128768.0,0.0,257536.0,0,0.0,257536.0,257536.0,0.0,1000.0,0.0,0.0,256000.0,2.592,6697.184000000002,0.0,0.0,0.0,128768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",1144,387238.0,0.0,774476.0,0,0.0,774476.0,774476.0,64512.0,1000.0,0.9847356209549396,128000.0,0.0,4.032,6701.216000000002,0.0,0.0,0.0,387238.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",1145,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,2.592,6703.808000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",1146,29568.0,0.0,59136.0,0,0.0,59136.0,59136.0,10414.0,4264.0,0.7094972067039106,407552.0,329856.0,14.624,6718.432000000002,0.0,0.0,0.0,29568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",1147,14400.0,0.0,28800.0,0,0.0,28800.0,28800.0,3418.0,4264.0,0.4449362145274668,407552.0,390144.0,13.056,6731.488000000001,0.0,0.0,0.0,14400.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",1148,15744.0,0.0,31488.0,0,0.0,31488.0,31488.0,4798.0,4232.0,0.5313399778516058,405504.0,390144.0,14.112,6745.600000000001,0.0,0.0,0.0,15744.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",1149,15744.0,0.0,31488.0,0,0.0,31488.0,31488.0,4798.0,4237.0,0.5310459324847814,405504.0,326272.0,14.016,6759.616000000001,0.0,0.0,0.0,15744.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",1150,524494.0,1061280.0,152988.0,0,0.0,1214268.0,1214268.0,132.0,1312.0,0.09141274238227147,248320.0,128000.0,18.72,6778.336000000001,133280.0,32000.0,448000.0,76494.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<float, 1>>(T1, int)",1151,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,0.0,416.0,2.144,6780.480000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<float, std::plus<float>>::Policy900, const float *, float *, at_cuda_detail::ScanTileState<float, 1>, std::plus<float>, at_cuda_detail::NullType, unsigned int, float, 0>(T2, T3, T4, int, T5, T6, T7)",1152,2177.0,85371.0,4354.0,0,0.0,89725.0,89725.0,4349.0,2053.0,0.6793189628241174,134400.0,129024.0,4.032,6784.5120000000015,85371.0,0.0,0.0,2177.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1153,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,512.0,0.0,128000.0,31808.0,2.752,6787.264000000002,0.0,0.0,0.0,256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::unrolled_elementwise_kernel<native::FillFunctor<bool>, std::array<char *, 1>, 16, TrivialOffsetCalculator<0, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithoutCast, memory::StoreWithoutCast>(int, T1, T2, T4, T5, T6, T7)",1154,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.112,6789.376000000002,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1155,68096.0,0.0,136192.0,0,0.0,136192.0,136192.0,0.0,3000.0,0.0,288000.0,12480.0,9.056,6798.432000000002,0.0,0.0,0.0,68096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",1156,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,768.0,0.0,160000.0,0.0,2.816,6801.248000000001,0.0,0.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",1157,524497.0,1061280.0,152994.0,0,0.0,1214274.0,1214274.0,132.0,1312.0,0.09141274238227147,242176.0,128000.0,18.688,6819.9360000000015,133280.0,32000.0,448000.0,76497.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",1158,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,251.0,0.19808306709265175,128000.0,32.0,9.984,6829.920000000002,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1159,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.432,6832.352000000002,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",1160,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,251.0,0.19808306709265175,128000.0,32.0,9.728,6842.080000000002,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1161,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.4,6844.480000000001,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",1162,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.592,6847.072000000001,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",1163,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.296,6850.368000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",1164,1536.0,36576.0,3072.0,0,0.0,39648.0,39648.0,62.0,251.0,0.19808306709265175,128000.0,32.0,9.856,6860.224000000001,36576.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",1165,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.432,6862.656000000001,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1166,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.368,6865.024000000001,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",1167,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.296,6868.3200000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",1168,448000.0,640000.0,320000.0,0,0.0,960000.0,960000.0,0.0,1000.0,0.0,0.0,128000.0,2.784,6871.104000000001,0.0,64000.0,288000.0,160000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1169,196945.0,327680.0,66210.0,0,0.0,393890.0,393890.0,0.0,768.0,0.0,256000.0,0.0,3.776,6874.880000000001,0.0,0.0,163840.0,33105.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",1170,18048.0,0.0,36096.0,0,0.0,36096.0,36096.0,124.0,251.0,0.33066666666666666,128000.0,32.0,12.832,6887.712000000001,0.0,0.0,0.0,18048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",1171,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.432,6890.144000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",1172,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.432,6892.576000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",1173,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.432,6895.008000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",1174,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.432,6897.4400000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1175,258.0,0.0,516.0,0,0.0,516.0,516.0,0.0,4.0,0.0,64.0,64.0,2.496,6899.936000000001,0.0,0.0,0.0,258.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",1176,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.016,6901.952,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",1177,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.016,6903.968,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",1178,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.592,6906.5599999999995,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",1179,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.112,6908.672,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithoutCast, memory::StoreWithoutCast>(int, T1, T2, T4, T5, T6, T7)",1180,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,3.0,0.0,64.0,32.0,2.368,6911.04,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",1181,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.528,6913.568,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1182,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.496,6916.064,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",1183,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,3.104,6919.168000000001,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",1184,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,3.168,6922.336,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",1185,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.4,6924.736,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1186,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.464,6927.2,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",1187,130.0,0.0,260.0,0,0.0,260.0,260.0,0.0,3.0,0.0,64.0,32.0,3.296,6930.496,0.0,0.0,0.0,130.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",1188,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.08,6932.576,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",1189,128.0,0.0,256.0,0,0.0,256.0,256.0,129.0,6.0,0.9555555555555556,32.0,32.0,2.976,6935.552,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",1190,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.464,6938.016,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",1191,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.4,6940.415999999999,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",1192,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,0.0,2.464,6942.879999999999,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(detail::TensorInfo<T1, T3>, detail::TensorInfo<const T1, T3>, detail::TensorInfo<const T2, T3>, int, int, T3, long)",1193,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,4352.0,4096.0,3.52,6946.4,0.0,0.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",1194,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.784,6949.183999999999,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",1195,6.0,0.0,12.0,0,0.0,12.0,12.0,0.0,2.0,0.0,32.0,32.0,3.424,6952.607999999999,0.0,0.0,0.0,6.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",1196,515.0,0.0,1030.0,0,0.0,1030.0,1030.0,0.0,2.0,0.0,32.0,32.0,2.752,6955.36,0.0,0.0,0.0,515.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",1197,0.0,128.0,0.0,0,0.0,128.0,128.0,8.0,6.0,0.5714285714285714,320.0,256.0,2.624,6957.9839999999995,0.0,128.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1198,288.0,0.0,576.0,0,0.0,576.0,576.0,0.0,10.0,0.0,512.0,512.0,2.496,6960.48,0.0,0.0,0.0,288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1199,1664.0,2308.0,1280.0,0,0.0,3588.0,3588.0,0.0,8.0,0.0,512.0,512.0,2.848,6963.3279999999995,4.0,256.0,1024.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",1200,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,8.0,0.0,512.0,512.0,2.496,6965.824,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1201,1536.0,2304.0,1024.0,0,0.0,3328.0,3328.0,0.0,8.0,0.0,512.0,512.0,3.008,6968.831999999999,0.0,256.0,1024.0,512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",1202,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,8.0,0.0,512.0,512.0,2.592,6971.423999999999,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1203,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,6973.9839999999995,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1204,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.488,6977.472,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1205,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,6979.9039999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1206,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,6982.464,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1207,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.04,6985.504,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1208,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,6988.096,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1209,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.576,6996.672,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1210,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,7005.44,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1211,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.832,7014.272,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1212,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,7017.408,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1213,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,7020.448,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1214,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,7024.0960000000005,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1215,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,7027.136,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1216,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.656,7029.792,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1217,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,7032.8,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1218,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,7035.84,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1219,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,7039.488,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1220,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,7042.56,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1221,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,7045.152,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1222,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.56,7047.712,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1223,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.592,7050.304,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",1224,16032.0,1503336.0,0.0,0,0.0,1503336.0,1503336.0,8335.0,16.0,0.9980840617890073,20480.0,4096.0,20.64,7070.944,1273157.0,198115.0,16032.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1225,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.672,7079.616,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1226,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,7082.176,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1227,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,7084.736000000001,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1228,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.36,7088.0960000000005,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1229,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.56,7090.656000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1230,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,7093.2480000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1231,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,7096.224,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1232,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,7098.816,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1233,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17144192.0,29344.0,23.936,7122.7519999999995,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1234,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.944,7125.696,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1235,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17149952.0,29088.0,23.584,7149.28,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1236,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.688,7151.968,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1237,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17831552.0,2048.0,22.816,7174.784,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1238,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,7177.375999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1239,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.624,7179.999999999999,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1240,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,7183.391999999999,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1241,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,7185.823999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1242,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,7188.415999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1243,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.2,7191.615999999998,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1244,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,7194.175999999999,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1245,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.832,7203.007999999999,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1246,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.896,7211.903999999999,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1247,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.96,7220.863999999999,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1248,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,7223.935999999999,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1249,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.072,7227.007999999999,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1250,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.68,7230.687999999999,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1251,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,7233.759999999999,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1252,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,7236.32,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1253,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,7239.36,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1254,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,7242.4,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1255,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,7246.048,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1256,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.2,7249.248,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1257,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.528,7251.776,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1258,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.56,7254.336,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1259,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.592,7256.928,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",1260,16128.0,1503590.0,0.0,0,0.0,1503590.0,1503590.0,8332.0,16.0,0.9980833732630571,20480.0,4096.0,20.704,7277.632,1273208.0,198126.0,16128.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1261,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.608,7286.24,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1262,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,7288.8,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1263,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,7291.360000000001,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1264,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.36,7294.72,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1265,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,7297.12,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1266,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,7299.68,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1267,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.04,7302.72,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1268,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,7305.280000000001,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1269,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17147392.0,28992.0,22.24,7327.52,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1270,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.944,7330.464000000001,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1271,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17143168.0,29408.0,23.104,7353.568000000001,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1272,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,7356.160000000001,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1273,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17835904.0,2048.0,22.912,7379.072000000001,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1274,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,7381.664000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1275,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,7384.224000000001,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1276,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.424,7387.648000000001,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1277,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,7390.080000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1278,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,7392.640000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1279,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.008,7395.648000000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1280,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,7398.240000000001,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1281,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.544,7406.784000000001,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1282,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.512,7415.296,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1283,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.896,7424.192,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1284,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,7427.328,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1285,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.008,7430.336,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1286,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.68,7434.0160000000005,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1287,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,7437.120000000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1288,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,7439.744000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1289,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,7442.816000000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1290,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.072,7445.888000000001,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1291,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,7449.536000000001,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1292,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,7452.640000000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1293,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,7455.200000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1294,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.592,7457.792000000001,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1295,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.688,7460.480000000001,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",1296,16384.0,1504256.0,0.0,0,0.0,1504256.0,1504256.0,8320.0,16.0,0.9980806142034548,20480.0,4096.0,20.32,7480.800000000001,1273344.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1297,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.8,7489.600000000001,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1298,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.656,7492.256000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1299,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,7494.816000000002,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1300,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.424,7498.240000000002,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1301,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,7500.672000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1302,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,7503.264000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1303,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.04,7506.304000000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1304,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,7508.896000000001,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1305,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17147776.0,28608.0,22.88,7531.776000000001,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1306,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,3.104,7534.880000000001,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1307,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17150720.0,29152.0,23.04,7557.920000000001,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1308,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.752,7560.672000000001,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1309,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17836032.0,2048.0,23.04,7583.712000000001,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1310,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,7586.336000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1311,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,7588.896000000002,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1312,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,7592.288000000001,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1313,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,7594.720000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1314,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,7597.312000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1315,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,7600.2880000000005,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1316,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,7602.848000000001,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1317,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.8,7611.648000000001,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1318,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,7620.416000000001,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1319,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,7629.184000000001,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1320,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,7632.224000000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1321,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.008,7635.232000000001,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1322,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,7638.880000000001,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1323,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,7641.920000000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1324,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,7644.512000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1325,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,7647.552000000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1326,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,2.976,7650.528,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1327,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,7654.176,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1328,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,7657.312000000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1329,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,7659.872000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1330,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.592,7662.464000000001,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1331,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.688,7665.152000000001,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",1332,16352.0,1504182.0,0.0,0,0.0,1504182.0,1504182.0,8323.0,16.0,0.9980813047127953,20480.0,4096.0,20.416,7685.568000000001,1273327.0,198151.0,16352.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1333,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.48,7694.048000000001,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1334,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,7696.64,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1335,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,7699.200000000001,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1336,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.424,7702.624000000001,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1337,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,7705.024,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1338,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,7707.584000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1339,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.008,7710.592000000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1340,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,7713.184,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1341,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17137152.0,29056.0,23.264,7736.448,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1342,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,3.008,7739.456,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1343,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17143936.0,29088.0,22.752,7762.2080000000005,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1344,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.88,7765.088000000001,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1345,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17841536.0,2048.0,22.944,7788.032000000001,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1346,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,7790.624000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1347,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.816,7793.4400000000005,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1348,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.488,7796.928000000001,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1349,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.528,7799.456000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1350,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,7802.048000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1351,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.072,7805.120000000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1352,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,7807.712,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1353,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,7816.4800000000005,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1354,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.544,7825.024,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1355,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.832,7833.856000000001,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1356,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,7836.896000000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1357,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.008,7839.904,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1358,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,7843.552000000001,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1359,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,7846.592000000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1360,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,7849.184,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1361,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,7852.256,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1362,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.072,7855.328,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1363,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.68,7859.008000000001,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1364,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.168,7862.176,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1365,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,7864.736000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1366,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.592,7867.328,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1367,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.592,7869.92,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",1368,16352.0,1504182.0,0.0,0,0.0,1504182.0,1504182.0,8323.0,16.0,0.9980813047127953,20480.0,4096.0,20.16,7890.08,1273327.0,198151.0,16352.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1369,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.512,7898.592,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1370,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,7901.152,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1371,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,7903.712,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1372,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.424,7907.136,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1373,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,7909.568,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1374,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,7912.128000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1375,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,7915.104,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1376,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,7917.696,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1377,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17143168.0,29600.0,23.648,7941.344,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1378,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,3.04,7944.384,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1379,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17139584.0,29504.0,23.232,7967.616,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1380,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,7970.208,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1381,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17833344.0,2048.0,22.816,7993.023999999999,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1382,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,7995.584,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1383,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,7998.144,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1384,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,8001.536,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1385,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,8003.936,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1386,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,8006.527999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1387,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,8009.503999999999,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1388,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.624,8012.127999999999,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1389,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.544,8020.671999999999,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1390,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.448,8029.119999999999,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1391,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,8037.887999999999,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1392,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,2.976,8040.863999999999,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1393,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.104,8043.967999999999,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1394,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.712,8047.679999999999,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1395,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,8050.7519999999995,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1396,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,8053.312,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1397,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.168,8056.48,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1398,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.072,8059.552,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1399,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.68,8063.232,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1400,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,8066.304,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1401,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,8068.8640000000005,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1402,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.592,8071.456,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1403,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.624,8074.08,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",1404,16384.0,1504270.0,0.0,0,0.0,1504270.0,1504270.0,8320.0,16.0,0.9980806142034548,20480.0,4096.0,20.224,8094.304,1273344.0,198158.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1405,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.832,8103.136,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1406,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.784,8105.92,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1407,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,8108.4800000000005,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1408,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.424,8111.904,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1409,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,8114.368,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1410,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,8116.992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1411,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.04,8120.032,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1412,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,8122.624,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1413,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17134688.0,29248.0,22.464,8145.088,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1414,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.944,8148.032,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1415,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17150848.0,29888.0,23.424,8171.456,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1416,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.656,8174.112,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1417,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17835136.0,2048.0,22.688,8196.8,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1418,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,8199.392,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1419,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,8201.952,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1420,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,8205.344,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1421,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,8207.776,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1422,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,8210.368,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1423,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,8213.344000000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1424,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,8215.936000000002,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1425,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.8,8224.736,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1426,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.864,8233.6,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1427,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.64,8242.24,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1428,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,8245.28,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1429,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,8248.320000000002,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1430,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.68,8252.000000000002,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1431,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,8255.040000000003,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1432,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,8257.600000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1433,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,8260.640000000003,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1434,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.072,8263.712000000003,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1435,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,8267.360000000002,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1436,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,8270.496000000003,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1437,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.656,8273.152000000004,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1438,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.592,8275.744000000004,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1439,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.688,8278.432000000004,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",1440,16352.0,1504180.0,0.0,0,0.0,1504180.0,1504180.0,8323.0,16.0,0.9980813047127953,20480.0,4096.0,20.32,8298.752000000004,1273327.0,198149.0,16352.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1441,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.704,8307.456000000004,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1442,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,8310.048000000004,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1443,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,8312.608000000004,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1444,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.584,8316.192000000005,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1445,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,8318.592000000004,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1446,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,8321.184000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1447,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,8324.160000000005,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1448,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,8326.720000000005,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1449,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17152128.0,29024.0,23.104,8349.824000000004,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1450,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,3.04,8352.864000000005,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1451,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17145472.0,28736.0,23.232,8376.096000000005,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1452,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.72,8378.816000000004,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1453,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17850880.0,2048.0,23.04,8401.856000000005,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1454,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,8404.448000000006,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1455,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,8407.008000000005,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1456,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.424,8410.432000000006,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1457,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,8412.864000000007,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1458,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,8415.456000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1459,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,8418.432000000008,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1460,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,8421.024000000009,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1461,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.8,8429.824000000008,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1462,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.512,8438.336000000008,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1463,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,8447.104000000008,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1464,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,8450.14400000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1465,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.072,8453.21600000001,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1466,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.68,8456.89600000001,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1467,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,8459.90400000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1468,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,8462.464000000009,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1469,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,8465.53600000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1470,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,8468.57600000001,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1471,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,8472.22400000001,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1472,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,8475.29600000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1473,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.528,8477.82400000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1474,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.656,8480.48000000001,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1475,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.688,8483.16800000001,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",1476,16320.0,1504096.0,0.0,0,0.0,1504096.0,1504096.0,8326.0,16.0,0.9980819947254855,20480.0,4096.0,20.128,8503.296000000011,1273310.0,198146.0,16320.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1477,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.576,8511.87200000001,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1478,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,8514.49600000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1479,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.624,8517.12000000001,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1480,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,8520.51200000001,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1481,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,8522.94400000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1482,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,8525.50400000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1483,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,8528.48000000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1484,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.624,8531.10400000001,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1485,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17136512.0,29728.0,22.912,8554.01600000001,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1486,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.912,8556.92800000001,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1487,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17140352.0,29792.0,22.464,8579.39200000001,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1488,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.624,8582.01600000001,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1489,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17831552.0,2048.0,23.392,8605.40800000001,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1490,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,8607.96800000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1491,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,8610.52800000001,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1492,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,8613.92000000001,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1493,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,8616.320000000009,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1494,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,8618.944000000009,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1495,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,8621.92000000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1496,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.88,8624.800000000008,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1497,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.416,8633.216000000008,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1498,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.416,8641.632000000007,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1499,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.512,8650.144000000008,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1500,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.168,8653.312000000007,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1501,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.008,8656.320000000007,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1502,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.84,8660.160000000007,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1503,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.168,8663.328000000007,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1504,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.688,8666.016000000007,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1505,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,8669.120000000006,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1506,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.008,8672.128000000006,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1507,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.68,8675.808000000006,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1508,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,8678.880000000006,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1509,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,8681.472000000007,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1510,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.592,8684.064000000008,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1511,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.56,8686.624000000007,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",1512,16384.0,1504266.0,0.0,0,0.0,1504266.0,1504266.0,8320.0,16.0,0.9980806142034548,20480.0,4096.0,20.32,8706.944000000007,1273344.0,198154.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1513,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.64,8715.584000000006,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1514,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,8718.176000000007,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1515,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,8720.736000000006,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1516,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.52,8724.256000000007,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1517,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,8726.720000000007,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1518,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.848,8729.568000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1519,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.072,8732.640000000007,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1520,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,8735.200000000006,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1521,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17146112.0,28768.0,23.04,8758.240000000007,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1522,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,3.168,8761.408000000007,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1523,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17148224.0,29216.0,24.064,8785.472000000007,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1524,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.752,8788.224000000007,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1525,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17831552.0,2048.0,22.912,8811.136000000008,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1526,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,8813.696000000007,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1527,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,8816.256000000007,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1528,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.52,8819.776000000007,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1529,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,8822.176000000007,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1530,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,8824.736000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1531,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,8827.680000000006,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1532,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,8830.272000000006,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1533,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,8839.040000000006,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1534,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.736,8847.776000000007,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1535,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,8856.544000000007,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1536,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,8859.616000000007,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1537,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,2.976,8862.592000000008,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1538,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,8866.240000000007,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1539,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,8869.312000000007,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1540,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,8871.904000000008,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1541,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,8875.040000000008,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1542,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,8878.080000000009,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1543,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,8881.728000000008,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1544,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,8884.76800000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1545,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,8887.328000000009,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1546,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.592,8889.92000000001,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1547,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.624,8892.544000000009,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",1548,16352.0,1504178.0,0.0,0,0.0,1504178.0,1504178.0,8323.0,16.0,0.9980813047127953,20480.0,4096.0,20.288,8912.83200000001,1273327.0,198147.0,16352.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1549,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.832,8921.66400000001,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1550,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.528,8924.19200000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1551,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,8926.75200000001,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1552,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.424,8930.17600000001,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1553,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,8932.57600000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1554,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,8935.20000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1555,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,8938.17600000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1556,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,8940.73600000001,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1557,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17144320.0,29536.0,22.208,8962.94400000001,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1558,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.944,8965.88800000001,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1559,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17145728.0,28960.0,23.936,8989.82400000001,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1560,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,8992.41600000001,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1561,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17830016.0,2048.0,23.008,9015.42400000001,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1562,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,9017.98400000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1563,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.592,9020.57600000001,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1564,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.744,9024.32000000001,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1565,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,9026.72000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1566,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,9029.28000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1567,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.912,9032.19200000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1568,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,9034.78400000001,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1569,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.576,9043.36000000001,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1570,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.544,9051.90400000001,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1571,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.448,9060.35200000001,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1572,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.168,9063.52000000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1573,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,9066.56000000001,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1574,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,9070.20800000001,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1575,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,9073.28000000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1576,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,9075.84000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1577,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,9078.88000000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1578,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.072,9081.95200000001,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1579,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,9085.60000000001,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1580,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,2.976,9088.57600000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1581,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.656,9091.23200000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1582,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.656,9093.888000000012,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1583,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.592,9096.480000000012,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",1584,16384.0,1504266.0,0.0,0,0.0,1504266.0,1504266.0,8320.0,16.0,0.9980806142034548,20480.0,4096.0,20.256,9116.736000000012,1273344.0,198154.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1585,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.576,9125.31200000001,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1586,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,9127.87200000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1587,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.752,9130.62400000001,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1588,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.36,9133.984000000011,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1589,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,9136.384000000011,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1590,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,9138.976000000011,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1591,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.008,9141.984000000011,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1592,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.624,9144.608000000011,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1593,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17150976.0,28800.0,23.36,9167.968000000012,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1594,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,3.168,9171.136000000011,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1595,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17153024.0,29120.0,23.648,9194.78400000001,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1596,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.56,9197.34400000001,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1597,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17837312.0,2048.0,22.88,9220.22400000001,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1598,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,9222.784000000009,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1599,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,9225.344000000008,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1600,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.456,9228.800000000008,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1601,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,9231.200000000008,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1602,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,9233.824000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1603,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.04,9236.864000000009,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1604,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.752,9239.616000000009,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1605,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.672,9248.28800000001,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1606,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.608,9256.89600000001,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1607,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.576,9265.472000000009,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1608,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,9268.51200000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1609,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.008,9271.52000000001,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1610,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,9275.168000000009,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1611,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,9278.20800000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1612,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,9280.83200000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1613,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,9283.87200000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1614,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,9286.912000000011,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1615,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.68,9290.592000000011,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1616,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,9293.728000000012,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1617,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.656,9296.384000000013,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1618,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.656,9299.040000000014,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1619,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.56,9301.600000000013,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",1620,16352.0,1504178.0,0.0,0,0.0,1504178.0,1504178.0,8323.0,16.0,0.9980813047127953,20480.0,4096.0,20.224,9321.824000000013,1273327.0,198147.0,16352.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1621,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.896,9330.720000000014,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1622,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,9333.280000000013,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1623,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.656,9335.936000000014,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1624,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.424,9339.360000000015,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1625,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,9341.760000000015,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1626,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,9344.352000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1627,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.008,9347.360000000015,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1628,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,9349.952000000016,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1629,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17145088.0,29120.0,23.232,9373.184000000016,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1630,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.944,9376.128000000015,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1631,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17142016.0,29408.0,24.16,9400.288000000015,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1632,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,9402.880000000016,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1633,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17834368.0,2048.0,23.04,9425.920000000016,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1634,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,9428.544000000016,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1635,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,9431.072000000016,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1636,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.36,9434.432000000017,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1637,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.496,9436.928000000016,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1638,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,9439.488000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1639,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.912,9442.400000000016,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1640,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,9444.960000000015,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1641,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.416,9453.376000000015,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1642,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.8,9462.176000000014,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1643,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,9470.944000000014,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1644,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,9473.984000000015,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1645,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,9477.024000000016,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1646,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.68,9480.704000000016,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1647,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,9483.744000000017,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1648,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,9486.304000000016,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1649,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.168,9489.472000000016,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1650,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.136,9492.608000000017,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1651,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.616,9496.224000000017,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1652,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,9499.232000000016,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1653,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.528,9501.760000000017,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1654,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.56,9504.320000000016,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1655,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.656,9506.976000000017,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",1656,16384.0,1504268.0,0.0,0,0.0,1504268.0,1504268.0,8320.0,16.0,0.9980806142034548,20480.0,4096.0,20.32,9527.296000000017,1273344.0,198156.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1657,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.448,9535.744000000017,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1658,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,9538.336000000018,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1659,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.592,9540.928000000018,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1660,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,9544.320000000018,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1661,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,9546.720000000018,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1662,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,9549.312000000018,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1663,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,9552.288000000019,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1664,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,9554.848000000018,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1665,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17139328.0,29216.0,23.712,9578.560000000018,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1666,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,3.008,9581.568000000017,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1667,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17146880.0,28896.0,24.0,9605.568000000017,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1668,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,9608.160000000018,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1669,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17831680.0,2048.0,22.88,9631.040000000017,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1670,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.528,9633.568000000017,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1671,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,9636.096000000018,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1672,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.424,9639.520000000019,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1673,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,9641.920000000018,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1674,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,9644.512000000019,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1675,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.008,9647.520000000019,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1676,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,9650.080000000018,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1677,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.8,9658.880000000017,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1678,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.48,9667.360000000017,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1679,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.672,9676.032000000017,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1680,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,9679.104000000018,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1681,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.008,9682.112000000017,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1682,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.616,9685.728000000017,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1683,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.2,9688.928000000018,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1684,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,9691.520000000019,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1685,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.2,9694.72000000002,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1686,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,9697.76000000002,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1687,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.584,9701.344000000021,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1688,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.168,9704.51200000002,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1689,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,9707.07200000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1690,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.816,9709.88800000002,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1691,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.656,9712.544000000022,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",1692,16384.0,1504268.0,0.0,0,0.0,1504268.0,1504268.0,8320.0,16.0,0.9980806142034548,20480.0,4096.0,20.128,9732.672000000022,1273344.0,198156.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1693,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.8,9741.472000000022,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1694,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.528,9744.000000000022,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1695,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.656,9746.656000000023,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1696,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,9750.048000000023,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1697,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,9752.448000000022,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1698,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,9755.008000000022,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1699,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.04,9758.048000000023,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1700,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,9760.640000000023,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1701,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17146624.0,29408.0,22.528,9783.168000000023,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1702,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.912,9786.080000000024,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1703,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17150976.0,29440.0,22.976,9809.056000000024,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1704,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.56,9811.616000000024,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1705,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17831936.0,2048.0,23.136,9834.752000000024,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1706,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,9837.312000000024,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1707,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,9839.840000000024,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1708,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,9843.232000000024,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1709,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,9845.664000000024,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1710,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,9848.224000000024,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1711,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.008,9851.232000000024,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1712,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,9853.792000000023,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1713,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.48,9862.272000000023,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1714,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.8,9871.072000000022,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1715,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.704,9879.776000000022,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1716,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,9882.784000000021,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1717,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.008,9885.792000000021,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1718,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.616,9889.408000000021,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1719,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.232,9892.640000000021,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1720,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,9895.232000000022,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1721,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,9898.240000000022,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1722,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,9901.280000000022,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1723,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.84,9905.120000000023,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1724,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.232,9908.352000000023,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1725,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,9910.944000000023,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1726,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.592,9913.536000000024,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1727,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.592,9916.128000000024,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",1728,16352.0,1504174.0,0.0,0,0.0,1504174.0,1504174.0,8323.0,16.0,0.9980813047127953,20480.0,4096.0,20.128,9936.256000000025,1273327.0,198143.0,16352.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1729,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.48,9944.736000000024,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1730,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,9947.296000000024,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1731,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,9949.856000000023,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1732,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,9953.248000000023,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1733,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,9955.680000000024,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1734,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,9958.272000000024,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1735,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,9961.216000000024,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1736,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,9963.776000000023,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1737,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17146880.0,29376.0,23.168,9986.944000000023,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1738,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.944,9989.888000000023,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1739,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17154048.0,28736.0,23.104,10012.992000000022,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1740,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.688,10015.680000000022,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1741,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17832960.0,2048.0,23.008,10038.688000000022,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1742,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,10041.248000000021,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1743,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.592,10043.840000000022,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1744,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,10047.232000000022,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1745,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,10049.632000000021,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1746,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,10052.224000000022,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1747,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,10055.200000000023,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1748,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,10057.760000000022,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1749,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.512,10066.272000000023,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1750,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.384,10074.656000000023,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1751,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.576,10083.232000000022,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1752,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.232,10086.464000000022,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1753,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,10089.504000000023,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1754,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,10093.152000000022,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1755,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,10096.288000000022,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1756,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.528,10098.816000000023,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1757,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,10101.856000000023,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1758,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,10104.896000000024,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1759,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.616,10108.512000000024,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1760,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,10111.552000000025,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1761,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,10114.112000000025,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1762,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.592,10116.704000000025,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1763,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.656,10119.360000000026,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",1764,16320.0,1504094.0,0.0,0,0.0,1504094.0,1504094.0,8326.0,16.0,0.9980819947254855,20480.0,4096.0,20.096,10139.456000000026,1273310.0,198144.0,16320.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1765,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.512,10147.968000000026,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1766,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,10150.560000000027,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1767,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.656,10153.216000000028,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1768,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.424,10156.640000000029,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1769,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,10159.008000000029,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1770,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,10161.60000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1771,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,10164.57600000003,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1772,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.656,10167.23200000003,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1773,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17150720.0,29344.0,22.656,10189.888000000032,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1774,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.944,10192.832000000031,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1775,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17141888.0,29536.0,22.944,10215.77600000003,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1776,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,10218.368000000031,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1777,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17839360.0,2048.0,23.072,10241.440000000031,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1778,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,10244.032000000032,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1779,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,10246.592000000031,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1780,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,10249.984000000031,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1781,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,10252.384000000031,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1782,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,10254.976000000031,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1783,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,10257.920000000031,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1784,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,10260.512000000032,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1785,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.736,10269.248000000032,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1786,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.544,10277.792000000032,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1787,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.736,10286.528000000033,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1788,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,10289.536000000033,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1789,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.008,10292.544000000033,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1790,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.68,10296.224000000033,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1791,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,10299.232000000033,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1792,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,10301.824000000033,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1793,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.168,10304.992000000033,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1794,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,10308.032000000034,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1795,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,10311.680000000033,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1796,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.168,10314.848000000033,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1797,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.656,10317.504000000034,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1798,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.592,10320.096000000034,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1799,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.624,10322.720000000034,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",1800,16384.0,1504266.0,0.0,0,0.0,1504266.0,1504266.0,8320.0,16.0,0.9980806142034548,20480.0,4096.0,20.096,10342.816000000033,1273344.0,198154.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1801,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.832,10351.648000000034,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1802,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,10354.272000000034,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1803,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.624,10356.896000000033,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1804,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.36,10360.256000000034,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1805,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,10362.656000000034,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1806,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,10365.216000000033,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1807,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,10368.160000000033,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1808,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,10370.752000000033,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1809,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17148800.0,28896.0,22.464,10393.216000000033,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1810,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.912,10396.128000000033,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1811,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17149696.0,29088.0,23.392,10419.520000000033,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1812,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,10422.112000000034,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1813,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17833600.0,2048.0,23.968,10446.080000000034,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1814,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,10448.640000000034,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1815,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.592,10451.232000000035,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1816,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.52,10454.752000000035,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1817,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,10457.120000000035,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1818,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,10459.712000000036,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1819,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.104,10462.816000000035,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1820,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,10465.376000000035,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1821,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,10474.144000000035,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1822,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.736,10482.880000000036,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1823,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.48,10491.360000000035,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1824,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,10494.432000000035,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1825,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,10497.472000000036,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1826,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.68,10501.152000000036,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1827,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,10504.288000000037,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1828,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,10506.848000000036,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1829,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.232,10510.080000000036,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1830,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.008,10513.088000000036,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1831,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,10516.736000000035,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1832,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.2,10519.936000000036,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1833,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,10522.496000000036,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1834,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.624,10525.120000000035,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1835,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.688,10527.808000000035,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",1836,16352.0,1504182.0,0.0,0,0.0,1504182.0,1504182.0,8323.0,16.0,0.9980813047127953,20480.0,4096.0,20.064,10547.872000000036,1273327.0,198151.0,16352.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1837,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.576,10556.448000000035,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1838,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,10559.040000000035,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1839,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,10561.600000000035,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1840,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.456,10565.056000000035,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1841,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,10567.520000000035,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1842,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,10570.080000000034,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1843,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.168,10573.248000000034,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1844,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,10575.840000000035,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1845,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17143040.0,28768.0,22.432,10598.272000000035,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1846,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.944,10601.216000000035,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1847,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17141376.0,29472.0,23.2,10624.416000000036,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1848,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,10627.008000000036,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1849,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17836416.0,2048.0,22.848,10649.856000000036,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1850,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,10652.448000000037,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1851,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,10654.976000000037,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1852,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.36,10658.336000000038,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1853,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.56,10660.896000000037,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1854,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,10663.456000000037,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1855,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.072,10666.528000000037,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1856,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,10669.120000000037,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1857,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.672,10677.792000000038,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1858,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.384,10686.176000000038,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1859,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.736,10694.912000000038,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1860,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,2.976,10697.888000000039,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1861,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,10700.92800000004,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1862,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.68,10704.60800000004,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1863,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,10707.61600000004,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1864,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,10710.20800000004,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1865,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,10713.344000000041,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1866,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,2.976,10716.320000000042,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1867,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.712,10720.032000000041,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1868,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,2.976,10723.008000000042,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1869,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.688,10725.696000000042,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1870,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.624,10728.320000000042,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1871,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.592,10730.912000000042,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",1872,16384.0,1504266.0,0.0,0,0.0,1504266.0,1504266.0,8320.0,16.0,0.9980806142034548,20480.0,4096.0,20.128,10751.040000000043,1273344.0,198154.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1873,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,10759.808000000043,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1874,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,10762.368000000042,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1875,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,10764.928000000042,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1876,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.424,10768.352000000043,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1877,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,10770.752000000042,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1878,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,10773.344000000043,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1879,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,10776.288000000042,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1880,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.624,10778.912000000042,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1881,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17142784.0,28896.0,23.008,10801.920000000042,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1882,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,3.008,10804.928000000042,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1883,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17144096.0,29088.0,22.976,10827.904000000042,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1884,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,10830.496000000043,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1885,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17837184.0,2048.0,23.456,10853.952000000043,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1886,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.72,10856.672000000042,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1887,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,10859.200000000043,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1888,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.36,10862.560000000043,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1889,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.528,10865.088000000043,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1890,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,10867.680000000044,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1891,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.008,10870.688000000044,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1892,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,10873.248000000043,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1893,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.512,10881.760000000044,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1894,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.544,10890.304000000044,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1895,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.64,10898.944000000043,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1896,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.168,10902.112000000043,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1897,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,10905.152000000044,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1898,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.744,10908.896000000044,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1899,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,10912.032000000045,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1900,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.656,10914.688000000046,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1901,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,10917.728000000046,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1902,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.008,10920.736000000046,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1903,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.616,10924.352000000046,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1904,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,10927.392000000047,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1905,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,10929.952000000047,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1906,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.688,10932.640000000047,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1907,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.56,10935.200000000046,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",1908,16384.0,1504256.0,0.0,0,0.0,1504256.0,1504256.0,8320.0,16.0,0.9980806142034548,20480.0,4096.0,20.256,10955.456000000046,1273344.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1909,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.448,10963.904000000046,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1910,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,10966.464000000045,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1911,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,10969.024000000045,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1912,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.36,10972.384000000045,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1913,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,10974.784000000045,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1914,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,10977.408000000045,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1915,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,10980.384000000045,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1916,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,10982.944000000045,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1917,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17152128.0,29312.0,22.752,11005.696000000045,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1918,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.976,11008.672000000046,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1919,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17147264.0,29216.0,22.432,11031.104000000047,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1920,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,11033.696000000047,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1921,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17838592.0,2048.0,22.976,11056.672000000048,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1922,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,11059.264000000048,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1923,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,11061.824000000048,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1924,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.552,11065.376000000047,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1925,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,11067.776000000047,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1926,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,11070.336000000047,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1927,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,11073.280000000046,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1928,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,11075.840000000046,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1929,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.352,11084.192000000046,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1930,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.8,11092.992000000046,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1931,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.608,11101.600000000046,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1932,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,2.944,11104.544000000045,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1933,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,11107.584000000046,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1934,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,11111.232000000045,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1935,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,11114.336000000045,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1936,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.688,11117.024000000045,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1937,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,11120.032000000045,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1938,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,2.976,11123.008000000045,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1939,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.616,11126.624000000045,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1940,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,11129.664000000046,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1941,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,11132.256000000047,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1942,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.56,11134.816000000046,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1943,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.592,11137.408000000047,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",1944,16384.0,1504270.0,0.0,0,0.0,1504270.0,1504270.0,8320.0,16.0,0.9980806142034548,20480.0,4096.0,20.096,11157.504000000046,1273344.0,198158.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1945,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,11166.272000000046,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1946,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,11168.864000000047,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1947,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.656,11171.520000000048,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1948,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.456,11174.976000000048,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1949,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,11177.376000000047,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1950,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.688,11180.064000000048,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1951,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.136,11183.200000000048,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1952,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.72,11185.920000000047,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1953,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17150208.0,29600.0,23.232,11209.152000000047,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1954,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.944,11212.096000000047,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1955,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17152896.0,29280.0,23.648,11235.744000000046,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1956,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.56,11238.304000000046,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1957,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17831424.0,2048.0,23.328,11261.632000000045,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1958,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.528,11264.160000000045,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1959,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,11266.720000000045,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1960,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,11270.112000000045,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1961,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,11272.480000000045,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1962,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,11275.104000000045,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1963,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,11278.080000000045,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1964,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,11280.672000000046,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1965,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.64,11289.312000000045,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1966,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.672,11297.984000000046,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1967,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.736,11306.720000000047,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1968,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,11309.760000000048,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1969,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,2.944,11312.704000000047,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1970,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.68,11316.384000000047,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1971,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,11319.392000000047,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1972,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,11321.952000000047,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1973,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,11324.992000000047,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1974,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.008,11328.000000000047,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1975,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.616,11331.616000000047,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1976,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,11334.720000000047,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1977,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,11337.280000000046,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1978,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.56,11339.840000000046,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1979,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.56,11342.400000000045,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",1980,16384.0,1504262.0,0.0,0,0.0,1504262.0,1504262.0,8320.0,16.0,0.9980806142034548,20480.0,4096.0,20.096,11362.496000000045,1273344.0,198150.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1981,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.704,11371.200000000044,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1982,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,11373.760000000044,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1983,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,11376.320000000043,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1984,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.36,11379.680000000044,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1985,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,11382.048000000044,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1986,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,11384.608000000044,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1987,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.136,11387.744000000044,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1988,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,11390.336000000045,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1989,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17150432.0,29920.0,22.528,11412.864000000045,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1990,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,3.008,11415.872000000045,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1991,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17153152.0,29312.0,23.36,11439.232000000045,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1992,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,11441.824000000046,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1993,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17831296.0,2048.0,22.88,11464.704000000045,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1994,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,11467.264000000045,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1995,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,11469.792000000045,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1996,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.424,11473.216000000046,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1997,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,11475.648000000047,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1998,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,11478.272000000046,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1999,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.04,11481.312000000047,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",2000,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,11483.904000000048,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2001,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.416,11492.320000000047,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2002,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.544,11500.864000000047,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2003,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.736,11509.600000000048,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2004,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,11512.704000000047,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2005,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,11515.744000000048,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",2006,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.68,11519.424000000048,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2007,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,11522.464000000049,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",2008,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,11525.05600000005,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2009,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,11528.06400000005,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2010,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.168,11531.232000000049,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",2011,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.616,11534.848000000049,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2012,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.168,11538.016000000049,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",2013,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,11540.576000000048,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",2014,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.592,11543.168000000049,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",2015,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.592,11545.76000000005,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",2016,16384.0,1504274.0,0.0,0,0.0,1504274.0,1504274.0,8320.0,16.0,0.9980806142034548,20480.0,4096.0,20.128,11565.88800000005,1273344.0,198162.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2017,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.704,11574.59200000005,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",2018,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,11577.15200000005,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",2019,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,11579.68000000005,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",2020,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.424,11583.10400000005,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",2021,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,11585.50400000005,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",2022,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,11588.06400000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2023,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,11591.04000000005,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",2024,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,11593.60000000005,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2025,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17153920.0,29120.0,22.944,11616.544000000049,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",2026,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.976,11619.52000000005,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2027,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17147392.0,29600.0,23.232,11642.75200000005,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",2028,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.688,11645.44000000005,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2029,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17837824.0,2048.0,23.264,11668.704000000049,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",2030,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,11671.29600000005,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",2031,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,11673.82400000005,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",2032,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.52,11677.34400000005,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",2033,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,11679.71200000005,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",2034,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,11682.27200000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2035,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,11685.24800000005,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",2036,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,11687.80800000005,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2037,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.48,11696.28800000005,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2038,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,11705.05600000005,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2039,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.544,11713.60000000005,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2040,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,11716.67200000005,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2041,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,2.944,11719.61600000005,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",2042,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.68,11723.29600000005,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2043,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,11726.43200000005,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",2044,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.528,11728.96000000005,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2045,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,11732.03200000005,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2046,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.008,11735.04000000005,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",2047,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,11738.68800000005,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2048,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,11741.72800000005,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",2049,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.528,11744.25600000005,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",2050,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.592,11746.84800000005,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",2051,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.56,11749.40800000005,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",2052,16352.0,1504178.0,0.0,0,0.0,1504178.0,1504178.0,8323.0,16.0,0.9980813047127953,20480.0,4096.0,20.128,11769.536000000051,1273327.0,198147.0,16352.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2053,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.512,11778.048000000052,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",2054,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,11780.672000000051,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",2055,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,11783.200000000052,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",2056,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,11786.592000000051,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",2057,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,11788.992000000051,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",2058,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,11791.584000000052,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2059,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.104,11794.688000000051,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",2060,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.528,11797.216000000051,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2061,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17145984.0,30240.0,22.528,11819.744000000052,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",2062,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,3.008,11822.752000000051,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2063,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17148544.0,29248.0,22.72,11845.47200000005,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",2064,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.624,11848.09600000005,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2065,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17837312.0,2048.0,22.752,11870.84800000005,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",2066,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.656,11873.504000000052,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",2067,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,11876.064000000051,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",2068,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.424,11879.488000000052,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",2069,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,11881.888000000052,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",2070,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,11884.448000000051,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2071,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.008,11887.456000000051,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",2072,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.72,11890.17600000005,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2073,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.48,11898.65600000005,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2074,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,11907.42400000005,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2075,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.48,11915.90400000005,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2076,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,11918.97600000005,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2077,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.008,11921.98400000005,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",2078,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.968,11925.95200000005,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2079,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,11928.992000000051,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",2080,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.688,11931.680000000051,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2081,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,11934.688000000051,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2082,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.008,11937.69600000005,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",2083,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.68,11941.376000000051,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2084,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,11944.416000000052,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",2085,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.656,11947.072000000053,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",2086,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.624,11949.696000000053,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",2087,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.624,11952.320000000052,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",2088,16384.0,1504266.0,0.0,0,0.0,1504266.0,1504266.0,8320.0,16.0,0.9980806142034548,20480.0,4096.0,20.16,11972.480000000052,1273344.0,198154.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2089,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,11981.248000000052,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",2090,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,11983.840000000053,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",2091,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.656,11986.496000000054,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",2092,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,11989.888000000054,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",2093,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,11992.288000000053,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",2094,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,11994.848000000053,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2095,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.04,11997.888000000054,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",2096,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,12000.480000000054,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2097,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17147648.0,29120.0,22.56,12023.040000000054,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",2098,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,3.008,12026.048000000053,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2099,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17145856.0,29216.0,23.552,12049.600000000053,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",2100,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,12052.192000000054,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2101,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17832960.0,2048.0,22.912,12075.104000000054,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",2102,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,12077.664000000053,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",2103,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,12080.192000000054,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",2104,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.456,12083.648000000054,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",2105,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,12086.016000000054,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",2106,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,12088.608000000055,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2107,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.04,12091.648000000056,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",2108,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,12094.240000000056,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2109,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,12103.008000000056,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2110,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.736,12111.744000000057,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2111,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.448,12120.192000000057,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2112,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,12123.264000000057,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2113,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,2.944,12126.208000000057,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",2114,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,12129.856000000056,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2115,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,12132.992000000057,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",2116,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,12135.552000000056,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2117,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,12138.624000000056,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2118,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,2.976,12141.600000000057,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",2119,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,12145.248000000056,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2120,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,2.976,12148.224000000057,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",2121,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,12150.784000000056,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",2122,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.592,12153.376000000057,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",2123,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.592,12155.968000000057,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",2124,16384.0,1504264.0,0.0,0,0.0,1504264.0,1504264.0,8320.0,16.0,0.9980806142034548,20480.0,4096.0,20.096,12176.064000000057,1273344.0,198152.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2125,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.736,12184.800000000057,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",2126,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,12187.360000000057,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",2127,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.624,12189.984000000057,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",2128,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.424,12193.408000000058,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",2129,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.528,12195.936000000058,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",2130,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,12198.496000000057,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2131,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,12201.440000000057,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",2132,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.528,12203.968000000057,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2133,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17136256.0,30048.0,22.432,12226.400000000058,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",2134,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.976,12229.376000000058,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2135,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17145984.0,28832.0,23.36,12252.736000000059,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",2136,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,12255.32800000006,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2137,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17834240.0,2048.0,23.424,12278.75200000006,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",2138,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,12281.31200000006,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",2139,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,12283.84000000006,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",2140,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.488,12287.32800000006,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",2141,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,12289.72800000006,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",2142,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.688,12292.41600000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2143,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,12295.360000000059,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",2144,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,12297.920000000058,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2145,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.48,12306.400000000058,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2146,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.512,12314.912000000058,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2147,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.448,12323.360000000059,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2148,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,12326.40000000006,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2149,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.072,12329.47200000006,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",2150,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,12333.120000000059,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2151,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,12336.25600000006,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",2152,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,12338.816000000059,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2153,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,12341.95200000006,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2154,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.008,12344.96000000006,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",2155,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.68,12348.64000000006,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2156,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,12351.68000000006,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",2157,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,12354.24000000006,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",2158,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.688,12356.92800000006,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",2159,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.688,12359.61600000006,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",2160,16352.0,1504180.0,0.0,0,0.0,1504180.0,1504180.0,8323.0,16.0,0.9980813047127953,20480.0,4096.0,20.096,12379.71200000006,1273327.0,198149.0,16352.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2161,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.832,12388.54400000006,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",2162,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,12391.13600000006,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",2163,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,12393.66400000006,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",2164,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.36,12397.024000000061,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",2165,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,12399.424000000061,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",2166,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,12401.98400000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2167,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.072,12405.05600000006,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",2168,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,12407.648000000061,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2169,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17150304.0,28832.0,23.168,12430.81600000006,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",2170,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,3.008,12433.82400000006,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2171,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17156352.0,28928.0,23.2,12457.024000000061,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",2172,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,12459.616000000062,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2173,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17834112.0,2048.0,22.912,12482.528000000062,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",2174,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,12485.088000000062,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",2175,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,12487.616000000062,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",2176,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.584,12491.200000000063,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",2177,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.56,12493.760000000062,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",2178,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,12496.384000000062,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2179,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,12499.360000000062,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",2180,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.624,12501.984000000062,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2181,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.704,12510.688000000062,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2182,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.8,12519.488000000061,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2183,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.896,12528.384000000062,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2184,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,2.976,12531.360000000062,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2185,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,12534.400000000063,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",2186,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.84,12538.240000000063,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2187,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,2.976,12541.216000000064,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",2188,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,12543.808000000065,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2189,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,12546.880000000065,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2190,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.2,12550.080000000065,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",2191,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.744,12553.824000000066,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2192,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.2,12557.024000000067,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",2193,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.528,12559.552000000067,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",2194,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.592,12562.144000000068,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",2195,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.592,12564.736000000068,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",2196,16384.0,1504260.0,0.0,0,0.0,1504260.0,1504260.0,8320.0,16.0,0.9980806142034548,20480.0,4096.0,20.192,12584.928000000067,1273344.0,198148.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2197,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.544,12593.472000000067,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",2198,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,12596.032000000067,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",2199,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,12598.592000000066,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",2200,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,12601.984000000066,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",2201,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,12604.448000000066,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",2202,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,12607.040000000066,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2203,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,12610.016000000067,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",2204,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,12612.608000000067,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2205,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17141888.0,29024.0,22.656,12635.264000000068,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",2206,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,3.04,12638.30400000007,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2207,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17142016.0,28768.0,22.432,12660.73600000007,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",2208,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.624,12663.36000000007,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2209,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17832704.0,2048.0,22.912,12686.27200000007,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",2210,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.752,12689.02400000007,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",2211,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,12691.58400000007,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",2212,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.36,12694.94400000007,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",2213,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,12697.376000000071,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",2214,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,12699.968000000072,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2215,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,12702.944000000072,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",2216,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,12705.536000000073,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2217,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.704,12714.240000000073,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2218,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,12723.008000000073,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2219,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.48,12731.488000000072,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2220,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,12734.496000000072,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2221,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,12737.536000000073,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",2222,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.68,12741.216000000073,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2223,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,12744.256000000074,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",2224,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,12746.880000000074,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2225,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,12749.888000000074,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2226,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.008,12752.896000000073,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",2227,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.712,12756.608000000073,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2228,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,12759.648000000074,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",2229,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,12762.240000000074,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",2230,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.624,12764.864000000074,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",2231,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.56,12767.424000000074,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",2232,16320.0,1504094.0,0.0,0,0.0,1504094.0,1504094.0,8326.0,16.0,0.9980819947254855,20480.0,4096.0,20.224,12787.648000000074,1273310.0,198144.0,16320.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2233,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.736,12796.384000000075,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",2234,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,12798.976000000075,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",2235,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,12801.536000000075,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",2236,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.328,12804.864000000074,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",2237,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.56,12807.424000000074,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",2238,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,12810.016000000074,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2239,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.104,12813.120000000074,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",2240,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,12815.712000000074,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2241,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17144960.0,29792.0,23.168,12838.880000000074,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",2242,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,3.04,12841.920000000075,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2243,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17148800.0,28992.0,23.488,12865.408000000074,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",2244,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.624,12868.032000000074,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2245,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17832704.0,2048.0,22.784,12890.816000000073,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",2246,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,12893.376000000073,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",2247,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,12895.904000000073,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",2248,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,12899.296000000073,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",2249,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,12901.760000000073,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",2250,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,12904.384000000073,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2251,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.072,12907.456000000073,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",2252,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,12910.048000000073,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2253,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.352,12918.400000000074,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2254,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.736,12927.136000000075,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2255,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.384,12935.520000000075,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2256,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,12938.560000000076,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2257,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.008,12941.568000000076,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",2258,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.872,12945.440000000075,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2259,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,12948.480000000076,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",2260,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,12951.040000000075,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2261,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,12954.080000000076,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2262,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.2,12957.280000000077,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",2263,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,12960.928000000076,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2264,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,12964.032000000076,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",2265,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,12966.592000000075,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",2266,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.592,12969.184000000076,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",2267,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.56,12971.744000000075,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",2268,16384.0,1504258.0,0.0,0,0.0,1504258.0,1504258.0,8320.0,16.0,0.9980806142034548,20480.0,4096.0,20.256,12992.000000000075,1273344.0,198146.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2269,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.48,13000.480000000074,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",2270,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.656,13003.136000000075,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",2271,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,13005.664000000075,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",2272,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.488,13009.152000000075,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",2273,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,13011.552000000074,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",2274,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,13014.144000000075,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2275,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.04,13017.184000000076,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",2276,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,13019.744000000075,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2277,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17138688.0,28864.0,22.144,13041.888000000075,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",2278,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.944,13044.832000000075,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2279,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17139072.0,29248.0,23.04,13067.872000000076,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",2280,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,13070.464000000076,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2281,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17835136.0,2048.0,23.072,13093.536000000076,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",2282,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,13096.096000000076,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",2283,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,13098.656000000075,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",2284,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.456,13102.112000000076,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",2285,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,13104.576000000076,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",2286,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,13107.168000000076,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2287,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,13110.112000000076,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",2288,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,13112.704000000076,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2289,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.416,13121.120000000075,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2290,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.544,13129.664000000075,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2291,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.736,13138.400000000076,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2292,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,2.944,13141.344000000076,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2293,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.168,13144.512000000075,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",2294,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,13148.160000000074,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2295,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,13151.232000000075,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",2296,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,13153.792000000074,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2297,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,13156.864000000074,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2298,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,13159.904000000075,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",2299,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.808,13163.712000000076,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2300,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,2.944,13166.656000000075,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",2301,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,13169.216000000075,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",2302,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.72,13171.936000000074,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",2303,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.592,13174.528000000075,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",2304,16352.0,1504188.0,0.0,0,0.0,1504188.0,1504188.0,8323.0,16.0,0.9980813047127953,20480.0,4096.0,20.128,13194.656000000075,1273327.0,198157.0,16352.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2305,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.96,13203.616000000075,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",2306,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,13206.176000000074,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",2307,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,13208.736000000074,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",2308,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.36,13212.096000000074,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",2309,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,13214.560000000074,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",2310,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,13217.152000000075,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2311,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.136,13220.288000000075,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",2312,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,13222.880000000076,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2313,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17148512.0,28864.0,22.368,13245.248000000076,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",2314,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.944,13248.192000000075,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2315,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17150848.0,28768.0,23.104,13271.296000000075,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",2316,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.624,13273.920000000075,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2317,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17841536.0,2048.0,22.88,13296.800000000074,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",2318,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.688,13299.488000000074,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",2319,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,13302.048000000073,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",2320,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,13305.440000000073,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",2321,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,13307.904000000073,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",2322,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,13310.496000000074,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2323,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,13313.440000000073,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",2324,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,13316.032000000074,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2325,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,13324.800000000074,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2326,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.832,13333.632000000074,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2327,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.448,13342.080000000075,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2328,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,2.976,13345.056000000075,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2329,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.072,13348.128000000075,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",2330,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.84,13351.968000000075,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2331,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,13355.040000000075,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",2332,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.656,13357.696000000076,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2333,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,13360.768000000076,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2334,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.168,13363.936000000076,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",2335,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,13367.584000000075,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2336,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,13370.688000000075,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",2337,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,13373.248000000074,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",2338,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.592,13375.840000000075,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",2339,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.56,13378.400000000074,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",2340,16320.0,1504098.0,0.0,0,0.0,1504098.0,1504098.0,8323.0,16.0,0.9980813047127953,20480.0,4096.0,20.128,13398.528000000075,1273310.0,198148.0,16320.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2341,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.48,13407.008000000074,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",2342,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,13409.600000000075,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",2343,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.688,13412.288000000075,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",2344,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.424,13415.712000000076,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",2345,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,13418.112000000076,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",2346,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,13420.768000000076,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2347,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,13423.744000000077,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",2348,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,13426.336000000078,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2349,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17142272.0,30080.0,22.368,13448.704000000078,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",2350,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.912,13451.616000000078,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2351,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17147008.0,29152.0,22.912,13474.528000000078,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",2352,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,13477.120000000079,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2353,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17839616.0,2048.0,23.04,13500.16000000008,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",2354,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,13502.75200000008,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",2355,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,13505.31200000008,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",2356,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.488,13508.80000000008,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",2357,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,13511.200000000079,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",2358,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,13513.85600000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2359,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,13516.80000000008,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",2360,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.624,13519.42400000008,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",2361,33088000.0,65856000.0,576000.0,0,0.0,66432000.0,66432000.0,88000.0,2056000.0,0.041044776119402986,132875904.0,176352.0,148.224,13667.64800000008,256000.0,0.0,32800000.0,288000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2362,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,13669.69600000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",2363,258.0,0.0,516.0,0,0.0,516.0,516.0,0.0,5.0,0.0,64.0,64.0,2.528,13672.22400000008,0.0,0.0,0.0,258.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",2364,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.432,13674.65600000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",2365,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,128000.0,128000.0,2.72,13677.37600000008,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",2366,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,13679.424000000081,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",2367,48128.0,0.0,96256.0,0,0.0,96256.0,96256.0,512.0,1512.0,0.25296442687747034,129024.0,8192.0,3.904,13683.328000000081,0.0,0.0,0.0,48128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",2368,27648.0,0.0,55296.0,0,0.0,55296.0,55296.0,2112.0,8610.0,0.1969781757134863,527360.0,0.0,4.768,13688.096000000081,0.0,0.0,0.0,27648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",2369,16337.0,0.0,32674.0,0,0.0,32674.0,32674.0,512.0,1512.0,0.25296442687747034,129024.0,8192.0,3.904,13692.000000000082,0.0,0.0,0.0,16337.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",2370,33792.0,0.0,67584.0,0,0.0,67584.0,67584.0,2112.0,8802.0,0.19351291918636612,527360.0,0.0,4.736,13696.736000000083,0.0,0.0,0.0,33792.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",2371,16132.0,0.0,32264.0,0,0.0,32264.0,32264.0,512.0,1512.0,0.25296442687747034,129024.0,8192.0,4.0,13700.736000000083,0.0,0.0,0.0,16132.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",2372,33792.0,0.0,67584.0,0,0.0,67584.0,67584.0,2112.0,8802.0,0.19351291918636612,527360.0,0.0,4.608,13705.344000000083,0.0,0.0,0.0,33792.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",2373,16129.0,0.0,32258.0,0,0.0,32258.0,32258.0,512.0,1512.0,0.25296442687747034,129024.0,8192.0,4.0,13709.344000000083,0.0,0.0,0.0,16129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",2374,26624.0,0.0,53248.0,0,0.0,53248.0,53248.0,2112.0,8578.0,0.19756782039289056,527360.0,32.0,4.896,13714.240000000083,0.0,0.0,0.0,26624.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",2375,352.0,0.0,704.0,0,0.0,704.0,704.0,0.0,3.0,0.0,1056.0,128.0,3.104,13717.344000000083,0.0,0.0,0.0,352.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",2376,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.016,13719.360000000082,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",2377,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,11.0,0.9829984544049459,128.0,0.0,4.352,13723.712000000083,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",2378,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.048,13725.760000000084,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",2379,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,11.0,0.9829984544049459,128.0,0.0,4.32,13730.080000000084,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 1>(detail::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, detail::TensorInfo<T1, T2>, T2, detail::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",2380,40292.0,0.0,80584.0,0,0.0,80584.0,80584.0,8815.0,2106.0,0.8071605164362238,131808.0,1728.0,6.112,13736.192000000083,0.0,0.0,0.0,40292.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::radixSortKVInPlace<(int)-2, (int)-1, 32, 4, float, long, unsigned int>(detail::TensorInfo<T5, T7>, T7, T7, T7, detail::TensorInfo<T6, T7>, T7, bool)",2381,64.0,0.0,128.0,0,0.0,128.0,128.0,458.0,8.0,0.9828326180257511,640.0,0.0,6.112,13742.304000000082,0.0,0.0,0.0,64.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2382,64000.0,0.0,128000.0,0,0.0,128000.0,128000.0,0.0,3000.0,0.0,130016.0,8000.0,3.872,13746.176000000081,0.0,0.0,0.0,64000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",2383,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,768.0,0.0,160000.0,0.0,2.752,13748.928000000082,0.0,0.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"native::<unnamed>::fill_reverse_indices_kernel(long *, int, detail::IntDivider<unsigned int>)",2384,128768.0,0.0,257536.0,0,0.0,257536.0,257536.0,0.0,1000.0,0.0,0.0,256000.0,2.528,13751.456000000082,0.0,0.0,0.0,128768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",2385,387238.0,0.0,774476.0,0,0.0,774476.0,774476.0,64512.0,1000.0,0.9847356209549396,128000.0,0.0,4.096,13755.552000000082,0.0,0.0,0.0,387238.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",2386,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,2.592,13758.144000000082,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",2387,29568.0,0.0,59136.0,0,0.0,59136.0,59136.0,10414.0,4264.0,0.7094972067039106,407552.0,309952.0,14.784,13772.928000000082,0.0,0.0,0.0,29568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",2388,14400.0,0.0,28800.0,0,0.0,28800.0,28800.0,3418.0,4279.0,0.44406911783811875,407552.0,390400.0,13.12,13786.048000000083,0.0,0.0,0.0,14400.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",2389,15744.0,0.0,31488.0,0,0.0,31488.0,31488.0,4798.0,4232.0,0.5313399778516058,405632.0,390144.0,14.144,13800.192000000083,0.0,0.0,0.0,15744.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",2390,15744.0,0.0,31488.0,0,0.0,31488.0,31488.0,4798.0,4246.0,0.5305174701459531,405504.0,326048.0,13.984,13814.176000000083,0.0,0.0,0.0,15744.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",2391,524494.0,1061280.0,152988.0,0,0.0,1214268.0,1214268.0,132.0,1312.0,0.09141274238227147,267264.0,128000.0,18.944,13833.120000000083,133280.0,32000.0,448000.0,76494.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<float, 1>>(T1, int)",2392,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,0.0,416.0,2.08,13835.200000000083,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<float, std::plus<float>>::Policy900, const float *, float *, at_cuda_detail::ScanTileState<float, 1>, std::plus<float>, at_cuda_detail::NullType, unsigned int, float, 0>(T2, T3, T4, int, T5, T6, T7)",2393,2177.0,85371.0,4354.0,0,0.0,89725.0,89725.0,4349.0,2053.0,0.6793189628241174,136416.0,129024.0,4.032,13839.232000000082,85371.0,0.0,0.0,2177.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",2394,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,512.0,0.0,128000.0,31808.0,2.624,13841.856000000082,0.0,0.0,0.0,256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::unrolled_elementwise_kernel<native::FillFunctor<bool>, std::array<char *, 1>, 16, TrivialOffsetCalculator<0, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithoutCast, memory::StoreWithoutCast>(int, T1, T2, T4, T5, T6, T7)",2395,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.048,13843.904000000082,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",2396,68096.0,0.0,136192.0,0,0.0,136192.0,136192.0,0.0,3000.0,0.0,288000.0,12608.0,9.088,13852.992000000082,0.0,0.0,0.0,68096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",2397,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,768.0,0.0,160000.0,0.0,2.88,13855.872000000081,0.0,0.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",2398,524497.0,1061280.0,152994.0,0,0.0,1214274.0,1214274.0,132.0,1312.0,0.09141274238227147,267264.0,128000.0,18.112,13873.98400000008,133280.0,32000.0,448000.0,76497.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",2399,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,251.0,0.19808306709265175,128000.0,32.0,9.6,13883.58400000008,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",2400,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.432,13886.016000000081,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",2401,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,251.0,0.19808306709265175,128000.0,32.0,9.696,13895.712000000081,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",2402,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.464,13898.176000000081,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",2403,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.56,13900.73600000008,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",2404,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.2,13903.936000000082,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",2405,1536.0,36576.0,3072.0,0,0.0,39648.0,39648.0,62.0,251.0,0.19808306709265175,128000.0,32.0,9.728,13913.66400000008,36576.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",2406,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.432,13916.096000000081,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",2407,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.432,13918.528000000082,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",2408,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.2,13921.728000000083,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",2409,448000.0,640000.0,320000.0,0,0.0,960000.0,960000.0,0.0,1000.0,0.0,0.0,128000.0,2.816,13924.544000000084,0.0,64000.0,288000.0,160000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",2410,196945.0,327680.0,66210.0,0,0.0,393890.0,393890.0,0.0,768.0,0.0,256000.0,0.0,3.776,13928.320000000083,0.0,0.0,163840.0,33105.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",2411,18048.0,0.0,36096.0,0,0.0,36096.0,36096.0,124.0,251.0,0.33066666666666666,128000.0,32.0,12.896,13941.216000000084,0.0,0.0,0.0,18048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",2412,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.4,13943.616000000084,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",2413,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.4,13946.016000000083,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",2414,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.432,13948.448000000084,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",2415,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.464,13950.912000000084,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",2416,258.0,0.0,516.0,0,0.0,516.0,516.0,0.0,5.0,0.0,64.0,64.0,2.528,13953.440000000084,0.0,0.0,0.0,258.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",2417,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.016,13955.456000000084,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",2418,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.048,13957.504000000084,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",2419,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.624,13960.128000000084,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",2420,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.048,13962.176000000085,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",2421,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,3.0,0.0,64.0,32.0,2.464,13964.640000000085,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",2422,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.528,13967.168000000085,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",2423,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.4,13969.568000000085,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",2424,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,3.008,13972.576000000085,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",2425,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,3.296,13975.872000000085,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",2426,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.464,13978.336000000085,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
