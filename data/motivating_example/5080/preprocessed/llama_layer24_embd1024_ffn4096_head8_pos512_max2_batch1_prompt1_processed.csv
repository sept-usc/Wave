Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.664,1.664,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.568,3.232,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,1.632,4.864,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,3.0,0.0,64.0,32.0,2.048,6.912,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.624,9.536,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",6,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.08,11.616,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",7,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,13.664,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",8,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.08,15.744,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",9,128.0,0.0,256.0,0,0.0,256.0,256.0,129.0,6.0,0.9555555555555556,32.0,32.0,2.912,18.656,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",10,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,21.183999999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",11,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.528,23.711999999999996,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.08,25.791999999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,128.0,0.0,256.0,0,0.0,256.0,256.0,129.0,6.0,0.9555555555555556,32.0,32.0,2.944,28.735999999999994,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.432,31.167999999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",15,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.4,33.56799999999999,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",16,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,3.0,0.0,64.0,0.0,2.56,36.12799999999999,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(detail::TensorInfo<T1, T3>, detail::TensorInfo<const T1, T3>, detail::TensorInfo<const T2, T3>, int, int, T3, long)",17,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,4352.0,4096.0,4.704,40.831999999999994,0.0,0.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",18,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.912,43.74399999999999,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",19,515.0,0.0,1030.0,0,0.0,1030.0,1030.0,0.0,2.0,0.0,32.0,32.0,2.72,46.46399999999999,0.0,0.0,0.0,515.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",20,0.0,128.0,0.0,0,0.0,128.0,128.0,8.0,6.0,0.5714285714285714,320.0,256.0,2.816,49.279999999999994,0.0,128.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",21,288.0,0.0,576.0,0,0.0,576.0,576.0,0.0,10.0,0.0,512.0,512.0,2.528,51.80799999999999,0.0,0.0,0.0,288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",22,1664.0,2304.0,1280.0,0,0.0,3584.0,3584.0,0.0,8.0,0.0,512.0,512.0,3.136,54.943999999999996,0.0,256.0,1024.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",23,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,8.0,0.0,512.0,512.0,2.528,57.471999999999994,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",24,1536.0,2304.0,1024.0,0,0.0,3328.0,3328.0,0.0,8.0,0.0,512.0,512.0,2.912,60.38399999999999,0.0,256.0,1024.0,512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",25,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,8.0,0.0,512.0,512.0,2.432,62.815999999999995,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",26,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.592,65.408,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",27,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.456,68.864,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",28,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,71.296,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",29,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,73.92,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",30,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,76.896,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",31,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,79.488,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",32,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,9.92,89.408,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",33,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.832,98.24000000000001,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",34,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.512,106.75200000000001,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",35,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,109.79200000000002,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",36,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.168,112.96000000000002,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",37,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,116.60800000000002,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",38,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,119.64800000000002,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",39,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,122.20800000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",40,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,2.976,125.18400000000003,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",41,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,128.22400000000002,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",42,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.68,131.90400000000002,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",43,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,134.94400000000002,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",44,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,137.50400000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",45,16384.0,1503744.0,0.0,0,0.0,1503744.0,1503744.0,8320.0,16.0,0.9980806142034548,12288.0,4096.0,20.16,157.66400000000002,1272832.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",46,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,166.43200000000002,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",47,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,169.056,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",48,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,171.584,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",49,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.584,175.168,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",50,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,177.6,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",51,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,180.16,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",52,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.912,183.072,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",53,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,185.66400000000002,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",54,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17149952.0,29376.0,23.36,209.024,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",55,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,3.104,212.12800000000001,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",56,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17156864.0,29024.0,23.68,235.80800000000002,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",57,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,238.40000000000003,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",58,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17836800.0,2048.0,22.88,261.28000000000003,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",59,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,263.84000000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",60,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.624,266.46400000000006,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",61,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,269.85600000000005,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",62,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,272.25600000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",63,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,274.81600000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",64,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.912,277.728,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",65,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,280.288,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",66,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.48,288.76800000000003,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",67,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.896,297.66400000000004,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",68,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,306.432,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",69,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,309.536,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",70,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.072,312.608,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",71,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.616,316.224,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",72,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,319.328,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",73,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,321.91999999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",74,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,324.92799999999994,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",75,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.072,327.99999999999994,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",76,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,331.64799999999997,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",77,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,334.65599999999995,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",78,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,337.24799999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",79,16352.0,1503660.0,0.0,0,0.0,1503660.0,1503660.0,8323.0,16.0,0.9980813047127953,12288.0,4096.0,20.192,357.43999999999994,1272815.0,198141.0,16352.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",80,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.736,366.17599999999993,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",81,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,368.79999999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",82,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,371.35999999999996,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",83,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.328,374.68799999999993,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",84,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,377.11999999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",85,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,379.71199999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",86,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,382.68799999999993,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",87,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,385.24799999999993,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",88,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17137408.0,31232.0,24.416,409.66399999999993,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",89,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.912,412.5759999999999,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",90,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17146496.0,29408.0,23.552,436.12799999999993,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",91,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.656,438.78399999999993,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",92,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17835776.0,2048.0,23.84,462.6239999999999,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",93,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.752,465.3759999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",94,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.592,467.9679999999999,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",95,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.328,471.2959999999999,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",96,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,473.69599999999986,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",97,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,476.25599999999986,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",98,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,479.23199999999986,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",99,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,481.82399999999984,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",100,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.832,490.65599999999984,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",101,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.544,499.1999999999998,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",102,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,9.12,508.3199999999998,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",103,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,511.3919999999998,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",104,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.136,514.5279999999998,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",105,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.68,518.2079999999997,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",106,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,521.2799999999997,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",107,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,523.8399999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",108,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,526.9119999999997,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",109,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,529.9519999999997,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",110,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.68,533.6319999999996,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",111,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,536.7039999999996,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",112,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,539.2639999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",113,16384.0,1503744.0,0.0,0,0.0,1503744.0,1503744.0,8320.0,16.0,0.9980806142034548,12288.0,4096.0,20.16,559.4239999999995,1272832.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",114,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.8,568.2239999999995,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",115,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,570.8159999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",116,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.656,573.4719999999994,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",117,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.424,576.8959999999994,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",118,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,579.3279999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",119,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,581.9199999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",120,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.008,584.9279999999994,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",121,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,587.4879999999994,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",122,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17153248.0,28448.0,23.2,610.6879999999994,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",123,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.944,613.6319999999994,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",124,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17158528.0,29184.0,22.848,636.4799999999993,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",125,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.56,639.0399999999993,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",126,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17847808.0,2048.0,22.88,661.9199999999993,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",127,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,664.5119999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",128,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.592,667.1039999999992,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",129,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.456,670.5599999999993,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",130,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,672.9599999999992,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",131,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,675.5199999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",132,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,678.4959999999992,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",133,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,681.0879999999992,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",134,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.928,690.0159999999992,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",135,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.448,698.4639999999991,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",136,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.672,707.1359999999992,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",137,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,710.2079999999992,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",138,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.072,713.2799999999992,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",139,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.616,716.8959999999992,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",140,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,719.9999999999992,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",141,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,722.6239999999992,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",142,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,725.7599999999992,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",143,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.072,728.8319999999992,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",144,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.616,732.4479999999992,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",145,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.2,735.6479999999992,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",146,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,738.2399999999992,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",147,16384.0,1503744.0,0.0,0,0.0,1503744.0,1503744.0,8320.0,16.0,0.9980806142034548,12288.0,4096.0,20.16,758.3999999999992,1272832.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",148,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,9.12,767.5199999999992,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",149,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,770.1439999999992,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",150,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.624,772.7679999999992,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",151,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,776.1599999999993,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",152,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,778.5919999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",153,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,781.1519999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",154,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.104,784.2559999999993,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",155,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,786.8479999999993,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",156,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17146944.0,29536.0,23.264,810.1119999999993,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",157,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,3.008,813.1199999999993,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",158,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17149952.0,29216.0,23.104,836.2239999999994,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",159,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.688,838.9119999999994,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",160,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17835648.0,2048.0,23.04,861.9519999999993,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",161,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,864.5439999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",162,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,867.0719999999993,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",163,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.36,870.4319999999993,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",164,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,872.8639999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",165,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,875.4239999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",166,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.072,878.4959999999993,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",167,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,881.0559999999992,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",168,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.736,889.7919999999992,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",169,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.736,898.5279999999992,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",170,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.384,906.9119999999992,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",171,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,909.9199999999993,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",172,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.008,912.9279999999993,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",173,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.84,916.7679999999993,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",174,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,919.8079999999993,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",175,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,922.3999999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",176,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,925.4079999999993,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",177,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.136,928.5439999999993,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",178,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,932.1919999999993,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",179,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,935.2639999999993,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",180,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,937.8559999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",181,16352.0,1503660.0,0.0,0,0.0,1503660.0,1503660.0,8323.0,16.0,0.9980813047127953,12288.0,4096.0,20.096,957.9519999999993,1272815.0,198141.0,16352.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",182,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,966.7199999999993,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",183,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.656,969.3759999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",184,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,971.9039999999993,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",185,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.424,975.3279999999993,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",186,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.592,977.9199999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",187,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,980.4799999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",188,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,983.4239999999992,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",189,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,986.0159999999992,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",190,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17159936.0,28992.0,23.584,1009.5999999999991,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",191,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,3.072,1012.6719999999991,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",192,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17151360.0,29920.0,23.232,1035.903999999999,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",193,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,1038.4959999999992,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",194,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17831936.0,2048.0,23.232,1061.7279999999992,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",195,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,1064.3199999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",196,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.656,1066.9759999999992,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",197,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,1070.3679999999993,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",198,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,1072.8319999999992,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",199,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,1075.3919999999991,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",200,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,1078.335999999999,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",201,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,1080.895999999999,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",202,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.704,1089.599999999999,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",203,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.896,1098.495999999999,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",204,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.8,1107.295999999999,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",205,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,1110.4319999999989,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",206,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.104,1113.535999999999,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",207,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.744,1117.2799999999988,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",208,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,1120.3519999999987,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",209,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,1122.9439999999988,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",210,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,1126.0159999999987,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",211,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,1129.0559999999987,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",212,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,1132.7039999999986,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",213,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,1135.8399999999986,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",214,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,1138.3999999999985,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",215,16384.0,1503744.0,0.0,0,0.0,1503744.0,1503744.0,8320.0,16.0,0.9980806142034548,12288.0,4096.0,20.224,1158.6239999999984,1272832.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",216,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,1167.3919999999985,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",217,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,1169.9839999999986,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",218,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,1172.5119999999986,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",219,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,1175.9039999999986,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",220,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.56,1178.4639999999986,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",221,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,1181.0559999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",222,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.072,1184.1279999999986,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",223,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.624,1186.7519999999986,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",224,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17133952.0,29152.0,22.144,1208.8959999999986,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",225,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.912,1211.8079999999986,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",226,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17162752.0,28608.0,24.096,1235.9039999999986,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",227,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.56,1238.4639999999986,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",228,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17836160.0,2048.0,23.008,1261.4719999999986,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",229,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,1264.0639999999987,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",230,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,1266.6239999999987,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",231,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.424,1270.0479999999986,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",232,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,1272.4799999999987,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",233,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,1275.0719999999988,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",234,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,1278.0479999999989,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",235,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,1280.639999999999,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",236,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.8,1289.439999999999,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",237,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.704,1298.1439999999989,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",238,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,1306.911999999999,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",239,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.2,1310.111999999999,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",240,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.008,1313.119999999999,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",241,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,1316.767999999999,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",242,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,1319.775999999999,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",243,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.656,1322.4319999999989,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",244,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,1325.535999999999,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",245,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.008,1328.543999999999,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",246,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,1332.1919999999989,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",247,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,1335.199999999999,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",248,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.656,1337.8559999999989,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",249,16384.0,1503744.0,0.0,0,0.0,1503744.0,1503744.0,8320.0,16.0,0.9980806142034548,12288.0,4096.0,20.224,1358.0799999999988,1272832.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",250,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.704,1366.7839999999987,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",251,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,1369.3439999999987,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",252,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,1371.9039999999986,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",253,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.424,1375.3279999999986,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",254,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,1377.7599999999986,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",255,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,1380.3519999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",256,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.04,1383.3919999999987,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",257,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,1385.9839999999988,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",258,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17156736.0,29504.0,23.104,1409.0879999999988,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",259,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,3.104,1412.1919999999989,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",260,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17145216.0,29280.0,22.848,1435.0399999999988,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",261,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.56,1437.5999999999988,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",262,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17832448.0,2048.0,23.52,1461.1199999999988,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",263,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,1463.7119999999989,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",264,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.496,1466.207999999999,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",265,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,1469.599999999999,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",266,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,1472.063999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",267,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,1474.687999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",268,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,1477.631999999999,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",269,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.624,1480.255999999999,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",270,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.8,1489.055999999999,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",271,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.512,1497.5679999999988,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",272,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.544,1506.111999999999,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",273,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,1509.247999999999,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",274,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.168,1512.4159999999988,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",275,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.616,1516.0319999999988,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",276,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,1519.0719999999988,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",277,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,1521.6639999999989,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",278,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,1524.7039999999988,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",279,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.168,1527.8719999999987,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",280,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.712,1531.5839999999987,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",281,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,1534.7199999999987,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",282,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,1537.3119999999988,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",283,16384.0,1503744.0,0.0,0,0.0,1503744.0,1503744.0,8320.0,16.0,0.9980806142034548,12288.0,4096.0,20.256,1557.5679999999988,1272832.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",284,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,9.184,1566.7519999999988,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",285,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,1569.343999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",286,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,1571.871999999999,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",287,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,1575.263999999999,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",288,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,1577.727999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",289,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,1580.319999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",290,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,1583.2959999999991,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",291,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,1585.8879999999992,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",292,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17146880.0,29184.0,22.912,1608.7999999999993,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",293,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,3.04,1611.8399999999992,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",294,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17141632.0,29184.0,22.368,1634.2079999999992,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",295,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.784,1636.9919999999993,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",296,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17835648.0,2048.0,23.168,1660.1599999999992,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",297,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.72,1662.8799999999992,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",298,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,1665.4399999999991,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",299,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,1668.8319999999992,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",300,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.56,1671.3919999999991,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",301,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,1673.9839999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",302,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,1676.9279999999992,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",303,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,1679.4879999999991,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",304,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.864,1688.3519999999992,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",305,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.672,1697.0239999999992,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",306,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.832,1705.8559999999993,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",307,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,1708.8639999999994,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",308,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.2,1712.0639999999994,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",309,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,1715.7119999999993,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",310,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,1718.7839999999992,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",311,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,1721.3439999999991,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",312,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,1724.4479999999992,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",313,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.072,1727.519999999999,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",314,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.68,1731.1999999999991,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",315,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,1734.239999999999,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",316,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.688,1736.9279999999992,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",317,16384.0,1503744.0,0.0,0,0.0,1503744.0,1503744.0,8320.0,16.0,0.9980806142034548,12288.0,4096.0,20.352,1757.2799999999993,1272832.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",318,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.48,1765.7599999999993,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",319,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,1768.3199999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",320,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,1770.8479999999993,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",321,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.36,1774.2079999999992,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",322,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,1776.6399999999992,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",323,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,1779.1999999999991,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",324,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,1782.1759999999992,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",325,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,1784.7679999999993,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",326,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17150464.0,28608.0,23.456,1808.2239999999993,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",327,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.976,1811.1999999999994,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",328,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17158784.0,28736.0,23.616,1834.8159999999993,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",329,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,1837.4079999999994,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",330,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17827712.0,2048.0,22.944,1860.3519999999994,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",331,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,1862.9439999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",332,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,1865.4719999999995,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",333,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,1868.8639999999996,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",334,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,1871.3279999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",335,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,1873.9199999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",336,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.008,1876.9279999999997,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",337,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.72,1879.6479999999997,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",338,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.736,1888.3839999999998,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",339,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,9.088,1897.4719999999998,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",340,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.576,1906.0479999999998,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",341,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,1909.0879999999997,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",342,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,1912.1279999999997,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",343,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,1915.7759999999996,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",344,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,1918.8799999999997,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",345,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,1921.5039999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",346,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,1924.6399999999996,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",347,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.104,1927.7439999999997,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",348,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.68,1931.4239999999998,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",349,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,1934.5279999999998,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",350,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,1937.12,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",351,16352.0,1503660.0,0.0,0,0.0,1503660.0,1503660.0,8323.0,16.0,0.9980813047127953,12288.0,4096.0,20.064,1957.184,1272815.0,198141.0,16352.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",352,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.448,1965.632,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",353,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,1968.192,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",354,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,1970.752,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",355,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.488,1974.24,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",356,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.56,1976.8,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",357,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,1979.456,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",358,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,1982.432,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",359,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.656,1985.088,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",360,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17145344.0,29664.0,22.912,2008.0,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",361,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.912,2010.912,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",362,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17144832.0,29056.0,22.944,2033.856,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",363,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.784,2036.64,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",364,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17840768.0,2048.0,23.168,2059.808,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",365,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.656,2062.464,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",366,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.496,2064.96,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",367,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.488,2068.448,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",368,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,2070.848,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",369,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,2073.408,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",370,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.04,2076.448,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",371,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.656,2079.104,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",372,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.704,2087.808,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",373,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.672,2096.48,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",374,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,9.056,2105.536,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",375,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,2108.544,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",376,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,2.944,2111.488,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",377,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.616,2115.104,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",378,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,2118.24,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",379,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,2120.7999999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",380,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,2123.8399999999997,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",381,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.072,2126.912,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",382,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,2130.56,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",383,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,2133.5679999999998,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",384,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,2136.1919999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",385,16352.0,1503660.0,0.0,0,0.0,1503660.0,1503660.0,8323.0,16.0,0.9980813047127953,12288.0,4096.0,20.128,2156.3199999999997,1272815.0,198141.0,16352.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",386,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.8,2165.12,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",387,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,2167.7439999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",388,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,2170.2719999999995,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",389,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,2173.6639999999993,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",390,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,2176.095999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",391,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,2178.655999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",392,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,2181.599999999999,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",393,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,2184.159999999999,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",394,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17151872.0,28672.0,23.424,2207.583999999999,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",395,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,3.008,2210.5919999999987,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",396,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17162624.0,29728.0,22.912,2233.5039999999985,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",397,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.816,2236.3199999999983,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",398,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17841920.0,2048.0,23.072,2259.3919999999985,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",399,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,2261.9519999999984,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",400,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,2264.479999999998,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",401,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.36,2267.8399999999983,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",402,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,2270.2399999999984,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",403,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,2272.767999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",404,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.072,2275.8399999999983,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",405,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,2278.3999999999983,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",406,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,2287.1679999999983,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",407,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.64,2295.807999999998,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",408,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.736,2304.543999999998,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",409,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,2.976,2307.519999999998,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",410,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.136,2310.655999999998,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",411,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,2314.3039999999983,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",412,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,2317.3439999999982,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",413,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,2319.9359999999983,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",414,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.168,2323.1039999999985,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",415,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,2326.1439999999984,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",416,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.584,2329.7279999999982,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",417,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,2332.863999999998,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",418,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,2335.423999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",419,16384.0,1503744.0,0.0,0,0.0,1503744.0,1503744.0,8320.0,16.0,0.9980806142034548,12288.0,4096.0,20.096,2355.519999999998,1272832.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",420,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,9.12,2364.639999999998,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",421,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,2367.199999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",422,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.592,2369.791999999998,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",423,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,2373.183999999998,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",424,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,2375.6159999999977,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",425,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,2378.1439999999975,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",426,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.104,2381.2479999999973,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",427,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,2383.8079999999973,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",428,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17136000.0,29280.0,22.56,2406.367999999997,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",429,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,3.072,2409.4399999999973,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",430,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17140992.0,29728.0,22.688,2432.1279999999974,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",431,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,2434.7199999999975,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",432,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17832192.0,2048.0,23.104,2457.8239999999973,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",433,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.72,2460.543999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",434,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.624,2463.167999999997,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",435,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,2466.5599999999968,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",436,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,2469.0239999999967,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",437,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,2471.5839999999966,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",438,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.04,2474.6239999999966,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",439,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.688,2477.3119999999967,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",440,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,9.12,2486.4319999999966,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",441,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.512,2494.943999999997,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",442,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.384,2503.327999999997,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",443,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,2506.3359999999966,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",444,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.072,2509.4079999999967,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",445,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,2513.055999999997,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",446,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,2516.127999999997,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",447,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,2518.687999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",448,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,2521.6959999999967,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",449,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.008,2524.7039999999965,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",450,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,2528.3519999999967,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",451,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,2531.3599999999965,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",452,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,2533.9199999999964,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",453,16384.0,1503744.0,0.0,0,0.0,1503744.0,1503744.0,8320.0,16.0,0.9980806142034548,12288.0,4096.0,20.224,2554.1439999999966,1272832.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",454,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.8,2562.943999999997,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",455,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,2565.5039999999967,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",456,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,2568.0319999999965,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",457,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.36,2571.3919999999966,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",458,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,2573.7919999999967,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",459,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,2576.3519999999967,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",460,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,2579.327999999997,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",461,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,2581.8879999999967,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",462,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17147264.0,29088.0,24.032,2605.919999999997,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",463,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.88,2608.799999999997,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",464,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17144192.0,28864.0,23.296,2632.095999999997,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",465,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,2634.687999999997,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",466,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17833472.0,2048.0,23.392,2658.0799999999967,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",467,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,2660.6399999999967,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",468,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,2663.1679999999965,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",469,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.328,2666.4959999999965,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",470,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,2668.9279999999962,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",471,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,2671.5199999999963,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",472,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.072,2674.5919999999965,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",473,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,2677.1519999999964,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",474,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.48,2685.6319999999964,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",475,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,9.056,2694.6879999999965,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",476,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,2703.4559999999965,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",477,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,2706.4959999999965,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",478,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.072,2709.5679999999966,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",479,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.68,2713.2479999999964,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",480,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,2716.2879999999964,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",481,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.656,2718.9439999999963,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",482,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,2721.9839999999963,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",483,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.168,2725.1519999999964,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",484,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.744,2728.8959999999965,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",485,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,2731.9999999999964,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",486,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,2734.5599999999963,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",487,16352.0,1503660.0,0.0,0,0.0,1503660.0,1503660.0,8323.0,16.0,0.9980813047127953,12288.0,4096.0,20.128,2754.6879999999965,1272815.0,198141.0,16352.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",488,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.672,2763.3599999999965,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",489,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.72,2766.0799999999963,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",490,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,2768.6399999999962,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",491,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.456,2772.0959999999964,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",492,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,2774.5599999999963,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",493,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,2777.1199999999963,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",494,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,2780.0959999999964,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",495,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,2782.6559999999963,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",496,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17145600.0,29760.0,22.912,2805.567999999996,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",497,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.912,2808.479999999996,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",498,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17158560.0,30400.0,24.48,2832.959999999996,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",499,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.752,2835.711999999996,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",500,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17833088.0,2048.0,22.976,2858.687999999996,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",501,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,2861.311999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",502,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.496,2863.807999999996,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",503,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.488,2867.2959999999957,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",504,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,2869.695999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",505,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,2872.287999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",506,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.008,2875.2959999999957,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",507,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.656,2877.9519999999957,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",508,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.672,2886.6239999999957,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",509,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.736,2895.3599999999956,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",510,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.832,2904.1919999999955,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",511,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,2907.3279999999954,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",512,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,2910.3679999999954,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",513,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.744,2914.1119999999955,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",514,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,2917.2159999999953,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",515,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,2919.7759999999953,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",516,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,2922.783999999995,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",517,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.072,2925.855999999995,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",518,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,2929.5039999999954,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",519,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,2932.5439999999953,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",520,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,2935.167999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",521,16384.0,1503744.0,0.0,0,0.0,1503744.0,1503744.0,8320.0,16.0,0.9980806142034548,12288.0,4096.0,20.096,2955.263999999995,1272832.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",522,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.64,2963.903999999995,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",523,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,2966.463999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",524,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.624,2969.0879999999947,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",525,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.328,2972.4159999999947,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",526,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,2974.8479999999945,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",527,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,2977.4399999999946,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",528,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.008,2980.4479999999944,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",529,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,2983.0079999999944,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",530,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17165440.0,28960.0,22.88,3005.8879999999945,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",531,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.912,3008.7999999999943,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",532,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17152128.0,28864.0,22.88,3031.6799999999944,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",533,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,3034.2719999999945,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",534,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17835392.0,2048.0,23.52,3057.7919999999945,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",535,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,3060.3519999999944,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",536,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,3062.879999999994,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",537,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.36,3066.2399999999943,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",538,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.528,3068.767999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",539,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.688,3071.455999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",540,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.136,3074.591999999994,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",541,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,3077.1839999999943,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",542,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.48,3085.6639999999943,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",543,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.448,3094.111999999994,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",544,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.8,3102.9119999999944,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",545,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,3106.0479999999943,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",546,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,3109.0879999999943,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",547,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.584,3112.671999999994,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",548,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,3115.711999999994,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",549,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,3118.271999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",550,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,3121.407999999994,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",551,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,3124.447999999994,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",552,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.616,3128.063999999994,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",553,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,3131.135999999994,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",554,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,3133.695999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",555,16352.0,1503660.0,0.0,0,0.0,1503660.0,1503660.0,8323.0,16.0,0.9980813047127953,12288.0,4096.0,20.224,3153.919999999994,1272815.0,198141.0,16352.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",556,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.992,3162.9119999999944,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",557,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,3165.4719999999943,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",558,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,3167.999999999994,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",559,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.36,3171.359999999994,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",560,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,3173.7599999999943,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",561,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,3176.287999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",562,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.072,3179.359999999994,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",563,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,3181.919999999994,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",564,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17148672.0,29664.0,22.432,3204.351999999994,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",565,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,3.04,3207.391999999994,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",566,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17147136.0,29760.0,23.648,3231.039999999994,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",567,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.56,3233.599999999994,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",568,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17828992.0,2048.0,23.232,3256.831999999994,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",569,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,3259.423999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",570,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,3261.951999999994,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",571,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.52,3265.471999999994,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",572,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,3267.9039999999936,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",573,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.688,3270.5919999999937,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",574,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.072,3273.663999999994,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",575,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.624,3276.2879999999936,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",576,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.544,3284.8319999999935,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",577,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.48,3293.3119999999935,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",578,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.448,3301.7599999999934,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",579,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,3304.767999999993,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",580,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.008,3307.775999999993,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",581,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.68,3311.455999999993,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",582,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,2.976,3314.431999999993,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",583,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.752,3317.183999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",584,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,3320.1919999999927,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",585,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.168,3323.359999999993,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",586,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.712,3327.071999999993,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",587,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,3330.111999999993,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",588,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,3332.703999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",589,16352.0,1503660.0,0.0,0,0.0,1503660.0,1503660.0,8323.0,16.0,0.9980813047127953,12288.0,4096.0,20.128,3352.831999999993,1272815.0,198141.0,16352.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",590,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,3361.599999999993,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",591,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,3364.191999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",592,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,3366.719999999993,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",593,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.36,3370.079999999993,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",594,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,3372.511999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",595,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,3375.071999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",596,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.136,3378.207999999993,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",597,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,3380.799999999993,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",598,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17145856.0,29536.0,22.848,3403.647999999993,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",599,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.912,3406.5599999999927,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",600,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17152768.0,29472.0,24.416,3430.975999999993,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",601,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,3433.567999999993,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",602,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17830400.0,2048.0,22.784,3456.351999999993,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",603,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.688,3459.039999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",604,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.496,3461.5359999999932,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",605,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.488,3465.023999999993,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",606,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.56,3467.583999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",607,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,3470.175999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",608,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,3473.151999999993,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",609,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.528,3475.679999999993,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",610,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.448,3484.127999999993,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",611,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.512,3492.639999999993,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",612,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.576,3501.215999999993,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",613,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,3504.319999999993,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",614,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,2.976,3507.295999999993,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",615,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.68,3510.975999999993,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",616,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,3514.0799999999927,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",617,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.656,3516.7359999999926,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",618,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,3519.8719999999926,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",619,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,3522.9119999999925,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",620,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,3526.5599999999927,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",621,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,3529.5679999999925,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",622,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,3532.1279999999924,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",623,16384.0,1503744.0,0.0,0,0.0,1503744.0,1503744.0,8320.0,16.0,0.9980806142034548,12288.0,4096.0,20.288,3552.4159999999924,1272832.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",624,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.448,3560.8639999999923,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",625,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.656,3563.5199999999923,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",626,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,3566.079999999992,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",627,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.36,3569.4399999999923,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",628,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.496,3571.9359999999924,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",629,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,3574.4959999999924,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",630,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.008,3577.503999999992,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",631,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,3580.0959999999923,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",632,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17136128.0,31872.0,23.968,3604.063999999992,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",633,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.976,3607.0399999999922,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",634,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17143680.0,29344.0,23.584,3630.623999999992,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",635,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,3633.215999999992,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",636,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17833600.0,2048.0,23.68,3656.895999999992,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",637,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,3659.455999999992,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",638,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.496,3661.951999999992,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",639,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.456,3665.407999999992,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",640,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,3667.839999999992,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",641,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,3670.399999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",642,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,3673.343999999992,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",643,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.528,3675.8719999999917,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",644,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.64,3684.5119999999915,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",645,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.864,3693.3759999999916,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",646,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.352,3701.7279999999914,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",647,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,3704.7679999999914,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",648,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.104,3707.871999999991,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",649,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.872,3711.743999999991,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",650,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,3714.879999999991,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",651,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,3717.439999999991,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",652,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,3720.479999999991,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",653,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,3723.519999999991,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",654,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,3727.167999999991,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",655,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,3730.175999999991,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",656,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,3732.7999999999906,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",657,16384.0,1503744.0,0.0,0,0.0,1503744.0,1503744.0,8320.0,16.0,0.9980806142034548,12288.0,4096.0,20.096,3752.8959999999906,1272832.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",658,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.48,3761.3759999999907,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",659,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,3763.9359999999906,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",660,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,3766.4639999999904,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",661,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,3769.85599999999,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",662,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,3772.31999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",663,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,3774.9119999999903,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",664,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,3777.85599999999,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",665,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,3780.41599999999,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",666,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17146624.0,29056.0,22.88,3803.2959999999903,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",667,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.912,3806.20799999999,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",668,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17159296.0,28416.0,22.816,3829.02399999999,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",669,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.72,3831.7439999999897,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",670,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17849984.0,2048.0,23.04,3854.7839999999896,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",671,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,3857.3439999999896,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",672,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.624,3859.9679999999894,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",673,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,3863.359999999989,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",674,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,3865.791999999989,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",675,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,3868.351999999989,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",676,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.008,3871.3599999999888,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",677,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.528,3873.8879999999886,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",678,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.544,3882.4319999999884,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",679,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.544,3890.9759999999883,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",680,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.448,3899.423999999988,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",681,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,3902.463999999988,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",682,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,3905.503999999988,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",683,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.872,3909.375999999988,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",684,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,3912.415999999988,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",685,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,3914.975999999988,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",686,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,3918.111999999988,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",687,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,3921.1519999999878,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",688,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.616,3924.7679999999878,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",689,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,3927.7759999999876,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",690,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,3930.3999999999874,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",691,16320.0,1503576.0,0.0,0,0.0,1503576.0,1503576.0,8326.0,16.0,0.9980819947254855,12288.0,4096.0,20.064,3950.463999999987,1272798.0,198138.0,16320.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",692,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,9.12,3959.583999999987,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",693,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,3962.143999999987,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",694,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.496,3964.639999999987,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",695,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.36,3967.9999999999873,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",696,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,3970.3999999999874,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",697,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,3972.9599999999873,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",698,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.04,3975.9999999999873,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",699,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,3978.5919999999874,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",700,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17146880.0,28960.0,22.56,4001.1519999999873,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",701,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.88,4004.0319999999874,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",702,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17146624.0,29664.0,23.872,4027.9039999999873,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",703,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.56,4030.463999999987,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",704,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17835904.0,2048.0,22.944,4053.407999999987,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",705,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,4055.967999999987,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",706,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.496,4058.463999999987,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",707,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.424,4061.887999999987,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",708,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,4064.319999999987,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",709,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,4066.879999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",710,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,4069.855999999987,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",711,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,4072.415999999987,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",712,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,9.248,4081.663999999987,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",713,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.512,4090.175999999987,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",714,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,4098.943999999987,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",715,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,4102.015999999987,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",716,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.072,4105.087999999987,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",717,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.712,4108.799999999987,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",718,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,4111.839999999987,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",719,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,4114.431999999987,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",720,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,4117.503999999987,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",721,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,2.944,4120.447999999988,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",722,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,4124.095999999988,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",723,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,4127.135999999988,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",724,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,4129.727999999987,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",725,16352.0,1503660.0,0.0,0,0.0,1503660.0,1503660.0,8323.0,16.0,0.9980813047127953,12288.0,4096.0,20.128,4149.855999999987,1272815.0,198141.0,16352.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",726,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.576,4158.431999999987,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",727,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.528,4160.959999999987,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",728,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.464,4163.423999999987,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",729,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.36,4166.783999999987,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",730,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,4169.215999999987,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",731,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,4171.807999999986,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",732,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,4174.751999999987,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",733,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.624,4177.375999999987,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",734,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17156480.0,28992.0,23.84,4201.215999999987,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",735,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.912,4204.127999999987,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",736,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17140736.0,28448.0,24.16,4228.287999999987,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",737,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,4230.8799999999865,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",738,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17836672.0,2048.0,23.072,4253.951999999987,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",739,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.528,4256.479999999987,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",740,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.496,4258.975999999987,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",741,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,4262.367999999987,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",742,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,4264.7999999999865,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",743,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,4267.359999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",744,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.04,4270.399999999987,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",745,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,4272.959999999987,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",746,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.416,4281.3759999999875,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",747,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.448,4289.823999999988,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",748,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.48,4298.303999999987,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",749,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,4301.311999999987,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",750,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,4304.351999999987,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",751,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.68,4308.031999999987,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",752,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,4311.039999999987,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",753,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,4313.663999999987,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",754,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,4316.703999999987,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",755,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,2.976,4319.679999999987,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",756,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,4323.327999999987,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",757,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,4326.431999999987,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",758,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,4328.9919999999875,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",759,16384.0,1503744.0,0.0,0,0.0,1503744.0,1503744.0,8320.0,16.0,0.9980806142034548,12288.0,4096.0,20.256,4349.247999999988,1272832.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",760,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.48,4357.727999999987,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",761,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.688,4360.415999999987,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",762,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,4362.943999999988,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",763,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.456,4366.399999999988,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",764,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,4368.831999999988,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",765,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,4371.391999999988,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",766,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,4374.335999999988,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",767,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,4376.895999999989,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",768,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17135904.0,30080.0,22.496,4399.391999999989,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",769,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.912,4402.303999999989,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",770,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17144960.0,29184.0,23.712,4426.01599999999,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",771,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.56,4428.57599999999,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",772,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17836672.0,2048.0,22.976,4451.55199999999,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",773,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,4454.11199999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",774,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.656,4456.76799999999,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",775,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.52,4460.2879999999905,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",776,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,4462.75199999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",777,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,4465.311999999991,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",778,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.04,4468.351999999991,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",779,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,4470.911999999991,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",780,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.512,4479.423999999991,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",781,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.48,4487.90399999999,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",782,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,9.12,4497.02399999999,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",783,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,4500.06399999999,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",784,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.008,4503.07199999999,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",785,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.68,4506.75199999999,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",786,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,4509.887999999991,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",787,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,4512.511999999991,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",788,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,4515.647999999991,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",789,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,2.976,4518.623999999991,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",790,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.904,4522.527999999991,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",791,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,4525.567999999991,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",792,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,4528.1279999999915,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",793,16352.0,1503660.0,0.0,0,0.0,1503660.0,1503660.0,8323.0,16.0,0.9980813047127953,12288.0,4096.0,20.256,4548.383999999992,1272815.0,198141.0,16352.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",794,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.736,4557.119999999992,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",795,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,4559.679999999992,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",796,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,4562.207999999992,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",797,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,4565.599999999992,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",798,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,4567.999999999992,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",799,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,4570.5919999999915,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",800,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,4573.535999999992,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",801,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,4576.1279999999915,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",802,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17147008.0,30400.0,24.0,4600.1279999999915,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",803,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.88,4603.007999999992,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",804,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17152608.0,28960.0,22.848,4625.855999999992,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",805,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.624,4628.479999999991,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",806,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17843456.0,2048.0,23.648,4652.1279999999915,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",807,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,4654.687999999992,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",808,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,4657.215999999992,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",809,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.488,4660.703999999992,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",810,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,4663.103999999992,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",811,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,4665.631999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",812,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.072,4668.703999999992,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",813,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,4671.263999999993,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",814,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.64,4679.903999999993,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",815,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.448,4688.3519999999935,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",816,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.416,4696.767999999994,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",817,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,4699.839999999994,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",818,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,4702.879999999994,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",819,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.712,4706.591999999994,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",820,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,4709.631999999994,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",821,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,4712.223999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",822,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,4715.359999999994,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",823,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,4718.399999999994,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",824,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,4722.047999999994,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",825,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,4725.087999999994,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",826,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,4727.711999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",827,16384.0,1503744.0,0.0,0,0.0,1503744.0,1503744.0,8320.0,16.0,0.9980806142034548,12288.0,4096.0,20.128,4747.839999999994,1272832.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",828,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.512,4756.3519999999935,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",829,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,4758.975999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",830,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,4761.5039999999935,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",831,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.36,4764.863999999993,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",832,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,4767.263999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",833,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,4769.823999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",834,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,4772.767999999994,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",835,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.656,4775.423999999994,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",836,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17143552.0,29344.0,22.912,4798.335999999994,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",837,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.912,4801.247999999994,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",838,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17146752.0,29312.0,23.104,4824.351999999994,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",839,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.784,4827.135999999994,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",840,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17834752.0,2048.0,23.2,4850.335999999994,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",841,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,4852.895999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",842,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.592,4855.487999999994,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",843,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.36,4858.847999999994,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",844,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,4861.3119999999935,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",845,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,4863.839999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",846,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,4866.783999999994,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",847,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,4869.375999999994,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",848,33088000.0,65856000.0,576000.0,0,0.0,66432000.0,66432000.0,88000.0,2056000.0,0.041044776119402986,132910848.0,185088.0,147.872,5017.247999999994,256000.0,0.0,32800000.0,288000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",849,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,5019.295999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",850,258.0,0.0,516.0,0,0.0,516.0,516.0,0.0,4.0,0.0,64.0,64.0,2.56,5021.855999999994,0.0,0.0,0.0,258.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",851,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.432,5024.287999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",852,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,128000.0,128000.0,2.72,5027.007999999994,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",853,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,5029.055999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",854,48128.0,0.0,96256.0,0,0.0,96256.0,96256.0,512.0,1512.0,0.25296442687747034,129024.0,8192.0,4.0,5033.055999999994,0.0,0.0,0.0,48128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",855,27648.0,0.0,55296.0,0,0.0,55296.0,55296.0,2112.0,8610.0,0.1969781757134863,527360.0,0.0,4.832,5037.8879999999945,0.0,0.0,0.0,27648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",856,16336.0,0.0,32672.0,0,0.0,32672.0,32672.0,512.0,1512.0,0.25296442687747034,129024.0,8192.0,4.224,5042.111999999995,0.0,0.0,0.0,16336.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",857,33792.0,0.0,67584.0,0,0.0,67584.0,67584.0,2112.0,8802.0,0.19351291918636612,527360.0,0.0,4.736,5046.8479999999945,0.0,0.0,0.0,33792.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",858,16130.0,0.0,32260.0,0,0.0,32260.0,32260.0,512.0,1512.0,0.25296442687747034,129024.0,8192.0,3.936,5050.783999999994,0.0,0.0,0.0,16130.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",859,29696.0,0.0,59392.0,0,0.0,59392.0,59392.0,2112.0,8674.0,0.19580938253291302,527360.0,0.0,4.832,5055.6159999999945,0.0,0.0,0.0,29696.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",860,16129.0,0.0,32258.0,0,0.0,32258.0,32258.0,512.0,1512.0,0.25296442687747034,129024.0,8192.0,3.936,5059.551999999994,0.0,0.0,0.0,16129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",861,28672.0,0.0,57344.0,0,0.0,57344.0,57344.0,2112.0,8642.0,0.19639204017109912,527360.0,32.0,4.64,5064.191999999995,0.0,0.0,0.0,28672.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",862,352.0,0.0,704.0,0,0.0,704.0,704.0,0.0,3.0,0.0,1056.0,128.0,3.072,5067.263999999995,0.0,0.0,0.0,352.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",863,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.016,5069.279999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",864,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,11.0,0.9829984544049459,128.0,0.0,4.256,5073.535999999995,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",865,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.048,5075.583999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",866,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,11.0,0.9829984544049459,128.0,0.0,4.256,5079.839999999995,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 1>(detail::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, detail::TensorInfo<T1, T2>, T2, detail::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",867,40292.0,0.0,80584.0,0,0.0,80584.0,80584.0,5904.0,2108.0,0.7368946580129805,131808.0,1760.0,6.016,5085.855999999994,0.0,0.0,0.0,40292.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::radixSortKVInPlace<(int)-2, (int)-1, 32, 4, float, long, unsigned int>(detail::TensorInfo<T5, T7>, T7, T7, T7, detail::TensorInfo<T6, T7>, T7, bool)",868,64.0,0.0,128.0,0,0.0,128.0,128.0,458.0,8.0,0.9828326180257511,640.0,0.0,6.016,5091.871999999994,0.0,0.0,0.0,64.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",869,64000.0,0.0,128000.0,0,0.0,128000.0,128000.0,0.0,3000.0,0.0,130016.0,8000.0,4.256,5096.127999999994,0.0,0.0,0.0,64000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",870,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,768.0,0.0,160000.0,0.0,2.912,5099.0399999999945,0.0,0.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"native::<unnamed>::fill_reverse_indices_kernel(long *, int, detail::IntDivider<unsigned int>)",871,128768.0,0.0,257536.0,0,0.0,257536.0,257536.0,0.0,1000.0,0.0,0.0,256000.0,2.496,5101.535999999995,0.0,0.0,0.0,128768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",872,387236.0,0.0,774472.0,0,0.0,774472.0,774472.0,64512.0,1000.0,0.9847356209549396,128000.0,0.0,4.0,5105.535999999995,0.0,0.0,0.0,387236.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",873,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,2.592,5108.127999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",874,29568.0,0.0,59136.0,0,0.0,59136.0,59136.0,10414.0,4255.0,0.7099325107369282,407552.0,310176.0,14.912,5123.0399999999945,0.0,0.0,0.0,29568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",875,14400.0,0.0,28800.0,0,0.0,28800.0,28800.0,3418.0,4312.0,0.44217335058214746,407552.0,390144.0,13.248,5136.287999999994,0.0,0.0,0.0,14400.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",876,15744.0,0.0,31488.0,0,0.0,31488.0,31488.0,4798.0,4235.0,0.5311635115686926,405504.0,390144.0,14.24,5150.527999999994,0.0,0.0,0.0,15744.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",877,15744.0,0.0,31488.0,0,0.0,31488.0,31488.0,4798.0,4239.0,0.5309284054442847,405504.0,326432.0,14.368,5164.895999999994,0.0,0.0,0.0,15744.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",878,524494.0,1061280.0,152988.0,0,0.0,1214268.0,1214268.0,132.0,1312.0,0.09141274238227147,251520.0,128000.0,18.496,5183.391999999994,133280.0,32000.0,448000.0,76494.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<float, 1>>(T1, int)",879,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,0.0,416.0,2.048,5185.439999999994,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<float, std::plus<float>>::Policy900, const float *, float *, at_cuda_detail::ScanTileState<float, 1>, std::plus<float>, at_cuda_detail::NullType, unsigned int, float, 0>(T2, T3, T4, int, T5, T6, T7)",880,2177.0,85371.0,4354.0,0,0.0,89725.0,89725.0,4349.0,2054.0,0.6792128689676714,135840.0,129024.0,4.16,5189.599999999994,85371.0,0.0,0.0,2177.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",881,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,512.0,0.0,128000.0,31808.0,2.624,5192.223999999994,0.0,0.0,0.0,256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::unrolled_elementwise_kernel<native::FillFunctor<bool>, std::array<char *, 1>, 16, TrivialOffsetCalculator<0, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithoutCast, memory::StoreWithoutCast>(int, T1, T2, T4, T5, T6, T7)",882,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.08,5194.303999999994,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",883,68096.0,0.0,136192.0,0,0.0,136192.0,136192.0,0.0,3000.0,0.0,288000.0,12192.0,9.12,5203.423999999994,0.0,0.0,0.0,68096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",884,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,768.0,0.0,160000.0,0.0,3.072,5206.495999999994,0.0,0.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",885,524497.0,1061280.0,152994.0,0,0.0,1214274.0,1214274.0,132.0,1312.0,0.09141274238227147,276096.0,128000.0,18.656,5225.151999999994,133280.0,32000.0,448000.0,76497.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",886,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,251.0,0.19808306709265175,128000.0,32.0,9.792,5234.943999999994,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",887,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.432,5237.375999999994,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",888,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,251.0,0.19808306709265175,128000.0,32.0,9.888,5247.263999999994,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",889,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.496,5249.759999999994,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",890,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.592,5252.3519999999935,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",891,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.392,5255.743999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",892,1536.0,36576.0,3072.0,0,0.0,39648.0,39648.0,62.0,251.0,0.19808306709265175,128000.0,32.0,9.664,5265.407999999993,36576.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",893,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.432,5267.839999999993,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",894,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.464,5270.303999999993,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",895,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.2,5273.503999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",896,448000.0,640000.0,320000.0,0,0.0,960000.0,960000.0,0.0,1000.0,0.0,0.0,128000.0,2.816,5276.319999999992,0.0,64000.0,288000.0,160000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",897,196945.0,327680.0,66210.0,0,0.0,393890.0,393890.0,0.0,768.0,0.0,256000.0,0.0,3.84,5280.159999999993,0.0,0.0,163840.0,33105.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",898,18048.0,0.0,36096.0,0,0.0,36096.0,36096.0,124.0,251.0,0.33066666666666666,128000.0,32.0,12.96,5293.119999999993,0.0,0.0,0.0,18048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",899,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.4,5295.519999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",900,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,5298.143999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",901,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.464,5300.607999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",902,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.464,5303.071999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",903,258.0,0.0,516.0,0,0.0,516.0,516.0,0.0,4.0,0.0,64.0,64.0,2.56,5305.631999999992,0.0,0.0,0.0,258.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",904,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.016,5307.647999999992,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",905,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.048,5309.695999999992,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",906,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.688,5312.383999999992,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",907,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.048,5314.431999999992,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithoutCast, memory::StoreWithoutCast>(int, T1, T2, T4, T5, T6, T7)",908,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,3.0,0.0,64.0,32.0,2.4,5316.831999999991,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",909,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.56,5319.391999999992,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",910,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.464,5321.855999999992,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",911,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,3.072,5324.927999999992,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",912,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,3.232,5328.159999999992,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",913,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.4,5330.559999999991,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",914,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.528,5333.087999999992,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",915,130.0,0.0,260.0,0,0.0,260.0,260.0,0.0,3.0,0.0,64.0,32.0,3.2,5336.287999999991,0.0,0.0,0.0,130.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",916,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.048,5338.335999999991,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",917,128.0,0.0,256.0,0,0.0,256.0,256.0,129.0,6.0,0.9555555555555556,32.0,32.0,3.008,5341.343999999991,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",918,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.464,5343.807999999991,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",919,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.464,5346.271999999991,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",920,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,0.0,2.496,5348.767999999991,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(detail::TensorInfo<T1, T3>, detail::TensorInfo<const T1, T3>, detail::TensorInfo<const T2, T3>, int, int, T3, long)",921,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,4352.0,4096.0,3.04,5351.807999999991,0.0,0.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",922,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.816,5354.623999999991,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",923,6.0,0.0,12.0,0,0.0,12.0,12.0,0.0,2.0,0.0,32.0,32.0,3.328,5357.951999999991,0.0,0.0,0.0,6.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",924,515.0,0.0,1030.0,0,0.0,1030.0,1030.0,0.0,2.0,0.0,32.0,32.0,2.944,5360.895999999992,0.0,0.0,0.0,515.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",925,0.0,128.0,0.0,0,0.0,128.0,128.0,8.0,6.0,0.5714285714285714,320.0,256.0,2.56,5363.455999999992,0.0,128.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",926,288.0,0.0,576.0,0,0.0,576.0,576.0,0.0,10.0,0.0,512.0,512.0,2.464,5365.919999999992,0.0,0.0,0.0,288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",927,1664.0,2308.0,1280.0,0,0.0,3588.0,3588.0,0.0,8.0,0.0,512.0,512.0,2.944,5368.863999999992,4.0,256.0,1024.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",928,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,8.0,0.0,512.0,512.0,2.464,5371.327999999992,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",929,1536.0,2304.0,1024.0,0,0.0,3328.0,3328.0,0.0,8.0,0.0,512.0,512.0,2.912,5374.2399999999925,0.0,256.0,1024.0,512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",930,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,8.0,0.0,512.0,512.0,2.464,5376.703999999992,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",931,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.592,5379.295999999992,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",932,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.52,5382.8159999999925,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",933,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,5385.247999999992,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",934,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,5387.775999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",935,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,5390.719999999993,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",936,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,5393.279999999993,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",937,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.736,5402.015999999993,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",938,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.544,5410.559999999993,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",939,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.64,5419.199999999993,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",940,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,5422.239999999993,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",941,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,5425.279999999993,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",942,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,4.0,5429.279999999993,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",943,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,5432.319999999993,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",944,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,5434.879999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",945,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,5438.015999999994,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",946,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.072,5441.087999999994,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",947,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.872,5444.959999999995,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",948,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,5447.967999999994,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",949,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,5450.559999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",950,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.624,5453.183999999994,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",951,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.56,5455.743999999994,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",952,16384.0,1504260.0,0.0,0,0.0,1504260.0,1504260.0,8320.0,16.0,0.9980806142034548,20480.0,4096.0,20.384,5476.127999999994,1273344.0,198148.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",953,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.736,5484.863999999994,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",954,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,5487.455999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",955,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,5489.983999999994,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",956,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.424,5493.407999999994,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",957,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,5495.839999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",958,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,5498.367999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",959,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,5501.311999999994,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",960,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.656,5503.967999999994,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",961,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17140736.0,29440.0,24.416,5528.383999999995,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",962,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.912,5531.295999999995,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",963,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17154304.0,28896.0,24.256,5555.551999999995,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",964,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,5558.143999999995,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",965,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17828992.0,2048.0,22.784,5580.927999999994,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",966,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,5583.519999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",967,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,5586.047999999994,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",968,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.424,5589.471999999994,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",969,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,5591.839999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",970,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,5594.399999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",971,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,5597.3439999999955,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",972,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.688,5600.031999999996,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",973,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.704,5608.735999999995,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",974,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.864,5617.599999999995,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",975,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.48,5626.0799999999945,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",976,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,5629.119999999994,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",977,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,5632.159999999994,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",978,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,5635.8079999999945,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",979,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.2,5639.007999999994,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",980,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,5641.567999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",981,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,5644.607999999995,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",982,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.008,5647.6159999999945,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",983,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.744,5651.359999999994,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",984,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,5654.399999999994,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",985,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.656,5657.055999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",986,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.72,5659.775999999994,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",987,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.688,5662.4639999999945,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",988,16352.0,1504180.0,0.0,0,0.0,1504180.0,1504180.0,8323.0,16.0,0.9980813047127953,20480.0,4096.0,20.448,5682.911999999995,1273327.0,198149.0,16352.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",989,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.48,5691.391999999994,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",990,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,5693.983999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",991,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,5696.511999999994,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",992,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.36,5699.871999999994,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",993,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,5702.271999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",994,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,5704.799999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",995,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,5707.743999999994,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",996,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.528,5710.2719999999945,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",997,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17154048.0,28960.0,22.368,5732.639999999995,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",998,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,3.008,5735.647999999995,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",999,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17144064.0,29216.0,22.88,5758.527999999995,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1000,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.56,5761.087999999995,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1001,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17837824.0,2048.0,22.848,5783.935999999995,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1002,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,5786.527999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1003,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,5789.055999999995,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1004,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.36,5792.415999999995,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1005,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,5794.879999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1006,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,5797.439999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1007,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,5800.3839999999955,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1008,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.656,5803.039999999995,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1009,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,5811.807999999995,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1010,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.512,5820.319999999995,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1011,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.736,5829.055999999995,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1012,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,5832.127999999995,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1013,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.072,5835.199999999995,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1014,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,5838.847999999995,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1015,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,5841.887999999995,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1016,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,5844.479999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1017,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,5847.551999999995,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1018,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.008,5850.559999999995,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1019,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,5854.207999999995,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1020,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,5857.247999999995,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1021,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,5859.839999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1022,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.56,5862.399999999995,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1023,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.624,5865.023999999995,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",1024,16320.0,1504092.0,0.0,0,0.0,1504092.0,1504092.0,8326.0,16.0,0.9980819947254855,20480.0,4096.0,20.224,5885.247999999995,1273310.0,198142.0,16320.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1025,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.48,5893.727999999995,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1026,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.656,5896.383999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1027,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.496,5898.879999999995,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1028,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.36,5902.239999999994,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1029,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,5904.639999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1030,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,5907.199999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1031,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.008,5910.207999999994,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1032,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,5912.799999999994,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1033,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17145600.0,28608.0,23.168,5935.9679999999935,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1034,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,3.008,5938.975999999993,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1035,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17149056.0,28672.0,22.944,5961.919999999994,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1036,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.624,5964.5439999999935,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1037,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17840384.0,2048.0,23.136,5987.679999999994,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1038,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,5990.239999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1039,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,5992.767999999995,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1040,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.36,5996.127999999994,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1041,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,5998.495999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1042,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,6001.023999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1043,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,6003.9999999999945,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1044,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.656,6006.6559999999945,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1045,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.832,6015.487999999995,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1046,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.896,6024.383999999995,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1047,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.48,6032.863999999994,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1048,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,6035.935999999994,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1049,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.008,6038.943999999994,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1050,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.808,6042.751999999994,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1051,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,6045.823999999994,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1052,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,6048.383999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1053,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,6051.519999999995,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1054,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.008,6054.527999999995,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1055,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.84,6058.367999999995,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1056,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,6061.471999999995,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1057,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,6064.031999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1058,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.56,6066.591999999996,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1059,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.56,6069.151999999996,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",1060,16384.0,1504256.0,0.0,0,0.0,1504256.0,1504256.0,8320.0,16.0,0.9980806142034548,20480.0,4096.0,20.256,6089.407999999997,1273344.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1061,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.416,6097.823999999997,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1062,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,6100.383999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1063,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,6102.9119999999975,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1064,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,6106.303999999997,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1065,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,6108.735999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1066,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,6111.327999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1067,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,6114.271999999997,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1068,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.656,6116.927999999997,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1069,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17139200.0,29408.0,23.264,6140.191999999997,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1070,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.912,6143.1039999999975,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1071,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17147904.0,29504.0,23.04,6166.1439999999975,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1072,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.624,6168.767999999997,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1073,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17829760.0,2048.0,23.296,6192.063999999998,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1074,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,6194.623999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1075,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.496,6197.119999999998,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1076,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.36,6200.479999999998,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1077,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,6202.879999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1078,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,6205.471999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1079,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.912,6208.383999999997,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1080,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,6210.975999999997,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1081,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,6219.743999999997,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1082,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.576,6228.319999999997,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1083,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.736,6237.055999999997,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1084,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,6240.063999999997,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1085,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.072,6243.135999999997,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1086,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.68,6246.815999999997,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1087,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,6249.855999999997,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1088,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,6252.415999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1089,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,6255.455999999997,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1090,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,2.976,6258.431999999997,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1091,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,6262.079999999997,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1092,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,6265.215999999998,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1093,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,6267.807999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1094,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.56,6270.367999999998,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1095,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.592,6272.959999999997,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",1096,16384.0,1504262.0,0.0,0,0.0,1504262.0,1504262.0,8320.0,16.0,0.9980806142034548,20480.0,4096.0,20.288,6293.247999999997,1273344.0,198150.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1097,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.896,6302.143999999997,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1098,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,6304.703999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1099,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,6307.263999999997,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1100,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.36,6310.623999999997,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1101,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,6313.055999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1102,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,6315.583999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1103,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.104,6318.687999999997,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1104,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,6321.279999999997,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1105,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17139936.0,29728.0,23.36,6344.639999999997,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1106,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.912,6347.551999999997,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1107,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17141888.0,28864.0,23.104,6370.655999999997,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1108,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.56,6373.215999999998,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1109,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17829504.0,2048.0,22.752,6395.967999999998,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1110,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,6398.559999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1111,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.496,6401.055999999998,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1112,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.36,6404.415999999997,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1113,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,6406.815999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1114,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,6409.3759999999975,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1115,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.136,6412.511999999998,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1116,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.624,6415.135999999998,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1117,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.704,6423.839999999997,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1118,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.48,6432.319999999997,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1119,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.672,6440.991999999997,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1120,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,6443.999999999996,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1121,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,6447.039999999996,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1122,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.584,6450.623999999996,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1123,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,6453.631999999996,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1124,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.528,6456.159999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1125,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,6459.295999999997,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1126,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,6462.335999999997,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1127,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,6465.983999999997,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1128,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,6469.023999999997,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1129,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,6471.6479999999965,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1130,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.656,6474.303999999996,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1131,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.56,6476.863999999997,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",1132,16352.0,1504180.0,0.0,0,0.0,1504180.0,1504180.0,8323.0,16.0,0.9980813047127953,20480.0,4096.0,20.192,6497.055999999997,1273327.0,198149.0,16352.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1133,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.512,6505.567999999997,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1134,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,6508.127999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1135,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.496,6510.623999999997,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1136,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,6514.015999999997,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1137,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,6516.4159999999965,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1138,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,6519.0719999999965,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1139,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,6522.047999999996,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1140,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,6524.6079999999965,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1141,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17135616.0,29664.0,22.528,6547.135999999997,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1142,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.912,6550.047999999997,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1143,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17146880.0,29088.0,23.616,6573.663999999997,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1144,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,6576.255999999997,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1145,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17844992.0,2048.0,22.912,6599.167999999997,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1146,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.656,6601.823999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1147,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,6604.351999999997,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1148,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.424,6607.775999999997,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1149,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,6610.207999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1150,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,6612.735999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1151,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.008,6615.743999999997,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1152,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,6618.303999999997,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1153,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.352,6626.655999999997,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1154,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.32,6634.975999999997,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1155,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.608,6643.583999999997,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1156,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,6646.623999999997,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1157,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,6649.663999999997,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1158,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,6653.311999999997,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1159,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,6656.447999999998,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1160,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,6659.007999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1161,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,6662.143999999998,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1162,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.008,6665.151999999998,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1163,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,6668.799999999998,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1164,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,6671.839999999998,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1165,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,6674.431999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1166,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.56,6676.991999999998,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1167,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.56,6679.551999999999,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",1168,16352.0,1504174.0,0.0,0,0.0,1504174.0,1504174.0,8323.0,16.0,0.9980813047127953,20480.0,4096.0,20.352,6699.903999999999,1273327.0,198143.0,16352.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1169,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.736,6708.6399999999985,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1170,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,6711.231999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1171,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,6713.759999999998,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1172,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.36,6717.119999999998,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1173,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.496,6719.615999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1174,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,6722.175999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1175,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.04,6725.2159999999985,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1176,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.656,6727.8719999999985,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1177,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17150720.0,29152.0,22.848,6750.719999999998,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1178,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.912,6753.631999999999,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1179,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17144064.0,29376.0,22.88,6776.511999999999,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1180,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.56,6779.071999999999,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1181,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17843456.0,2048.0,23.2,6802.271999999999,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1182,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,6804.895999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1183,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,6807.423999999999,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1184,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,6810.815999999999,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1185,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,6813.247999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1186,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,6815.807999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1187,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,6818.7519999999995,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1188,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,6821.312,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1189,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.544,6829.856,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1190,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.608,6838.464,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1191,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.8,6847.264,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1192,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,6850.304,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1193,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,6853.344,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1194,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.68,6857.024,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1195,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,6860.064,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1196,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.528,6862.592000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1197,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.168,6865.76,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1198,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.072,6868.832,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1199,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.68,6872.512000000001,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1200,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,6875.584000000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1201,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.72,6878.304000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1202,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.656,6880.960000000001,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1203,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.56,6883.520000000001,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",1204,16320.0,1504096.0,0.0,0,0.0,1504096.0,1504096.0,8323.0,16.0,0.9980813047127953,20480.0,4096.0,20.16,6903.680000000001,1273310.0,198146.0,16320.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1205,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.96,6912.640000000001,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1206,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,6915.200000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1207,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,6917.760000000002,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1208,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.36,6921.120000000002,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1209,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,6923.520000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1210,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,6926.048000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1211,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.912,6928.960000000002,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1212,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.656,6931.616000000002,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1213,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17149696.0,29440.0,22.624,6954.240000000002,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1214,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.976,6957.216000000001,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1215,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17145344.0,29440.0,22.912,6980.1280000000015,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1216,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.624,6982.752000000001,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1217,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17832448.0,2048.0,22.816,7005.568000000001,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1218,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,7008.160000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1219,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,7010.720000000001,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1220,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.52,7014.240000000002,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1221,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.528,7016.768000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1222,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,7019.328000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1223,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.04,7022.368000000002,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1224,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,7024.960000000002,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1225,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.448,7033.408000000002,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1226,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.704,7042.112000000002,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1227,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.736,7050.848000000002,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1228,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,7053.888000000002,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1229,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.072,7056.960000000002,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1230,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,7060.608000000002,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1231,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,7063.616000000002,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1232,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,7066.208000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1233,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,7069.248000000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1234,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.136,7072.384000000002,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1235,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.712,7076.096000000002,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1236,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,7079.136000000002,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1237,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,7081.696000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1238,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.592,7084.288000000002,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1239,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.56,7086.848000000003,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",1240,16384.0,1504262.0,0.0,0,0.0,1504262.0,1504262.0,8320.0,16.0,0.9980806142034548,20480.0,4096.0,20.192,7107.040000000003,1273344.0,198150.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1241,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.736,7115.776000000003,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1242,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,7118.368000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1243,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.496,7120.864000000002,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1244,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,7124.256000000002,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1245,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,7126.688000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1246,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,7129.248000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1247,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,7132.224000000002,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1248,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,7134.784000000002,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1249,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17152256.0,28416.0,23.776,7158.560000000002,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1250,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.912,7161.4720000000025,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1251,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17150848.0,30048.0,23.68,7185.152000000003,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1252,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.56,7187.712000000003,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1253,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17831680.0,2048.0,23.008,7210.720000000003,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1254,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,7213.280000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1255,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,7215.808000000004,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1256,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.328,7219.136000000004,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1257,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,7221.536000000004,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1258,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,7224.096000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1259,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,7227.0400000000045,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1260,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,7229.600000000005,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1261,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,7238.368000000005,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1262,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,7247.136000000005,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1263,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.576,7255.712000000005,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1264,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,7258.752000000005,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1265,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.072,7261.824000000005,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1266,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.712,7265.5360000000055,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1267,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,7268.640000000006,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1268,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,7271.200000000006,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1269,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,7274.272000000006,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1270,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.136,7277.408000000007,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1271,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,7281.056000000007,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1272,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,7284.192000000007,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1273,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,7286.816000000007,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1274,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.528,7289.344000000007,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1275,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.592,7291.936000000007,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",1276,16384.0,1504264.0,0.0,0,0.0,1504264.0,1504264.0,8320.0,16.0,0.9980806142034548,20480.0,4096.0,20.16,7312.096000000007,1273344.0,198152.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1277,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.832,7320.928000000007,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1278,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,7323.520000000007,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1279,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.496,7326.016000000007,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1280,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,7329.408000000007,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1281,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,7331.808000000006,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1282,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,7334.432000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1283,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.04,7337.472000000006,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1284,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,7340.0320000000065,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1285,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17147008.0,29440.0,22.24,7362.272000000006,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1286,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.944,7365.216000000007,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1287,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17145472.0,29760.0,23.328,7388.544000000007,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1288,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.56,7391.1040000000075,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1289,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17833600.0,2048.0,23.424,7414.5280000000075,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1290,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,7417.120000000007,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1291,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.688,7419.808000000007,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1292,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,7423.200000000007,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1293,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,7425.600000000007,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1294,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.496,7428.096000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1295,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.912,7431.008000000007,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1296,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,7433.5680000000075,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1297,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.704,7442.272000000007,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1298,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.704,7450.976000000007,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1299,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.736,7459.712000000007,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1300,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,7462.720000000007,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1301,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,7465.760000000007,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1302,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,7469.408000000007,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1303,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.168,7472.576000000006,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1304,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.72,7475.296000000007,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1305,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,7478.432000000007,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1306,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.136,7481.5680000000075,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1307,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,7485.216000000008,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1308,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,7488.256000000008,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1309,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,7490.880000000007,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1310,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.56,7493.440000000008,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1311,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.56,7496.000000000008,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",1312,16352.0,1504174.0,0.0,0,0.0,1504174.0,1504174.0,8323.0,16.0,0.9980813047127953,20480.0,4096.0,20.256,7516.2560000000085,1273327.0,198143.0,16352.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1313,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,7525.0240000000085,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1314,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,7527.616000000008,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1315,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.656,7530.272000000008,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1316,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.36,7533.632000000008,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1317,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.528,7536.160000000008,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1318,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,7538.720000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1319,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.04,7541.760000000008,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1320,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.72,7544.480000000009,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1321,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17154816.0,29184.0,22.88,7567.360000000009,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1322,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.944,7570.304000000009,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1323,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17156096.0,29088.0,23.072,7593.376000000009,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1324,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.688,7596.064000000009,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1325,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17831936.0,2048.0,23.296,7619.36000000001,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1326,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,7621.92000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1327,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.496,7624.41600000001,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1328,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,7627.80800000001,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1329,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,7630.20800000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1330,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,7632.800000000009,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1331,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,7635.74400000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1332,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,7638.336000000009,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1333,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.832,7647.16800000001,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1334,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.704,7655.872000000009,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1335,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.736,7664.608000000009,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1336,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,7667.680000000009,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1337,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.168,7670.848000000009,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1338,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.712,7674.5600000000095,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1339,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,7677.6000000000095,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1340,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,7680.16000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1341,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,7683.20000000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1342,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,2.976,7686.1760000000095,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1343,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.616,7689.7920000000095,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1344,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,7692.832000000009,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1345,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,7695.39200000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1346,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.592,7697.9840000000095,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1347,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.688,7700.67200000001,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",1348,16320.0,1504090.0,0.0,0,0.0,1504090.0,1504090.0,8323.0,16.0,0.9980813047127953,20480.0,4096.0,20.16,7720.832000000009,1273310.0,198140.0,16320.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1349,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.48,7729.312000000009,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1350,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,7731.872000000009,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1351,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.592,7734.464000000009,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1352,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,7737.856000000009,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1353,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,7740.288000000009,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1354,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,7742.848000000009,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1355,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.072,7745.920000000009,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1356,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.528,7748.448000000009,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1357,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17144960.0,29120.0,22.272,7770.720000000009,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1358,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.976,7773.696000000009,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1359,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17146368.0,29440.0,23.072,7796.768000000009,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1360,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,7799.360000000009,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1361,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17836160.0,2048.0,23.008,7822.368000000009,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1362,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,7824.928000000009,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1363,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,7827.456000000009,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1364,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,7830.848000000009,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1365,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,7833.248000000009,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1366,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,7835.776000000009,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1367,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,7838.752000000009,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1368,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,7841.344000000008,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1369,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.544,7849.888000000008,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1370,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,7858.656000000008,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1371,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.576,7867.232000000008,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1372,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,7870.272000000008,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1373,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,7873.312000000008,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1374,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.872,7877.184000000008,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1375,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,7880.320000000009,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1376,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,7882.880000000009,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1377,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,7885.952000000009,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1378,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.104,7889.05600000001,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1379,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.616,7892.67200000001,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1380,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.168,7895.840000000009,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1381,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,7898.40000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1382,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.56,7900.96000000001,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1383,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.56,7903.52000000001,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",1384,16384.0,1504256.0,0.0,0,0.0,1504256.0,1504256.0,8320.0,16.0,0.9980806142034548,20480.0,4096.0,20.48,7924.00000000001,1273344.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1385,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.928,7932.92800000001,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1386,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,7935.55200000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1387,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.496,7938.04800000001,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1388,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.36,7941.408000000009,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1389,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,7943.840000000009,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1390,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,7946.3680000000095,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1391,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,7949.31200000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1392,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,7951.90400000001,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1393,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17141632.0,29120.0,23.136,7975.04000000001,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1394,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.912,7977.95200000001,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1395,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17148288.0,29408.0,23.84,8001.79200000001,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1396,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.784,8004.57600000001,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1397,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17833344.0,2048.0,22.656,8027.23200000001,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1398,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,8029.85600000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1399,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.496,8032.35200000001,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1400,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.36,8035.7120000000095,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1401,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,8038.112000000009,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1402,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,8040.67200000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1403,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,8043.648000000009,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1404,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,8046.20800000001,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1405,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.704,8054.912000000009,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1406,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.736,8063.648000000009,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1407,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.448,8072.09600000001,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1408,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,8075.23200000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1409,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,8078.27200000001,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1410,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.616,8081.88800000001,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1411,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,8084.96000000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1412,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,8087.52000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1413,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,8090.56000000001,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1414,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.104,8093.664000000011,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1415,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,8097.312000000011,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1416,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.168,8100.4800000000105,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1417,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,8103.040000000011,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1418,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.56,8105.600000000011,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1419,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.56,8108.160000000012,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",1420,16384.0,1504260.0,0.0,0,0.0,1504260.0,1504260.0,8320.0,16.0,0.9980806142034548,20480.0,4096.0,20.192,8128.352000000012,1273344.0,198148.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1421,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.544,8136.896000000012,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1422,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,8139.456000000012,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1423,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.656,8142.112000000012,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1424,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,8145.504000000012,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1425,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.56,8148.064000000012,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1426,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,8150.656000000012,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1427,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.04,8153.696000000012,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1428,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,8156.256000000012,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1429,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17143936.0,29088.0,22.336,8178.592000000012,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1430,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.88,8181.4720000000125,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1431,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17148032.0,29632.0,23.04,8204.512000000013,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1432,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.688,8207.200000000013,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1433,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17833472.0,2048.0,23.104,8230.304000000013,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1434,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,8232.896000000013,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1435,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,8235.424000000014,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1436,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.36,8238.784000000014,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1437,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,8241.216000000015,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1438,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,8243.872000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1439,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.136,8247.008000000016,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1440,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,8249.568000000016,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1441,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.736,8258.304000000016,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1442,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.576,8266.880000000016,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1443,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.512,8275.392000000016,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1444,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,8278.432000000017,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1445,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.2,8281.632000000018,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1446,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,8285.280000000017,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1447,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,8288.384000000016,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1448,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,8290.976000000017,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1449,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,8293.984000000017,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1450,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.136,8297.120000000017,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1451,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.616,8300.736000000017,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1452,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,8303.808000000017,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1453,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,8306.432000000017,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1454,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.56,8308.992000000017,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1455,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.528,8311.520000000017,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",1456,16352.0,1504176.0,0.0,0,0.0,1504176.0,1504176.0,8323.0,16.0,0.9980813047127953,20480.0,4096.0,20.128,8331.648000000017,1273327.0,198145.0,16352.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1457,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,8340.416000000017,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1458,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,8342.976000000017,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1459,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,8345.504000000017,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1460,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.328,8348.832000000017,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1461,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,8351.232000000016,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1462,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,8353.792000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1463,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,8356.736000000015,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1464,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,8359.296000000015,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1465,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17144480.0,28928.0,23.328,8382.624000000014,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1466,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,3.072,8385.696000000014,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1467,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17155072.0,28544.0,23.2,8408.896000000015,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1468,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.56,8411.456000000015,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1469,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17833984.0,2048.0,22.688,8434.144000000015,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1470,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,8436.768000000015,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1471,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,8439.328000000014,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1472,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.456,8442.784000000014,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1473,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,8445.184000000014,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1474,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,8447.744000000013,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1475,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.008,8450.752000000013,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1476,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,8453.312000000013,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1477,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.896,8462.208000000013,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1478,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.48,8470.688000000013,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1479,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.64,8479.328000000012,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1480,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,8482.464000000013,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1481,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,8485.504000000014,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1482,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.616,8489.120000000014,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1483,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,8492.160000000014,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1484,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.656,8494.816000000015,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1485,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,8497.888000000015,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1486,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.136,8501.024000000016,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1487,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,8504.672000000015,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1488,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,8507.712000000016,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1489,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,8510.272000000015,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1490,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.56,8512.832000000015,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1491,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.592,8515.424000000015,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",1492,16352.0,1504176.0,0.0,0,0.0,1504176.0,1504176.0,8323.0,16.0,0.9980813047127953,20480.0,4096.0,20.192,8535.616000000015,1273327.0,198145.0,16352.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1493,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.544,8544.160000000014,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1494,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,8546.752000000015,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1495,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.496,8549.248000000014,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1496,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,8552.640000000014,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1497,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,8555.072000000015,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1498,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,8557.632000000014,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1499,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,8560.608000000015,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1500,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,8563.168000000014,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1501,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17140096.0,29376.0,22.592,8585.760000000015,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1502,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,3.008,8588.768000000015,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1503,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17147648.0,29152.0,22.464,8611.232000000015,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1504,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.56,8613.792000000014,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1505,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17834112.0,2048.0,23.04,8636.832000000015,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1506,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,8639.424000000015,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1507,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,8641.952000000016,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1508,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.36,8645.312000000016,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1509,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.496,8647.808000000015,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1510,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,8650.368000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1511,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.04,8653.408000000016,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1512,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,8656.000000000016,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1513,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.736,8664.736000000017,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1514,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.672,8673.408000000018,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1515,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.576,8681.984000000017,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1516,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,8684.992000000017,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1517,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,8688.032000000017,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1518,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.68,8691.712000000018,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1519,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,8694.816000000017,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1520,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,8697.408000000018,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1521,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,8700.448000000019,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1522,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,8703.48800000002,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1523,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,8707.136000000019,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1524,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,8710.240000000018,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1525,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,8712.832000000019,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1526,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.56,8715.392000000018,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1527,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.56,8717.952000000018,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",1528,16352.0,1504172.0,0.0,0,0.0,1504172.0,1504172.0,8323.0,16.0,0.9980813047127953,20480.0,4096.0,20.224,8738.176000000018,1273327.0,198141.0,16352.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1529,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.416,8746.592000000017,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1530,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,8749.152000000016,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1531,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,8751.680000000017,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1532,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.488,8755.168000000016,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1533,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,8757.600000000017,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1534,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,8760.160000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1535,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,8763.104000000016,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1536,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,8765.696000000016,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1537,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17141632.0,29248.0,22.464,8788.160000000016,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1538,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.912,8791.072000000016,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1539,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17146496.0,29312.0,23.456,8814.528000000017,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1540,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,8817.120000000017,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1541,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17830272.0,2048.0,23.04,8840.160000000018,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1542,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,8842.784000000018,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1543,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.496,8845.280000000017,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1544,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.488,8848.768000000016,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1545,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,8851.200000000017,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1546,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,8853.728000000017,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1547,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,8856.704000000018,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1548,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,8859.264000000017,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1549,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.512,8867.776000000018,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1550,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.512,8876.288000000019,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1551,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.704,8884.992000000018,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1552,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,8888.096000000018,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1553,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,8891.136000000019,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1554,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,8894.784000000018,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1555,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,8897.824000000019,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1556,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.656,8900.48000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1557,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,8903.52000000002,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1558,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,8906.560000000021,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1559,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.712,8910.27200000002,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1560,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,8913.344000000021,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1561,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,8915.90400000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1562,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.56,8918.46400000002,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1563,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.592,8921.05600000002,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",1564,16352.0,1504174.0,0.0,0,0.0,1504174.0,1504174.0,8323.0,16.0,0.9980813047127953,20480.0,4096.0,20.16,8941.21600000002,1273327.0,198143.0,16352.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1565,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.544,8949.76000000002,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1566,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.528,8952.28800000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1567,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,8954.81600000002,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1568,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.424,8958.240000000022,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1569,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,8960.640000000021,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1570,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,8963.168000000021,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1571,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,8966.112000000021,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1572,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,8968.67200000002,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1573,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17147008.0,29120.0,22.208,8990.880000000021,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1574,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.88,8993.76000000002,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1575,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17150816.0,29120.0,23.648,9017.40800000002,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1576,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.624,9020.03200000002,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1577,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17834368.0,2048.0,23.104,9043.136000000019,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1578,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,9045.696000000018,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1579,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.592,9048.288000000019,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1580,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.296,9051.584000000019,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1581,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.496,9054.080000000018,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1582,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,9056.608000000018,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1583,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.072,9059.680000000018,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1584,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,9062.240000000018,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1585,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.448,9070.688000000018,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1586,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.48,9079.168000000018,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1587,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.416,9087.584000000017,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1588,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,9090.720000000018,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1589,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.136,9093.856000000018,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1590,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.712,9097.568000000017,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1591,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,9100.640000000018,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1592,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,9103.232000000018,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1593,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,9106.336000000018,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1594,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,9109.376000000018,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1595,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.776,9113.152000000018,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1596,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,9116.224000000018,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1597,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,9118.816000000019,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1598,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.592,9121.40800000002,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1599,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.56,9123.968000000019,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",1600,16384.0,1504270.0,0.0,0,0.0,1504270.0,1504270.0,8320.0,16.0,0.9980806142034548,20480.0,4096.0,20.256,9144.224000000018,1273344.0,198158.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1601,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.544,9152.768000000018,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1602,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,9155.392000000018,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1603,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.56,9157.952000000018,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1604,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.36,9161.312000000018,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1605,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,9163.776000000018,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1606,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,9166.336000000018,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1607,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.008,9169.344000000017,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1608,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.656,9172.000000000018,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1609,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17158528.0,28448.0,23.424,9195.424000000019,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1610,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.912,9198.33600000002,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1611,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17149184.0,28480.0,23.008,9221.34400000002,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1612,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,9223.93600000002,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1613,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17835904.0,2048.0,23.072,9247.00800000002,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1614,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,9249.63200000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1615,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,9252.16000000002,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1616,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,9255.55200000002,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1617,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,9257.98400000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1618,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,9260.576000000021,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1619,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.072,9263.648000000021,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1620,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,9266.20800000002,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1621,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.416,9274.62400000002,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1622,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.448,9283.07200000002,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1623,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.64,9291.71200000002,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1624,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,9294.78400000002,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1625,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.072,9297.85600000002,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1626,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.616,9301.47200000002,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1627,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,9304.60800000002,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1628,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,9307.16800000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1629,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.168,9310.33600000002,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1630,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.072,9313.40800000002,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1631,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,9317.056000000019,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1632,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,9320.128000000019,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1633,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,9322.72000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1634,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.592,9325.31200000002,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1635,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.56,9327.87200000002,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",1636,16352.0,1504178.0,0.0,0,0.0,1504178.0,1504178.0,8323.0,16.0,0.9980813047127953,20480.0,4096.0,20.16,9348.03200000002,1273327.0,198147.0,16352.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1637,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.8,9356.832000000019,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1638,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.72,9359.552000000018,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1639,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,9362.080000000018,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1640,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,9365.472000000018,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1641,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.528,9368.000000000018,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1642,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,9370.560000000018,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1643,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,9373.536000000018,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1644,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,9376.096000000018,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1645,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17145472.0,29568.0,22.432,9398.528000000018,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1646,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.912,9401.440000000019,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1647,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17141504.0,30240.0,23.2,9424.64000000002,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1648,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.72,9427.360000000019,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1649,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17831168.0,2048.0,22.88,9450.240000000018,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1650,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,9452.832000000019,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1651,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.592,9455.424000000019,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1652,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.456,9458.88000000002,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1653,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,9461.280000000019,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1654,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,9463.840000000018,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1655,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.976,9466.816000000019,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1656,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.656,9469.47200000002,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1657,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.608,9478.08000000002,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1658,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.544,9486.62400000002,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1659,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.544,9495.16800000002,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1660,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,2.976,9498.14400000002,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1661,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,9501.184000000021,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1662,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.616,9504.800000000021,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1663,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,9507.872000000021,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1664,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,9510.464000000022,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1665,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,9513.504000000023,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1666,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.072,9516.576000000023,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1667,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.616,9520.192000000023,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1668,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.008,9523.200000000023,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1669,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,9525.760000000022,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1670,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.592,9528.352000000023,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1671,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.56,9530.912000000022,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",1672,16384.0,1504256.0,0.0,0,0.0,1504256.0,1504256.0,8320.0,16.0,0.9980806142034548,20480.0,4096.0,20.224,9551.136000000022,1273344.0,198144.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1673,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.544,9559.680000000022,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1674,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,9562.272000000023,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1675,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.624,9564.896000000022,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1676,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,9568.288000000022,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1677,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,9570.752000000022,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1678,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.688,9573.440000000022,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1679,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,9576.384000000022,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1680,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,9578.976000000022,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1681,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17137664.0,29728.0,23.456,9602.432000000023,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1682,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.912,9605.344000000023,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1683,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17151232.0,29248.0,24.192,9629.536000000022,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1684,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.56,9632.096000000021,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1685,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17829376.0,2048.0,23.424,9655.520000000022,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1686,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,9658.112000000023,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1687,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,9660.640000000023,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1688,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,9664.032000000023,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1689,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,9666.464000000024,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1690,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,9669.088000000023,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1691,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.04,9672.128000000024,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1692,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,9674.720000000025,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1693,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.48,9683.200000000024,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1694,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.544,9691.744000000024,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1695,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.736,9700.480000000025,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1696,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,9703.552000000025,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1697,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.232,9706.784000000025,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1698,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.616,9710.400000000025,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1699,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.104,9713.504000000024,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1700,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,9716.096000000025,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1701,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,9719.232000000025,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1702,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.072,9722.304000000026,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1703,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.68,9725.984000000026,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1704,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,9729.024000000027,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1705,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,9731.616000000027,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1706,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.592,9734.208000000028,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1707,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.56,9736.768000000027,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",1708,16352.0,1504174.0,0.0,0,0.0,1504174.0,1504174.0,8323.0,16.0,0.9980813047127953,20480.0,4096.0,20.288,9757.056000000028,1273327.0,198143.0,16352.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1709,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.608,9765.664000000028,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1710,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.624,9768.288000000028,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1711,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,9770.816000000028,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1712,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,9774.208000000028,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1713,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,9776.608000000027,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1714,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,9779.168000000027,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1715,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.104,9782.272000000026,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1716,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.528,9784.800000000027,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1717,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17145472.0,28672.0,22.432,9807.232000000027,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1718,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.912,9810.144000000028,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1719,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17144192.0,29152.0,23.2,9833.344000000028,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1720,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.624,9835.968000000028,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1721,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17841920.0,2048.0,23.168,9859.136000000028,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1722,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,9861.728000000028,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1723,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.656,9864.38400000003,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1724,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.424,9867.80800000003,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1725,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,9870.24000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1726,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,9872.80000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1727,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.04,9875.840000000031,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1728,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.56,9878.40000000003,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1729,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.608,9887.00800000003,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1730,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.672,9895.680000000031,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1731,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,9904.448000000031,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1732,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,9907.488000000032,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1733,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,9910.528000000033,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1734,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,9914.176000000032,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1735,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,9917.248000000032,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1736,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,9919.840000000033,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1737,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,9922.880000000034,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1738,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,9925.920000000035,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1739,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.712,9929.632000000034,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1740,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.136,9932.768000000035,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1741,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,9935.360000000035,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1742,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.656,9938.016000000036,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1743,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.688,9940.704000000036,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",1744,16384.0,1504260.0,0.0,0,0.0,1504260.0,1504260.0,8320.0,16.0,0.9980806142034548,20480.0,4096.0,20.384,9961.088000000036,1273344.0,198148.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1745,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.448,9969.536000000036,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1746,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,9972.128000000037,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1747,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,9974.656000000037,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1748,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.36,9978.016000000038,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1749,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,9980.448000000039,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1750,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,9983.072000000038,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1751,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,2.944,9986.016000000038,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1752,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.784,9988.800000000037,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1753,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17140736.0,28896.0,23.008,10011.808000000037,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1754,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,3.072,10014.880000000037,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1755,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17144576.0,28960.0,22.88,10037.760000000037,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1756,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.592,10040.352000000037,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1757,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17836288.0,2048.0,22.496,10062.848000000036,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1758,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,10065.440000000037,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1759,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.72,10068.160000000036,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1760,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,10071.552000000036,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1761,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,10073.952000000036,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1762,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,10076.544000000036,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1763,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.104,10079.648000000036,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1764,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,10082.240000000036,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1765,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.8,10091.040000000035,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1766,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.8,10099.840000000035,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1767,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.8,10108.640000000034,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1768,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.04,10111.680000000035,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1769,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.04,10114.720000000036,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1770,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,10118.368000000035,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1771,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,10121.440000000035,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1772,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,10124.032000000036,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1773,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,10127.104000000036,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1774,768.0,512.0,1536.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,2048.0,2048.0,3.136,10130.240000000036,512.0,0.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1775,174080.0,0.0,348160.0,0,0.0,348160.0,348160.0,0.0,64.0,0.0,4096.0,4096.0,3.648,10133.888000000035,0.0,0.0,0.0,174080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1776,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,6144.0,4096.0,3.072,10136.960000000036,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1777,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.56,10139.520000000035,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1778,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.592,10142.112000000036,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1779,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,80.0,0.0,8192.0,8192.0,2.56,10144.672000000035,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",1780,16384.0,1504264.0,0.0,0,0.0,1504264.0,1504264.0,8320.0,16.0,0.9980806142034548,20480.0,4096.0,20.224,10164.896000000035,1273344.0,198152.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1781,1116160.0,2131968.0,133120.0,0,0.0,2265088.0,2265088.0,17408.0,66560.0,0.2073170731707317,4456448.0,2048.0,8.768,10173.664000000035,32768.0,0.0,1049600.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1782,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.656,10176.320000000036,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1783,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,10178.848000000036,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1784,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.392,10182.240000000036,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1785,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.528,10184.768000000036,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1786,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,10187.424000000037,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1787,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.072,10190.496000000037,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1788,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,10193.088000000038,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1789,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17137792.0,29536.0,22.72,10215.808000000037,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1790,45056.0,86016.0,8192.0,0,0.0,94208.0,94208.0,0.0,64.0,0.0,16384.0,16384.0,2.912,10218.720000000038,4096.0,0.0,40960.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1791,4235264.0,8429568.0,73728.0,0,0.0,8503296.0,8503296.0,11264.0,263168.0,0.041044776119402986,17148800.0,29696.0,22.848,10241.568000000038,32768.0,0.0,4198400.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1792,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,96.0,0.0,32768.0,16384.0,2.56,10244.128000000037,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1793,4261888.0,8423424.0,133120.0,0,0.0,8556544.0,8556544.0,17408.0,263168.0,0.06204379562043796,17834240.0,2048.0,22.976,10267.104000000038,32768.0,0.0,4195328.0,66560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",1794,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8192.0,4096.0,2.592,10269.696000000038,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1795,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,10272.224000000038,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",1796,768.0,3297.0,1536.0,0,0.0,4833.0,4833.0,22.0,9.0,0.7096774193548387,4096.0,32.0,3.36,10275.584000000039,3296.0,1.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",1797,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,10278.01600000004,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1798,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,10280.60800000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1799,2048.0,1024.0,4096.0,0,0.0,5120.0,5120.0,0.0,96.0,0.0,4224.0,4096.0,3.008,10283.61600000004,0.0,1024.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1800,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,24.0,0.0,8192.0,4096.0,2.592,10286.20800000004,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",1801,33088000.0,65856000.0,576000.0,0,0.0,66432000.0,66432000.0,88000.0,2056000.0,0.041044776119402986,132906656.0,182048.0,147.904,10434.112000000041,256000.0,0.0,32800000.0,288000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1802,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,10436.160000000042,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1803,258.0,0.0,516.0,0,0.0,516.0,516.0,0.0,5.0,0.0,64.0,64.0,2.56,10438.720000000041,0.0,0.0,0.0,258.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",1804,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.432,10441.152000000042,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",1805,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,128000.0,128000.0,2.656,10443.808000000043,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",1806,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,10445.856000000043,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",1807,48128.0,0.0,96256.0,0,0.0,96256.0,96256.0,512.0,1512.0,0.25296442687747034,129024.0,8192.0,4.032,10449.888000000043,0.0,0.0,0.0,48128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",1808,27648.0,0.0,55296.0,0,0.0,55296.0,55296.0,2112.0,8610.0,0.1969781757134863,527360.0,0.0,4.8,10454.688000000042,0.0,0.0,0.0,27648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",1809,16312.0,0.0,32624.0,0,0.0,32624.0,32624.0,512.0,1512.0,0.25296442687747034,129024.0,8192.0,4.032,10458.720000000041,0.0,0.0,0.0,16312.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",1810,33792.0,0.0,67584.0,0,0.0,67584.0,67584.0,2112.0,8802.0,0.19351291918636612,527360.0,0.0,4.736,10463.456000000042,0.0,0.0,0.0,33792.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",1811,16130.0,0.0,32260.0,0,0.0,32260.0,32260.0,512.0,1512.0,0.25296442687747034,129024.0,8192.0,3.872,10467.328000000041,0.0,0.0,0.0,16130.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",1812,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,2112.0,8770.0,0.19408197022606138,527360.0,0.0,4.896,10472.224000000042,0.0,0.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",1813,16129.0,0.0,32258.0,0,0.0,32258.0,32258.0,512.0,1512.0,0.25296442687747034,129024.0,8192.0,4.032,10476.256000000041,0.0,0.0,0.0,16129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",1814,28672.0,0.0,57344.0,0,0.0,57344.0,57344.0,2112.0,8642.0,0.19639204017109912,527360.0,32.0,4.8,10481.05600000004,0.0,0.0,0.0,28672.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",1815,352.0,0.0,704.0,0,0.0,704.0,704.0,0.0,3.0,0.0,1056.0,128.0,3.04,10484.096000000041,0.0,0.0,0.0,352.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",1816,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.016,10486.112000000041,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",1817,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,11.0,0.9829984544049459,128.0,0.0,4.288,10490.400000000041,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",1818,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.176,10492.576000000041,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",1819,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,11.0,0.9829984544049459,128.0,0.0,4.256,10496.83200000004,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 1>(detail::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, detail::TensorInfo<T1, T2>, T2, detail::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",1820,40292.0,0.0,80584.0,0,0.0,80584.0,80584.0,9266.0,2102.0,0.8150950035186488,131808.0,1728.0,5.92,10502.75200000004,0.0,0.0,0.0,40292.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::radixSortKVInPlace<(int)-2, (int)-1, 32, 4, float, long, unsigned int>(detail::TensorInfo<T5, T7>, T7, T7, T7, detail::TensorInfo<T6, T7>, T7, bool)",1821,64.0,0.0,128.0,0,0.0,128.0,128.0,458.0,8.0,0.9828326180257511,640.0,0.0,6.048,10508.800000000041,0.0,0.0,0.0,64.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1822,64000.0,0.0,128000.0,0,0.0,128000.0,128000.0,0.0,3000.0,0.0,130016.0,8000.0,3.936,10512.73600000004,0.0,0.0,0.0,64000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",1823,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,768.0,0.0,160000.0,0.0,2.944,10515.68000000004,0.0,0.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"native::<unnamed>::fill_reverse_indices_kernel(long *, int, detail::IntDivider<unsigned int>)",1824,128768.0,0.0,257536.0,0,0.0,257536.0,257536.0,0.0,1000.0,0.0,0.0,256000.0,2.496,10518.17600000004,0.0,0.0,0.0,128768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",1825,387237.0,0.0,774474.0,0,0.0,774474.0,774474.0,64512.0,1000.0,0.9847356209549396,128000.0,0.0,3.968,10522.14400000004,0.0,0.0,0.0,387237.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",1826,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,2.592,10524.73600000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",1827,29568.0,0.0,59136.0,0,0.0,59136.0,59136.0,10414.0,4240.0,0.7106592056776306,408576.0,306944.0,14.624,10539.36000000004,0.0,0.0,0.0,29568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",1828,14400.0,0.0,28800.0,0,0.0,28800.0,28800.0,3418.0,4293.0,0.4432628712229283,407552.0,390272.0,13.152,10552.51200000004,0.0,0.0,0.0,14400.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",1829,15744.0,0.0,31488.0,0,0.0,31488.0,31488.0,4798.0,4232.0,0.5313399778516058,405504.0,390272.0,13.888,10566.400000000041,0.0,0.0,0.0,15744.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",1830,15744.0,0.0,31488.0,0,0.0,31488.0,31488.0,4798.0,4233.0,0.5312811427305946,405504.0,324576.0,14.208,10580.608000000042,0.0,0.0,0.0,15744.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",1831,524494.0,1061280.0,152988.0,0,0.0,1214268.0,1214268.0,132.0,1312.0,0.09141274238227147,262912.0,128000.0,18.112,10598.720000000041,133280.0,32000.0,448000.0,76494.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<float, 1>>(T1, int)",1832,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,0.0,416.0,2.176,10600.89600000004,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<float, std::plus<float>>::Policy900, const float *, float *, at_cuda_detail::ScanTileState<float, 1>, std::plus<float>, at_cuda_detail::NullType, unsigned int, float, 0>(T2, T3, T4, int, T5, T6, T7)",1833,2177.0,85371.0,4354.0,0,0.0,89725.0,89725.0,4349.0,2056.0,0.6790007806401249,134720.0,129024.0,3.84,10604.73600000004,85371.0,0.0,0.0,2177.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1834,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,512.0,0.0,128000.0,31808.0,2.752,10607.488000000041,0.0,0.0,0.0,256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::unrolled_elementwise_kernel<native::FillFunctor<bool>, std::array<char *, 1>, 16, TrivialOffsetCalculator<0, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithoutCast, memory::StoreWithoutCast>(int, T1, T2, T4, T5, T6, T7)",1835,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.048,10609.536000000042,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",1836,68096.0,0.0,136192.0,0,0.0,136192.0,136192.0,0.0,3000.0,0.0,288000.0,12224.0,8.832,10618.368000000042,0.0,0.0,0.0,68096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",1837,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,768.0,0.0,160000.0,0.0,3.072,10621.440000000042,0.0,0.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",1838,524497.0,1061280.0,152994.0,0,0.0,1214274.0,1214274.0,132.0,1312.0,0.09141274238227147,251008.0,128000.0,18.368,10639.808000000043,133280.0,32000.0,448000.0,76497.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",1839,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,251.0,0.19808306709265175,128000.0,32.0,9.6,10649.408000000043,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1840,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.432,10651.840000000044,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",1841,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,251.0,0.19808306709265175,128000.0,32.0,9.952,10661.792000000043,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1842,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.432,10664.224000000044,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",1843,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.528,10666.752000000044,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",1844,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.2,10669.952000000045,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",1845,1536.0,36576.0,3072.0,0,0.0,39648.0,39648.0,62.0,251.0,0.19808306709265175,128000.0,32.0,9.632,10679.584000000044,36576.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",1846,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.528,10682.112000000045,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1847,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.432,10684.544000000045,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",1848,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.264,10687.808000000045,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",1849,448000.0,640000.0,320000.0,0,0.0,960000.0,960000.0,0.0,1000.0,0.0,0.0,128000.0,2.816,10690.624000000045,0.0,64000.0,288000.0,160000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",1850,196945.0,327680.0,66210.0,0,0.0,393890.0,393890.0,0.0,768.0,0.0,256000.0,0.0,3.744,10694.368000000046,0.0,0.0,163840.0,33105.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",1851,18048.0,0.0,36096.0,0,0.0,36096.0,36096.0,124.0,251.0,0.33066666666666666,128000.0,32.0,12.928,10707.296000000046,0.0,0.0,0.0,18048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",1852,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.4,10709.696000000045,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",1853,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,10712.288000000046,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",1854,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.368,10714.656000000046,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",1855,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.56,10717.216000000046,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",1856,258.0,0.0,516.0,0,0.0,516.0,516.0,0.0,5.0,0.0,64.0,64.0,2.56,10719.776000000045,0.0,0.0,0.0,258.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",1857,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.016,10721.792000000045,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",1858,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.048,10723.840000000046,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",1859,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.656,10726.496000000046,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",1860,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.048,10728.544000000047,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",1861,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,3.0,0.0,64.0,32.0,2.464,10731.008000000047,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",1862,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.528,10733.536000000047,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",1863,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.496,10736.032000000047,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",1864,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,3.072,10739.104000000047,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",1865,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,3.264,10742.368000000046,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",1866,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.368,10744.736000000046,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0
