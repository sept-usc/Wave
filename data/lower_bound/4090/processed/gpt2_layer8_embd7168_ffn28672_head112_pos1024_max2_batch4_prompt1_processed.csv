Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum,flops_log,flops_threshold,is_matmul_candidate,is_attention_candidate,elementwise_add_fma_ops,role
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",340.0,153668.0,503028.0,0.0,0.0,0.0,503028.0,503028.0,80.0,2472.0,0.0313479623824451,354112.0,114944.0,0.0129,33.908708000000004,154160.0,41532.0,153668.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,11066.0,3592.0,13.12840310149549,16.159490349504665,False,False,0,other
ampere_sgemm_128x32_sliced1x4_nn,341.0,4956585984.0,9927622656.0,0.0,0.0,0.0,9927622656.0,9927622656.0,16180416.0,4987416.0,0.7643870189445948,637391276.0,1048320.0,0.669892,34.5786,6193152.0,8257536.0,4956585984.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,19918477.375,32760.0,23.018586876169103,16.159490349504665,True,True,0,QKV
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",342.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,3584.0,0.0,229376.0,229376.0,0.00408,34.58268,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,7168.0,7168.0,0.0,16.159490349504665,False,False,0,other
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",343.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,3584.0,0.0,229376.0,229376.0,0.00404,34.58672,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,7168.0,7168.0,0.0,16.159490349504665,False,False,0,other
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",344.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1792.0,0.0,114688.0,114688.0,0.002736,34.589456,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,3584.0,3584.0,0.0,16.159490349504665,False,False,0,other
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",345.0,917504.0,30507008.0,0.0,0.0,0.0,30507008.0,30507008.0,238336.0,448.0,0.99812382739212,573440.0,114688.0,0.032852,34.622308,23080960.0,5591040.0,917504.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,17920.0,3584.0,17.2334670184556,16.159490349504665,True,True,0,Attention
ampere_sgemm_128x32_sliced1x4_nn,346.0,1644625920.0,3292463104.0,0.0,0.0,0.0,3292463104.0,3292463104.0,5319552.0,7566152.625,0.4130213402280113,212338540.0,232960.0,0.22370400000000001,34.846012,1376256.0,1835008.0,1644625920.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,6635579.375,7280.0,21.914901785748235,16.159490349504665,True,False,0,Wo
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",347.0,28672.0,57344.0,0.0,0.0,0.0,57344.0,57344.0,0.0,672.0,0.0,229376.0,114688.0,0.002336,34.848348,0.0,0.0,28672.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,7168.0,3584.0,10.956840934798622,16.159490349504665,False,False,28672,elementwise_add
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",348.0,153668.0,503028.0,0.0,0.0,0.0,503028.0,503028.0,80.0,2472.0,0.0313479623824451,353968.0,114944.0,0.012876,34.86122400000001,154160.0,41532.0,153668.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,11061.5,3592.0,13.12840310149549,16.159490349504665,False,False,0,other
ampere_sgemm_128x32_sliced1x4_nn,349.0,6610616320.0,13253345280.0,0.0,0.0,0.0,13253345280.0,13253345280.0,21978880.0,6668256.0,0.7672278303841613,850046920.0,2329600.0,0.899664,35.760888,13762560.0,18350080.0,6610616320.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,26563966.25,72800.0,23.307515831550173,16.159490349504665,True,True,0,FFN1
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",350.0,0.0,114688.0,0.0,0.0,0.0,114688.0,114688.0,0.0,1792.0,0.0,458752.0,458752.0,0.0026320000000000002,35.76352,0.0,114688.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,14336.0,14336.0,11.64997939616457,16.159490349504665,False,False,0,other
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",351.0,0.0,229376.0,0.0,0.0,0.0,229376.0,229376.0,0.0,1792.0,0.0,458752.0,458752.0,0.002628,35.766148,0.0,229376.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,14336.0,14336.0,12.343122217099008,16.159490349504665,False,False,0,other
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",352.0,0.0,114688.0,0.0,0.0,0.0,114688.0,114688.0,0.0,1792.0,0.0,458752.0,458752.0,0.002552,35.7687,0.0,114688.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,14336.0,14336.0,11.64997939616457,16.159490349504665,False,False,0,other
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",353.0,114688.0,229376.0,0.0,0.0,0.0,229376.0,229376.0,0.0,2688.0,0.0,917504.0,458752.0,0.0031279999999999997,35.771828,0.0,0.0,114688.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,28672.0,14336.0,12.343122217099008,16.159490349504665,False,False,0,add
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",354.0,0.0,114688.0,0.0,0.0,0.0,114688.0,114688.0,0.0,1792.0,0.0,458752.0,458752.0,0.00262,35.774448,0.0,114688.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,14336.0,14336.0,11.64997939616457,16.159490349504665,False,False,0,other
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",355.0,611920.25,1567904.5,0.0,0.0,0.0,1567904.5,1567904.5,0.0,1792.0,0.0,458752.0,458752.0,0.0026560000000000004,35.777104,114688.0,229376.0,611920.25,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,14336.0,14336.0,14.265251210219168,16.159490349504665,False,False,0,other
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",356.0,114688.0,229376.0,0.0,0.0,0.0,229376.0,229376.0,0.0,1792.0,0.0,458752.0,458752.0,0.002536,35.77964,0.0,0.0,114688.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,14336.0,14336.0,12.343122217099008,16.159490349504665,False,False,0,add
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",357.0,0.0,114688.0,0.0,0.0,0.0,114688.0,114688.0,0.0,2688.0,0.0,917504.0,458752.0,0.003164,35.782804000000006,0.0,114688.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,28672.0,14336.0,11.64997939616457,16.159490349504665,False,False,0,other
ampere_sgemm_128x32_sliced1x4_nn,358.0,6577127424.0,13157466112.0,0.0,0.0,0.0,13157466112.0,13157466112.0,20974464.0,29229211.5,0.4179967917396701,848241836.0,232960.0,0.870052,36.652856,1376256.0,1835008.0,6577127424.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,26507557.375,7280.0,23.300255199699627,16.159490349504665,True,False,0,FFN2
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",359.0,28672.0,57344.0,0.0,0.0,0.0,57344.0,57344.0,0.0,672.0,0.0,229376.0,114688.0,0.00234,36.655196000000004,0.0,0.0,28672.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,7168.0,3584.0,10.956840934798622,16.159490349504665,False,False,28672,elementwise_add
