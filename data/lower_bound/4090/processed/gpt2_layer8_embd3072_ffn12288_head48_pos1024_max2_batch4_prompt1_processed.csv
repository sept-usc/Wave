Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum,flops_log,flops_threshold,is_matmul_candidate,is_attention_candidate,elementwise_add_fma_ops,role
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",374.5,71748.0,240884.0,0.0,0.0,0.0,240884.0,240884.0,80.0,1064.0,0.0699300699300699,147456.0,49408.0,7.104,7832.559999999996,72240.0,25148.0,71748.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,4608.0,1544.0,12.3920749201637,14.79592642136011,False,False,0,other
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),375.5,905969664.0,1812824064.0,0.0,0.0,0.0,1812824064.0,1812824064.0,2712096.0,3456.0,0.9987273305758828,116785152.0,442368.0,125.88,7958.439999999996,0.0,884736.0,905969664.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,3649536.0,13824.0,21.318151723194035,14.79592642136011,True,True,0,QKV
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",376.5,0.0,184320.0,0.0,0.0,0.0,184320.0,184320.0,0.0,11520.0,0.0,479232.0,147456.0,3.608,7962.047999999995,147456.0,36864.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,14976.0,4608.0,12.12443408182217,14.79592642136011,False,False,0,splitKreduce
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",377.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,4.0120000000000005,7966.059999999996,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0,0.0,14.79592642136011,False,False,0,other
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",378.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,4.02,7970.079999999995,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0,0.0,14.79592642136011,False,False,0,other
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",379.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.648,7972.7279999999955,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0,0.0,14.79592642136011,False,False,0,other
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",380.5,393216.0,13074432.0,0.0,0.0,0.0,13074432.0,13074432.0,102144.0,192.0,0.99812382739212,245760.0,49152.0,17.572000000000003,7990.2999999999965,9891840.0,2396160.0,393216.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0,16.386169201774198,14.79592642136011,True,True,0,Attention
ampere_sgemm_128x32_sliced1x4_nn,381.5,314572800.0,632586240.0,0.0,0.0,0.0,632586240.0,632586240.0,1106880.0,306432.0,0.7831816329303084,38956356.0,245760.0,45.592,8035.891999999996,1474560.0,1966080.0,314572800.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1217386.125,7680.0,20.26532711867833,14.79592642136011,True,True,0,Wo
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",382.5,0.0,86016.0,0.0,0.0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,2.752,8038.643999999996,73728.0,12288.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0,11.362300230119235,14.79592642136011,False,False,0,splitKreduce
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",383.5,12288.0,24576.0,0.0,0.0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.108,8040.751999999996,0.0,0.0,12288.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0,10.109566325223746,14.79592642136011,False,False,12288,elementwise_add
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",384.5,71748.0,240884.0,0.0,0.0,0.0,240884.0,240884.0,80.0,1064.0,0.0699300699300699,147456.0,49408.0,7.1240000000000006,8047.875999999995,72240.0,25148.0,71748.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,4608.0,1544.0,12.3920749201637,14.79592642136011,False,False,0,other
ampere_sgemm_32x32_sliced1x4_nn,385.5,1208352768.0,2419458048.0,0.0,0.0,0.0,2419458048.0,2419458048.0,5996544.0,1330176.0,0.8184486373165618,158450448.0,196608.0,165.528,8213.403999999995,1179648.0,1572864.0,1208352768.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,4951576.5,6144.0,21.606809405340986,14.79592642136011,True,True,0,FFN1
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",386.5,0.0,49152.0,0.0,0.0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.228,8215.631999999996,0.0,49152.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0,10.802693161352469,14.79592642136011,False,False,0,other
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",387.5,0.0,98304.0,0.0,0.0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.2640000000000002,8217.895999999997,0.0,98304.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0,11.495830169541591,14.79592642136011,False,False,0,other
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",388.5,0.0,49152.0,0.0,0.0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.18,8220.075999999995,0.0,49152.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0,10.802693161352469,14.79592642136011,False,False,0,other
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",389.5,49152.0,98304.0,0.0,0.0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,2.584,8222.659999999996,0.0,0.0,49152.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0,11.495830169541591,14.79592642136011,False,False,0,add
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",390.5,0.0,49152.0,0.0,0.0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.2,8224.859999999997,0.0,49152.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0,10.802693161352469,14.79592642136011,False,False,0,other
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",391.5,269972.875,687401.75,0.0,0.0,0.0,687401.75,687401.75,0.0,768.0,0.0,196608.0,196608.0,2.324,8227.183999999997,49152.0,98304.0,269972.875,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0,13.44067564397177,14.79592642136011,False,False,0,other
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",392.5,49152.0,98304.0,0.0,0.0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.224,8229.407999999996,0.0,0.0,49152.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0,11.495830169541591,14.79592642136011,False,False,0,add
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",393.5,0.0,49152.0,0.0,0.0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.456,8231.863999999998,0.0,49152.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0,10.802693161352469,14.79592642136011,False,False,0,other
ampere_sgemm_128x32_sliced1x4_nn,394.5,1211105280.0,2425651200.0,0.0,0.0,0.0,2425651200.0,2425651200.0,3952320.0,1218528.0,0.764346582997605,155780960.0,245760.0,163.784,8395.647999999997,1474560.0,1966080.0,1211105280.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,4868155.0,7680.0,21.60936586178123,14.79592642136011,True,True,0,FFN2
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",395.5,0.0,86016.0,0.0,0.0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,2.7119999999999997,8398.359999999997,73728.0,12288.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0,11.362300230119235,14.79592642136011,False,False,0,splitKreduce
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",396.5,12288.0,24576.0,0.0,0.0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.144,8400.503999999997,0.0,0.0,12288.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0,10.109566325223746,14.79592642136011,False,False,12288,elementwise_add
