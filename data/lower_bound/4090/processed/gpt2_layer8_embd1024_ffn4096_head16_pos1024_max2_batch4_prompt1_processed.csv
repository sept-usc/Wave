Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum,flops_log,flops_threshold,is_matmul_candidate,is_attention_candidate,elementwise_add_fma_ops,role
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",385.0,30788.0,109812.0,0.0,0.0,0.0,109812.0,109812.0,80.0,360.0,0.1818181818181818,49152.0,16640.0,4.312,2280.1519999999978,31280.0,16956.0,30788.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1536.0,520.0,11.606534198134796,13.421060936087612,False,False,0,other
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),386.0,100663296.0,202113024.0,0.0,0.0,0.0,202113024.0,202113024.0,346368.0,3072.0,0.9912087912087912,12976128.0,393216.0,17.832,2297.9839999999976,0.0,786432.0,100663296.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,405504.0,12288.0,19.124337628590073,13.421060936087612,True,True,0,QKV
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",387.0,0.0,122880.0,0.0,0.0,0.0,122880.0,122880.0,0.0,5760.0,0.0,405504.0,49152.0,2.6919999999999997,2300.6759999999977,110592.0,12288.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,12672.0,1536.0,11.718971686369219,13.421060936087612,False,False,0,splitKreduce
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",388.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,512.0,0.0,32768.0,32768.0,4.016,2304.6919999999977,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0,0.0,13.421060936087612,False,False,0,other
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",389.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,512.0,0.0,32768.0,32768.0,4.016,2308.707999999998,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0,0.0,13.421060936087612,False,False,0,other
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",390.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,2.632,2311.3399999999974,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,512.0,512.0,0.0,13.421060936087612,False,False,0,other
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",391.0,131072.0,4358144.0,0.0,0.0,0.0,4358144.0,4358144.0,34048.0,64.0,0.99812382739212,81920.0,16384.0,12.0,2323.3399999999974,3297280.0,798720.0,131072.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2560.0,512.0,15.287557066076381,13.421060936087612,True,True,0,Attention
ampere_sgemm_32x32_sliced1x4_nn,392.0,33554432.0,68026368.0,0.0,0.0,0.0,68026368.0,68026368.0,196608.0,37376.0,0.8402625820568927,4718592.0,65536.0,9.82,2333.1599999999976,393216.0,524288.0,33554432.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,147456.0,2048.0,18.03540596738514,13.421060936087612,True,True,0,Wo
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",393.0,0.0,24576.0,0.0,0.0,0.0,24576.0,24576.0,0.0,1408.0,0.0,69632.0,16384.0,2.352,2335.5119999999974,20480.0,4096.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2176.0,512.0,10.109566325223746,13.421060936087612,False,False,0,splitKreduce
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",394.0,4096.0,8192.0,0.0,0.0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.08,2337.591999999998,0.0,0.0,4096.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0,9.011035410141815,13.421060936087612,False,False,4096,elementwise_add
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",395.0,30788.0,109812.0,0.0,0.0,0.0,109812.0,109812.0,80.0,360.0,0.1818181818181818,49152.0,16640.0,4.264,2341.855999999997,31280.0,16956.0,30788.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1536.0,520.0,11.606534198134796,13.421060936087612,False,False,0,other
ampere_sgemm_128x32_nn,396.0,138412032.0,277741568.0,0.0,0.0,0.0,277741568.0,277741568.0,754432.0,138880.0,0.8445336008024072,17384088.0,458752.0,22.287999999999997,2364.143999999997,0.0,917504.0,138412032.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,543252.75,14336.0,19.44220163138784,13.421060936087612,True,True,0,FFN1
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",397.0,0.0,147456.0,0.0,0.0,0.0,147456.0,147456.0,0.0,7168.0,0.0,475136.0,65536.0,3.168,2367.311999999997,131072.0,16384.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,14848.0,2048.0,11.901291886836486,13.421060936087612,False,False,0,splitKreduce
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",398.0,0.0,16384.0,0.0,0.0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.08,2369.391999999997,0.0,16384.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0,9.704121561132915,13.421060936087612,False,False,0,other
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",399.0,0.0,32768.0,0.0,0.0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,2.076,2371.467999999997,0.0,32768.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0,10.397238225511654,13.421060936087612,False,False,0,other
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",400.0,0.0,16384.0,0.0,0.0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.116,2373.583999999997,0.0,16384.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0,9.704121561132915,13.421060936087612,False,False,0,other
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",401.0,16384.0,32768.0,0.0,0.0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.212,2375.7959999999975,0.0,0.0,16384.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0,10.397238225511654,13.421060936087612,False,False,0,add
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",402.0,0.0,16384.0,0.0,0.0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.076,2377.871999999997,0.0,16384.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0,9.704121561132915,13.421060936087612,False,False,0,other
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",403.0,94191.875,237535.75,0.0,0.0,0.0,237535.75,237535.75,0.0,256.0,0.0,65536.0,65536.0,2.172,2380.043999999997,16384.0,32768.0,94191.875,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0,12.378077627328429,13.421060936087612,False,False,0,other
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",404.0,16384.0,32768.0,0.0,0.0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,2.156,2382.199999999997,0.0,0.0,16384.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0,10.397238225511654,13.421060936087612,False,False,0,add
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",405.0,0.0,16384.0,0.0,0.0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.176,2384.375999999997,0.0,16384.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0,9.704121561132915,13.421060936087612,False,False,0,other
ampere_sgemm_32x32_sliced1x4_nn,406.0,139460608.0,280526848.0,0.0,0.0,0.0,280526848.0,280526848.0,738304.0,148992.0,0.8320830929024813,18937732.0,114688.0,22.78,2407.155999999997,688128.0,917504.0,139460608.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,591804.125,3584.0,19.452179996706388,13.421060936087612,True,True,0,FFN2
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",407.0,0.0,36864.0,0.0,0.0,0.0,36864.0,36864.0,0.0,1792.0,0.0,118784.0,16384.0,2.844,2409.999999999997,32768.0,4096.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,3712.0,512.0,10.515017870423751,13.421060936087612,False,False,0,splitKreduce
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",408.0,4096.0,8192.0,0.0,0.0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.08,2412.0799999999963,0.0,0.0,4096.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0,9.011035410141815,13.421060936087612,False,False,4096,elementwise_add
