Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum,flops_log,flops_threshold,is_matmul_candidate,is_attention_candidate,elementwise_add_fma_ops,role
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",385.0,102672.0,373712.0,0.0,0.0,0.0,373712.0,373712.0,320.0,1088.0,0.2272727272727272,147456.0,50176.0,4.204000000000001,2209.472,104640.0,63728.0,102672.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,4608.0,1568.0,12.831243402131022,14.013126392179355,False,False,0,other
ampere_sgemm_32x32_sliced1x4_nn,386.0,56623104.0,114794496.0,0.0,0.0,0.0,114794496.0,114794496.0,331776.0,86400.0,0.7933884297520661,10616832.0,442368.0,12.624,2222.096,663552.0,884736.0,56623104.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,331776.0,13824.0,18.558654105160727,14.013126392179355,True,True,0,QKV
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",387.0,0.0,184320.0,0.0,0.0,0.0,184320.0,184320.0,0.0,8064.0,0.0,451584.0,147456.0,3.012,2225.108,147456.0,36864.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,14112.0,4608.0,12.12443408182217,14.013126392179355,False,False,0,splitKreduce
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",388.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,4.088,2229.196,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0,0.0,14.013126392179355,False,False,0,other
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",389.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,4.1,2233.2960000000003,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0,0.0,14.013126392179355,False,False,0,other
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",390.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.7119999999999997,2236.008,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0,0.0,14.013126392179355,False,False,0,other
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",391.0,393216.0,13074432.0,0.0,0.0,0.0,13074432.0,13074432.0,102144.0,192.0,0.99812382739212,245760.0,49152.0,17.692,2253.7,9891840.0,2396160.0,393216.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0,16.386169201774198,14.013126392179355,True,True,0,Attention
ampere_sgemm_32x32_sliced1x4_nn,392.0,18874368.0,38436864.0,0.0,0.0,0.0,38436864.0,38436864.0,116736.0,29184.0,0.8,3538944.0,196608.0,8.276,2261.9759999999997,294912.0,393216.0,18874368.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,110592.0,6144.0,17.464527583069344,14.013126392179355,True,True,0,Wo
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",393.0,0.0,73728.0,0.0,0.0,0.0,73728.0,73728.0,0.0,3072.0,0.0,199680.0,49152.0,2.756,2264.732,61440.0,12288.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,6240.0,1536.0,11.208151487891582,14.013126392179355,False,False,0,splitKreduce
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",394.0,12288.0,24576.0,0.0,0.0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.092,2266.824,0.0,0.0,12288.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0,10.109566325223746,14.013126392179355,False,False,12288,elementwise_add
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",395.0,102672.0,373712.0,0.0,0.0,0.0,373712.0,373712.0,320.0,1088.0,0.2272727272727272,147456.0,50176.0,4.248,2271.072,104640.0,63728.0,102672.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,4608.0,1568.0,12.831243402131022,14.013126392179355,False,False,0,other
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),396.0,75497472.0,151486464.0,0.0,0.0,0.0,151486464.0,151486464.0,253344.0,7680.0,0.9705774181684442,10616832.0,983040.0,14.004000000000001,2285.076,0.0,491520.0,75497472.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,331776.0,30720.0,18.836006838988656,14.013126392179355,True,True,0,FFN1
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",397.0,0.0,344064.0,0.0,0.0,0.0,344064.0,344064.0,0.0,13824.0,0.0,995328.0,196608.0,3.668,2288.744,294912.0,49152.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,31104.0,6144.0,12.748585871994445,14.013126392179355,False,False,0,splitKreduce
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",398.0,0.0,49152.0,0.0,0.0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.2720000000000002,2291.016,0.0,49152.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0,10.802693161352469,14.013126392179355,False,False,0,other
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",399.0,0.0,98304.0,0.0,0.0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.24,2293.256,0.0,98304.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0,11.495830169541591,14.013126392179355,False,False,0,other
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",400.0,0.0,49152.0,0.0,0.0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.3400000000000003,2295.5959999999995,0.0,49152.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0,10.802693161352469,14.013126392179355,False,False,0,other
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",401.0,49152.0,98304.0,0.0,0.0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,2.556,2298.152,0.0,0.0,49152.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0,11.495830169541591,14.013126392179355,False,False,0,add
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",402.0,0.0,49152.0,0.0,0.0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.2680000000000002,2300.4199999999996,0.0,49152.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0,10.802693161352469,14.013126392179355,False,False,0,other
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",403.0,285677.875,718811.75,0.0,0.0,0.0,718811.75,718811.75,0.0,768.0,0.0,196608.0,196608.0,2.32,2302.74,49152.0,98304.0,285677.875,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0,13.48535617163072,14.013126392179355,False,False,0,other
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",404.0,49152.0,98304.0,0.0,0.0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.3160000000000003,2305.0559999999996,0.0,0.0,49152.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0,11.495830169541591,14.013126392179355,False,False,0,add
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",405.0,0.0,49152.0,0.0,0.0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.604,2307.66,0.0,49152.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0,10.802693161352469,14.013126392179355,False,False,0,other
ampere_sgemm_32x32_sliced1x4_nn,406.0,77070336.0,155344896.0,0.0,0.0,0.0,155344896.0,155344896.0,419328.0,114048.0,0.7861771058315334,14436388.0,344064.0,15.940000000000001,2323.6,516096.0,688128.0,77070336.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,451137.125,10752.0,18.861158344856985,14.013126392179355,True,True,0,FFN2
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",407.0,0.0,110592.0,0.0,0.0,0.0,110592.0,110592.0,0.0,4224.0,0.0,347136.0,49152.0,3.284,2326.884,98304.0,12288.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,10848.0,1536.0,11.613612074928163,14.013126392179355,False,False,0,splitKreduce
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",408.0,12288.0,24576.0,0.0,0.0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.168,2329.0519999999997,0.0,0.0,12288.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0,10.109566325223746,14.013126392179355,False,False,12288,elementwise_add
