Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum,flops_log,flops_threshold,is_matmul_candidate,is_attention_candidate,elementwise_add_fma_ops,role
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",578.0,591360.0,1207296.0,0.0,0.0,0.0,1207296.0,1207296.0,10752.0,37632.0,0.2222222222222222,2752512.0,11044.0,5.324,2812.879999999995,24576.0,0.0,591360.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,86016.0,345.125,14.003894534433767,9.462947781981656,True,False,0,Q
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",579.0,0.0,2304.0,0.0,0.0,0.0,2304.0,2304.0,0.0,2304.0,0.0,6144.0,2756.0,2.396,2815.275999999995,1536.0,768.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,192.0,86.125,7.742835955430749,9.462947781981656,False,False,0,other
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",580.0,0.0,768.0,0.0,0.0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.368,2817.643999999995,768.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,192.0,0.0,6.645090969505644,9.462947781981656,False,False,0,other
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",581.0,591360.0,1207296.0,0.0,0.0,0.0,1207296.0,1207296.0,10752.0,37632.0,0.2222222222222222,2752512.0,10916.0,5.312,2822.9559999999947,24576.0,0.0,591360.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,86016.0,341.125,14.003894534433767,9.462947781981656,True,False,0,K
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",582.0,0.0,2304.0,0.0,0.0,0.0,2304.0,2304.0,0.0,2304.0,0.0,6144.0,2736.0,2.456,2825.411999999995,1536.0,768.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,192.0,85.5,7.742835955430749,9.462947781981656,False,False,0,other
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",583.0,0.0,768.0,0.0,0.0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.396,2827.8079999999945,768.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,192.0,0.0,6.645090969505644,9.462947781981656,False,False,0,other
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",584.0,591360.0,1207296.0,0.0,0.0,0.0,1207296.0,1207296.0,10752.0,37632.0,0.2222222222222222,2752512.0,10908.0,5.288,2833.0959999999945,24576.0,0.0,591360.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,86016.0,340.875,14.003894534433767,9.462947781981656,True,False,0,V
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",585.0,0.0,2304.0,0.0,0.0,0.0,2304.0,2304.0,0.0,2304.0,0.0,6144.0,2884.0,2.396,2835.4919999999947,1536.0,768.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,192.0,90.125,7.742835955430749,9.462947781981656,False,False,0,other
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",586.0,0.0,768.0,0.0,0.0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.356,2837.847999999995,768.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,192.0,0.0,6.645090969505644,9.462947781981656,False,False,0,other
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",587.0,0.0,768.0,0.0,0.0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.644,2840.4919999999947,0.0,768.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,144.0,96.0,6.645090969505644,9.462947781981656,False,False,0,other
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",588.0,0.0,384.0,0.0,0.0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.66,2843.1519999999946,384.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,48.0,48.0,5.953243334287785,9.462947781981656,False,False,0,other
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",589.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.148,2846.2999999999947,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,96.0,96.0,0.0,9.462947781981656,False,False,0,other
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",590.0,0.0,768.0,0.0,0.0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.652,2848.9519999999948,0.0,768.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,144.0,96.0,6.645090969505644,9.462947781981656,False,False,0,other
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",591.0,768.0,1536.0,0.0,0.0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.196,2851.1479999999947,0.0,0.0,768.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,192.0,96.0,7.337587743538596,9.462947781981656,False,False,0,add
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",592.0,0.0,768.0,0.0,0.0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.636,2853.7839999999946,0.0,768.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,144.0,96.0,6.645090969505644,9.462947781981656,False,False,0,other
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",593.0,0.0,384.0,0.0,0.0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.664,2856.4479999999944,384.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,48.0,48.0,5.953243334287785,9.462947781981656,False,False,0,other
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",594.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.12,2859.5679999999948,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,96.0,96.0,0.0,9.462947781981656,False,False,0,other
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",595.0,0.0,768.0,0.0,0.0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.668,2862.2359999999944,0.0,768.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,144.0,96.0,6.645090969505644,9.462947781981656,False,False,0,other
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",596.0,768.0,1536.0,0.0,0.0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.18,2864.4159999999943,0.0,0.0,768.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,192.0,96.0,7.337587743538596,9.462947781981656,False,False,0,add
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",597.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,60.0,0.0,6144.0,6144.0,2.584,2866.9999999999945,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,192.0,192.0,0.0,9.462947781981656,False,False,0,other
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",598.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,60.0,0.0,6144.0,6144.0,2.58,2869.5799999999945,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,192.0,192.0,0.0,9.462947781981656,False,False,0,other
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",599.0,12288.0,1103616.0,0.0,0.0,0.0,1103616.0,1103616.0,6240.0,12.0,0.9980806142034548,15360.0,3072.0,20.492,2890.071999999994,930432.0,148608.0,12288.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,480.0,96.0,13.914103525338557,9.462947781981656,True,True,0,Attention
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",600.0,590592.0,1205760.0,0.0,0.0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.2575757575757575,2506752.0,2012.0,5.555999999999999,2895.6279999999942,24576.0,0.0,590592.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,78336.0,62.875,14.002621460842123,9.462947781981656,True,False,0,Wo
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",601.0,768.0,1536.0,0.0,0.0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.184,2897.811999999994,0.0,0.0,768.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,192.0,96.0,7.337587743538596,9.462947781981656,False,False,768,elementwise_add
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",602.0,0.0,768.0,0.0,0.0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.148,2899.9599999999937,0.0,768.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,96.0,96.0,6.645090969505644,9.462947781981656,False,False,0,other
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",603.0,0.0,1889.0,0.0,0.0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.468,2903.427999999994,1888.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,96.0,1.0,7.5443321080536885,9.462947781981656,False,False,0,other
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",604.0,1.0,2.0,0.0,0.0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.952,2905.3799999999937,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0986122886681098,9.462947781981656,False,False,0,add
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",605.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.02,2907.3999999999937,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.0,9.462947781981656,False,False,0,other
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",606.0,0.0,768.0,0.0,0.0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.56,2909.9599999999937,0.0,768.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,99.0,96.0,6.645090969505644,9.462947781981656,False,False,0,other
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",607.0,0.0,768.0,0.0,0.0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.172,2912.131999999994,0.0,768.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,192.0,96.0,6.645090969505644,9.462947781981656,False,False,0,other
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",608.0,2362368.0,4773888.0,0.0,0.0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.1261261261261261,9732096.0,4552.0,12.744,2924.875999999994,49152.0,0.0,2362368.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,304128.0,142.25,15.378671834668,9.462947781981656,True,False,0,FFN1
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",609.0,35328.0,73728.0,0.0,0.0,0.0,73728.0,73728.0,0.0,48.0,0.0,12288.0,12288.0,2.276,2927.1519999999937,3072.0,0.0,35328.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,384.0,384.0,11.208151487891582,9.462947781981656,True,False,0,other
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",610.0,2362368.0,4773888.0,0.0,0.0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.1261261261261261,9732096.0,4584.0,12.784,2939.935999999994,49152.0,0.0,2362368.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,304128.0,143.25,15.378671834668,9.462947781981656,True,False,0,FFN2
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",611.0,0.0,3072.0,0.0,0.0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.072,2942.007999999994,0.0,3072.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,768.0,384.0,8.030409562130485,9.462947781981656,False,False,0,other
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",612.0,2360064.0,4744704.0,0.0,0.0,0.0,4744704.0,4744704.0,13056.0,148224.0,0.0809523809523809,10028080.0,2380.0,12.920000000000002,2954.927999999994,24576.0,0.0,2360064.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,313377.5,74.375,15.37253981738748,9.462947781981656,True,False,0,FFN3
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",613.0,768.0,1536.0,0.0,0.0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.192,2957.1199999999935,0.0,0.0,768.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,192.0,96.0,7.337587743538596,9.462947781981656,False,False,768,elementwise_add
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",614.0,0.0,768.0,0.0,0.0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.132,2959.2519999999936,0.0,768.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,96.0,96.0,6.645090969505644,9.462947781981656,False,False,0,other
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",615.0,0.0,1889.0,0.0,0.0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.484,2962.7359999999935,1888.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,96.0,1.0,7.5443321080536885,9.462947781981656,False,False,0,other
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",616.0,1.0,2.0,0.0,0.0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.968,2964.703999999994,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0986122886681098,9.462947781981656,False,False,0,add
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",617.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2966.719999999994,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.0,9.462947781981656,False,False,0,other
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",618.0,0.0,768.0,0.0,0.0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.584,2969.3039999999937,0.0,768.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,99.0,96.0,6.645090969505644,9.462947781981656,False,False,0,other
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",619.0,0.0,768.0,0.0,0.0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.168,2971.4719999999934,0.0,768.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,192.0,96.0,6.645090969505644,9.462947781981656,False,False,0,other
