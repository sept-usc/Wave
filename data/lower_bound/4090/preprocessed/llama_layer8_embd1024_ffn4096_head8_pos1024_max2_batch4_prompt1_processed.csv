Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.824,1.824,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,3.52,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,5.248,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.08,7.328,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.336,9.664,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",6,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.304,11.968,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",7,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,15.264,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",8,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,18.528,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",9,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.496,21.023999999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",10,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,22.752,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",11,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,24.448,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.728,26.176000000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,0.0,0.0,0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,2.432,28.608,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,30.688000000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",15,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.176,32.864000000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",16,0.0,0.0,0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,32.0,32.0,2.496,35.36000000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",17,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,37.40800000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",18,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,39.48800000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",19,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,2.24,41.72800000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",20,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,4352.0,16384.0,3.808,45.53600000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,136.0,512.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",21,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,48.09600000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",22,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,51.45600000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",23,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.464,53.92000000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",24,0.0,512.0,0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,2.016,55.93600000000001,0.0,512.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",25,0.0,0.0,0,0,0.0,0.0,0.0,0.0,20.0,0.0,2048.0,2048.0,2.592,58.528000000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",26,4096.0,9216.0,0,0,0.0,9216.0,9216.0,0.0,32.0,0.0,2048.0,2048.0,2.976,61.504000000000005,0.0,1024.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",27,0.0,512.0,0,0,0.0,512.0,512.0,0.0,32.0,0.0,2048.0,2048.0,2.08,63.584,0.0,512.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",28,3584.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,32.0,0.0,2048.0,2048.0,3.008,66.592,0.0,1024.0,3584.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",29,0.0,512.0,0,0,0.0,512.0,512.0,0.0,32.0,0.0,2048.0,2048.0,2.112,68.704,0.0,512.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",30,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.016,70.72,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",31,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,4.0,74.72,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",32,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,76.64,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",33,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,78.688,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",34,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.72,81.408,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",35,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.656,84.06400000000001,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,36,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.216,93.28,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",37,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.272,95.552,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,38,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,8.992,104.54400000000001,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",39,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.176,106.72000000000001,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,40,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.28,116.00000000000001,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",41,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.272,118.27200000000002,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",42,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.72,120.99200000000002,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",43,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.688,123.68000000000002,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",44,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.032,127.71200000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",45,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.688,130.4,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",46,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.08,132.48000000000002,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",47,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.624,135.104,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",48,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.624,137.728,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",49,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.096,141.824,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",50,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.72,144.544,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",51,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.08,146.62400000000002,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",52,65536.0,5883904.0,0,0,0.0,5883904.0,5883904.0,33280.0,64.0,0.9980806142034548,49152.0,16384.0,20.16,166.78400000000002,4960256.0,792576.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,53,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.344,176.12800000000001,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",54,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.24,178.36800000000002,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",55,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.048,180.41600000000003,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",56,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.016,182.43200000000002,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",57,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.904,186.336,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",58,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,188.32000000000002,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",59,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,190.336,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",60,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.624,192.96,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",61,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.656,195.616,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_64x32_sliced1x4_tn,62,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,171203.0,0.791842104303273,18016480.0,135168.0,25.504,221.12,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,563015.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",63,188416.0,393216.0,0,0,0.0,393216.0,393216.0,0.0,256.0,0.0,65536.0,65536.0,2.336,223.45600000000002,16384.0,0.0,188416.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,64,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,171655.0,0.791407173731558,18015872.0,135168.0,25.28,248.73600000000002,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,562996.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",65,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.144,250.88000000000002,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,66,134217728.0,270270464.0,0,0,0.0,270270464.0,270270464.0,651264.0,140288.0,0.8227684346701164,17825792.0,131072.0,22.912,273.79200000000003,786432.0,1048576.0,134217728.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,557056.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",67,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.272,276.064,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",68,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.048,278.112,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",69,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.144,280.25600000000003,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",70,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.904,284.16,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",71,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,286.08000000000004,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",72,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,288.064,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",73,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.72,290.78400000000005,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",74,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.656,293.44000000000005,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,75,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.024,302.46400000000006,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",76,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.304,304.76800000000003,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,77,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,8.928,313.696,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",78,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.208,315.90400000000005,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,79,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.28,325.184,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",80,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.208,327.39200000000005,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",81,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.656,330.04800000000006,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",82,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.72,332.7680000000001,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",83,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.064,336.8320000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",84,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.688,339.5200000000001,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",85,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.048,341.5680000000001,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",86,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.688,344.2560000000001,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",87,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.592,346.84800000000007,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",88,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.0,350.84800000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",89,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.848,353.6960000000001,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",90,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.112,355.8080000000001,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",91,65536.0,5883904.0,0,0,0.0,5883904.0,5883904.0,33280.0,64.0,0.9980806142034548,49152.0,16384.0,20.128,375.9360000000001,4960256.0,792576.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,92,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.248,385.1840000000001,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",93,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.24,387.4240000000001,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",94,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.048,389.4720000000001,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",95,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,1.984,391.4560000000001,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",96,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.904,395.36000000000007,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",97,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,397.34400000000005,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",98,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,399.36000000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",99,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.688,402.04800000000006,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",100,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.656,404.70400000000006,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_64x32_sliced1x4_tn,101,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,170789.0,0.7922408895776794,18026752.0,135168.0,25.344,430.04800000000006,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,563336.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",102,188416.0,393216.0,0,0,0.0,393216.0,393216.0,0.0,256.0,0.0,65536.0,65536.0,2.368,432.41600000000005,16384.0,0.0,188416.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,103,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,171701.0,0.7913629376704964,18013856.0,135168.0,25.6,458.0160000000001,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,562933.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",104,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.144,460.1600000000001,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,105,134217728.0,270270464.0,0,0,0.0,270270464.0,270270464.0,651264.0,140288.0,0.8227684346701164,17825792.0,131072.0,22.464,482.6240000000001,786432.0,1048576.0,134217728.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,557056.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",106,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.496,485.12000000000006,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",107,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.112,487.2320000000001,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",108,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,1.984,489.21600000000007,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",109,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.904,493.12000000000006,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",110,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,495.0400000000001,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",111,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,497.02400000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",112,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.624,499.6480000000001,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",113,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.656,502.3040000000001,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,114,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.248,511.5520000000001,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",115,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.304,513.8560000000001,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,116,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.056,522.9120000000001,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",117,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.432,525.3440000000002,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,118,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.12,534.4640000000002,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",119,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.208,536.6720000000001,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",120,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.656,539.3280000000001,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",121,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.656,541.984,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",122,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.032,546.0160000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",123,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.72,548.7360000000001,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",124,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.08,550.8160000000001,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",125,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.688,553.5040000000001,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",126,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.624,556.1280000000002,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",127,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.032,560.1600000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",128,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.688,562.8480000000002,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",129,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.08,564.9280000000002,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",130,65536.0,5883904.0,0,0,0.0,5883904.0,5883904.0,33280.0,64.0,0.9980806142034548,49152.0,16384.0,20.192,585.1200000000002,4960256.0,792576.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,131,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.12,594.2400000000002,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",132,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.208,596.4480000000002,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",133,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.112,598.5600000000002,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",134,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,1.984,600.5440000000002,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",135,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.84,604.3840000000002,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",136,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,606.3360000000002,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",137,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,608.3520000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",138,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.656,611.0080000000002,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",139,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.688,613.6960000000001,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_64x32_sliced1x4_tn,140,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,171861.0,0.7912091116173121,18017248.0,135168.0,25.376,639.0720000000001,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,563039.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",141,188416.0,393216.0,0,0,0.0,393216.0,393216.0,0.0,256.0,0.0,65536.0,65536.0,2.304,641.3760000000001,16384.0,0.0,188416.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,142,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,170998.0,0.7920395202502365,18011776.0,135168.0,25.344,666.7200000000001,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,562868.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",143,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.144,668.8640000000001,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,144,134217728.0,270270464.0,0,0,0.0,270270464.0,270270464.0,651264.0,140288.0,0.8227684346701164,17825792.0,131072.0,22.816,691.6800000000002,786432.0,1048576.0,134217728.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,557056.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",145,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.24,693.9200000000002,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",146,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.112,696.0320000000002,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",147,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.016,698.0480000000001,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",148,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.872,701.9200000000001,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",149,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,703.9040000000001,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",150,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,705.8880000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",151,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.592,708.4800000000001,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",152,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.624,711.1040000000002,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,153,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.28,720.3840000000001,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",154,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.272,722.6560000000002,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,155,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.184,731.8400000000001,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",156,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.208,734.0480000000001,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,157,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.28,743.3280000000001,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",158,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.208,745.5360000000001,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",159,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.624,748.1600000000001,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",160,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.656,750.816,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",161,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.064,754.88,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",162,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.752,757.632,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",163,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.08,759.712,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",164,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.688,762.4,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",165,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.656,765.0559999999999,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",166,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.0,769.0559999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",167,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.656,771.7119999999999,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",168,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.048,773.7599999999999,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",169,65536.0,5883904.0,0,0,0.0,5883904.0,5883904.0,33280.0,64.0,0.9980806142034548,49152.0,16384.0,20.416,794.1759999999999,4960256.0,792576.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,170,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.184,803.3599999999999,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",171,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.464,805.824,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",172,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.08,807.904,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",173,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.016,809.92,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",174,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.904,813.824,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",175,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.888,815.712,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",176,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,817.696,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",177,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.656,820.352,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",178,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.688,823.04,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_64x32_sliced1x4_tn,179,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,171474.0,0.7915812810396505,18014016.0,135168.0,25.312,848.352,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,562938.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",180,188416.0,393216.0,0,0,0.0,393216.0,393216.0,0.0,256.0,0.0,65536.0,65536.0,2.304,850.656,16384.0,0.0,188416.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,181,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,171585.0,0.791474498966396,18009664.0,135168.0,25.408,876.064,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,562802.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",182,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.144,878.208,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,183,134217728.0,270270464.0,0,0,0.0,270270464.0,270270464.0,651264.0,140288.0,0.8227684346701164,17825792.0,131072.0,23.168,901.376,786432.0,1048576.0,134217728.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,557056.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",184,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.208,903.584,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",185,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.08,905.664,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",186,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.048,907.712,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",187,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.872,911.584,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",188,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,913.5039999999999,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",189,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,915.5519999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",190,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.656,918.2079999999999,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",191,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.752,920.9599999999998,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,192,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.216,930.1759999999998,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",193,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.272,932.4479999999999,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,194,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.248,941.6959999999999,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",195,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.272,943.968,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,196,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,8.96,952.928,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",197,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.272,955.2,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",198,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.688,957.888,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",199,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.624,960.5120000000001,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",200,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.032,964.5440000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",201,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.688,967.2320000000001,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",202,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.112,969.344,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",203,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.688,972.032,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",204,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.592,974.624,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",205,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.032,978.6560000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",206,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.688,981.344,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",207,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.048,983.392,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",208,65536.0,5883904.0,0,0,0.0,5883904.0,5883904.0,33280.0,64.0,0.9980806142034548,49152.0,16384.0,20.16,1003.552,4960256.0,792576.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,209,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.28,1012.832,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",210,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.304,1015.136,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",211,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.08,1017.216,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",212,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.016,1019.232,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",213,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.904,1023.136,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",214,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,1025.088,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",215,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,1027.072,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",216,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.624,1029.696,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",217,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.656,1032.3519999999999,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_64x32_sliced1x4_tn,218,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,171711.0,0.7913533217898479,18014272.0,135168.0,25.44,1057.792,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,562946.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",219,188416.0,393216.0,0,0,0.0,393216.0,393216.0,0.0,256.0,0.0,65536.0,65536.0,2.336,1060.128,16384.0,0.0,188416.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,220,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,171262.0,0.791785305266946,18011488.0,135168.0,25.568,1085.696,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,562859.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",221,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.144,1087.84,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,222,134217728.0,270270464.0,0,0,0.0,270270464.0,270270464.0,651264.0,140288.0,0.8227684346701164,17825792.0,131072.0,22.432,1110.272,786432.0,1048576.0,134217728.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,557056.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",223,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.24,1112.512,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",224,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.208,1114.72,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",225,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.016,1116.736,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",226,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.936,1120.672,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",227,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,1122.624,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",228,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,1124.672,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",229,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.656,1127.328,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",230,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.656,1129.984,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,231,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.088,1139.072,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",232,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.24,1141.312,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,233,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.024,1150.3359999999998,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",234,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.24,1152.5759999999998,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,235,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.024,1161.5999999999997,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",236,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.24,1163.8399999999997,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",237,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.688,1166.5279999999998,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",238,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.624,1169.1519999999998,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",239,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.032,1173.1839999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",240,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.784,1175.9679999999998,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",241,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.08,1178.0479999999998,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",242,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.784,1180.8319999999999,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",243,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.688,1183.52,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",244,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.032,1187.552,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",245,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.72,1190.272,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",246,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.048,1192.32,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",247,65536.0,5883904.0,0,0,0.0,5883904.0,5883904.0,33280.0,64.0,0.9980806142034548,49152.0,16384.0,20.16,1212.48,4960256.0,792576.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,248,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.312,1221.792,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",249,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.272,1224.0639999999999,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",250,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.112,1226.176,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",251,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.016,1228.192,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",252,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.936,1232.128,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",253,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.144,1234.272,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",254,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,1236.2559999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",255,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.624,1238.8799999999999,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",256,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.688,1241.568,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_64x32_sliced1x4_tn,257,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,171226.0,0.7918199613369159,18012544.0,135168.0,25.504,1267.072,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,562892.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",258,188416.0,393216.0,0,0,0.0,393216.0,393216.0,0.0,256.0,0.0,65536.0,65536.0,2.368,1269.4399999999998,16384.0,0.0,188416.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,259,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,171059.0,0.7919807666817054,18013344.0,135168.0,25.344,1294.7839999999999,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,562917.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",260,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.144,1296.9279999999999,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,261,134217728.0,270270464.0,0,0,0.0,270270464.0,270270464.0,651264.0,140288.0,0.8227684346701164,17825792.0,131072.0,22.816,1319.744,786432.0,1048576.0,134217728.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,557056.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",262,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.208,1321.952,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",263,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.016,1323.968,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",264,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.016,1325.9840000000002,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",265,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,4.0,1329.9840000000002,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",266,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,1331.968,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",267,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,1334.048,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",268,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.688,1336.736,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",269,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.656,1339.392,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,270,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.248,1348.64,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",271,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.208,1350.8480000000002,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,272,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,8.96,1359.8080000000002,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",273,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.272,1362.0800000000002,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,274,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.152,1371.2320000000002,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",275,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.272,1373.5040000000001,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",276,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.688,1376.1920000000002,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",277,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.656,1378.8480000000002,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",278,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.0,1382.8480000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",279,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.784,1385.6320000000003,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",280,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.08,1387.7120000000002,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",281,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.752,1390.4640000000002,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",282,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.688,1393.1520000000003,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",283,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.032,1397.1840000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",284,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.688,1399.8720000000003,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",285,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.176,1402.0480000000002,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",286,65536.0,5883904.0,0,0,0.0,5883904.0,5883904.0,33280.0,64.0,0.9980806142034548,49152.0,16384.0,20.128,1422.1760000000002,4960256.0,792576.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,287,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.28,1431.4560000000001,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",288,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.24,1433.6960000000001,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",289,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.208,1435.9040000000002,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",290,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.048,1437.9520000000002,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",291,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.872,1441.8240000000003,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",292,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,1443.7760000000003,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",293,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,1445.7920000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",294,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.752,1448.5440000000003,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",295,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.656,1451.2000000000003,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_64x32_sliced1x4_tn,296,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,170831.0,0.7922004147939107,18002432.0,135168.0,25.6,1476.8000000000002,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,562576.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",297,188416.0,393216.0,0,0,0.0,393216.0,393216.0,0.0,256.0,0.0,65536.0,65536.0,2.336,1479.1360000000002,16384.0,0.0,188416.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,298,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,171549.0,0.7915091278334202,18011616.0,135168.0,25.728,1504.8640000000003,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,562863.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",299,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.176,1507.0400000000002,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,300,134217728.0,270270464.0,0,0,0.0,270270464.0,270270464.0,651264.0,140288.0,0.8227684346701164,17825792.0,131072.0,22.464,1529.5040000000001,786432.0,1048576.0,134217728.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,557056.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",301,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.272,1531.776,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",302,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.08,1533.856,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",303,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,1.952,1535.808,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",304,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.936,1539.744,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",305,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,1541.696,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",306,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,1543.7759999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",307,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.688,1546.464,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",308,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.656,1549.12,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,309,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.088,1558.2079999999999,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",310,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.304,1560.512,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,311,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.12,1569.6319999999998,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",312,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.24,1571.8719999999998,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,313,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.184,1581.0559999999998,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",314,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.24,1583.2959999999998,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",315,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.688,1585.984,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",316,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.752,1588.7359999999999,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",317,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.0,1592.7359999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",318,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.656,1595.3919999999998,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",319,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.016,1597.408,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",320,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.688,1600.096,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",321,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.656,1602.752,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",322,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.064,1606.816,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",323,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.752,1609.568,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",324,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.048,1611.616,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",325,65536.0,5883904.0,0,0,0.0,5883904.0,5883904.0,33280.0,64.0,0.9980806142034548,49152.0,16384.0,20.16,1631.776,4960256.0,792576.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,326,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.184,1640.96,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",327,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.208,1643.1680000000001,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",328,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.08,1645.248,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",329,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.016,1647.2640000000001,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",330,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.872,1651.1360000000002,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",331,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,1653.1200000000001,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",332,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,1655.104,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",333,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.656,1657.76,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",334,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.656,1660.416,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_64x32_sliced1x4_tn,335,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,170872.0,0.7921609076843734,18012576.0,135168.0,25.344,1685.76,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,562893.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",336,188416.0,393216.0,0,0,0.0,393216.0,393216.0,0.0,256.0,0.0,65536.0,65536.0,2.304,1688.064,16384.0,0.0,188416.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,337,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,170715.0,0.7923122123557901,18013088.0,135168.0,25.728,1713.7920000000001,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,562909.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",338,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.336,1716.1280000000002,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,339,134217728.0,270270464.0,0,0,0.0,270270464.0,270270464.0,651264.0,140288.0,0.8227684346701164,17825792.0,131072.0,22.464,1738.592,786432.0,1048576.0,134217728.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,557056.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",340,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.208,1740.8000000000002,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",341,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.112,1742.9120000000003,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",342,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.016,1744.9280000000003,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",343,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.872,1748.8000000000004,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",344,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,1750.7520000000004,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",345,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,1752.7680000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",346,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.688,1755.4560000000006,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",347,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.656,1758.1120000000005,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_64x32_sliced1x4_tn,348,1048576000.0,2104320000.0,0,0,0.0,2104320000.0,2104320000.0,4848000.0,1092000.0,0.8161616161616162,135842176.0,512000.0,151.008,1909.1200000000006,3072000.0,4096000.0,1048576000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4245068.0,16000.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",349,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,1910.8480000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",350,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,64.0,128.0,2.592,1913.4400000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",351,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,1915.4240000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",352,0.0,128000.0,0,0,0.0,128000.0,128000.0,0.0,2000.0,0.0,512000.0,512000.0,2.56,1917.9840000000006,0.0,128000.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,16000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",353,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.76,1919.7440000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",354,0.0,0.0,0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,34368.0,3.68,1923.4240000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16128.0,1074.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",355,0.0,0.0,0,0,0.0,0.0,0.0,9472.0,34440.0,0.2157041355438149,2109440.0,0.0,4.288,1927.7120000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",356,0.0,0.0,0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,34688.0,3.52,1931.2320000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16128.0,1084.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",357,0.0,0.0,0,0,0.0,0.0,0.0,9472.0,35208.0,0.21199641897940913,2109440.0,0.0,4.352,1935.5840000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",358,0.0,0.0,0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,34880.0,3.392,1938.9760000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16128.0,1090.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",359,0.0,0.0,0,0,0.0,0.0,0.0,9472.0,35080.0,0.21260549470281917,2109440.0,0.0,4.224,1943.2000000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",360,0.0,0.0,0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,34048.0,3.616,1946.8160000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16128.0,1064.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",361,0.0,0.0,0,0,0.0,0.0,0.0,9472.0,34312.0,0.216334734149461,2109440.0,128.0,4.32,1951.1360000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,65920.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",362,0.0,0.0,0,0,0.0,0.0,0.0,0.0,12.0,0.0,4128.0,512.0,2.4,1953.5360000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,129.0,16.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",363,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.696,1955.2320000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",364,0.0,0.0,0,0,0.0,0.0,0.0,497.0,16.0,0.9688109161793372,512.0,0.0,3.456,1958.6880000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",365,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.664,1960.3520000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",366,0.0,0.0,0,0,0.0,0.0,0.0,497.0,16.0,0.9688109161793372,512.0,0.0,3.424,1963.7760000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",367,0.0,0.0,0,0,0.0,0.0,0.0,45312.0,8432.0,0.8431080678773445,527232.0,6688.0,5.728,1969.5040000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16476.0,209.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",368,0.0,0.0,0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,544.0,6.496,1976.0000000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,80.0,17.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",369,0.0,0.0,0,0,0.0,0.0,0.0,0.0,12000.0,0.0,520064.0,56928.0,3.744,1979.7440000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16252.0,1779.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",370,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3000.0,0.0,640000.0,0.0,2.848,1982.5920000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,20000.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",371,0.0,0.0,0,0,0.0,0.0,0.0,0.0,4000.0,0.0,0.0,1024000.0,2.272,1984.8640000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,32000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",372,0.0,0.0,0,0,0.0,0.0,0.0,98304.0,4000.0,0.960900844541758,512000.0,0.0,4.16,1989.0240000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",373,0.0,0.0,0,0,0.0,0.0,0.0,156.0,64.0,0.7090909090909091,8192.0,0.0,2.176,1991.2000000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",374,0.0,0.0,0,0,0.0,0.0,0.0,51858.0,19506.0,0.7266689086934589,1884672.0,1300256.0,9.664,2000.8640000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,58896.0,40633.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",375,0.0,0.0,0,0,0.0,0.0,0.0,18654.0,19503.0,0.4888749115496501,1885952.0,1030240.0,8.384,2009.2480000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,58936.0,32195.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",376,0.0,0.0,0,0,0.0,0.0,0.0,15858.0,19724.0,0.445674779382834,1896704.0,1579008.0,8.128,2017.3760000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,59272.0,49344.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",377,0.0,0.0,0,0,0.0,0.0,0.0,15858.0,19648.0,0.44662873880470905,1888128.0,1206752.0,8.256,2025.6320000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,59004.0,37711.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",378,0.0,0.0,0,0,0.0,0.0,0.0,14336.0,4000.0,0.7818499127399651,1024000.0,0.0,4.0,2029.6320000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",379,0.0,0.0,0,0,0.0,0.0,0.0,39.0,16.0,0.7090909090909091,2048.0,0.0,2.24,2031.8720000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",380,0.0,0.0,0,0,0.0,0.0,0.0,13650.0,10454.0,0.5662960504480584,1276928.0,886336.0,6.784,2038.6560000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,39904.0,27698.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",381,0.0,0.0,0,0,0.0,0.0,0.0,0.0,16000.0,0.0,1549568.0,1536000.0,4.128,2042.7840000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48424.0,48000.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",382,1792000.0,4245120.0,0,0,0.0,4245120.0,4245120.0,528.0,5248.0,0.09141274238227147,1036032.0,512000.0,17.152,2059.9360000000006,533120.0,128000.0,1792000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32376.0,16000.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",383,0.0,655488.0,0,0,0.0,655488.0,655488.0,71840.0,8000.0,0.8997995991983968,512000.0,512000.0,46.528,2106.4640000000004,655488.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,16000.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",384,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2000.0,0.0,512000.0,128000.0,2.624,2109.088,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,4000.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",385,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,1.952,2111.0400000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",386,0.0,0.0,0,0,0.0,0.0,0.0,0.0,12000.0,0.0,1152000.0,54176.0,7.52,2118.5600000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,36000.0,1693.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",387,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3000.0,0.0,640000.0,0.0,2.784,2121.3440000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,20000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",388,1792000.0,4245120.0,0,0,0.0,4245120.0,4245120.0,528.0,5248.0,0.09141274238227147,1036800.0,512000.0,17.024,2138.3680000000004,533120.0,128000.0,1792000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32400.0,16000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",389,0.0,0.0,0,0,0.0,0.0,0.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,22.08,2160.4480000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",390,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,2162.592,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",391,0.0,0.0,0,0,0.0,0.0,0.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,21.856,2184.4480000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",392,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.176,2186.6240000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",393,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.048,2188.672,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",394,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.008,2191.68,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",395,0.0,147456.0,0,0,0.0,147456.0,147456.0,320.0,1004.0,0.24169184290030213,512000.0,128.0,8.16,2199.8399999999997,147456.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",396,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,2201.8239999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",397,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.2,2205.0239999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",398,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,2207.071999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",399,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.008,2210.079999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",400,1152000.0,2560000.0,0,0,0.0,2560000.0,2560000.0,0.0,4000.0,0.0,0.0,512000.0,3.264,2213.343999999999,0.0,256000.0,1152000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,16000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",401,640000.0,1280000.0,0,0,0.0,1280000.0,1280000.0,0.0,3000.0,0.0,1024000.0,0.0,4.288,2217.631999999999,0.0,0.0,640000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",402,0.0,0.0,0,0,0.0,0.0,0.0,640.0,1004.0,0.38929440389294406,512000.0,128.0,11.936,2229.5679999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",403,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.016,2231.5839999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",404,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2233.5999999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",405,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.304,2235.9039999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",406,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.08,2237.9839999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",407,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,64.0,128.0,2.624,2240.6079999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",408,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,2242.3359999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",409,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,2244.0319999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",410,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.208,2246.2399999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",411,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,2247.9359999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",412,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,32.0,2.368,2250.303999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",413,0.0,0.0,0,0,0.0,0.0,0.0,0.0,5.0,0.0,32.0,32.0,5.024,2255.327999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",414,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.144,2257.471999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",415,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,2259.5199999999986,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",416,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.816,2262.3359999999984,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",417,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.168,2265.5039999999985,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",418,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,2267.5519999999983,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",419,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,2269.695999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",420,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,32.0,3.392,2273.087999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",421,0.0,0.0,0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,64.0,32.0,2.624,2275.7119999999977,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",422,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.08,2277.7919999999976,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",423,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,2.112,2279.9039999999977,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",424,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,0.0,2.112,2282.015999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",425,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,2.24,2284.2559999999976,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",426,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,16640.0,16384.0,4.96,2289.2159999999976,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,520.0,512.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",427,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,2.592,2291.8079999999977,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",428,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,2295.1039999999975,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",429,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.496,2297.5999999999976,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",430,0.0,512.0,0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,2.08,2299.6799999999976,0.0,512.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",431,0.0,0.0,0,0,0.0,0.0,0.0,0.0,20.0,0.0,2048.0,2048.0,2.56,2302.2399999999975,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",432,4096.0,9216.0,0,0,0.0,9216.0,9216.0,0.0,32.0,0.0,2048.0,2048.0,2.784,2305.0239999999976,0.0,1024.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",433,0.0,512.0,0,0,0.0,512.0,512.0,0.0,32.0,0.0,2048.0,2048.0,2.048,2307.0719999999974,0.0,512.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",434,3600.0,8224.0,0,0,0.0,8224.0,8224.0,0.0,32.0,0.0,2048.0,2048.0,2.752,2309.8239999999973,0.0,1024.0,3600.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",435,0.0,512.0,0,0,0.0,512.0,512.0,0.0,32.0,0.0,2048.0,2048.0,2.08,2311.9039999999973,0.0,512.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",436,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.144,2314.047999999997,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",437,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.904,2317.951999999997,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",438,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,2319.935999999997,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",439,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,2321.919999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",440,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.688,2324.607999999997,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",441,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.656,2327.263999999997,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,442,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.024,2336.287999999997,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",443,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.24,2338.5279999999966,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,444,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.184,2347.711999999997,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",445,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.368,2350.0799999999967,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,446,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.056,2359.135999999997,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",447,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.208,2361.343999999997,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",448,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.848,2364.191999999997,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",449,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.624,2366.8159999999966,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",450,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,3.968,2370.7839999999965,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",451,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.688,2373.4719999999966,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",452,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.08,2375.5519999999965,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",453,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.72,2378.2719999999963,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",454,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.656,2380.9279999999962,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",455,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.0,2384.9279999999962,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",456,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.72,2387.647999999996,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",457,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.048,2389.695999999996,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",458,0.0,0.0,0,0,0.0,0.0,0.0,0.0,320.0,0.0,32768.0,32768.0,2.688,2392.383999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",459,0.0,0.0,0,0,0.0,0.0,0.0,0.0,320.0,0.0,32768.0,32768.0,2.592,2394.975999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",460,65536.0,5885952.0,0,0,0.0,5885952.0,5885952.0,33280.0,64.0,0.9980806142034548,81920.0,16384.0,20.128,2415.103999999996,4962304.0,792576.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2560.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,461,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.216,2424.319999999996,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",462,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.272,2426.591999999996,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",463,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.08,2428.671999999996,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",464,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.048,2430.7199999999957,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",465,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.904,2434.6239999999957,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",466,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,2436.543999999996,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",467,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,2438.5279999999957,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",468,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.624,2441.1519999999955,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",469,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.816,2443.9679999999953,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_64x32_sliced1x4_tn,470,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,171233.0,0.7918132224190484,18014720.0,135168.0,25.344,2469.3119999999954,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,562960.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",471,188416.0,393216.0,0,0,0.0,393216.0,393216.0,0.0,256.0,0.0,65536.0,65536.0,2.336,2471.647999999995,16384.0,0.0,188416.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,472,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,171921.0,0.7911514422638897,18015712.0,135168.0,25.28,2496.9279999999953,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,562991.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",473,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.336,2499.263999999995,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,474,134217728.0,270270464.0,0,0,0.0,270270464.0,270270464.0,651264.0,140288.0,0.8227684346701164,17825792.0,131072.0,22.464,2521.727999999995,786432.0,1048576.0,134217728.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,557056.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",475,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.208,2523.935999999995,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",476,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.08,2526.015999999995,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",477,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.048,2528.063999999995,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",478,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.872,2531.9359999999947,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",479,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,2533.887999999995,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",480,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2535.903999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",481,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.624,2538.527999999995,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",482,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.624,2541.1519999999946,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,483,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.248,2550.3999999999946,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",484,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.24,2552.6399999999944,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,485,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.248,2561.8879999999945,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",486,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.24,2564.1279999999942,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,487,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.344,2573.4719999999943,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",488,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.272,2575.7439999999942,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",489,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.688,2578.4319999999943,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",490,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.656,2581.0879999999943,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",491,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.032,2585.1199999999944,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",492,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.688,2587.8079999999945,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",493,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.112,2589.9199999999946,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",494,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.688,2592.6079999999947,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",495,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.624,2595.2319999999945,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",496,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.032,2599.2639999999947,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",497,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.688,2601.9519999999948,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",498,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.016,2603.967999999995,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",499,0.0,0.0,0,0,0.0,0.0,0.0,0.0,320.0,0.0,32768.0,32768.0,2.56,2606.527999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",500,0.0,0.0,0,0,0.0,0.0,0.0,0.0,320.0,0.0,32768.0,32768.0,2.72,2609.2479999999946,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",501,65536.0,5885952.0,0,0,0.0,5885952.0,5885952.0,33280.0,64.0,0.9980806142034548,81920.0,16384.0,20.16,2629.4079999999944,4962304.0,792576.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2560.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,502,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.088,2638.4959999999946,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",503,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.208,2640.7039999999947,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",504,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.08,2642.7839999999946,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",505,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.016,2644.7999999999947,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",506,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.872,2648.6719999999946,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",507,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,2650.623999999995,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",508,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2652.639999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",509,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.752,2655.391999999995,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",510,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.656,2658.0479999999948,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_64x32_sliced1x4_tn,511,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,171073.0,0.7919672834859675,18005728.0,135168.0,25.216,2683.2639999999947,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,562679.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",512,188416.0,393216.0,0,0,0.0,393216.0,393216.0,0.0,256.0,0.0,65536.0,65536.0,2.336,2685.5999999999945,16384.0,0.0,188416.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,513,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,171683.0,0.791380246844572,18010688.0,135168.0,25.28,2710.8799999999947,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,562834.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",514,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.24,2713.1199999999944,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,515,134217728.0,270270464.0,0,0,0.0,270270464.0,270270464.0,651264.0,140288.0,0.8227684346701164,17825792.0,131072.0,22.368,2735.4879999999944,786432.0,1048576.0,134217728.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,557056.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",516,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.272,2737.7599999999943,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",517,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.112,2739.8719999999944,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",518,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.016,2741.8879999999945,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",519,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.904,2745.7919999999945,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",520,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,2747.7759999999944,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",521,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,2749.7599999999943,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",522,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.592,2752.3519999999944,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",523,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.656,2755.0079999999944,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,524,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.024,2764.0319999999942,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",525,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.272,2766.303999999994,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,526,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.28,2775.5839999999944,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",527,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.24,2777.823999999994,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,528,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.344,2787.167999999994,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",529,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.24,2789.407999999994,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",530,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.624,2792.031999999994,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",531,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.624,2794.6559999999936,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",532,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.032,2798.6879999999937,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",533,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.784,2801.471999999994,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",534,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.08,2803.5519999999938,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",535,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.816,2806.3679999999936,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",536,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.656,2809.0239999999935,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",537,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.032,2813.0559999999937,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",538,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.624,2815.6799999999935,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",539,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.048,2817.7279999999932,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",540,0.0,0.0,0,0,0.0,0.0,0.0,0.0,320.0,0.0,32768.0,32768.0,2.784,2820.5119999999933,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",541,0.0,0.0,0,0,0.0,0.0,0.0,0.0,320.0,0.0,32768.0,32768.0,2.592,2823.1039999999934,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",542,65536.0,5885952.0,0,0,0.0,5885952.0,5885952.0,33280.0,64.0,0.9980806142034548,81920.0,16384.0,20.192,2843.2959999999935,4962304.0,792576.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2560.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,543,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.12,2852.4159999999933,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",544,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.272,2854.6879999999933,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",545,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.08,2856.767999999993,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",546,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.016,2858.7839999999933,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",547,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.968,2862.751999999993,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",548,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,2864.735999999993,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",549,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.112,2866.847999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",550,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.656,2869.503999999993,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",551,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.656,2872.159999999993,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_64x32_sliced1x4_tn,552,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,171021.0,0.7920173662416315,18019296.0,135168.0,25.344,2897.503999999993,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,563103.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",553,188416.0,393216.0,0,0,0.0,393216.0,393216.0,0.0,256.0,0.0,65536.0,65536.0,2.304,2899.807999999993,16384.0,0.0,188416.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,554,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,171016.0,0.7920221822250328,18012032.0,135168.0,25.184,2924.9919999999934,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,562876.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",555,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.144,2927.135999999993,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,556,134217728.0,270270464.0,0,0,0.0,270270464.0,270270464.0,651264.0,140288.0,0.8227684346701164,17825792.0,131072.0,22.592,2949.7279999999932,786432.0,1048576.0,134217728.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,557056.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",557,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.368,2952.095999999993,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",558,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.08,2954.175999999993,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",559,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.016,2956.191999999993,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",560,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.872,2960.063999999993,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",561,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,2962.0159999999933,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",562,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.952,2963.9679999999935,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",563,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.656,2966.6239999999934,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",564,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.656,2969.2799999999934,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,565,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.28,2978.5599999999936,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",566,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.272,2980.8319999999935,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,567,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,8.928,2989.7599999999934,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",568,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.272,2992.0319999999933,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,569,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.152,3001.1839999999934,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",570,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.208,3003.3919999999935,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",571,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.784,3006.1759999999936,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",572,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.656,3008.8319999999935,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",573,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.0,3012.8319999999935,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",574,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.688,3015.5199999999936,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",575,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.08,3017.5999999999935,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",576,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.752,3020.3519999999935,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",577,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.656,3023.0079999999934,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",578,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,3.968,3026.9759999999933,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",579,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.656,3029.6319999999932,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",580,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.08,3031.711999999993,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",581,0.0,0.0,0,0,0.0,0.0,0.0,0.0,320.0,0.0,32768.0,32768.0,2.656,3034.367999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",582,0.0,0.0,0,0,0.0,0.0,0.0,0.0,320.0,0.0,32768.0,32768.0,2.624,3036.991999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",583,65536.0,5885952.0,0,0,0.0,5885952.0,5885952.0,33280.0,64.0,0.9980806142034548,81920.0,16384.0,20.192,3057.183999999993,4962304.0,792576.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2560.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,584,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,8.928,3066.111999999993,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",585,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.208,3068.319999999993,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",586,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.048,3070.3679999999927,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",587,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.016,3072.3839999999927,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",588,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.904,3076.2879999999927,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",589,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,3078.2719999999927,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",590,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,3080.2879999999927,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",591,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.624,3082.9119999999925,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",592,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.688,3085.5999999999926,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_64x32_sliced1x4_tn,593,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,171497.0,0.7915591526579407,18008544.0,135168.0,25.28,3110.879999999993,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,562767.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",594,188416.0,393216.0,0,0,0.0,393216.0,393216.0,0.0,256.0,0.0,65536.0,65536.0,2.272,3113.1519999999928,16384.0,0.0,188416.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,595,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,171751.0,0.7913148606039987,18012640.0,135168.0,25.12,3138.2719999999927,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,562895.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",596,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.176,3140.4479999999926,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,597,134217728.0,270270464.0,0,0,0.0,270270464.0,270270464.0,651264.0,140288.0,0.8227684346701164,17825792.0,131072.0,22.464,3162.9119999999925,786432.0,1048576.0,134217728.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,557056.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",598,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.24,3165.1519999999923,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",599,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.08,3167.2319999999922,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",600,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.016,3169.2479999999923,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",601,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.968,3173.215999999992,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",602,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.888,3175.103999999992,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",603,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,3177.087999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",604,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.624,3179.711999999992,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",605,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.688,3182.399999999992,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,606,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.152,3191.551999999992,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",607,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.208,3193.759999999992,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,608,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.28,3203.0399999999922,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",609,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.208,3205.2479999999923,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,610,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.088,3214.3359999999925,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",611,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.24,3216.5759999999923,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",612,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.688,3219.2639999999924,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",613,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.72,3221.983999999992,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",614,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.0,3225.983999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",615,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.816,3228.799999999992,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",616,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.176,3230.975999999992,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",617,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.784,3233.759999999992,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",618,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.592,3236.351999999992,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",619,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.032,3240.3839999999923,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",620,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.688,3243.0719999999924,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",621,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.112,3245.1839999999925,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",622,0.0,0.0,0,0,0.0,0.0,0.0,0.0,320.0,0.0,32768.0,32768.0,2.624,3247.8079999999923,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",623,0.0,0.0,0,0,0.0,0.0,0.0,0.0,320.0,0.0,32768.0,32768.0,2.592,3250.3999999999924,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",624,65536.0,5885952.0,0,0,0.0,5885952.0,5885952.0,33280.0,64.0,0.9980806142034548,81920.0,16384.0,20.192,3270.5919999999924,4962304.0,792576.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2560.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,625,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.216,3279.8079999999923,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",626,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.208,3282.0159999999923,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",627,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.08,3284.0959999999923,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",628,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.016,3286.1119999999923,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",629,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.872,3289.983999999992,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",630,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,3291.9359999999924,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",631,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,3293.9519999999925,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",632,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.656,3296.6079999999924,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",633,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.688,3299.2959999999925,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_64x32_sliced1x4_tn,634,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,170983.0,0.7920539691844422,18016960.0,135168.0,25.408,3324.7039999999924,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,563030.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",635,188416.0,393216.0,0,0,0.0,393216.0,393216.0,0.0,256.0,0.0,65536.0,65536.0,2.4,3327.1039999999925,16384.0,0.0,188416.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,636,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,171242.0,0.7918045582646206,18016672.0,135168.0,25.28,3352.3839999999927,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,563021.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",637,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.368,3354.7519999999927,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,638,134217728.0,270270464.0,0,0,0.0,270270464.0,270270464.0,651264.0,140288.0,0.8227684346701164,17825792.0,131072.0,22.528,3377.2799999999925,786432.0,1048576.0,134217728.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,557056.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",639,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.4,3379.6799999999926,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",640,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.112,3381.7919999999926,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",641,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.016,3383.8079999999927,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",642,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.872,3387.6799999999926,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",643,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,3389.631999999993,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",644,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,3391.6159999999927,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",645,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.72,3394.3359999999925,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",646,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.688,3397.0239999999926,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,647,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.152,3406.1759999999927,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",648,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.272,3408.4479999999926,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,649,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.184,3417.631999999993,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",650,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.208,3419.839999999993,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,651,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,8.928,3428.7679999999928,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",652,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.24,3431.0079999999925,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",653,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.752,3433.7599999999925,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",654,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.688,3436.4479999999926,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",655,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.032,3440.4799999999927,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",656,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.784,3443.263999999993,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",657,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.112,3445.375999999993,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",658,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,3.296,3448.6719999999927,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",659,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.656,3451.3279999999927,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",660,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.0,3455.3279999999927,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",661,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.752,3458.0799999999927,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",662,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.08,3460.1599999999926,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",663,0.0,0.0,0,0,0.0,0.0,0.0,0.0,320.0,0.0,32768.0,32768.0,2.56,3462.7199999999925,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",664,0.0,0.0,0,0,0.0,0.0,0.0,0.0,320.0,0.0,32768.0,32768.0,2.656,3465.3759999999925,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",665,65536.0,5885952.0,0,0,0.0,5885952.0,5885952.0,33280.0,64.0,0.9980806142034548,81920.0,16384.0,20.256,3485.6319999999923,4962304.0,792576.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2560.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,666,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.152,3494.7839999999924,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",667,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.24,3497.023999999992,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",668,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.08,3499.103999999992,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",669,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.048,3501.151999999992,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",670,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.872,3505.0239999999917,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",671,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,3506.975999999992,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",672,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,3508.991999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",673,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.688,3511.679999999992,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",674,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.592,3514.271999999992,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_64x32_sliced1x4_tn,675,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,171349.0,0.7917015656207719,18014624.0,135168.0,25.408,3539.679999999992,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,562957.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",676,188416.0,393216.0,0,0,0.0,393216.0,393216.0,0.0,256.0,0.0,65536.0,65536.0,2.336,3542.015999999992,16384.0,0.0,188416.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,677,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,170910.0,0.792124294857293,18014432.0,135168.0,25.44,3567.455999999992,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,562951.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",678,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.336,3569.7919999999917,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,679,134217728.0,270270464.0,0,0,0.0,270270464.0,270270464.0,651264.0,140288.0,0.8227684346701164,17825792.0,131072.0,22.592,3592.383999999992,786432.0,1048576.0,134217728.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,557056.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",680,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.272,3594.6559999999918,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",681,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.08,3596.7359999999917,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",682,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,1.984,3598.7199999999916,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",683,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,4.064,3602.7839999999915,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",684,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,3604.7359999999917,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",685,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,3606.7839999999915,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",686,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.688,3609.4719999999916,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",687,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.656,3612.1279999999915,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,688,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.184,3621.3119999999917,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",689,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.24,3623.5519999999915,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,690,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.28,3632.8319999999917,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",691,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.208,3635.039999999992,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,692,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.28,3644.319999999992,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",693,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.304,3646.623999999992,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",694,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.72,3649.343999999992,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",695,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.688,3652.031999999992,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",696,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.0,3656.031999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",697,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.656,3658.687999999992,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",698,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.048,3660.7359999999917,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",699,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.688,3663.423999999992,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",700,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.656,3666.0799999999917,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",701,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.064,3670.1439999999916,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",702,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.688,3672.8319999999917,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",703,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.048,3674.8799999999915,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",704,0.0,0.0,0,0,0.0,0.0,0.0,0.0,320.0,0.0,32768.0,32768.0,2.624,3677.5039999999913,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",705,0.0,0.0,0,0,0.0,0.0,0.0,0.0,320.0,0.0,32768.0,32768.0,2.592,3680.0959999999914,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",706,65536.0,5885952.0,0,0,0.0,5885952.0,5885952.0,33280.0,64.0,0.9980806142034548,81920.0,16384.0,20.352,3700.447999999991,4962304.0,792576.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2560.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,707,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.216,3709.663999999991,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",708,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.24,3711.903999999991,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",709,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.144,3714.0479999999907,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",710,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.08,3716.1279999999906,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",711,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.872,3719.9999999999905,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",712,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,3721.9839999999904,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",713,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.952,3723.9359999999906,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",714,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.656,3726.5919999999905,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",715,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.656,3729.2479999999905,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_64x32_sliced1x4_tn,716,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,171404.0,0.7916486359017246,18014016.0,135168.0,25.408,3754.6559999999904,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,562938.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",717,188416.0,393216.0,0,0,0.0,393216.0,393216.0,0.0,256.0,0.0,65536.0,65536.0,2.368,3757.0239999999903,16384.0,0.0,188416.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,718,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,171070.0,0.7919701727035486,18012704.0,135168.0,25.44,3782.4639999999904,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,562897.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",719,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.144,3784.60799999999,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,720,134217728.0,270270464.0,0,0,0.0,270270464.0,270270464.0,651264.0,140288.0,0.8227684346701164,17825792.0,131072.0,22.496,3807.1039999999903,786432.0,1048576.0,134217728.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,557056.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",721,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.208,3809.3119999999903,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",722,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.048,3811.35999999999,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",723,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,1.984,3813.34399999999,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",724,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.872,3817.21599999999,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",725,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,3819.19999999999,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",726,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,3821.2479999999896,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",727,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.656,3823.9039999999895,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",728,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.688,3826.5919999999896,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,729,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.216,3835.8079999999895,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",730,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.24,3838.0479999999893,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,731,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.088,3847.1359999999895,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",732,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.272,3849.4079999999894,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,733,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.184,3858.5919999999896,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",734,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.272,3860.8639999999896,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",735,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.72,3863.5839999999894,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",736,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.688,3866.2719999999895,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",737,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,3.968,3870.2399999999893,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",738,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.656,3872.8959999999893,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",739,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.048,3874.943999999989,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",740,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.848,3877.791999999989,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",741,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.816,3880.607999999989,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",742,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.032,3884.639999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",743,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.688,3887.327999999989,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",744,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.112,3889.439999999989,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",745,0.0,0.0,0,0,0.0,0.0,0.0,0.0,320.0,0.0,32768.0,32768.0,2.56,3891.999999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",746,0.0,0.0,0,0,0.0,0.0,0.0,0.0,320.0,0.0,32768.0,32768.0,2.592,3894.591999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",747,65536.0,5885952.0,0,0,0.0,5885952.0,5885952.0,33280.0,64.0,0.9980806142034548,81920.0,16384.0,20.16,3914.751999999989,4962304.0,792576.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2560.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,748,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.248,3923.999999999989,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",749,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.24,3926.239999999989,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",750,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.08,3928.319999999989,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",751,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,1.984,3930.3039999999887,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",752,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.872,3934.1759999999886,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",753,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,3936.127999999989,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",754,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.952,3938.079999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",755,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.688,3940.767999999989,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",756,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.656,3943.423999999989,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_64x32_sliced1x4_tn,757,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,170904.0,0.7921300756049858,18007264.0,135168.0,25.216,3968.639999999989,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,562727.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",758,188416.0,393216.0,0,0,0.0,393216.0,393216.0,0.0,256.0,0.0,65536.0,65536.0,2.336,3970.9759999999887,16384.0,0.0,188416.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,759,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,170836.0,0.7921955966427442,18022272.0,135168.0,25.44,3996.415999999989,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,563196.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",760,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.208,3998.623999999989,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,761,134217728.0,270270464.0,0,0,0.0,270270464.0,270270464.0,651264.0,140288.0,0.8227684346701164,17825792.0,131072.0,22.432,4021.0559999999887,786432.0,1048576.0,134217728.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,557056.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",762,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.24,4023.2959999999885,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",763,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.08,4025.3759999999884,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",764,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.048,4027.423999999988,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",765,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.904,4031.327999999988,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",766,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,4033.2799999999884,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",767,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,4035.2639999999883,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",768,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.688,4037.9519999999884,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",769,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.624,4040.575999999988,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_64x32_sliced1x4_tn,770,1048576000.0,2104320000.0,0,0,0.0,2104320000.0,2104320000.0,4848000.0,1092000.0,0.8161616161616162,135858816.0,512000.0,150.944,4191.519999999989,3072000.0,4096000.0,1048576000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4245588.0,16000.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",771,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,4193.247999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",772,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,96.0,160.0,2.656,4195.903999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",773,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,4197.983999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",774,0.0,128000.0,0,0,0.0,128000.0,128000.0,0.0,2000.0,0.0,512000.0,512000.0,2.528,4200.511999999989,0.0,128000.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,16000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",775,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,4202.207999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",776,0.0,0.0,0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,38208.0,3.584,4205.791999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16128.0,1194.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",777,0.0,0.0,0,0,0.0,0.0,0.0,9472.0,34440.0,0.2157041355438149,2109440.0,0.0,4.32,4210.111999999988,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",778,0.0,0.0,0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,38272.0,3.68,4213.791999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16128.0,1196.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",779,0.0,0.0,0,0,0.0,0.0,0.0,9472.0,35208.0,0.21199641897940913,2109440.0,0.0,4.384,4218.175999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",780,0.0,0.0,0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,37440.0,3.84,4222.015999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16128.0,1170.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",781,0.0,0.0,0,0,0.0,0.0,0.0,9472.0,34696.0,0.2144539032783916,2109440.0,0.0,4.352,4226.367999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",782,0.0,0.0,0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,37888.0,3.584,4229.951999999988,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16128.0,1184.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",783,0.0,0.0,0,0,0.0,0.0,0.0,9472.0,34888.0,0.21352569882777278,2109440.0,128.0,4.384,4234.335999999988,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,65920.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",784,0.0,0.0,0,0,0.0,0.0,0.0,0.0,12.0,0.0,4128.0,512.0,2.464,4236.799999999988,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,129.0,16.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",785,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.664,4238.463999999988,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",786,0.0,0.0,0,0,0.0,0.0,0.0,497.0,16.0,0.9688109161793372,512.0,0.0,3.552,4242.015999999988,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",787,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.696,4243.711999999988,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",788,0.0,0.0,0,0,0.0,0.0,0.0,497.0,16.0,0.9688109161793372,512.0,0.0,3.552,4247.263999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",789,0.0,0.0,0,0,0.0,0.0,0.0,31968.0,8426.0,0.7914046640590187,527232.0,7136.0,5.952,4253.215999999988,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16476.0,223.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",790,0.0,0.0,0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,544.0,6.464,4259.679999999988,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,80.0,17.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",791,0.0,0.0,0,0,0.0,0.0,0.0,0.0,12000.0,0.0,520064.0,52640.0,3.712,4263.391999999988,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16252.0,1645.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",792,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3000.0,0.0,640000.0,0.0,2.848,4266.239999999988,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,20000.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",793,0.0,0.0,0,0,0.0,0.0,0.0,0.0,4000.0,0.0,0.0,1024000.0,2.272,4268.511999999988,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,32000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",794,0.0,0.0,0,0,0.0,0.0,0.0,98304.0,4000.0,0.960900844541758,512000.0,0.0,4.096,4272.607999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",795,0.0,0.0,0,0,0.0,0.0,0.0,156.0,64.0,0.7090909090909091,8192.0,0.0,2.176,4274.783999999988,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",796,0.0,0.0,0,0,0.0,0.0,0.0,50958.0,19428.0,0.7239792004091723,1916800.0,1282208.0,9.728,4284.511999999988,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,59900.0,40069.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",797,0.0,0.0,0,0,0.0,0.0,0.0,15954.0,19738.0,0.4469909223355374,1891072.0,1148256.0,8.16,4292.671999999988,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,59096.0,35883.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",798,0.0,0.0,0,0,0.0,0.0,0.0,15858.0,19625.0,0.4469182425386805,1888768.0,1579008.0,8.352,4301.023999999988,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,59024.0,49344.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",799,0.0,0.0,0,0,0.0,0.0,0.0,15858.0,19419.0,0.44952802109022877,1899648.0,1203488.0,8.48,4309.503999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,59364.0,37609.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",800,0.0,0.0,0,0,0.0,0.0,0.0,14336.0,4000.0,0.7818499127399651,1024000.0,0.0,3.968,4313.471999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",801,0.0,0.0,0,0,0.0,0.0,0.0,39.0,16.0,0.7090909090909091,2048.0,0.0,2.176,4315.647999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",802,0.0,0.0,0,0,0.0,0.0,0.0,13650.0,10471.0,0.5658969362795904,1279616.0,885056.0,6.688,4322.3359999999875,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,39988.0,27658.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",803,0.0,0.0,0,0,0.0,0.0,0.0,0.0,16000.0,0.0,1549216.0,1536000.0,4.096,4326.431999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48413.0,48000.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",804,1792000.0,4245120.0,0,0,0.0,4245120.0,4245120.0,528.0,5248.0,0.09141274238227147,1040384.0,512000.0,17.056,4343.487999999987,533120.0,128000.0,1792000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32512.0,16000.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",805,0.0,655488.0,0,0,0.0,655488.0,655488.0,71840.0,8000.0,0.8997995991983968,512000.0,512000.0,46.592,4390.079999999986,655488.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,16000.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",806,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2000.0,0.0,512000.0,128000.0,2.592,4392.671999999986,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,4000.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",807,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,1.92,4394.591999999986,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",808,0.0,0.0,0,0,0.0,0.0,0.0,0.0,12000.0,0.0,1152000.0,55136.0,7.456,4402.047999999986,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,36000.0,1723.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",809,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3000.0,0.0,640000.0,0.0,2.976,4405.023999999986,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,20000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",810,1792000.0,4245120.0,0,0,0.0,4245120.0,4245120.0,528.0,5248.0,0.09141274238227147,1029632.0,512000.0,16.992,4422.015999999986,533120.0,128000.0,1792000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32176.0,16000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",811,0.0,0.0,0,0,0.0,0.0,0.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,21.888,4443.903999999986,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",812,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,4446.047999999986,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",813,0.0,0.0,0,0,0.0,0.0,0.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,21.984,4468.0319999999865,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",814,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.112,4470.143999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",815,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.016,4472.159999999986,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",816,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.976,4475.135999999986,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",817,0.0,147456.0,0,0,0.0,147456.0,147456.0,320.0,1004.0,0.24169184290030213,512000.0,128.0,8.032,4483.167999999986,147456.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",818,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,4485.215999999986,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",819,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,4488.607999999986,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",820,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,4490.623999999985,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",821,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.944,4493.567999999986,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",822,1152000.0,2560000.0,0,0,0.0,2560000.0,2560000.0,0.0,4000.0,0.0,0.0,512000.0,3.232,4496.799999999986,0.0,256000.0,1152000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,16000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",823,640000.0,1280000.0,0,0,0.0,1280000.0,1280000.0,0.0,3000.0,0.0,1024000.0,0.0,4.192,4500.991999999986,0.0,0.0,640000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",824,0.0,0.0,0,0,0.0,0.0,0.0,640.0,1004.0,0.38929440389294406,512000.0,128.0,11.616,4512.607999999986,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",825,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.016,4514.623999999985,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",826,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,4516.703999999985,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",827,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.272,4518.975999999985,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",828,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.048,4521.023999999985,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",829,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,96.0,160.0,2.624,4523.647999999985,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",830,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,4525.343999999985,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",831,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.632,4526.975999999984,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",832,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.08,4529.055999999984,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",833,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,4530.783999999984,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",834,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,128.0,32.0,2.336,4533.119999999984,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",835,0.0,0.0,0,0,0.0,0.0,0.0,0.0,5.0,0.0,32.0,32.0,4.768,4537.8879999999845,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",836,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.112,4539.9999999999845,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",837,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,4542.015999999984,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",838,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.784,4544.799999999984,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",839,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,4548.031999999984,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",840,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.112,4550.143999999984,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
