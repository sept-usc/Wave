Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.856,1.856,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,3.552,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",3,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.496,6.048,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",4,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.616,9.664,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",5,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.168,12.832,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",6,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.176,15.008000000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",7,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.952,16.96,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",8,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,18.688000000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",9,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.728,20.416000000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",10,0.0,0.0,0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,2.528,22.944000000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",11,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,24.992000000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",12,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,27.136000000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",13,0.0,0.0,0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,32.0,32.0,2.56,29.696,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,31.712000000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",15,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,33.792,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",16,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,2.08,35.872,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",17,0.0,0.0,0,0,0.0,0.0,0.0,0.0,288.0,0.0,3264.0,12288.0,3.84,39.712,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,102.0,384.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",18,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,42.272000000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",19,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,45.632000000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",20,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.464,48.096000000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",21,0.0,512.0,0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,2.08,50.176,0.0,512.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",22,0.0,0.0,0,0,0.0,0.0,0.0,0.0,20.0,0.0,2048.0,2048.0,2.624,52.800000000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",23,4096.0,9216.0,0,0,0.0,9216.0,9216.0,0.0,32.0,0.0,2048.0,2048.0,2.912,55.712,0.0,1024.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",24,0.0,512.0,0,0,0.0,512.0,512.0,0.0,32.0,0.0,2048.0,2048.0,2.08,57.792,0.0,512.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",25,3584.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,32.0,0.0,2048.0,2048.0,2.88,60.672000000000004,0.0,1024.0,3584.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",26,0.0,512.0,0,0,0.0,512.0,512.0,0.0,32.0,0.0,2048.0,2048.0,2.048,62.720000000000006,0.0,512.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",27,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,1.984,64.70400000000001,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",28,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.904,68.608,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",29,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,70.592,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",30,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,72.672,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",31,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.688,75.36,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",32,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.688,78.048,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,33,18874368.0,39124992.0,0,0,0.0,39124992.0,39124992.0,141312.0,21504.0,0.8679245283018868,2654208.0,98304.0,7.488,85.536,589824.0,786432.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,82944.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",34,0.0,30720.0,0,0,0.0,30720.0,30720.0,0.0,1440.0,0.0,101376.0,12288.0,2.336,87.872,27648.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3168.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,35,18874368.0,39124992.0,0,0,0.0,39124992.0,39124992.0,141312.0,21504.0,0.8679245283018868,2654208.0,98304.0,7.104,94.976,589824.0,786432.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,82944.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",36,0.0,30720.0,0,0,0.0,30720.0,30720.0,0.0,1440.0,0.0,101376.0,12288.0,2.336,97.312,27648.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3168.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,37,18874368.0,39124992.0,0,0,0.0,39124992.0,39124992.0,141312.0,21504.0,0.8679245283018868,2654208.0,98304.0,7.072,104.384,589824.0,786432.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,82944.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",38,0.0,30720.0,0,0,0.0,30720.0,30720.0,0.0,1440.0,0.0,101376.0,12288.0,2.4,106.784,27648.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3168.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",39,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.72,109.504,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",40,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.624,112.128,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",41,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.064,116.19200000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",42,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.72,118.912,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",43,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.048,120.96000000000001,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",44,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.656,123.61600000000001,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",45,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.624,126.24000000000001,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",46,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.064,130.304,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",47,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.848,133.15200000000002,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",48,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.048,135.20000000000002,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",49,49152.0,4412928.0,0,0,0.0,4412928.0,4412928.0,24960.0,48.0,0.9980806142034548,36864.0,12288.0,20.16,155.36,3720192.0,594432.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,50,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2753696.0,61440.0,7.968,163.328,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86053.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",51,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.624,165.952,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",52,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.048,168.0,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",53,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.016,170.016,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",54,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.84,173.856,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",55,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.016,175.87199999999999,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",56,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,177.88799999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",57,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.688,180.57599999999996,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",58,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.656,183.23199999999997,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",59,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11088384.0,67328.0,14.08,197.31199999999998,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,346512.0,2104.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",60,141312.0,294912.0,0,0,0.0,294912.0,294912.0,0.0,192.0,0.0,49152.0,49152.0,2.272,199.58399999999997,12288.0,0.0,141312.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",61,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11033984.0,66400.0,14.784,214.36799999999997,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,344812.0,2075.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",62,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.176,216.54399999999995,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,63,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,79104.0,0.826890756302521,10027008.0,98304.0,15.488,232.03199999999995,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313344.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",64,0.0,27648.0,0,0,0.0,27648.0,27648.0,0.0,864.0,0.0,98304.0,12288.0,2.208,234.23999999999995,24576.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",65,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.08,236.31999999999996,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",66,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,1.984,238.30399999999997,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",67,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.808,242.11199999999997,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",68,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,244.09599999999998,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",69,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,246.14399999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",70,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.72,248.86399999999998,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",71,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.688,251.55199999999996,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,72,18874368.0,39124992.0,0,0,0.0,39124992.0,39124992.0,141312.0,21504.0,0.8679245283018868,2654208.0,98304.0,7.552,259.104,589824.0,786432.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,82944.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",73,0.0,30720.0,0,0,0.0,30720.0,30720.0,0.0,1440.0,0.0,101376.0,12288.0,2.4,261.50399999999996,27648.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3168.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,74,18874368.0,39124992.0,0,0,0.0,39124992.0,39124992.0,141312.0,21504.0,0.8679245283018868,2654208.0,98304.0,7.232,268.736,589824.0,786432.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,82944.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",75,0.0,30720.0,0,0,0.0,30720.0,30720.0,0.0,1440.0,0.0,101376.0,12288.0,2.528,271.264,27648.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3168.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,76,18874368.0,39124992.0,0,0,0.0,39124992.0,39124992.0,141312.0,21504.0,0.8679245283018868,2654208.0,98304.0,7.232,278.49600000000004,589824.0,786432.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,82944.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",77,0.0,30720.0,0,0,0.0,30720.0,30720.0,0.0,1440.0,0.0,101376.0,12288.0,2.368,280.86400000000003,27648.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3168.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",78,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.784,283.648,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",79,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.656,286.30400000000003,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",80,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.064,290.36800000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",81,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.72,293.0880000000001,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",82,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.08,295.16800000000006,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",83,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.656,297.82400000000007,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",84,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.784,300.60800000000006,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",85,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.128,304.73600000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",86,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.72,307.4560000000001,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",87,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.08,309.53600000000006,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",88,49152.0,4412928.0,0,0,0.0,4412928.0,4412928.0,24960.0,48.0,0.9980806142034548,36864.0,12288.0,20.096,329.63200000000006,3720192.0,594432.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,89,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2753856.0,61440.0,7.936,337.56800000000004,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86058.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",90,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.528,340.09600000000006,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",91,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.048,342.14400000000006,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",92,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,1.984,344.12800000000004,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",93,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.84,347.968,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",94,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.016,349.98400000000004,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",95,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,352.03200000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",96,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.624,354.65600000000006,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",97,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.688,357.34400000000005,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",98,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11130752.0,69728.0,13.6,370.9440000000001,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,347836.0,2179.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",99,141312.0,294912.0,0,0,0.0,294912.0,294912.0,0.0,192.0,0.0,49152.0,49152.0,2.24,373.1840000000001,12288.0,0.0,141312.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",100,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11046144.0,65216.0,14.784,387.9680000000001,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,345192.0,2038.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",101,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.112,390.0800000000001,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,102,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,79104.0,0.826890756302521,10027008.0,98304.0,16.128,406.2080000000001,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313344.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",103,0.0,27648.0,0,0,0.0,27648.0,27648.0,0.0,864.0,0.0,98304.0,12288.0,2.24,408.4480000000001,24576.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",104,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.08,410.5280000000001,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",105,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.016,412.5440000000001,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",106,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.808,416.3520000000001,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",107,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,418.3040000000001,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",108,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,420.38400000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",109,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.656,423.0400000000001,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",110,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.688,425.72800000000007,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,111,18874368.0,39124992.0,0,0,0.0,39124992.0,39124992.0,141312.0,21504.0,0.8679245283018868,2654208.0,98304.0,7.616,433.34400000000005,589824.0,786432.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,82944.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",112,0.0,30720.0,0,0,0.0,30720.0,30720.0,0.0,1440.0,0.0,101376.0,12288.0,2.336,435.68000000000006,27648.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3168.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,113,18874368.0,39124992.0,0,0,0.0,39124992.0,39124992.0,141312.0,21504.0,0.8679245283018868,2654208.0,98304.0,7.328,443.00800000000004,589824.0,786432.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,82944.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",114,0.0,30720.0,0,0,0.0,30720.0,30720.0,0.0,1440.0,0.0,101376.0,12288.0,2.304,445.312,27648.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3168.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,115,18874368.0,39124992.0,0,0,0.0,39124992.0,39124992.0,141312.0,21504.0,0.8679245283018868,2654208.0,98304.0,7.2,452.512,589824.0,786432.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,82944.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",116,0.0,30720.0,0,0,0.0,30720.0,30720.0,0.0,1440.0,0.0,101376.0,12288.0,2.304,454.816,27648.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3168.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",117,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.72,457.536,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",118,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.656,460.192,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",119,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.064,464.25600000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",120,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.688,466.944,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",121,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.144,469.088,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",122,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.656,471.744,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",123,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.592,474.336,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",124,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.032,478.368,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",125,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.752,481.12,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",126,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.112,483.232,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",127,49152.0,4412928.0,0,0,0.0,4412928.0,4412928.0,24960.0,48.0,0.9980806142034548,36864.0,12288.0,20.192,503.42400000000004,3720192.0,594432.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,128,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2753024.0,61440.0,7.712,511.136,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86032.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",129,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.528,513.664,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",130,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.048,515.712,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",131,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,1.984,517.696,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",132,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.84,521.5360000000001,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",133,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.016,523.552,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",134,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,525.6320000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",135,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.688,528.32,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",136,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.656,530.976,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",137,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11055104.0,67008.0,13.856,544.832,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,345472.0,2094.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",138,141312.0,294912.0,0,0,0.0,294912.0,294912.0,0.0,192.0,0.0,49152.0,49152.0,2.464,547.296,12288.0,0.0,141312.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",139,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11063040.0,65920.0,14.56,561.856,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,345720.0,2060.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",140,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.144,564.0,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,141,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,79104.0,0.826890756302521,10027008.0,98304.0,15.456,579.456,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313344.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",142,0.0,27648.0,0,0,0.0,27648.0,27648.0,0.0,864.0,0.0,98304.0,12288.0,2.24,581.696,24576.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",143,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.08,583.7760000000001,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",144,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.08,585.8560000000001,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",145,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.808,589.6640000000001,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",146,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,591.6480000000001,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",147,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.176,593.8240000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",148,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.624,596.4480000000002,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",149,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.752,599.2000000000002,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,150,18874368.0,39124992.0,0,0,0.0,39124992.0,39124992.0,141312.0,21504.0,0.8679245283018868,2654208.0,98304.0,7.104,606.3040000000002,589824.0,786432.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,82944.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",151,0.0,30720.0,0,0,0.0,30720.0,30720.0,0.0,1440.0,0.0,101376.0,12288.0,2.368,608.6720000000003,27648.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3168.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,152,18874368.0,39124992.0,0,0,0.0,39124992.0,39124992.0,141312.0,21504.0,0.8679245283018868,2654208.0,98304.0,7.296,615.9680000000003,589824.0,786432.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,82944.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",153,0.0,30720.0,0,0,0.0,30720.0,30720.0,0.0,1440.0,0.0,101376.0,12288.0,2.368,618.3360000000004,27648.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3168.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,154,18874368.0,39124992.0,0,0,0.0,39124992.0,39124992.0,141312.0,21504.0,0.8679245283018868,2654208.0,98304.0,7.296,625.6320000000004,589824.0,786432.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,82944.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",155,0.0,30720.0,0,0,0.0,30720.0,30720.0,0.0,1440.0,0.0,101376.0,12288.0,2.336,627.9680000000004,27648.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3168.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",156,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.848,630.8160000000004,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",157,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.752,633.5680000000003,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",158,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.032,637.6000000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",159,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.88,640.4800000000004,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",160,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.048,642.5280000000004,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",161,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.72,645.2480000000004,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",162,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.752,648.0000000000003,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",163,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,3.968,651.9680000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",164,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.72,654.6880000000003,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",165,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.112,656.8000000000003,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",166,49152.0,4412928.0,0,0,0.0,4412928.0,4412928.0,24960.0,48.0,0.9980806142034548,36864.0,12288.0,20.224,677.0240000000003,3720192.0,594432.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,167,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2754240.0,61440.0,7.808,684.8320000000003,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86070.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",168,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.464,687.2960000000004,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",169,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.08,689.3760000000004,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",170,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.016,691.3920000000004,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",171,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.84,695.2320000000004,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",172,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,697.1840000000004,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",173,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,699.2320000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",174,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.72,701.9520000000005,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",175,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.752,704.7040000000004,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",176,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11127168.0,67232.0,13.504,718.2080000000004,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,347724.0,2101.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",177,141312.0,294912.0,0,0,0.0,294912.0,294912.0,0.0,192.0,0.0,49152.0,49152.0,2.304,720.5120000000004,12288.0,0.0,141312.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",178,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11114240.0,67584.0,13.984,734.4960000000004,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,347320.0,2112.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",179,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.112,736.6080000000004,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,180,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,79104.0,0.826890756302521,10027008.0,98304.0,15.392,752.0000000000005,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313344.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",181,0.0,27648.0,0,0,0.0,27648.0,27648.0,0.0,864.0,0.0,98304.0,12288.0,2.24,754.2400000000005,24576.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",182,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.112,756.3520000000004,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",183,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.048,758.4000000000004,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",184,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.84,762.2400000000005,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",185,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.144,764.3840000000005,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",186,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,766.4000000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",187,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.72,769.1200000000005,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",188,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.688,771.8080000000004,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,189,18874368.0,39124992.0,0,0,0.0,39124992.0,39124992.0,141312.0,21504.0,0.8679245283018868,2654208.0,98304.0,7.104,778.9120000000005,589824.0,786432.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,82944.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",190,0.0,30720.0,0,0,0.0,30720.0,30720.0,0.0,1440.0,0.0,101376.0,12288.0,2.368,781.2800000000005,27648.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3168.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,191,18874368.0,39124992.0,0,0,0.0,39124992.0,39124992.0,141312.0,21504.0,0.8679245283018868,2654208.0,98304.0,7.104,788.3840000000006,589824.0,786432.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,82944.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",192,0.0,30720.0,0,0,0.0,30720.0,30720.0,0.0,1440.0,0.0,101376.0,12288.0,2.4,790.7840000000006,27648.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3168.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,193,18874368.0,39124992.0,0,0,0.0,39124992.0,39124992.0,141312.0,21504.0,0.8679245283018868,2654208.0,98304.0,7.2,797.9840000000006,589824.0,786432.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,82944.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",194,0.0,30720.0,0,0,0.0,30720.0,30720.0,0.0,1440.0,0.0,101376.0,12288.0,2.336,800.3200000000006,27648.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3168.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",195,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.688,803.0080000000006,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",196,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.592,805.6000000000006,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",197,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.064,809.6640000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",198,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.752,812.4160000000005,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",199,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.08,814.4960000000005,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",200,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.656,817.1520000000005,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",201,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.624,819.7760000000005,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",202,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.096,823.8720000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",203,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.656,826.5280000000005,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",204,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.144,828.6720000000005,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",205,49152.0,4412928.0,0,0,0.0,4412928.0,4412928.0,24960.0,48.0,0.9980806142034548,36864.0,12288.0,20.064,848.7360000000004,3720192.0,594432.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,206,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2754752.0,61440.0,7.872,856.6080000000004,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86086.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",207,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.528,859.1360000000004,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",208,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.08,861.2160000000005,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",209,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.016,863.2320000000004,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",210,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.904,867.1360000000004,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",211,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,869.0880000000004,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",212,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,871.1040000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",213,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.688,873.7920000000004,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",214,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.72,876.5120000000004,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",215,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11082368.0,66176.0,13.984,890.4960000000004,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,346324.0,2068.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",216,141312.0,294912.0,0,0,0.0,294912.0,294912.0,0.0,192.0,0.0,49152.0,49152.0,2.304,892.8000000000004,12288.0,0.0,141312.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",217,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11111808.0,65824.0,14.368,907.1680000000005,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,347244.0,2057.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",218,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.08,909.2480000000005,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,219,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,79104.0,0.826890756302521,10027008.0,98304.0,15.296,924.5440000000006,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313344.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",220,0.0,27648.0,0,0,0.0,27648.0,27648.0,0.0,864.0,0.0,98304.0,12288.0,2.208,926.7520000000005,24576.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",221,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.08,928.8320000000006,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",222,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.048,930.8800000000006,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",223,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.776,934.6560000000005,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",224,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,936.6400000000006,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",225,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,938.6880000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",226,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.624,941.3120000000006,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",227,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.624,943.9360000000006,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,228,18874368.0,39124992.0,0,0,0.0,39124992.0,39124992.0,141312.0,21504.0,0.8679245283018868,2654208.0,98304.0,7.2,951.1360000000006,589824.0,786432.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,82944.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",229,0.0,30720.0,0,0,0.0,30720.0,30720.0,0.0,1440.0,0.0,101376.0,12288.0,2.368,953.5040000000007,27648.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3168.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,230,18874368.0,39124992.0,0,0,0.0,39124992.0,39124992.0,141312.0,21504.0,0.8679245283018868,2654208.0,98304.0,7.136,960.6400000000007,589824.0,786432.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,82944.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",231,0.0,30720.0,0,0,0.0,30720.0,30720.0,0.0,1440.0,0.0,101376.0,12288.0,2.4,963.0400000000006,27648.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3168.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,232,18874368.0,39124992.0,0,0,0.0,39124992.0,39124992.0,141312.0,21504.0,0.8679245283018868,2654208.0,98304.0,7.04,970.0800000000006,589824.0,786432.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,82944.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",233,0.0,30720.0,0,0,0.0,30720.0,30720.0,0.0,1440.0,0.0,101376.0,12288.0,2.4,972.4800000000006,27648.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3168.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",234,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.656,975.1360000000005,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",235,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.56,977.6960000000005,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",236,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.0,981.6960000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",237,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.72,984.4160000000005,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",238,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.08,986.4960000000005,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",239,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.752,989.2480000000005,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",240,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.624,991.8720000000005,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",241,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.096,995.9680000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",242,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.688,998.6560000000005,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",243,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.048,1000.7040000000005,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",244,49152.0,4412928.0,0,0,0.0,4412928.0,4412928.0,24960.0,48.0,0.9980806142034548,36864.0,12288.0,20.064,1020.7680000000005,3720192.0,594432.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,245,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2753888.0,61440.0,7.872,1028.6400000000006,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86059.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",246,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.496,1031.1360000000006,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",247,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.112,1033.2480000000007,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",248,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,1.984,1035.2320000000007,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",249,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.808,1039.0400000000006,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",250,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.112,1041.1520000000007,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",251,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,1043.1680000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",252,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.72,1045.8880000000008,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",253,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.688,1048.576000000001,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",254,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11126528.0,64960.0,13.792,1062.3680000000008,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,347704.0,2030.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",255,141312.0,294912.0,0,0,0.0,294912.0,294912.0,0.0,192.0,0.0,49152.0,49152.0,2.336,1064.7040000000009,12288.0,0.0,141312.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",256,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11045248.0,66912.0,14.624,1079.3280000000009,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,345164.0,2091.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",257,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.144,1081.472000000001,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,258,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,79104.0,0.826890756302521,10027008.0,98304.0,15.552,1097.0240000000008,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313344.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",259,0.0,27648.0,0,0,0.0,27648.0,27648.0,0.0,864.0,0.0,98304.0,12288.0,2.208,1099.2320000000009,24576.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",260,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.048,1101.2800000000009,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",261,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.08,1103.3600000000008,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",262,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.904,1107.2640000000008,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",263,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,1109.2480000000007,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",264,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,1111.2960000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",265,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.656,1113.9520000000007,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",266,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.624,1116.5760000000007,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,267,18874368.0,39124992.0,0,0,0.0,39124992.0,39124992.0,141312.0,21504.0,0.8679245283018868,2654208.0,98304.0,7.104,1123.6800000000007,589824.0,786432.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,82944.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",268,0.0,30720.0,0,0,0.0,30720.0,30720.0,0.0,1440.0,0.0,101376.0,12288.0,2.336,1126.0160000000008,27648.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3168.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,269,18874368.0,39124992.0,0,0,0.0,39124992.0,39124992.0,141312.0,21504.0,0.8679245283018868,2654208.0,98304.0,7.168,1133.1840000000007,589824.0,786432.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,82944.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",270,0.0,30720.0,0,0,0.0,30720.0,30720.0,0.0,1440.0,0.0,101376.0,12288.0,2.368,1135.5520000000006,27648.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3168.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,271,18874368.0,39124992.0,0,0,0.0,39124992.0,39124992.0,141312.0,21504.0,0.8679245283018868,2654208.0,98304.0,7.232,1142.7840000000006,589824.0,786432.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,82944.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",272,0.0,30720.0,0,0,0.0,30720.0,30720.0,0.0,1440.0,0.0,101376.0,12288.0,2.336,1145.1200000000006,27648.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3168.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",273,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.752,1147.8720000000005,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",274,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.592,1150.4640000000006,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",275,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.16,1154.6240000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",276,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.752,1157.3760000000007,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",277,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.08,1159.4560000000006,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",278,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.72,1162.1760000000006,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",279,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.688,1164.8640000000007,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",280,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.032,1168.8960000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",281,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.72,1171.6160000000007,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",282,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.048,1173.6640000000007,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",283,49152.0,4412928.0,0,0,0.0,4412928.0,4412928.0,24960.0,48.0,0.9980806142034548,36864.0,12288.0,20.096,1193.7600000000007,3720192.0,594432.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,284,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2753728.0,61440.0,7.872,1201.6320000000007,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86054.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",285,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.528,1204.1600000000008,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",286,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.112,1206.2720000000008,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",287,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.048,1208.3200000000008,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",288,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.936,1212.2560000000008,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",289,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.016,1214.2720000000008,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",290,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,1216.3200000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",291,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.624,1218.9440000000009,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",292,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.624,1221.568000000001,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",293,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11092608.0,65088.0,14.336,1235.904000000001,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,346644.0,2034.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",294,141312.0,294912.0,0,0,0.0,294912.0,294912.0,0.0,192.0,0.0,49152.0,49152.0,2.368,1238.2720000000008,12288.0,0.0,141312.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",295,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11075584.0,68064.0,14.304,1252.576000000001,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,346112.0,2127.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",296,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.112,1254.688000000001,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,297,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,79104.0,0.826890756302521,10027008.0,98304.0,15.488,1270.176000000001,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313344.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",298,0.0,27648.0,0,0,0.0,27648.0,27648.0,0.0,864.0,0.0,98304.0,12288.0,2.176,1272.352000000001,24576.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",299,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.016,1274.368000000001,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",300,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,1.984,1276.352000000001,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",301,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.808,1280.160000000001,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",302,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.016,1282.176000000001,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",303,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,1284.224000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",304,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.624,1286.848000000001,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",305,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.72,1289.5680000000011,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,306,18874368.0,39124992.0,0,0,0.0,39124992.0,39124992.0,141312.0,21504.0,0.8679245283018868,2654208.0,98304.0,7.264,1296.832000000001,589824.0,786432.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,82944.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",307,0.0,30720.0,0,0,0.0,30720.0,30720.0,0.0,1440.0,0.0,101376.0,12288.0,2.336,1299.168000000001,27648.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3168.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,308,18874368.0,39124992.0,0,0,0.0,39124992.0,39124992.0,141312.0,21504.0,0.8679245283018868,2654208.0,98304.0,7.36,1306.528000000001,589824.0,786432.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,82944.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",309,0.0,30720.0,0,0,0.0,30720.0,30720.0,0.0,1440.0,0.0,101376.0,12288.0,2.368,1308.8960000000009,27648.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3168.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,310,18874368.0,39124992.0,0,0,0.0,39124992.0,39124992.0,141312.0,21504.0,0.8679245283018868,2654208.0,98304.0,7.392,1316.288000000001,589824.0,786432.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,82944.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",311,0.0,30720.0,0,0,0.0,30720.0,30720.0,0.0,1440.0,0.0,101376.0,12288.0,2.368,1318.6560000000009,27648.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3168.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",312,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.816,1321.472000000001,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",313,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.624,1324.096000000001,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",314,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.032,1328.1280000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",315,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.688,1330.816000000001,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",316,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.048,1332.864000000001,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",317,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.72,1335.584000000001,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",318,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.688,1338.272000000001,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",319,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.064,1342.3360000000011,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",320,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.688,1345.0240000000013,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",321,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.08,1347.1040000000012,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",322,49152.0,4412928.0,0,0,0.0,4412928.0,4412928.0,24960.0,48.0,0.9980806142034548,36864.0,12288.0,20.0,1367.1040000000012,3720192.0,594432.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,323,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2754912.0,61440.0,7.648,1374.752000000001,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86091.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",324,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.464,1377.216000000001,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",325,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.112,1379.328000000001,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",326,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.08,1381.408000000001,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",327,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.808,1385.216000000001,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",328,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,1387.200000000001,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",329,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,1389.248000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",330,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.656,1391.904000000001,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",331,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.656,1394.5600000000009,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",332,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11112960.0,67776.0,13.76,1408.3200000000008,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,347280.0,2118.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",333,141312.0,294912.0,0,0,0.0,294912.0,294912.0,0.0,192.0,0.0,49152.0,49152.0,2.304,1410.624000000001,12288.0,0.0,141312.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",334,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11133568.0,65696.0,13.568,1424.192000000001,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,347924.0,2053.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",335,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.144,1426.336000000001,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,336,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,79104.0,0.826890756302521,10027008.0,98304.0,15.584,1441.920000000001,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313344.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",337,0.0,27648.0,0,0,0.0,27648.0,27648.0,0.0,864.0,0.0,98304.0,12288.0,2.272,1444.192000000001,24576.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",338,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.112,1446.304000000001,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",339,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,1.984,1448.288000000001,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",340,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.84,1452.1280000000008,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",341,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,1454.1120000000008,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",342,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.112,1456.2240000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",343,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.656,1458.8800000000008,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",344,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.656,1461.5360000000007,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
ampere_sgemm_64x32_sliced1x4_tn,345,3733979136.0,7501991936.0,0,0,0.0,7501991936.0,7501991936.0,17548608.0,3893360.0,0.8184233835252436,484585728.0,2430976.0,517.312,1978.8480000000009,14585856.0,19447808.0,3733979136.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,15143304.0,75968.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",346,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,1980.576000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",347,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,64.0,128.0,2.56,1983.1360000000009,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",348,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,1985.1840000000009,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",349,0.0,607744.0,0,0,0.0,607744.0,607744.0,0.0,9520.0,0.0,2430976.0,2430976.0,4.768,1989.952000000001,0.0,607744.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75968.0,75968.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",350,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.664,1991.616000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",351,0.0,0.0,0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435072.0,168896.0,5.056,1996.672000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76096.0,5278.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",352,0.0,0.0,0,0,0.0,0.0,0.0,44104.0,718188.0,0.057857094131907455,27388928.0,864.0,13.024,2009.6960000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,855904.0,27.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",353,0.0,0.0,0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435072.0,167296.0,5.152,2014.8480000000009,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76096.0,5228.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",354,0.0,0.0,0,0,0.0,0.0,0.0,44104.0,721764.0,0.05758694709793333,27544032.0,832.0,13.024,2027.8720000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,860751.0,26.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",355,0.0,0.0,0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435072.0,165184.0,5.248,2033.1200000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76096.0,5162.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",356,0.0,0.0,0,0,0.0,0.0,0.0,44104.0,719380.0,0.05776676394004328,27430176.0,992.0,13.696,2046.8160000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,857193.0,31.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",357,0.0,0.0,0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435072.0,168832.0,5.248,2052.0640000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76096.0,5276.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",358,0.0,0.0,0,0,0.0,0.0,0.0,44104.0,717592.0,0.05790236524807797,27373568.0,1056.0,13.312,2065.3760000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,855424.0,33.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",359,0.0,0.0,0,0,0.0,0.0,0.0,0.0,57.0,0.0,19104.0,2400.0,3.264,2068.640000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,597.0,75.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",360,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.856,2070.496000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",361,0.0,0.0,0,0,0.0,0.0,0.0,497.0,46.0,0.9152854511970534,2400.0,0.0,3.648,2074.144000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",362,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.696,2075.840000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",363,0.0,0.0,0,0,0.0,0.0,0.0,497.0,46.0,0.9152854511970534,2400.0,0.0,3.616,2079.456000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",364,0.0,0.0,0,0,0.0,0.0,0.0,225792.0,38392.0,0.8546770432728704,2472160.0,8960.0,7.04,2086.496000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,77255.0,280.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",365,0.0,0.0,0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,544.0,6.432,2092.928000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,80.0,17.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",366,0.0,0.0,0,0,0.0,0.0,0.0,0.0,56976.0,0.0,2445120.0,245024.0,5.024,2097.9520000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76410.0,7657.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",367,0.0,0.0,0,0,0.0,0.0,0.0,0.0,14280.0,0.0,3038720.0,0.0,5.824,2103.7760000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,94960.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",368,0.0,0.0,0,0,0.0,0.0,0.0,0.0,18992.0,0.0,0.0,4861952.0,4.384,2108.1600000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,151936.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",369,0.0,0.0,0,0,0.0,0.0,0.0,98304.0,18992.0,0.8380848451780112,2430976.0,0.0,5.824,2113.984000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75968.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",370,0.0,0.0,0,0,0.0,0.0,0.0,156.0,64.0,0.7090909090909091,8192.0,0.0,2.176,2116.1600000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",371,0.0,0.0,0,0,0.0,0.0,0.0,173778.0,98892.0,0.6373198371658049,9347456.0,6142016.0,17.088,2133.248000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,292108.0,191938.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",372,0.0,0.0,0,0,0.0,0.0,0.0,67626.0,112441.0,0.3755602081447461,9505536.0,7495680.0,15.008,2148.2560000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,297048.0,234240.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",373,0.0,0.0,0,0,0.0,0.0,0.0,68478.0,113020.0,0.3772934137015284,9495168.0,7495680.0,15.904,2164.1600000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,296724.0,234240.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",374,0.0,0.0,0,0,0.0,0.0,0.0,68478.0,111295.0,0.38091370784266826,9516416.0,5691808.0,15.904,2180.0640000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,297388.0,177869.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",375,0.0,0.0,0,0,0.0,0.0,0.0,14336.0,18992.0,0.4301488238118099,4861952.0,0.0,7.84,2187.904000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,151936.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",376,0.0,0.0,0,0,0.0,0.0,0.0,39.0,16.0,0.7090909090909091,2048.0,0.0,2.144,2190.0480000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",377,0.0,0.0,0,0,0.0,0.0,0.0,55759.0,139959.0,0.2848945932412961,7516800.0,4249952.0,13.952,2204.000000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,234900.0,132811.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",378,0.0,0.0,0,0,0.0,0.0,0.0,0.0,75968.0,0.0,7323904.0,7292928.0,10.4,2214.400000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,228872.0,227904.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",379,8508416.0,20076672.0,0,0,0.0,20076672.0,20076672.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,62.24,2276.640000000001,2452096.0,607744.0,8508416.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,227904.0,75968.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",380,0.0,3052116.0,0,0,0.0,3052116.0,3052116.0,334872.0,37984.0,0.8981268908103933,2430976.0,2430976.0,210.72,2487.3600000000006,3052116.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75968.0,75968.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",381,0.0,0.0,0,0,0.0,0.0,0.0,0.0,9520.0,0.0,2430976.0,607488.0,4.768,2492.1280000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75968.0,18984.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",382,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,1.92,2494.0480000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",383,0.0,0.0,0,0,0.0,0.0,0.0,0.0,56976.0,0.0,5469696.0,262688.0,10.08,2504.1280000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,170928.0,8209.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",384,0.0,0.0,0,0,0.0,0.0,0.0,0.0,14280.0,0.0,3038720.0,0.0,5.856,2509.984000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,94960.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",385,8508416.0,20076672.0,0,0,0.0,20076672.0,20076672.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,61.856,2571.840000000001,2452096.0,607744.0,8508416.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,227904.0,75968.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",386,0.0,0.0,0,0,0.0,0.0,0.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,7.68,2579.520000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",387,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,2581.6640000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",388,0.0,0.0,0,0,0.0,0.0,0.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,7.936,2589.600000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",389,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,2591.7440000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",390,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.08,2593.8240000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",391,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.008,2596.8320000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",392,0.0,990796.0,0,0,0.0,990796.0,990796.0,7692.0,4832.0,0.6141807729160013,2431392.0,2560.0,7.712,2604.5440000000003,990796.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75981.0,80.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",393,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,2606.5280000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",394,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.2,2609.728,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",395,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,2611.776,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",396,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.944,2614.72,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",397,1769472.0,4754432.0,0,0,0.0,4754432.0,4754432.0,0.0,18992.0,0.0,0.0,2430976.0,4.128,2618.848,0.0,1215488.0,1769472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,75968.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",398,3038720.0,6077440.0,0,0,0.0,6077440.0,6077440.0,0.0,14280.0,0.0,4861952.0,0.0,8.288,2627.136,0.0,0.0,3038720.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,151936.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",399,0.0,0.0,0,0,0.0,0.0,0.0,14092.0,4912.0,0.7415280993475057,2432256.0,2784.0,9.344,2636.48,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76008.0,87.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",400,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,64.0,128.0,2.592,2639.072,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",401,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,2640.768,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",402,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,2642.496,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",403,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.08,2644.576,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",404,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2646.592,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",405,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.848,2649.44,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",406,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,2652.672,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",407,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,2654.752,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",408,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.112,2656.864,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",409,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,32.0,3.264,2660.128,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",410,0.0,0.0,0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,64.0,32.0,2.528,2662.656,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",411,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,1.984,2664.64,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",412,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,2.048,2666.6879999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",413,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,0.0,2.08,2668.7679999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",414,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,2.272,2671.0399999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",415,0.0,0.0,0,0,0.0,0.0,0.0,0.0,288.0,0.0,12480.0,12288.0,4.896,2675.9359999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,390.0,384.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",416,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,2.56,2678.4959999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",417,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,2681.8239999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",418,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.432,2684.2559999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",419,0.0,512.0,0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,1.984,2686.2399999999993,0.0,512.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",420,0.0,0.0,0,0,0.0,0.0,0.0,0.0,20.0,0.0,2048.0,2048.0,2.592,2688.8319999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",421,4096.0,9216.0,0,0,0.0,9216.0,9216.0,0.0,32.0,0.0,2048.0,2048.0,2.88,2691.7119999999995,0.0,1024.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",422,0.0,512.0,0,0,0.0,512.0,512.0,0.0,32.0,0.0,2048.0,2048.0,2.08,2693.7919999999995,0.0,512.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",423,3600.0,8224.0,0,0,0.0,8224.0,8224.0,0.0,32.0,0.0,2048.0,2048.0,2.848,2696.6399999999994,0.0,1024.0,3600.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",424,0.0,512.0,0,0,0.0,512.0,512.0,0.0,32.0,0.0,2048.0,2048.0,2.272,2698.9119999999994,0.0,512.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",425,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.048,2700.959999999999,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",426,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.872,2704.831999999999,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",427,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,2706.783999999999,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",428,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2708.7999999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",429,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.816,2711.615999999999,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",430,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.72,2714.335999999999,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,431,18874368.0,39124992.0,0,0,0.0,39124992.0,39124992.0,141312.0,21504.0,0.8679245283018868,2654208.0,98304.0,7.296,2721.6319999999987,589824.0,786432.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,82944.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",432,0.0,30720.0,0,0,0.0,30720.0,30720.0,0.0,1440.0,0.0,101376.0,12288.0,2.368,2723.9999999999986,27648.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3168.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,433,18874368.0,39124992.0,0,0,0.0,39124992.0,39124992.0,141312.0,21504.0,0.8679245283018868,2654208.0,98304.0,7.136,2731.1359999999986,589824.0,786432.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,82944.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",434,0.0,30720.0,0,0,0.0,30720.0,30720.0,0.0,1440.0,0.0,101376.0,12288.0,2.336,2733.4719999999984,27648.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3168.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,435,18874368.0,39124992.0,0,0,0.0,39124992.0,39124992.0,141312.0,21504.0,0.8679245283018868,2654208.0,98304.0,7.168,2740.6399999999985,589824.0,786432.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,82944.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",436,0.0,30720.0,0,0,0.0,30720.0,30720.0,0.0,1440.0,0.0,101376.0,12288.0,2.368,2743.0079999999984,27648.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3168.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",437,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.72,2745.7279999999982,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",438,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.688,2748.4159999999983,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",439,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.032,2752.4479999999985,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",440,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.688,2755.1359999999986,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",441,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.112,2757.2479999999987,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",442,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.688,2759.935999999999,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",443,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.592,2762.527999999999,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",444,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.064,2766.5919999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",445,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.72,2769.3119999999985,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",446,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.112,2771.4239999999986,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",447,0.0,0.0,0,0,0.0,0.0,0.0,0.0,240.0,0.0,24576.0,24576.0,2.656,2774.0799999999986,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",448,0.0,0.0,0,0,0.0,0.0,0.0,0.0,240.0,0.0,24576.0,24576.0,2.656,2776.7359999999985,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",449,48512.0,4412784.0,0,0,0.0,4412784.0,4412784.0,24972.0,48.0,0.9980815347721822,61440.0,12288.0,20.16,2796.8959999999984,3721388.0,594372.0,48512.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,450,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2754112.0,61440.0,7.552,2804.4479999999985,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86066.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",451,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.464,2806.9119999999984,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",452,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.048,2808.959999999998,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",453,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.048,2811.007999999998,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",454,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.872,2814.879999999998,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",455,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,2816.8639999999978,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",456,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,2818.8479999999977,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",457,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.72,2821.5679999999975,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",458,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.816,2824.3839999999973,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",459,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11098496.0,66368.0,14.176,2838.559999999997,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,346828.0,2074.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",460,141312.0,294912.0,0,0,0.0,294912.0,294912.0,0.0,192.0,0.0,49152.0,49152.0,2.304,2840.8639999999973,12288.0,0.0,141312.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",461,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11060992.0,65952.0,14.304,2855.1679999999974,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,345656.0,2061.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",462,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.176,2857.3439999999973,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,463,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,79104.0,0.826890756302521,10027008.0,98304.0,15.52,2872.8639999999973,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313344.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",464,0.0,27648.0,0,0,0.0,27648.0,27648.0,0.0,864.0,0.0,98304.0,12288.0,2.176,2875.0399999999972,24576.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",465,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.08,2877.119999999997,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",466,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,1.984,2879.103999999997,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",467,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.904,2883.007999999997,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",468,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,2884.9599999999973,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",469,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,2887.007999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",470,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.848,2889.855999999997,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",471,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.656,2892.511999999997,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,472,18874368.0,39124992.0,0,0,0.0,39124992.0,39124992.0,141312.0,21504.0,0.8679245283018868,2654208.0,98304.0,7.328,2899.839999999997,589824.0,786432.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,82944.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",473,0.0,30720.0,0,0,0.0,30720.0,30720.0,0.0,1440.0,0.0,101376.0,12288.0,2.4,2902.239999999997,27648.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3168.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,474,18874368.0,39124992.0,0,0,0.0,39124992.0,39124992.0,141312.0,21504.0,0.8679245283018868,2654208.0,98304.0,7.296,2909.535999999997,589824.0,786432.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,82944.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",475,0.0,30720.0,0,0,0.0,30720.0,30720.0,0.0,1440.0,0.0,101376.0,12288.0,2.336,2911.8719999999967,27648.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3168.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,476,18874368.0,39124992.0,0,0,0.0,39124992.0,39124992.0,141312.0,21504.0,0.8679245283018868,2654208.0,98304.0,7.04,2918.9119999999966,589824.0,786432.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,82944.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",477,0.0,30720.0,0,0,0.0,30720.0,30720.0,0.0,1440.0,0.0,101376.0,12288.0,2.368,2921.2799999999966,27648.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3168.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",478,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.72,2923.9999999999964,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",479,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.656,2926.6559999999963,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",480,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.16,2930.815999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",481,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.72,2933.535999999996,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",482,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.048,2935.5839999999957,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",483,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.688,2938.271999999996,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",484,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.688,2940.959999999996,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",485,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.0,2944.959999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",486,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.752,2947.711999999996,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",487,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.112,2949.823999999996,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",488,0.0,0.0,0,0,0.0,0.0,0.0,0.0,240.0,0.0,24576.0,24576.0,2.624,2952.447999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",489,0.0,0.0,0,0,0.0,0.0,0.0,0.0,240.0,0.0,24576.0,24576.0,2.656,2955.1039999999957,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",490,49152.0,4414464.0,0,0,0.0,4414464.0,4414464.0,24960.0,48.0,0.9980806142034548,61440.0,12288.0,20.128,2975.231999999996,3721728.0,594432.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,491,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2752096.0,61440.0,7.808,2983.039999999996,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86003.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",492,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.496,2985.535999999996,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",493,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.144,2987.6799999999957,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",494,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.08,2989.7599999999957,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",495,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.808,2993.5679999999957,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",496,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,2995.519999999996,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",497,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2997.535999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",498,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.688,3000.223999999996,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",499,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.656,3002.879999999996,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",500,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11067776.0,65792.0,14.016,3016.895999999996,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,345868.0,2056.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",501,141312.0,294912.0,0,0,0.0,294912.0,294912.0,0.0,192.0,0.0,49152.0,49152.0,2.304,3019.199999999996,12288.0,0.0,141312.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",502,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11114624.0,65472.0,14.24,3033.439999999996,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,347332.0,2046.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",503,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.272,3035.711999999996,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,504,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,79104.0,0.826890756302521,10027008.0,98304.0,15.488,3051.1999999999957,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313344.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",505,0.0,27648.0,0,0,0.0,27648.0,27648.0,0.0,864.0,0.0,98304.0,12288.0,2.4,3053.599999999996,24576.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",506,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.08,3055.6799999999957,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",507,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,1.952,3057.631999999996,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",508,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.904,3061.535999999996,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",509,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,3063.487999999996,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",510,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,3065.567999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",511,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.624,3068.191999999996,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",512,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.72,3070.9119999999957,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,513,18874368.0,39124992.0,0,0,0.0,39124992.0,39124992.0,141312.0,21504.0,0.8679245283018868,2654208.0,98304.0,7.2,3078.1119999999955,589824.0,786432.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,82944.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",514,0.0,30720.0,0,0,0.0,30720.0,30720.0,0.0,1440.0,0.0,101376.0,12288.0,2.368,3080.4799999999955,27648.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3168.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,515,18874368.0,39124992.0,0,0,0.0,39124992.0,39124992.0,141312.0,21504.0,0.8679245283018868,2654208.0,98304.0,7.36,3087.8399999999956,589824.0,786432.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,82944.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",516,0.0,30720.0,0,0,0.0,30720.0,30720.0,0.0,1440.0,0.0,101376.0,12288.0,2.336,3090.1759999999954,27648.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3168.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,517,18874368.0,39124992.0,0,0,0.0,39124992.0,39124992.0,141312.0,21504.0,0.8679245283018868,2654208.0,98304.0,7.392,3097.567999999995,589824.0,786432.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,82944.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",518,0.0,30720.0,0,0,0.0,30720.0,30720.0,0.0,1440.0,0.0,101376.0,12288.0,2.368,3099.935999999995,27648.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3168.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",519,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.784,3102.7199999999953,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",520,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.656,3105.375999999995,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",521,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.288,3109.663999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",522,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.72,3112.383999999995,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",523,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.048,3114.431999999995,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",524,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.688,3117.119999999995,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",525,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.72,3119.8399999999947,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",526,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.128,3123.967999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",527,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.72,3126.6879999999946,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",528,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.112,3128.7999999999947,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",529,0.0,0.0,0,0,0.0,0.0,0.0,0.0,240.0,0.0,24576.0,24576.0,2.72,3131.5199999999945,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",530,0.0,0.0,0,0,0.0,0.0,0.0,0.0,240.0,0.0,24576.0,24576.0,2.592,3134.1119999999946,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",531,49152.0,4414464.0,0,0,0.0,4414464.0,4414464.0,24960.0,48.0,0.9980806142034548,61440.0,12288.0,20.096,3154.2079999999946,3721728.0,594432.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,532,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2753088.0,61440.0,7.904,3162.1119999999946,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86034.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",533,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.496,3164.6079999999947,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",534,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.112,3166.719999999995,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",535,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.016,3168.735999999995,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",536,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.872,3172.6079999999947,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",537,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,3174.559999999995,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",538,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,3176.575999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",539,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.656,3179.231999999995,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",540,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.656,3181.887999999995,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",541,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11128192.0,66048.0,13.92,3195.807999999995,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,347756.0,2064.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",542,141312.0,294912.0,0,0,0.0,294912.0,294912.0,0.0,192.0,0.0,49152.0,49152.0,2.336,3198.143999999995,12288.0,0.0,141312.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",543,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11131520.0,66752.0,13.824,3211.967999999995,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,347860.0,2086.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",544,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.112,3214.079999999995,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,545,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,79104.0,0.826890756302521,10027008.0,98304.0,15.264,3229.343999999995,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313344.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",546,0.0,27648.0,0,0,0.0,27648.0,27648.0,0.0,864.0,0.0,98304.0,12288.0,2.176,3231.519999999995,24576.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",547,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.048,3233.5679999999948,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",548,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.112,3235.679999999995,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",549,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.84,3239.519999999995,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",550,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,3241.503999999995,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",551,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,3243.5519999999947,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",552,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.688,3246.239999999995,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",553,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.72,3248.9599999999946,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,554,18874368.0,39124992.0,0,0,0.0,39124992.0,39124992.0,141312.0,21504.0,0.8679245283018868,2654208.0,98304.0,7.104,3256.0639999999944,589824.0,786432.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,82944.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",555,0.0,30720.0,0,0,0.0,30720.0,30720.0,0.0,1440.0,0.0,101376.0,12288.0,2.496,3258.5599999999945,27648.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3168.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,556,18874368.0,39124992.0,0,0,0.0,39124992.0,39124992.0,141312.0,21504.0,0.8679245283018868,2654208.0,98304.0,7.232,3265.7919999999945,589824.0,786432.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,82944.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",557,0.0,30720.0,0,0,0.0,30720.0,30720.0,0.0,1440.0,0.0,101376.0,12288.0,2.368,3268.1599999999944,27648.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3168.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,558,18874368.0,39124992.0,0,0,0.0,39124992.0,39124992.0,141312.0,21504.0,0.8679245283018868,2654208.0,98304.0,7.328,3275.4879999999944,589824.0,786432.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,82944.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",559,0.0,30720.0,0,0,0.0,30720.0,30720.0,0.0,1440.0,0.0,101376.0,12288.0,2.368,3277.8559999999943,27648.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3168.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",560,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.688,3280.5439999999944,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",561,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.624,3283.167999999994,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",562,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.064,3287.231999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",563,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.656,3289.887999999994,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",564,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.048,3291.935999999994,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",565,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.72,3294.6559999999936,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",566,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.72,3297.3759999999934,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",567,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.096,3301.4719999999934,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",568,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.688,3304.1599999999935,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",569,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.08,3306.2399999999934,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",570,0.0,0.0,0,0,0.0,0.0,0.0,0.0,240.0,0.0,24576.0,24576.0,2.624,3308.863999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",571,0.0,0.0,0,0,0.0,0.0,0.0,0.0,240.0,0.0,24576.0,24576.0,2.656,3311.519999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",572,49152.0,4414464.0,0,0,0.0,4414464.0,4414464.0,24960.0,48.0,0.9980806142034548,61440.0,12288.0,20.32,3331.8399999999933,3721728.0,594432.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,573,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2753472.0,61440.0,7.872,3339.711999999993,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86046.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",574,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.496,3342.2079999999933,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",575,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.112,3344.3199999999933,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",576,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,1.984,3346.3039999999933,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",577,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.776,3350.079999999993,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",578,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,3351.999999999993,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",579,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,3353.983999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",580,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.624,3356.607999999993,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",581,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.656,3359.263999999993,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",582,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11121536.0,63840.0,13.824,3373.087999999993,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,347548.0,1995.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",583,141312.0,294912.0,0,0,0.0,294912.0,294912.0,0.0,192.0,0.0,49152.0,49152.0,2.464,3375.551999999993,12288.0,0.0,141312.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",584,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11131776.0,66272.0,13.856,3389.407999999993,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,347868.0,2071.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",585,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.144,3391.551999999993,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,586,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,79104.0,0.826890756302521,10027008.0,98304.0,15.552,3407.103999999993,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313344.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",587,0.0,27648.0,0,0,0.0,27648.0,27648.0,0.0,864.0,0.0,98304.0,12288.0,2.208,3409.311999999993,24576.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",588,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.112,3411.423999999993,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",589,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.016,3413.4399999999932,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",590,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.84,3417.2799999999934,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",591,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.016,3419.2959999999935,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",592,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,3421.3119999999935,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",593,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.688,3423.9999999999936,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",594,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.624,3426.6239999999934,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,595,18874368.0,39124992.0,0,0,0.0,39124992.0,39124992.0,141312.0,21504.0,0.8679245283018868,2654208.0,98304.0,7.264,3433.8879999999936,589824.0,786432.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,82944.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",596,0.0,30720.0,0,0,0.0,30720.0,30720.0,0.0,1440.0,0.0,101376.0,12288.0,2.336,3436.2239999999933,27648.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3168.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,597,18874368.0,39124992.0,0,0,0.0,39124992.0,39124992.0,141312.0,21504.0,0.8679245283018868,2654208.0,98304.0,7.104,3443.327999999993,589824.0,786432.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,82944.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",598,0.0,30720.0,0,0,0.0,30720.0,30720.0,0.0,1440.0,0.0,101376.0,12288.0,2.56,3445.887999999993,27648.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3168.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,599,18874368.0,39124992.0,0,0,0.0,39124992.0,39124992.0,141312.0,21504.0,0.8679245283018868,2654208.0,98304.0,7.136,3453.023999999993,589824.0,786432.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,82944.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",600,0.0,30720.0,0,0,0.0,30720.0,30720.0,0.0,1440.0,0.0,101376.0,12288.0,2.336,3455.359999999993,27648.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3168.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",601,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.72,3458.0799999999927,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",602,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.624,3460.7039999999924,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",603,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,3.968,3464.6719999999923,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",604,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.688,3467.3599999999924,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",605,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.08,3469.4399999999923,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",606,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.72,3472.159999999992,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",607,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.656,3474.815999999992,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",608,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.064,3478.879999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",609,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.816,3481.6959999999917,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",610,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.048,3483.7439999999915,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",611,0.0,0.0,0,0,0.0,0.0,0.0,0.0,240.0,0.0,24576.0,24576.0,2.592,3486.3359999999916,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",612,0.0,0.0,0,0,0.0,0.0,0.0,0.0,240.0,0.0,24576.0,24576.0,2.624,3488.9599999999914,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",613,49152.0,4414464.0,0,0,0.0,4414464.0,4414464.0,24960.0,48.0,0.9980806142034548,61440.0,12288.0,20.224,3509.1839999999916,3721728.0,594432.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,614,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2752832.0,61440.0,7.648,3516.8319999999917,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86026.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",615,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.528,3519.3599999999915,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",616,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.048,3521.4079999999913,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",617,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.016,3523.4239999999913,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",618,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.872,3527.295999999991,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",619,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,3529.2479999999914,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",620,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,3531.295999999991,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",621,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.688,3533.9839999999913,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",622,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.656,3536.6399999999912,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",623,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11133696.0,64224.0,13.536,3550.1759999999913,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,347928.0,2007.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",624,141312.0,294912.0,0,0,0.0,294912.0,294912.0,0.0,192.0,0.0,49152.0,49152.0,2.304,3552.4799999999914,12288.0,0.0,141312.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",625,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11092992.0,66656.0,13.952,3566.4319999999916,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,346656.0,2083.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",626,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.112,3568.5439999999917,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,627,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,79104.0,0.826890756302521,10027008.0,98304.0,15.84,3584.383999999992,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313344.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",628,0.0,27648.0,0,0,0.0,27648.0,27648.0,0.0,864.0,0.0,98304.0,12288.0,2.208,3586.591999999992,24576.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",629,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.24,3588.8319999999917,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",630,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.048,3590.8799999999915,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",631,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.808,3594.6879999999915,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",632,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,3596.6399999999917,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",633,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,3598.6879999999915,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",634,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.656,3601.3439999999914,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",635,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.624,3603.967999999991,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,636,18874368.0,39124992.0,0,0,0.0,39124992.0,39124992.0,141312.0,21504.0,0.8679245283018868,2654208.0,98304.0,7.232,3611.199999999991,589824.0,786432.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,82944.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",637,0.0,30720.0,0,0,0.0,30720.0,30720.0,0.0,1440.0,0.0,101376.0,12288.0,2.368,3613.567999999991,27648.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3168.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,638,18874368.0,39124992.0,0,0,0.0,39124992.0,39124992.0,141312.0,21504.0,0.8679245283018868,2654208.0,98304.0,7.296,3620.863999999991,589824.0,786432.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,82944.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",639,0.0,30720.0,0,0,0.0,30720.0,30720.0,0.0,1440.0,0.0,101376.0,12288.0,2.4,3623.263999999991,27648.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3168.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,640,18874368.0,39124992.0,0,0,0.0,39124992.0,39124992.0,141312.0,21504.0,0.8679245283018868,2654208.0,98304.0,7.36,3630.623999999991,589824.0,786432.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,82944.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",641,0.0,30720.0,0,0,0.0,30720.0,30720.0,0.0,1440.0,0.0,101376.0,12288.0,2.368,3632.991999999991,27648.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3168.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",642,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.784,3635.775999999991,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",643,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.592,3638.3679999999913,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",644,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.064,3642.431999999991,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",645,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.752,3645.183999999991,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",646,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.112,3647.295999999991,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",647,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.784,3650.0799999999913,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",648,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.624,3652.703999999991,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",649,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.032,3656.7359999999912,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",650,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.688,3659.4239999999913,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",651,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.048,3661.471999999991,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",652,0.0,0.0,0,0,0.0,0.0,0.0,0.0,240.0,0.0,24576.0,24576.0,2.656,3664.127999999991,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",653,0.0,0.0,0,0,0.0,0.0,0.0,0.0,240.0,0.0,24576.0,24576.0,2.624,3666.751999999991,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",654,49152.0,4414464.0,0,0,0.0,4414464.0,4414464.0,24960.0,48.0,0.9980806142034548,61440.0,12288.0,20.192,3686.943999999991,3721728.0,594432.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,655,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2753248.0,61440.0,7.936,3694.879999999991,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86039.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",656,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.432,3697.311999999991,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",657,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.112,3699.423999999991,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",658,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.016,3701.439999999991,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",659,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.808,3705.247999999991,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",660,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,3707.199999999991,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",661,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,3709.2159999999913,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",662,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.656,3711.871999999991,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",663,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.656,3714.527999999991,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",664,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11143168.0,70400.0,13.472,3727.9999999999914,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,348224.0,2200.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",665,141312.0,294912.0,0,0,0.0,294912.0,294912.0,0.0,192.0,0.0,49152.0,49152.0,2.336,3730.335999999991,12288.0,0.0,141312.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",666,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11137792.0,66912.0,13.568,3743.9039999999914,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,348056.0,2091.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",667,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.08,3745.9839999999913,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,668,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,79104.0,0.826890756302521,10027008.0,98304.0,15.456,3761.4399999999914,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313344.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",669,0.0,27648.0,0,0,0.0,27648.0,27648.0,0.0,864.0,0.0,98304.0,12288.0,2.304,3763.7439999999915,24576.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",670,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.08,3765.8239999999914,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",671,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,1.984,3767.8079999999914,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",672,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.872,3771.679999999991,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",673,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,3773.663999999991,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",674,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,3775.679999999991,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",675,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.72,3778.399999999991,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",676,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.624,3781.023999999991,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,677,18874368.0,39124992.0,0,0,0.0,39124992.0,39124992.0,141312.0,21504.0,0.8679245283018868,2654208.0,98304.0,7.2,3788.2239999999906,589824.0,786432.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,82944.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",678,0.0,30720.0,0,0,0.0,30720.0,30720.0,0.0,1440.0,0.0,101376.0,12288.0,2.368,3790.5919999999905,27648.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3168.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,679,18874368.0,39124992.0,0,0,0.0,39124992.0,39124992.0,141312.0,21504.0,0.8679245283018868,2654208.0,98304.0,7.392,3797.9839999999904,589824.0,786432.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,82944.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",680,0.0,30720.0,0,0,0.0,30720.0,30720.0,0.0,1440.0,0.0,101376.0,12288.0,2.336,3800.31999999999,27648.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3168.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,681,18874368.0,39124992.0,0,0,0.0,39124992.0,39124992.0,141312.0,21504.0,0.8679245283018868,2654208.0,98304.0,7.104,3807.42399999999,589824.0,786432.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,82944.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",682,0.0,30720.0,0,0,0.0,30720.0,30720.0,0.0,1440.0,0.0,101376.0,12288.0,2.304,3809.72799999999,27648.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3168.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",683,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.656,3812.38399999999,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",684,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.624,3815.00799999999,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",685,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.224,3819.23199999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",686,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.752,3821.98399999999,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",687,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.08,3824.06399999999,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",688,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.688,3826.75199999999,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",689,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.624,3829.3759999999897,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",690,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.0,3833.3759999999897,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",691,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.752,3836.1279999999897,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",692,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.048,3838.1759999999895,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",693,0.0,0.0,0,0,0.0,0.0,0.0,0.0,240.0,0.0,24576.0,24576.0,2.656,3840.8319999999894,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",694,0.0,0.0,0,0,0.0,0.0,0.0,0.0,240.0,0.0,24576.0,24576.0,2.656,3843.4879999999894,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",695,49152.0,4414464.0,0,0,0.0,4414464.0,4414464.0,24960.0,48.0,0.9980806142034548,61440.0,12288.0,20.16,3863.647999999989,3721728.0,594432.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,696,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2752608.0,61440.0,7.648,3871.2959999999894,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86019.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",697,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.528,3873.823999999989,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",698,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.048,3875.871999999989,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",699,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,1.984,3877.855999999989,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",700,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.84,3881.695999999989,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",701,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,3883.679999999989,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",702,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,3885.759999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",703,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.688,3888.447999999989,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",704,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.656,3891.103999999989,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",705,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11046528.0,64416.0,13.888,3904.991999999989,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,345204.0,2013.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",706,141312.0,294912.0,0,0,0.0,294912.0,294912.0,0.0,192.0,0.0,49152.0,49152.0,2.272,3907.2639999999888,12288.0,0.0,141312.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",707,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11072896.0,68704.0,13.92,3921.183999999989,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,346028.0,2147.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",708,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.112,3923.295999999989,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,709,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,79104.0,0.826890756302521,10027008.0,98304.0,15.744,3939.039999999989,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313344.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",710,0.0,27648.0,0,0,0.0,27648.0,27648.0,0.0,864.0,0.0,98304.0,12288.0,2.24,3941.279999999989,24576.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",711,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.112,3943.391999999989,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",712,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,1.984,3945.375999999989,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",713,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.808,3949.183999999989,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",714,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,3951.135999999989,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",715,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,3953.119999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",716,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.656,3955.775999999989,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",717,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.688,3958.463999999989,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,718,18874368.0,39124992.0,0,0,0.0,39124992.0,39124992.0,141312.0,21504.0,0.8679245283018868,2654208.0,98304.0,7.2,3965.663999999989,589824.0,786432.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,82944.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",719,0.0,30720.0,0,0,0.0,30720.0,30720.0,0.0,1440.0,0.0,101376.0,12288.0,2.368,3968.031999999989,27648.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3168.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,720,18874368.0,39124992.0,0,0,0.0,39124992.0,39124992.0,141312.0,21504.0,0.8679245283018868,2654208.0,98304.0,7.168,3975.199999999989,589824.0,786432.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,82944.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",721,0.0,30720.0,0,0,0.0,30720.0,30720.0,0.0,1440.0,0.0,101376.0,12288.0,2.368,3977.567999999989,27648.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3168.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,722,18874368.0,39124992.0,0,0,0.0,39124992.0,39124992.0,141312.0,21504.0,0.8679245283018868,2654208.0,98304.0,7.168,3984.735999999989,589824.0,786432.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,82944.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",723,0.0,30720.0,0,0,0.0,30720.0,30720.0,0.0,1440.0,0.0,101376.0,12288.0,2.368,3987.103999999989,27648.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3168.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",724,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.688,3989.791999999989,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",725,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.656,3992.447999999989,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",726,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.096,3996.543999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",727,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.752,3999.295999999989,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",728,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.08,4001.375999999989,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",729,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.752,4004.127999999989,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",730,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.656,4006.7839999999887,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",731,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.0,4010.7839999999887,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",732,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.656,4013.4399999999887,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",733,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.08,4015.5199999999886,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",734,0.0,0.0,0,0,0.0,0.0,0.0,0.0,240.0,0.0,24576.0,24576.0,2.624,4018.1439999999884,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",735,0.0,0.0,0,0,0.0,0.0,0.0,0.0,240.0,0.0,24576.0,24576.0,2.784,4020.9279999999885,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",736,49152.0,4414464.0,0,0,0.0,4414464.0,4414464.0,24960.0,48.0,0.9980806142034548,61440.0,12288.0,20.096,4041.0239999999885,3721728.0,594432.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,737,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2753760.0,61440.0,7.84,4048.8639999999887,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86055.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",738,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.496,4051.3599999999888,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",739,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.048,4053.4079999999885,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",740,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.016,4055.4239999999886,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",741,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.808,4059.2319999999886,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",742,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.016,4061.2479999999887,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",743,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,4063.2639999999888,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",744,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.656,4065.9199999999887,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",745,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.688,4068.607999999989,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",746,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11097088.0,65216.0,13.952,4082.559999999989,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,346784.0,2038.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",747,141312.0,294912.0,0,0,0.0,294912.0,294912.0,0.0,192.0,0.0,49152.0,49152.0,2.24,4084.799999999989,12288.0,0.0,141312.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",748,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11136640.0,71104.0,13.664,4098.463999999989,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,348020.0,2222.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",749,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.144,4100.607999999989,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,750,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,79104.0,0.826890756302521,10027008.0,98304.0,15.584,4116.191999999989,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313344.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",751,0.0,27648.0,0,0,0.0,27648.0,27648.0,0.0,864.0,0.0,98304.0,12288.0,2.272,4118.463999999989,24576.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",752,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.08,4120.543999999989,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",753,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.048,4122.591999999989,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",754,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.872,4126.463999999989,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",755,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,4128.383999999989,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",756,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,4130.399999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",757,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.688,4133.087999999989,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",758,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.688,4135.775999999989,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
ampere_sgemm_64x32_sliced1x4_tn,759,3733979136.0,7501991936.0,0,0,0.0,7501991936.0,7501991936.0,17548608.0,3893360.0,0.8184233835252436,483711360.0,2430976.0,522.368,4658.143999999989,14585856.0,19447808.0,3733979136.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,15115980.0,75968.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",760,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,4659.839999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",761,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,96.0,160.0,2.592,4662.431999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",762,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,4664.415999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",763,0.0,607744.0,0,0,0.0,607744.0,607744.0,0.0,9520.0,0.0,2430976.0,2430976.0,4.704,4669.119999999989,0.0,607744.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75968.0,75968.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",764,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,4670.847999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",765,0.0,0.0,0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435072.0,166528.0,5.184,4676.031999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76096.0,5204.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",766,0.0,0.0,0,0,0.0,0.0,0.0,44104.0,718188.0,0.057857094131907455,27337536.0,800.0,12.864,4688.895999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,854298.0,25.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",767,0.0,0.0,0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435072.0,167168.0,5.248,4694.143999999988,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76096.0,5224.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",768,0.0,0.0,0,0,0.0,0.0,0.0,44104.0,721764.0,0.05758694709793333,27476416.0,992.0,13.344,4707.4879999999885,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,858638.0,31.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",769,0.0,0.0,0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435072.0,165632.0,5.152,4712.6399999999885,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76096.0,5176.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",770,0.0,0.0,0,0,0.0,0.0,0.0,44104.0,719976.0,0.0577217045335567,27424288.0,1024.0,13.184,4725.823999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,857009.0,32.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",771,0.0,0.0,0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435072.0,165440.0,5.312,4731.135999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76096.0,5170.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",772,0.0,0.0,0,0,0.0,0.0,0.0,44104.0,721615.0,0.057598152847193294,27457984.0,960.0,13.248,4744.383999999988,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,858062.0,30.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",773,0.0,0.0,0,0,0.0,0.0,0.0,0.0,57.0,0.0,19104.0,2400.0,3.328,4747.711999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,597.0,75.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",774,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.664,4749.375999999988,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",775,0.0,0.0,0,0,0.0,0.0,0.0,497.0,46.0,0.9152854511970534,2400.0,0.0,3.648,4753.0239999999885,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",776,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.696,4754.719999999988,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",777,0.0,0.0,0,0,0.0,0.0,0.0,497.0,46.0,0.9152854511970534,2400.0,0.0,3.68,4758.399999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",778,0.0,0.0,0,0,0.0,0.0,0.0,179184.0,38398.0,0.8235240047430394,2472160.0,9728.0,7.296,4765.695999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,77255.0,304.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",779,0.0,0.0,0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,544.0,6.464,4772.159999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,80.0,17.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",780,0.0,0.0,0,0,0.0,0.0,0.0,0.0,56976.0,0.0,2445120.0,250080.0,4.96,4777.119999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76410.0,7815.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",781,0.0,0.0,0,0,0.0,0.0,0.0,0.0,14280.0,0.0,3038720.0,0.0,5.984,4783.103999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,94960.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",782,0.0,0.0,0,0,0.0,0.0,0.0,0.0,18992.0,0.0,0.0,4861952.0,4.352,4787.455999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,151936.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",783,0.0,0.0,0,0,0.0,0.0,0.0,98304.0,18992.0,0.8380848451780112,2430976.0,0.0,5.888,4793.343999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75968.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",784,0.0,0.0,0,0,0.0,0.0,0.0,156.0,64.0,0.7090909090909091,8192.0,0.0,2.304,4795.647999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",785,0.0,0.0,0,0,0.0,0.0,0.0,176478.0,99141.0,0.6402969316338859,9404160.0,6043392.0,17.632,4813.279999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,293880.0,188856.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",786,0.0,0.0,0,0,0.0,0.0,0.0,67626.0,108827.0,0.3832521974690144,9483648.0,7495680.0,15.072,4828.351999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,296364.0,234240.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",787,0.0,0.0,0,0,0.0,0.0,0.0,68478.0,112561.0,0.37824999033357454,9476992.0,7495680.0,15.616,4843.967999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,296156.0,234240.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",788,0.0,0.0,0,0,0.0,0.0,0.0,68478.0,111382.0,0.38072945624374516,9508352.0,5687232.0,16.032,4859.999999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,297136.0,177726.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",789,0.0,0.0,0,0,0.0,0.0,0.0,14336.0,18992.0,0.4301488238118099,4861952.0,0.0,7.872,4867.871999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,151936.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",790,0.0,0.0,0,0,0.0,0.0,0.0,39.0,16.0,0.7090909090909091,2048.0,0.0,2.208,4870.079999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",791,0.0,0.0,0,0,0.0,0.0,0.0,55759.0,140914.0,0.28351120896106735,7417088.0,4253120.0,13.92,4883.999999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,231784.0,132910.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",792,0.0,0.0,0,0,0.0,0.0,0.0,0.0,75968.0,0.0,7324032.0,7292928.0,10.528,4894.527999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,228876.0,227904.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",793,8508416.0,20076672.0,0,0,0.0,20076672.0,20076672.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,61.92,4956.447999999989,2452096.0,607744.0,8508416.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,227904.0,75968.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",794,0.0,3052116.0,0,0,0.0,3052116.0,3052116.0,334872.0,37984.0,0.8981268908103933,2430976.0,2430976.0,211.104,5167.55199999999,3052116.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75968.0,75968.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",795,0.0,0.0,0,0,0.0,0.0,0.0,0.0,9520.0,0.0,2430976.0,607360.0,4.832,5172.38399999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75968.0,18980.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",796,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,1.92,5174.30399999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",797,0.0,0.0,0,0,0.0,0.0,0.0,0.0,56976.0,0.0,5469696.0,268128.0,10.048,5184.35199999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,170928.0,8379.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",798,0.0,0.0,0,0,0.0,0.0,0.0,0.0,14280.0,0.0,3038720.0,0.0,5.696,5190.04799999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,94960.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",799,8508416.0,20076672.0,0,0,0.0,20076672.0,20076672.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,62.432,5252.47999999999,2452096.0,607744.0,8508416.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,227904.0,75968.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",800,0.0,0.0,0,0,0.0,0.0,0.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,7.456,5259.93599999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",801,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,5262.07999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",802,0.0,0.0,0,0,0.0,0.0,0.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,7.616,5269.69599999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",803,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,5271.83999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",804,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.048,5273.88799999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",805,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.944,5276.83199999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",806,0.0,990796.0,0,0,0.0,990796.0,990796.0,7692.0,4832.0,0.6141807729160013,2431392.0,2560.0,7.712,5284.543999999991,990796.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75981.0,80.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",807,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,5286.591999999991,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",808,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,5289.855999999991,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",809,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,5291.87199999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",810,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.944,5294.815999999991,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",811,1769472.0,4754432.0,0,0,0.0,4754432.0,4754432.0,0.0,18992.0,0.0,0.0,2430976.0,4.128,5298.94399999999,0.0,1215488.0,1769472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,75968.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",812,3038720.0,6077440.0,0,0,0.0,6077440.0,6077440.0,0.0,14280.0,0.0,4861952.0,4608.0,8.192,5307.13599999999,0.0,0.0,3038720.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,151936.0,144.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",813,0.0,0.0,0,0,0.0,0.0,0.0,14092.0,4912.0,0.7415280993475057,2432256.0,2784.0,9.472,5316.60799999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76008.0,87.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",814,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,96.0,160.0,2.752,5319.359999999991,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",815,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,5321.087999999991,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",816,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,5322.783999999991,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",817,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.048,5324.83199999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",818,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,5326.91199999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",819,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.816,5329.72799999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",820,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.136,5332.8639999999905,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",821,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,5334.91199999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
