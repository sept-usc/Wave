Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.856,1.856,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,3.584,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",3,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.56,6.144,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",4,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,9.536,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",5,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,12.895999999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",6,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,15.04,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",7,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.824,16.864,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",8,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,18.592000000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",9,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.696,20.288000000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",10,0.0,0.0,0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,2.464,22.752000000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",11,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,24.800000000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",12,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,26.944000000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",13,0.0,0.0,0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,32.0,32.0,2.528,29.472,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,31.520000000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",15,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,33.6,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",16,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,2.112,35.712,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",17,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,2176.0,8192.0,3.84,39.55200000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,68.0,256.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",18,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,42.144000000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",19,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,45.440000000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",20,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.496,47.93600000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",21,0.0,512.0,0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,2.4,50.336000000000006,0.0,512.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",22,0.0,0.0,0,0,0.0,0.0,0.0,0.0,20.0,0.0,2048.0,2048.0,2.624,52.96000000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",23,4096.0,9216.0,0,0,0.0,9216.0,9216.0,0.0,32.0,0.0,2048.0,2048.0,2.88,55.84000000000001,0.0,1024.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",24,0.0,512.0,0,0,0.0,512.0,512.0,0.0,32.0,0.0,2048.0,2048.0,2.08,57.92000000000001,0.0,512.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",25,3584.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,32.0,0.0,2048.0,2048.0,2.848,60.76800000000001,0.0,1024.0,3584.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",26,0.0,512.0,0,0,0.0,512.0,512.0,0.0,32.0,0.0,2048.0,2048.0,2.016,62.784000000000006,0.0,512.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",27,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,1.984,64.768,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",28,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.488,68.256,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",29,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,70.24,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",30,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,72.288,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",31,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.688,74.976,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",32,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.656,77.632,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",33,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.44,83.072,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",34,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.184,88.256,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",35,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.152,93.408,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49216.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",36,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.688,96.096,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",37,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.624,98.72,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",38,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.68,102.4,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",39,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.752,105.152,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",40,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.08,107.232,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",41,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.784,110.016,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",42,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.656,112.67200000000001,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",43,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.776,116.44800000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",44,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.752,119.2,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",45,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.08,121.28,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",46,32768.0,2941952.0,0,0,0.0,2941952.0,2941952.0,16640.0,32.0,0.9980806142034548,24576.0,8192.0,20.224,141.504,2480128.0,396288.0,32768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",47,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,9920.0,5.12,146.624,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,310.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",48,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.112,148.736,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",49,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.048,150.784,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",50,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.456,154.23999999999998,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",51,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,156.19199999999998,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",52,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,158.23999999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",53,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.656,160.896,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",54,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.72,163.61599999999999,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",55,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5244672.0,52224.0,8.0,171.61599999999999,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,163896.0,1632.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",56,94208.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,128.0,0.0,32768.0,32768.0,2.272,173.88799999999998,8192.0,0.0,94208.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",57,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5246080.0,49696.0,7.872,181.76,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,163940.0,1553.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",58,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.112,183.87199999999999,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
ampere_sgemm_32x32_sliced1x4_tn,59,37748736.0,76873728.0,0,0,0.0,76873728.0,76873728.0,233472.0,42240.0,0.8467966573816156,5141760.0,98304.0,9.952,193.82399999999998,589824.0,786432.0,37748736.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160680.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",60,0.0,26624.0,0,0,0.0,26624.0,26624.0,0.0,832.0,0.0,98304.0,8192.0,2.528,196.35199999999998,24576.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",61,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.272,198.62399999999997,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",62,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.144,200.76799999999997,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",63,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.52,204.28799999999998,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",64,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,206.23999999999998,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",65,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,208.28799999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",66,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.624,210.91199999999998,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",67,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.624,213.53599999999997,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",68,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.216,218.75199999999998,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",69,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.472,224.224,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",70,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.344,229.56799999999998,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49216.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",71,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.816,232.384,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",72,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.656,235.04,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",73,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.648,238.688,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",74,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.816,241.504,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",75,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.176,243.67999999999998,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",76,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.688,246.36799999999997,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",77,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.592,248.95999999999998,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",78,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.68,252.64,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",79,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.72,255.35999999999999,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",80,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.048,257.40799999999996,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",81,32768.0,2941952.0,0,0,0.0,2941952.0,2941952.0,16640.0,32.0,0.9980806142034548,24576.0,8192.0,20.352,277.75999999999993,2480128.0,396288.0,32768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",82,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,10976.0,4.928,282.68799999999993,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,343.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",83,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.048,284.73599999999993,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",84,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.048,286.78399999999993,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",85,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.488,290.27199999999993,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",86,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.016,292.28799999999995,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",87,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,294.33599999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",88,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.752,297.08799999999997,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",89,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.72,299.808,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",90,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5269376.0,52352.0,7.936,307.74399999999997,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,164668.0,1636.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",91,94208.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,128.0,0.0,32768.0,32768.0,2.272,310.01599999999996,8192.0,0.0,94208.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",92,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5246208.0,55584.0,7.776,317.792,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,163944.0,1737.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",93,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.112,319.904,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
ampere_sgemm_32x32_sliced1x4_tn,94,37748736.0,76873728.0,0,0,0.0,76873728.0,76873728.0,233472.0,42240.0,0.8467966573816156,5135168.0,98304.0,10.08,329.984,589824.0,786432.0,37748736.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160474.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",95,0.0,26624.0,0,0,0.0,26624.0,26624.0,0.0,832.0,0.0,98304.0,8192.0,2.56,332.544,24576.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",96,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.08,334.62399999999997,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",97,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.08,336.70399999999995,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",98,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.456,340.15999999999997,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",99,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,342.08,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",100,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,344.096,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",101,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.656,346.752,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",102,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.688,349.44,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",103,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.44,354.88,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",104,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.248,360.128,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",105,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.184,365.312,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49216.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",106,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.688,368.0,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",107,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.688,370.688,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",108,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.648,374.336,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",109,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.688,377.024,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",110,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.144,379.168,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",111,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.88,382.048,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",112,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.752,384.8,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",113,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.648,388.44800000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",114,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.72,391.16800000000006,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",115,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.016,393.1840000000001,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",116,32768.0,2941952.0,0,0,0.0,2941952.0,2941952.0,16640.0,32.0,0.9980806142034548,24576.0,8192.0,20.256,413.44000000000005,2480128.0,396288.0,32768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",117,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,9216.0,5.184,418.6240000000001,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",118,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.112,420.7360000000001,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",119,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.048,422.7840000000001,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",120,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.456,426.2400000000001,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",121,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.016,428.25600000000014,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",122,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,430.27200000000016,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",123,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.624,432.8960000000002,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",124,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.656,435.5520000000002,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",125,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5246976.0,52928.0,7.904,443.4560000000002,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,163968.0,1654.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",126,94208.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,128.0,0.0,32768.0,32768.0,2.336,445.7920000000002,8192.0,0.0,94208.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",127,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5251456.0,50176.0,8.032,453.8240000000002,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,164108.0,1568.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",128,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.112,455.9360000000002,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
ampere_sgemm_32x32_sliced1x4_tn,129,37748736.0,76873728.0,0,0,0.0,76873728.0,76873728.0,233472.0,42240.0,0.8467966573816156,5139296.0,98304.0,10.016,465.9520000000002,589824.0,786432.0,37748736.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160603.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",130,0.0,26624.0,0,0,0.0,26624.0,26624.0,0.0,832.0,0.0,98304.0,8192.0,2.496,468.4480000000002,24576.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",131,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.112,470.56000000000023,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",132,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.016,472.57600000000025,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",133,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.52,476.09600000000023,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",134,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.016,478.11200000000025,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",135,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,480.16000000000025,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",136,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.656,482.81600000000026,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",137,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.688,485.50400000000025,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",138,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.312,490.81600000000026,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",139,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.248,496.06400000000025,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",140,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.408,501.47200000000026,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49216.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",141,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.72,504.1920000000003,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",142,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.752,506.9440000000003,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",143,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.648,510.5920000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",144,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.72,513.3120000000004,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",145,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.112,515.4240000000003,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",146,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.816,518.2400000000004,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",147,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.56,520.8000000000003,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",148,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.808,524.6080000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",149,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.72,527.3280000000003,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",150,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.112,529.4400000000003,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",151,32768.0,2941952.0,0,0,0.0,2941952.0,2941952.0,16640.0,32.0,0.9980806142034548,24576.0,8192.0,20.16,549.6000000000003,2480128.0,396288.0,32768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",152,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,9664.0,5.152,554.7520000000003,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,302.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",153,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.112,556.8640000000003,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",154,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.016,558.8800000000002,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",155,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.488,562.3680000000003,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",156,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,564.3520000000003,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",157,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,566.4000000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",158,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.72,569.1200000000003,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",159,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.688,571.8080000000003,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",160,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5250048.0,51360.0,8.224,580.0320000000004,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,164064.0,1605.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",161,94208.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,128.0,0.0,32768.0,32768.0,2.304,582.3360000000004,8192.0,0.0,94208.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",162,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5243264.0,51072.0,8.416,590.7520000000004,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,163852.0,1596.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",163,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.08,592.8320000000004,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
ampere_sgemm_32x32_sliced1x4_tn,164,37748736.0,76873728.0,0,0,0.0,76873728.0,76873728.0,233472.0,42240.0,0.8467966573816156,5140256.0,98304.0,9.888,602.7200000000005,589824.0,786432.0,37748736.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160633.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",165,0.0,26624.0,0,0,0.0,26624.0,26624.0,0.0,832.0,0.0,98304.0,8192.0,2.56,605.2800000000004,24576.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",166,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.144,607.4240000000004,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",167,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.016,609.4400000000004,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",168,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.456,612.8960000000004,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",169,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,614.8480000000004,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",170,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,616.8640000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",171,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.624,619.4880000000004,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",172,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.688,622.1760000000004,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",173,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.152,627.3280000000004,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",174,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.248,632.5760000000005,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",175,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.312,637.8880000000005,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49216.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",176,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.72,640.6080000000005,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",177,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.624,643.2320000000005,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",178,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.584,646.8160000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",179,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.656,649.4720000000004,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",180,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.048,651.5200000000004,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",181,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.656,654.1760000000004,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",182,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.688,656.8640000000004,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",183,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.712,660.5760000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",184,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.688,663.2640000000004,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",185,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.112,665.3760000000003,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",186,32768.0,2941952.0,0,0,0.0,2941952.0,2941952.0,16640.0,32.0,0.9980806142034548,24576.0,8192.0,20.288,685.6640000000003,2480128.0,396288.0,32768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",187,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,10720.0,4.992,690.6560000000003,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,335.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",188,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.08,692.7360000000003,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",189,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.048,694.7840000000003,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",190,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.552,698.3360000000004,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",191,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,700.3200000000004,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",192,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,702.4000000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",193,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.688,705.0880000000004,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",194,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.624,707.7120000000004,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",195,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5244032.0,50272.0,8.192,715.9040000000005,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,163876.0,1571.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",196,94208.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,128.0,0.0,32768.0,32768.0,2.272,718.1760000000005,8192.0,0.0,94208.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",197,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5250560.0,52640.0,8.064,726.2400000000005,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,164080.0,1645.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",198,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.144,728.3840000000005,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
ampere_sgemm_32x32_sliced1x4_tn,199,37748736.0,76873728.0,0,0,0.0,76873728.0,76873728.0,233472.0,42240.0,0.8467966573816156,5135648.0,98304.0,10.24,738.6240000000005,589824.0,786432.0,37748736.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160489.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",200,0.0,26624.0,0,0,0.0,26624.0,26624.0,0.0,832.0,0.0,98304.0,8192.0,2.56,741.1840000000004,24576.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",201,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.112,743.2960000000004,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",202,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,1.984,745.2800000000004,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",203,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.52,748.8000000000004,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",204,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,750.7520000000004,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",205,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,752.8000000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",206,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.688,755.4880000000004,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",207,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.688,758.1760000000004,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",208,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.568,763.7440000000004,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",209,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.408,769.1520000000004,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",210,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.152,774.3040000000004,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49216.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",211,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.656,776.9600000000004,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",212,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.624,779.5840000000004,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",213,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.68,783.2640000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",214,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.72,785.9840000000004,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",215,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.08,788.0640000000004,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",216,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.72,790.7840000000004,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",217,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.656,793.4400000000004,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",218,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.616,797.0560000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",219,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.656,799.7120000000003,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",220,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.048,801.7600000000003,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",221,32768.0,2941952.0,0,0,0.0,2941952.0,2941952.0,16640.0,32.0,0.9980806142034548,24576.0,8192.0,20.32,822.0800000000004,2480128.0,396288.0,32768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",222,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,10560.0,5.248,827.3280000000004,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,330.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",223,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.144,829.4720000000004,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",224,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.016,831.4880000000004,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",225,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.52,835.0080000000004,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",226,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,836.9600000000004,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",227,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,838.9440000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",228,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.624,841.5680000000004,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",229,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.656,844.2240000000004,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",230,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5248128.0,50528.0,8.16,852.3840000000004,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,164004.0,1579.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",231,94208.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,128.0,0.0,32768.0,32768.0,2.272,854.6560000000004,8192.0,0.0,94208.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",232,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5243136.0,52160.0,8.0,862.6560000000004,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,163848.0,1630.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",233,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.112,864.7680000000004,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
ampere_sgemm_32x32_sliced1x4_tn,234,37748736.0,76873728.0,0,0,0.0,76873728.0,76873728.0,233472.0,42240.0,0.8467966573816156,5143520.0,98304.0,10.048,874.8160000000004,589824.0,786432.0,37748736.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160735.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",235,0.0,26624.0,0,0,0.0,26624.0,26624.0,0.0,832.0,0.0,98304.0,8192.0,2.528,877.3440000000004,24576.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",236,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.048,879.3920000000004,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",237,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.048,881.4400000000004,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",238,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.552,884.9920000000004,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",239,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,886.9760000000005,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",240,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,888.9920000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",241,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.688,891.6800000000004,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",242,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.688,894.3680000000004,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",243,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.28,899.6480000000004,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",244,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.28,904.9280000000003,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",245,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.088,910.0160000000003,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49216.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",246,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.72,912.7360000000003,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",247,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.656,915.3920000000003,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",248,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.616,919.0080000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",249,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.816,921.8240000000003,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",250,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.048,923.8720000000003,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",251,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.624,926.4960000000003,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",252,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.624,929.1200000000003,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",253,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.68,932.8000000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",254,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.784,935.5840000000003,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",255,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.112,937.6960000000003,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",256,32768.0,2941952.0,0,0,0.0,2941952.0,2941952.0,16640.0,32.0,0.9980806142034548,24576.0,8192.0,20.256,957.9520000000002,2480128.0,396288.0,32768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",257,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,9856.0,5.12,963.0720000000002,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,308.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",258,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.08,965.1520000000003,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",259,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,1.984,967.1360000000003,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",260,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.424,970.5600000000003,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",261,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,972.5440000000003,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",262,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.112,974.6560000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",263,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.688,977.3440000000003,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",264,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.624,979.9680000000003,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",265,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5245824.0,53248.0,8.032,988.0000000000003,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,163932.0,1664.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",266,94208.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,128.0,0.0,32768.0,32768.0,2.272,990.2720000000004,8192.0,0.0,94208.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",267,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5247232.0,51904.0,8.0,998.2720000000004,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,163976.0,1622.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",268,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.112,1000.3840000000004,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
ampere_sgemm_32x32_sliced1x4_tn,269,37748736.0,76873728.0,0,0,0.0,76873728.0,76873728.0,233472.0,42240.0,0.8467966573816156,5141792.0,98304.0,10.016,1010.4000000000003,589824.0,786432.0,37748736.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160681.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",270,0.0,26624.0,0,0,0.0,26624.0,26624.0,0.0,832.0,0.0,98304.0,8192.0,2.528,1012.9280000000003,24576.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",271,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.112,1015.0400000000003,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",272,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.016,1017.0560000000003,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",273,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.488,1020.5440000000003,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",274,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,1022.4960000000003,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",275,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,1024.4800000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",276,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.624,1027.1040000000003,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",277,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.688,1029.7920000000004,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",278,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.28,1035.0720000000003,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",279,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.28,1040.3520000000003,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",280,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.248,1045.6000000000004,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49216.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",281,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.72,1048.3200000000004,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",282,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.592,1050.9120000000005,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",283,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.584,1054.4960000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",284,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.656,1057.1520000000005,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",285,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.112,1059.2640000000006,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",286,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.72,1061.9840000000006,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",287,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.656,1064.6400000000006,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",288,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.648,1068.2880000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",289,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.72,1071.0080000000005,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",290,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.048,1073.0560000000005,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",291,32768.0,2941952.0,0,0,0.0,2941952.0,2941952.0,16640.0,32.0,0.9980806142034548,24576.0,8192.0,20.32,1093.3760000000004,2480128.0,396288.0,32768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",292,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,9152.0,5.248,1098.6240000000005,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,286.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",293,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.08,1100.7040000000004,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",294,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.08,1102.7840000000003,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",295,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.52,1106.3040000000003,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",296,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,1108.2560000000003,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",297,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,1110.3040000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",298,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.624,1112.9280000000003,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",299,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.656,1115.5840000000003,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",300,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5242880.0,52736.0,8.16,1123.7440000000004,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,163840.0,1648.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",301,94208.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,128.0,0.0,32768.0,32768.0,2.368,1126.1120000000003,8192.0,0.0,94208.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",302,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5252224.0,52832.0,7.936,1134.0480000000002,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,164132.0,1651.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",303,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.144,1136.1920000000002,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
ampere_sgemm_32x32_sliced1x4_tn,304,37748736.0,76873728.0,0,0,0.0,76873728.0,76873728.0,233472.0,42240.0,0.8467966573816156,5143936.0,98304.0,9.76,1145.9520000000002,589824.0,786432.0,37748736.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160748.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",305,0.0,26624.0,0,0,0.0,26624.0,26624.0,0.0,832.0,0.0,98304.0,8192.0,2.592,1148.5440000000003,24576.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",306,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.08,1150.6240000000003,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",307,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,1.952,1152.5760000000002,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",308,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.424,1156.0000000000002,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",309,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,1157.9840000000002,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",310,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,1160.064,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",311,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.688,1162.7520000000002,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",312,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.688,1165.4400000000003,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
ampere_sgemm_64x32_sliced1x4_tn,313,2489319424.0,5012672512.0,0,0,0.0,5012672512.0,5012672512.0,12078912.0,2601904.0,0.8227684346701164,313353600.0,2430976.0,345.76,1511.2000000000003,14585856.0,19447808.0,2489319424.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,9792300.0,75968.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",314,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.664,1512.8640000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",315,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,64.0,128.0,2.592,1515.4560000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",316,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,1517.4720000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",317,0.0,607744.0,0,0,0.0,607744.0,607744.0,0.0,9520.0,0.0,2430976.0,2430976.0,4.928,1522.4000000000005,0.0,607744.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75968.0,75968.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",318,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.664,1524.0640000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",319,0.0,0.0,0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435072.0,165952.0,5.248,1529.3120000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76096.0,5186.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",320,0.0,0.0,0,0,0.0,0.0,0.0,44104.0,718188.0,0.057857094131907455,27399840.0,800.0,13.248,1542.5600000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,856245.0,25.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",321,0.0,0.0,0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435072.0,167360.0,5.216,1547.7760000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76096.0,5230.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",322,0.0,0.0,0,0,0.0,0.0,0.0,44104.0,717592.0,0.05790236524807797,27348512.0,992.0,12.608,1560.3840000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,854641.0,31.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",323,0.0,0.0,0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435072.0,166400.0,5.152,1565.5360000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76096.0,5200.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",324,0.0,0.0,0,0,0.0,0.0,0.0,44104.0,719976.0,0.0577217045335567,27433568.0,1248.0,12.96,1578.4960000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,857299.0,39.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",325,0.0,0.0,0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435072.0,165120.0,5.184,1583.6800000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76096.0,5160.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",326,0.0,0.0,0,0,0.0,0.0,0.0,44104.0,718188.0,0.057857094131907455,27407008.0,800.0,12.992,1596.6720000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,856469.0,25.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",327,0.0,0.0,0,0,0.0,0.0,0.0,0.0,57.0,0.0,19104.0,2400.0,3.2,1599.8720000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,597.0,75.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",328,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.696,1601.5680000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",329,0.0,0.0,0,0,0.0,0.0,0.0,497.0,46.0,0.9152854511970534,2400.0,0.0,3.68,1605.2480000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",330,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.696,1606.9440000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",331,0.0,0.0,0,0,0.0,0.0,0.0,497.0,46.0,0.9152854511970534,2400.0,0.0,3.68,1610.6240000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",332,0.0,0.0,0,0,0.0,0.0,0.0,211008.0,38384.0,0.8460896901263874,2472160.0,9824.0,7.264,1617.8880000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,77255.0,307.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",333,0.0,0.0,0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,544.0,6.496,1624.3840000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,80.0,17.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",334,0.0,0.0,0,0,0.0,0.0,0.0,0.0,56976.0,0.0,2445120.0,250432.0,5.12,1629.5040000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76410.0,7826.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",335,0.0,0.0,0,0,0.0,0.0,0.0,0.0,14280.0,0.0,3038720.0,0.0,5.888,1635.3920000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,94960.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",336,0.0,0.0,0,0,0.0,0.0,0.0,0.0,18992.0,0.0,0.0,4861952.0,4.352,1639.7440000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,151936.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",337,0.0,0.0,0,0,0.0,0.0,0.0,98304.0,18992.0,0.8380848451780112,2430976.0,0.0,5.792,1645.5360000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75968.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",338,0.0,0.0,0,0,0.0,0.0,0.0,156.0,64.0,0.7090909090909091,8192.0,0.0,2.176,1647.7120000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",339,0.0,0.0,0,0,0.0,0.0,0.0,176478.0,98438.0,0.6419342635568683,9310976.0,6041280.0,17.44,1665.1520000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,290968.0,188790.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",340,0.0,0.0,0,0,0.0,0.0,0.0,67626.0,114372.0,0.3715755118188112,9517440.0,7495680.0,15.232,1680.3840000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,297420.0,234240.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",341,0.0,0.0,0,0,0.0,0.0,0.0,68478.0,112007.0,0.3794110313876499,9437312.0,4565376.0,16.064,1696.4480000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,294916.0,142668.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",342,0.0,0.0,0,0,0.0,0.0,0.0,68478.0,112684.0,0.37799317737715415,9483776.0,5349600.0,15.936,1712.3840000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,296368.0,167175.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",343,0.0,0.0,0,0,0.0,0.0,0.0,14336.0,18992.0,0.4301488238118099,4861952.0,0.0,7.872,1720.2560000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,151936.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",344,0.0,0.0,0,0,0.0,0.0,0.0,39.0,16.0,0.7090909090909091,2048.0,0.0,2.176,1722.4320000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",345,0.0,0.0,0,0,0.0,0.0,0.0,55759.0,139496.0,0.28557015185270546,7381248.0,4259648.0,13.792,1736.2240000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,230664.0,133114.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",346,0.0,0.0,0,0,0.0,0.0,0.0,0.0,75968.0,0.0,7325600.0,7292928.0,10.528,1746.7520000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,228925.0,227904.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",347,8508416.0,20076672.0,0,0,0.0,20076672.0,20076672.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,62.464,1809.2160000000001,2452096.0,607744.0,8508416.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,227904.0,75968.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",348,0.0,3052116.0,0,0,0.0,3052116.0,3052116.0,334872.0,37984.0,0.8981268908103933,2430976.0,2430976.0,211.296,2020.5120000000002,3052116.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75968.0,75968.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",349,0.0,0.0,0,0,0.0,0.0,0.0,0.0,9520.0,0.0,2430976.0,607360.0,4.64,2025.1520000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75968.0,18980.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",350,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,1.92,2027.0720000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",351,0.0,0.0,0,0,0.0,0.0,0.0,0.0,56976.0,0.0,5469696.0,265952.0,10.208,2037.2800000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,170928.0,8311.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",352,0.0,0.0,0,0,0.0,0.0,0.0,0.0,14280.0,0.0,3038720.0,0.0,5.824,2043.1040000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,94960.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",353,8508416.0,20076672.0,0,0,0.0,20076672.0,20076672.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,62.432,2105.5360000000005,2452096.0,607744.0,8508416.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,227904.0,75968.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",354,0.0,0.0,0,0,0.0,0.0,0.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,7.808,2113.3440000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",355,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.112,2115.4560000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",356,0.0,0.0,0,0,0.0,0.0,0.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,7.552,2123.0080000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",357,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.112,2125.120000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",358,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.112,2127.232000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",359,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.976,2130.208000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",360,0.0,990796.0,0,0,0.0,990796.0,990796.0,7692.0,4832.0,0.6141807729160013,2431392.0,2560.0,7.904,2138.112000000001,990796.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75981.0,80.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",361,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2140.128000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",362,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,2143.360000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",363,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2145.376000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",364,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.912,2148.288000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",365,1769472.0,4754432.0,0,0,0.0,4754432.0,4754432.0,0.0,18992.0,0.0,0.0,2430976.0,4.224,2152.512000000001,0.0,1215488.0,1769472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,75968.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",366,3038720.0,6077440.0,0,0,0.0,6077440.0,6077440.0,0.0,14280.0,0.0,4861952.0,4608.0,8.32,2160.8320000000012,0.0,0.0,3038720.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,151936.0,144.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",367,0.0,0.0,0,0,0.0,0.0,0.0,14092.0,4912.0,0.7415280993475057,2432256.0,2656.0,9.248,2170.0800000000013,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76008.0,83.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",368,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,64.0,128.0,2.592,2172.6720000000014,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",369,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.664,2174.3360000000016,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",370,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,2176.0640000000017,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",371,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.08,2178.1440000000016,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",372,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,2180.1280000000015,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",373,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.88,2183.0080000000016,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",374,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.2,2186.2080000000014,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",375,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,2188.2880000000014,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",376,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.176,2190.4640000000013,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",377,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,32.0,3.36,2193.8240000000014,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",378,0.0,0.0,0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,64.0,32.0,2.496,2196.3200000000015,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",379,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.016,2198.3360000000016,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",380,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,2.048,2200.3840000000014,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",381,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,0.0,2.112,2202.4960000000015,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",382,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,2.304,2204.8000000000015,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",383,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,8320.0,8192.0,4.896,2209.6960000000017,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,260.0,256.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",384,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,2.592,2212.288000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",385,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,2215.552000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",386,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.432,2217.9840000000017,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",387,0.0,512.0,0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,2.016,2220.000000000002,0.0,512.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",388,0.0,0.0,0,0,0.0,0.0,0.0,0.0,20.0,0.0,2048.0,2048.0,2.592,2222.592000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",389,4096.0,9216.0,0,0,0.0,9216.0,9216.0,0.0,32.0,0.0,2048.0,2048.0,2.848,2225.440000000002,0.0,1024.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",390,0.0,512.0,0,0,0.0,512.0,512.0,0.0,32.0,0.0,2048.0,2048.0,2.112,2227.552000000002,0.0,512.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",391,3600.0,8224.0,0,0,0.0,8224.0,8224.0,0.0,32.0,0.0,2048.0,2048.0,2.816,2230.3680000000018,0.0,1024.0,3600.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",392,0.0,512.0,0,0,0.0,512.0,512.0,0.0,32.0,0.0,2048.0,2048.0,2.08,2232.4480000000017,0.0,512.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",393,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.048,2234.4960000000015,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",394,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.456,2237.9520000000016,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",395,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,2239.904000000002,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",396,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,2241.8880000000017,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",397,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.656,2244.5440000000017,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",398,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.688,2247.232000000002,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",399,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.248,2252.480000000002,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",400,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.216,2257.6960000000017,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",401,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.344,2263.040000000002,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49216.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",402,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.688,2265.728000000002,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",403,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.56,2268.288000000002,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",404,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.616,2271.904000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",405,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.72,2274.6240000000016,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",406,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.112,2276.7360000000017,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",407,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.752,2279.4880000000016,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",408,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.624,2282.1120000000014,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",409,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.744,2285.8560000000016,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",410,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.72,2288.5760000000014,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",411,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.048,2290.624000000001,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",412,0.0,0.0,0,0,0.0,0.0,0.0,0.0,160.0,0.0,16384.0,16384.0,2.592,2293.2160000000013,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",413,0.0,0.0,0,0,0.0,0.0,0.0,0.0,160.0,0.0,16384.0,16384.0,2.624,2295.840000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",414,32768.0,2942976.0,0,0,0.0,2942976.0,2942976.0,16640.0,32.0,0.9980806142034548,40960.0,8192.0,20.352,2316.192000000001,2481152.0,396288.0,32768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1280.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",415,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,9920.0,5.152,2321.344000000001,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,310.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",416,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.08,2323.424000000001,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",417,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.016,2325.440000000001,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",418,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.424,2328.864000000001,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",419,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,2330.784000000001,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",420,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,2332.768000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",421,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.688,2335.456000000001,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",422,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.688,2338.144000000001,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",423,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5243520.0,52512.0,8.128,2346.2720000000013,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,163860.0,1641.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",424,94208.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,128.0,0.0,32768.0,32768.0,2.272,2348.5440000000012,8192.0,0.0,94208.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",425,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5277440.0,51168.0,7.904,2356.4480000000012,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,164920.0,1599.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",426,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.112,2358.5600000000013,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
ampere_sgemm_32x32_sliced1x4_tn,427,37748736.0,76873728.0,0,0,0.0,76873728.0,76873728.0,233472.0,42240.0,0.8467966573816156,5135456.0,98304.0,10.048,2368.608000000001,589824.0,786432.0,37748736.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160483.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",428,0.0,26624.0,0,0,0.0,26624.0,26624.0,0.0,832.0,0.0,98304.0,8192.0,2.496,2371.104000000001,24576.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",429,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.08,2373.184000000001,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",430,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.112,2375.296000000001,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",431,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.488,2378.784000000001,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",432,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,2380.704000000001,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",433,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,2382.752000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",434,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.624,2385.3760000000007,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",435,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.624,2388.0000000000005,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",436,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.024,2393.0240000000003,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",437,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.12,2398.1440000000002,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",438,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.376,2403.5200000000004,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49216.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",439,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.72,2406.2400000000002,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",440,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.592,2408.8320000000003,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",441,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.648,2412.4800000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",442,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.656,2415.1360000000004,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",443,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.048,2417.184,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",444,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.784,2419.9680000000003,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",445,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.624,2422.592,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",446,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.648,2426.2400000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",447,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.72,2428.96,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",448,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.08,2431.04,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",449,0.0,0.0,0,0,0.0,0.0,0.0,0.0,160.0,0.0,16384.0,16384.0,2.592,2433.632,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",450,0.0,0.0,0,0,0.0,0.0,0.0,0.0,160.0,0.0,16384.0,16384.0,2.56,2436.192,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",451,32768.0,2942976.0,0,0,0.0,2942976.0,2942976.0,16640.0,32.0,0.9980806142034548,40960.0,8192.0,20.384,2456.576,2481152.0,396288.0,32768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1280.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",452,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,10144.0,4.992,2461.568,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,317.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",453,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.112,2463.6800000000003,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",454,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.112,2465.7920000000004,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",455,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.488,2469.28,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",456,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,2471.2320000000004,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",457,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2473.2480000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",458,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.656,2475.9040000000005,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",459,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.656,2478.5600000000004,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",460,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5250560.0,52576.0,8.0,2486.5600000000004,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,164080.0,1643.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",461,94208.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,128.0,0.0,32768.0,32768.0,2.336,2488.896,8192.0,0.0,94208.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",462,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5243904.0,53248.0,7.936,2496.8320000000003,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,163872.0,1664.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",463,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.144,2498.976,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
ampere_sgemm_32x32_sliced1x4_tn,464,37748736.0,76873728.0,0,0,0.0,76873728.0,76873728.0,233472.0,42240.0,0.8467966573816156,5137824.0,98304.0,9.856,2508.8320000000003,589824.0,786432.0,37748736.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160557.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",465,0.0,26624.0,0,0,0.0,26624.0,26624.0,0.0,832.0,0.0,98304.0,8192.0,2.56,2511.3920000000003,24576.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",466,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.048,2513.44,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",467,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.016,2515.456,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",468,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.424,2518.88,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",469,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,2520.864,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",470,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,2522.912,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",471,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.656,2525.5679999999998,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",472,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.688,2528.256,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",473,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.376,2533.632,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",474,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.248,2538.88,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",475,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.28,2544.1600000000003,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49216.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",476,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.656,2546.8160000000003,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",477,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.656,2549.472,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",478,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.648,2553.1200000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",479,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.752,2555.8720000000003,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",480,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.048,2557.92,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",481,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.72,2560.64,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",482,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.56,2563.2,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",483,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.712,2566.912,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",484,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.688,2569.6,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",485,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.112,2571.712,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",486,0.0,0.0,0,0,0.0,0.0,0.0,0.0,160.0,0.0,16384.0,16384.0,2.656,2574.368,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",487,0.0,0.0,0,0,0.0,0.0,0.0,0.0,160.0,0.0,16384.0,16384.0,2.624,2576.9919999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",488,32768.0,2942976.0,0,0,0.0,2942976.0,2942976.0,16640.0,32.0,0.9980806142034548,40960.0,8192.0,20.288,2597.2799999999997,2481152.0,396288.0,32768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1280.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",489,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,9728.0,5.376,2602.656,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,304.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",490,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.048,2604.7039999999997,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",491,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,1.984,2606.6879999999996,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",492,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.456,2610.144,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",493,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,2612.1279999999997,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",494,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,2614.1759999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",495,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.72,2616.8959999999993,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",496,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.656,2619.551999999999,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",497,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5246336.0,51648.0,8.064,2627.615999999999,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,163948.0,1614.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",498,94208.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,128.0,0.0,32768.0,32768.0,2.304,2629.919999999999,8192.0,0.0,94208.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",499,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5251840.0,51072.0,7.936,2637.8559999999993,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,164120.0,1596.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",500,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.08,2639.9359999999992,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
ampere_sgemm_32x32_sliced1x4_tn,501,37748736.0,76873728.0,0,0,0.0,76873728.0,76873728.0,233472.0,42240.0,0.8467966573816156,5138816.0,98304.0,10.112,2650.0479999999993,589824.0,786432.0,37748736.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160588.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",502,0.0,26624.0,0,0,0.0,26624.0,26624.0,0.0,832.0,0.0,98304.0,8192.0,2.56,2652.6079999999993,24576.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",503,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.24,2654.847999999999,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",504,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,1.984,2656.831999999999,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",505,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.52,2660.351999999999,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",506,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,2662.303999999999,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",507,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.952,2664.2559999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",508,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.656,2666.9119999999994,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",509,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.784,2669.6959999999995,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",510,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.152,2674.8479999999995,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",511,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.312,2680.1599999999994,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",512,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.376,2685.5359999999996,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49216.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",513,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.752,2688.2879999999996,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",514,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.624,2690.9119999999994,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",515,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.648,2694.5599999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",516,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.656,2697.2159999999994,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",517,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.144,2699.359999999999,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",518,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.72,2702.079999999999,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",519,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.624,2704.703999999999,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",520,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.648,2708.351999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",521,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.688,2711.039999999999,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",522,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.048,2713.087999999999,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",523,0.0,0.0,0,0,0.0,0.0,0.0,0.0,160.0,0.0,16384.0,16384.0,2.56,2715.647999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",524,0.0,0.0,0,0,0.0,0.0,0.0,0.0,160.0,0.0,16384.0,16384.0,2.56,2718.2079999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",525,32768.0,2942976.0,0,0,0.0,2942976.0,2942976.0,16640.0,32.0,0.9980806142034548,40960.0,8192.0,20.384,2738.5919999999987,2481152.0,396288.0,32768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1280.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",526,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,10016.0,5.408,2743.9999999999986,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,313.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",527,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.112,2746.1119999999987,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",528,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,1.984,2748.0959999999986,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",529,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.488,2751.5839999999985,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",530,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,2753.5359999999987,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",531,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2755.5519999999988,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",532,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.688,2758.239999999999,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",533,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.688,2760.927999999999,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",534,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5248000.0,53792.0,8.192,2769.119999999999,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,164000.0,1681.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",535,94208.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,128.0,0.0,32768.0,32768.0,2.336,2771.4559999999988,8192.0,0.0,94208.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",536,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5244160.0,52672.0,8.32,2779.775999999999,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,163880.0,1646.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",537,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.144,2781.9199999999987,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
ampere_sgemm_32x32_sliced1x4_tn,538,37748736.0,76873728.0,0,0,0.0,76873728.0,76873728.0,233472.0,42240.0,0.8467966573816156,5133952.0,98304.0,10.112,2792.031999999999,589824.0,786432.0,37748736.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160436.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",539,0.0,26624.0,0,0,0.0,26624.0,26624.0,0.0,832.0,0.0,98304.0,8192.0,2.496,2794.527999999999,24576.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",540,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.08,2796.607999999999,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",541,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.016,2798.623999999999,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",542,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.552,2802.175999999999,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",543,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,2804.159999999999,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",544,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2806.175999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",545,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.688,2808.863999999999,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",546,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.656,2811.519999999999,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",547,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.056,2816.575999999999,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",548,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.312,2821.887999999999,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",549,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.344,2827.231999999999,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49216.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",550,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.752,2829.983999999999,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",551,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.624,2832.607999999999,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",552,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.616,2836.223999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",553,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.752,2838.9759999999987,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",554,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.048,2841.0239999999985,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",555,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.656,2843.6799999999985,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",556,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.592,2846.2719999999986,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",557,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.648,2849.9199999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",558,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.752,2852.6719999999987,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",559,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.112,2854.7839999999987,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",560,0.0,0.0,0,0,0.0,0.0,0.0,0.0,160.0,0.0,16384.0,16384.0,2.56,2857.3439999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",561,0.0,0.0,0,0,0.0,0.0,0.0,0.0,160.0,0.0,16384.0,16384.0,2.624,2859.9679999999985,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",562,32768.0,2942976.0,0,0,0.0,2942976.0,2942976.0,16640.0,32.0,0.9980806142034548,40960.0,8192.0,20.352,2880.3199999999983,2481152.0,396288.0,32768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1280.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",563,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,9632.0,5.024,2885.3439999999982,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,301.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",564,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.048,2887.391999999998,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",565,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.048,2889.439999999998,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",566,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.584,2893.0239999999976,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",567,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,2895.0079999999975,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",568,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2897.0239999999976,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",569,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.72,2899.7439999999974,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",570,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.656,2902.3999999999974,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",571,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5244544.0,51776.0,8.256,2910.655999999997,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,163892.0,1618.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",572,94208.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,128.0,0.0,32768.0,32768.0,2.304,2912.9599999999973,8192.0,0.0,94208.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",573,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5246080.0,52160.0,8.16,2921.119999999997,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,163940.0,1630.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",574,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.144,2923.263999999997,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
ampere_sgemm_32x32_sliced1x4_tn,575,37748736.0,76873728.0,0,0,0.0,76873728.0,76873728.0,233472.0,42240.0,0.8467966573816156,5140384.0,98304.0,10.048,2933.3119999999967,589824.0,786432.0,37748736.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160637.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",576,0.0,26624.0,0,0,0.0,26624.0,26624.0,0.0,832.0,0.0,98304.0,8192.0,2.496,2935.807999999997,24576.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",577,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.08,2937.8879999999967,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",578,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.144,2940.0319999999965,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",579,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.52,2943.5519999999965,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",580,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,2945.5039999999967,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",581,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,2947.5519999999965,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",582,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.72,2950.2719999999963,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",583,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.72,2952.991999999996,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",584,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.216,2958.207999999996,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",585,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.088,2963.295999999996,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",586,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.312,2968.607999999996,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49216.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",587,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.656,2971.263999999996,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",588,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.656,2973.919999999996,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",589,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.616,2977.535999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",590,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.72,2980.2559999999958,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",591,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.112,2982.367999999996,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",592,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.656,2985.023999999996,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",593,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.656,2987.6799999999957,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",594,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.68,2991.3599999999956,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",595,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.656,2994.0159999999955,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",596,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.08,2996.0959999999955,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",597,0.0,0.0,0,0,0.0,0.0,0.0,0.0,160.0,0.0,16384.0,16384.0,2.624,2998.7199999999953,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",598,0.0,0.0,0,0,0.0,0.0,0.0,0.0,160.0,0.0,16384.0,16384.0,2.656,3001.375999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",599,32768.0,2942976.0,0,0,0.0,2942976.0,2942976.0,16640.0,32.0,0.9980806142034548,40960.0,8192.0,20.352,3021.727999999995,2481152.0,396288.0,32768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1280.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",600,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,9952.0,5.12,3026.847999999995,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,311.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",601,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.08,3028.927999999995,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",602,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.016,3030.943999999995,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",603,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.488,3034.431999999995,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",604,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,3036.383999999995,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",605,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,3038.399999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",606,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.656,3041.055999999995,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",607,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.688,3043.743999999995,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",608,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5247616.0,51392.0,8.128,3051.8719999999953,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,163988.0,1606.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",609,94208.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,128.0,0.0,32768.0,32768.0,2.336,3054.207999999995,8192.0,0.0,94208.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",610,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5246720.0,52416.0,8.224,3062.4319999999952,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,163960.0,1638.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",611,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.24,3064.671999999995,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
ampere_sgemm_32x32_sliced1x4_tn,612,37748736.0,76873728.0,0,0,0.0,76873728.0,76873728.0,233472.0,42240.0,0.8467966573816156,5139744.0,98304.0,9.984,3074.655999999995,589824.0,786432.0,37748736.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160617.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",613,0.0,26624.0,0,0,0.0,26624.0,26624.0,0.0,832.0,0.0,98304.0,8192.0,2.528,3077.1839999999947,24576.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",614,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.112,3079.295999999995,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",615,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.016,3081.311999999995,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",616,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.456,3084.767999999995,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",617,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.016,3086.783999999995,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",618,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,3088.799999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",619,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.752,3091.551999999995,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",620,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.688,3094.2399999999952,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",621,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.312,3099.551999999995,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",622,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.312,3104.863999999995,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",623,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.28,3110.1439999999952,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49216.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",624,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.656,3112.799999999995,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",625,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.592,3115.3919999999953,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",626,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.648,3119.0399999999954,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",627,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.688,3121.7279999999955,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",628,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.08,3123.8079999999954,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",629,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.72,3126.5279999999952,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",630,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.656,3129.183999999995,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",631,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.648,3132.8319999999953,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",632,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.752,3135.5839999999953,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",633,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.112,3137.6959999999954,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",634,0.0,0.0,0,0,0.0,0.0,0.0,0.0,160.0,0.0,16384.0,16384.0,2.528,3140.223999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",635,0.0,0.0,0,0,0.0,0.0,0.0,0.0,160.0,0.0,16384.0,16384.0,2.56,3142.783999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",636,32768.0,2942976.0,0,0,0.0,2942976.0,2942976.0,16640.0,32.0,0.9980806142034548,40960.0,8192.0,20.32,3163.1039999999953,2481152.0,396288.0,32768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1280.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",637,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,10720.0,5.056,3168.1599999999953,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,335.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",638,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.112,3170.2719999999954,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",639,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.048,3172.319999999995,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",640,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.488,3175.807999999995,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",641,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,3177.791999999995,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",642,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,3179.807999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",643,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.688,3182.495999999995,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",644,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.624,3185.119999999995,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",645,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5243776.0,52256.0,8.224,3193.343999999995,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,163868.0,1633.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",646,94208.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,128.0,0.0,32768.0,32768.0,2.368,3195.711999999995,8192.0,0.0,94208.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",647,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5245184.0,53760.0,7.968,3203.679999999995,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,163912.0,1680.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",648,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.112,3205.791999999995,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
ampere_sgemm_32x32_sliced1x4_tn,649,37748736.0,76873728.0,0,0,0.0,76873728.0,76873728.0,233472.0,42240.0,0.8467966573816156,5136992.0,98304.0,10.176,3215.967999999995,589824.0,786432.0,37748736.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160531.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",650,0.0,26624.0,0,0,0.0,26624.0,26624.0,0.0,832.0,0.0,98304.0,8192.0,2.496,3218.463999999995,24576.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",651,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.048,3220.5119999999947,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",652,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,1.984,3222.4959999999946,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",653,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.52,3226.0159999999946,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",654,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.016,3228.0319999999947,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",655,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,3230.0799999999945,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",656,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.624,3232.7039999999943,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",657,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.688,3235.3919999999944,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",658,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.184,3240.5759999999946,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",659,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.216,3245.7919999999945,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",660,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.152,3250.9439999999945,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49216.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",661,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.752,3253.6959999999945,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",662,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.688,3256.3839999999946,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",663,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.648,3260.0319999999947,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",664,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.752,3262.7839999999946,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",665,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.144,3264.9279999999944,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",666,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.656,3267.5839999999944,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",667,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.592,3270.1759999999945,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",668,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.648,3273.8239999999946,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",669,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.752,3276.5759999999946,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",670,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.144,3278.7199999999943,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",671,0.0,0.0,0,0,0.0,0.0,0.0,0.0,160.0,0.0,16384.0,16384.0,2.592,3281.3119999999944,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",672,0.0,0.0,0,0,0.0,0.0,0.0,0.0,160.0,0.0,16384.0,16384.0,2.656,3283.9679999999944,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",673,32768.0,2942976.0,0,0,0.0,2942976.0,2942976.0,16640.0,32.0,0.9980806142034548,40960.0,8192.0,20.32,3304.2879999999946,2481152.0,396288.0,32768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1280.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",674,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,10016.0,5.184,3309.4719999999948,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,313.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",675,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.048,3311.5199999999945,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",676,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.112,3313.6319999999946,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",677,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.52,3317.1519999999946,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",678,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.016,3319.1679999999947,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",679,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,3321.2159999999944,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",680,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.72,3323.9359999999942,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",681,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.72,3326.655999999994,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",682,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5243392.0,51424.0,8.352,3335.007999999994,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,163856.0,1607.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",683,94208.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,128.0,0.0,32768.0,32768.0,2.24,3337.2479999999937,8192.0,0.0,94208.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",684,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5254528.0,52576.0,7.968,3345.2159999999935,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,164204.0,1643.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",685,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.208,3347.4239999999936,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
ampere_sgemm_32x32_sliced1x4_tn,686,37748736.0,76873728.0,0,0,0.0,76873728.0,76873728.0,233472.0,42240.0,0.8467966573816156,5131712.0,98304.0,10.176,3357.5999999999935,589824.0,786432.0,37748736.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160366.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",687,0.0,26624.0,0,0,0.0,26624.0,26624.0,0.0,832.0,0.0,98304.0,8192.0,2.528,3360.1279999999933,24576.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",688,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.112,3362.2399999999934,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",689,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.048,3364.287999999993,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",690,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.424,3367.711999999993,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",691,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,3369.6639999999934,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",692,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,3371.6799999999935,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",693,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.688,3374.3679999999936,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",694,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.816,3377.1839999999934,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
ampere_sgemm_64x32_sliced1x4_tn,695,2489319424.0,5012672512.0,0,0,0.0,5012672512.0,5012672512.0,12078912.0,2601904.0,0.8227684346701164,313524864.0,2430976.0,346.816,3723.999999999993,14585856.0,19447808.0,2489319424.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,9797652.0,75968.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",696,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,3725.7279999999932,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",697,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,96.0,160.0,2.624,3728.351999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",698,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,3730.399999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",699,0.0,607744.0,0,0,0.0,607744.0,607744.0,0.0,9520.0,0.0,2430976.0,2430976.0,4.832,3735.2319999999927,0.0,607744.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75968.0,75968.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",700,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,3736.9599999999928,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",701,0.0,0.0,0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435072.0,168128.0,5.248,3742.207999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76096.0,5254.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",702,0.0,0.0,0,0,0.0,0.0,0.0,44104.0,718188.0,0.057857094131907455,27396864.0,864.0,12.768,3754.975999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,856152.0,27.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",703,0.0,0.0,0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435072.0,167360.0,5.152,3760.127999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76096.0,5230.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",704,0.0,0.0,0,0,0.0,0.0,0.0,44104.0,717592.0,0.05790236524807797,27343456.0,1056.0,12.96,3773.087999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,854483.0,33.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",705,0.0,0.0,0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435072.0,165952.0,5.184,3778.271999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76096.0,5186.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",706,0.0,0.0,0,0,0.0,0.0,0.0,44104.0,719082.0,0.05778932003469665,27433952.0,1056.0,12.928,3791.199999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,857311.0,33.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",707,0.0,0.0,0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435072.0,166720.0,5.216,3796.415999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76096.0,5210.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",708,0.0,0.0,0,0,0.0,0.0,0.0,44104.0,719231.0,0.05777803978593933,27455584.0,1056.0,13.184,3809.599999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,857987.0,33.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",709,0.0,0.0,0,0,0.0,0.0,0.0,0.0,57.0,0.0,19104.0,2400.0,3.264,3812.863999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,597.0,75.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",710,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.664,3814.5279999999934,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",711,0.0,0.0,0,0,0.0,0.0,0.0,497.0,46.0,0.9152854511970534,2400.0,0.0,3.744,3818.2719999999936,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",712,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.696,3819.9679999999935,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",713,0.0,0.0,0,0,0.0,0.0,0.0,497.0,46.0,0.9152854511970534,2400.0,0.0,3.712,3823.6799999999935,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",714,0.0,0.0,0,0,0.0,0.0,0.0,193920.0,38398.0,0.8347179297342435,2472160.0,9504.0,7.136,3830.8159999999934,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,77255.0,297.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",715,0.0,0.0,0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,544.0,6.432,3837.247999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,80.0,17.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",716,0.0,0.0,0,0,0.0,0.0,0.0,0.0,56976.0,0.0,2445120.0,250848.0,4.96,3842.2079999999933,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76410.0,7839.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",717,0.0,0.0,0,0,0.0,0.0,0.0,0.0,14280.0,0.0,3038720.0,0.0,6.176,3848.383999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,94960.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",718,0.0,0.0,0,0,0.0,0.0,0.0,0.0,18992.0,0.0,0.0,4861952.0,4.32,3852.7039999999934,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,151936.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",719,0.0,0.0,0,0,0.0,0.0,0.0,98304.0,18992.0,0.8380848451780112,2430976.0,0.0,5.92,3858.6239999999934,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75968.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",720,0.0,0.0,0,0,0.0,0.0,0.0,156.0,64.0,0.7090909090909091,8192.0,0.0,2.176,3860.7999999999934,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",721,0.0,0.0,0,0,0.0,0.0,0.0,180078.0,98204.0,0.6471061728749973,9295360.0,5961760.0,17.44,3878.2399999999934,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,290480.0,186305.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",722,0.0,0.0,0,0,0.0,0.0,0.0,67626.0,108891.0,0.3831132412175598,9478528.0,7495680.0,15.2,3893.4399999999932,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,296204.0,234240.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",723,0.0,0.0,0,0,0.0,0.0,0.0,68478.0,109360.0,0.3850583114969804,9511296.0,4642144.0,16.128,3909.5679999999934,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,297228.0,145067.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",724,0.0,0.0,0,0,0.0,0.0,0.0,68478.0,110134.0,0.38338969386155464,9547392.0,5898880.0,16.128,3925.6959999999935,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,298356.0,184340.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",725,0.0,0.0,0,0,0.0,0.0,0.0,14336.0,18992.0,0.4301488238118099,4861952.0,0.0,7.808,3933.5039999999935,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,151936.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",726,0.0,0.0,0,0,0.0,0.0,0.0,39.0,16.0,0.7090909090909091,2048.0,0.0,2.24,3935.7439999999933,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",727,0.0,0.0,0,0,0.0,0.0,0.0,55759.0,132919.0,0.29552465046269305,7412480.0,4254240.0,13.696,3949.4399999999932,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,231640.0,132945.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",728,0.0,0.0,0,0,0.0,0.0,0.0,0.0,75968.0,0.0,7323648.0,7292928.0,10.4,3959.8399999999933,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,228864.0,227904.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",729,8508416.0,20076672.0,0,0,0.0,20076672.0,20076672.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,62.304,4022.1439999999934,2452096.0,607744.0,8508416.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,227904.0,75968.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",730,0.0,3052116.0,0,0,0.0,3052116.0,3052116.0,334872.0,37984.0,0.8981268908103933,2430976.0,2430976.0,210.816,4232.959999999994,3052116.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75968.0,75968.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",731,0.0,0.0,0,0,0.0,0.0,0.0,0.0,9520.0,0.0,2430976.0,607360.0,4.768,4237.727999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75968.0,18980.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",732,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,1.92,4239.647999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",733,0.0,0.0,0,0,0.0,0.0,0.0,0.0,56976.0,0.0,5469696.0,269056.0,10.112,4249.759999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,170928.0,8408.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",734,0.0,0.0,0,0,0.0,0.0,0.0,0.0,14280.0,0.0,3038720.0,0.0,5.824,4255.5839999999935,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,94960.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",735,8508416.0,20076672.0,0,0,0.0,20076672.0,20076672.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,61.696,4317.279999999993,2452096.0,607744.0,8508416.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,227904.0,75968.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",736,0.0,0.0,0,0,0.0,0.0,0.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,7.84,4325.1199999999935,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",737,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.112,4327.231999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",738,0.0,0.0,0,0,0.0,0.0,0.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,7.84,4335.071999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",739,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,4337.215999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",740,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.048,4339.263999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",741,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.976,4342.239999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",742,0.0,990796.0,0,0,0.0,990796.0,990796.0,7692.0,4832.0,0.6141807729160013,2431392.0,2560.0,7.808,4350.047999999993,990796.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75981.0,80.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",743,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,4352.095999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",744,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,4355.327999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",745,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,4357.3119999999935,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",746,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.008,4360.319999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",747,1769472.0,4754432.0,0,0,0.0,4754432.0,4754432.0,0.0,18992.0,0.0,0.0,2430976.0,4.128,4364.447999999993,0.0,1215488.0,1769472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,75968.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",748,3038720.0,6077440.0,0,0,0.0,6077440.0,6077440.0,0.0,14280.0,0.0,4861952.0,2560.0,8.288,4372.735999999993,0.0,0.0,3038720.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,151936.0,80.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",749,0.0,0.0,0,0,0.0,0.0,0.0,14092.0,4912.0,0.7415280993475057,2432256.0,2816.0,9.28,4382.015999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76008.0,88.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",750,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,96.0,160.0,2.592,4384.607999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",751,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.888,4386.495999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",752,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,4388.223999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",753,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.08,4390.303999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",754,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,4392.351999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",755,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.848,4395.199999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",756,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,4398.431999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",757,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,4400.479999999991,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
