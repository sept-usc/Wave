Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.856,1.856,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,3.552,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,5.28,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.016,7.296,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.336,9.632,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",6,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.336,11.968,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",7,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,15.296,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",8,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.104,18.4,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",9,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.208,20.607999999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",10,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,22.304,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",11,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,24.032,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.76,25.792,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,0.0,0.0,0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,2.464,28.256,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,30.304000000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",15,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.208,32.512,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",16,0.0,0.0,0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,32.0,32.0,2.496,35.008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",17,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,37.056000000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",18,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.304,39.36000000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",19,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,2.144,41.504000000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",20,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,17408.0,65536.0,3.84,45.34400000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,544.0,2048.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",21,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,17408.0,65536.0,3.68,49.02400000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,544.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",22,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.144,51.168000000000006,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",23,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,53.184000000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",24,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,56.544000000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",25,92228.0,306420.0,0,0,0.0,306420.0,306420.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,8.544,65.08800000000001,92720.0,29244.0,92228.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2056.0
ampere_sgemm_128x32_sliced1x4_nn,26,1610612736.0,3232235520.0,0,0,0.0,3232235520.0,3232235520.0,5458944.0,1628160.0,0.7702644126571305,207618048.0,786432.0,231.104,296.192,4718592.0,6291456.0,1610612736.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6488064.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",27,0.0,294912.0,0,0,0.0,294912.0,294912.0,0.0,16896.0,0.0,835584.0,196608.0,3.84,300.032,245760.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,26112.0,6144.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",28,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,3.008,303.03999999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",29,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,2.688,305.72799999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",30,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,2.624,308.352,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",31,524288.0,17416192.0,0,0,0.0,17416192.0,17416192.0,136192.0,256.0,0.99812382739212,196608.0,65536.0,20.512,328.864,13172736.0,3194880.0,524288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
ampere_sgemm_128x32_sliced1x4_nn,32,536870912.0,1077411840.0,0,0,0.0,1077411840.0,1077411840.0,1819648.0,542720.0,0.7702644126571305,69206016.0,262144.0,76.384,405.248,1572864.0,2097152.0,536870912.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2162688.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",33,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,5632.0,0.0,278528.0,65536.0,2.72,407.968,81920.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8704.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",34,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.208,410.17600000000004,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",35,92228.0,306420.0,0,0,0.0,306420.0,306420.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,8.704,418.88000000000005,92720.0,29244.0,92228.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2056.0
ampere_sgemm_128x32_sliced1x4_nn,36,2148007936.0,4299685888.0,0,0,0.0,4299685888.0,4299685888.0,6931456.0,2166784.0,0.7618458075407991,277086208.0,262144.0,288.128,707.008,1572864.0,2097152.0,2148007936.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8658944.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",37,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.304,709.312,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",38,0.0,131072.0,0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.24,711.552,0.0,131072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",39,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.24,713.792,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",40,65536.0,131072.0,0,0,0.0,131072.0,131072.0,0.0,1536.0,0.0,524288.0,262144.0,2.528,716.32,0.0,0.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16384.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",41,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.4,718.72,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",42,355992.0,908592.0,0,0,0.0,908592.0,908592.0,0.0,1024.0,0.0,262144.0,262144.0,2.4,721.12,65536.0,131072.0,355992.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",43,65536.0,131072.0,0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.304,723.424,0.0,0.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",44,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,2.656,726.0799999999999,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16384.0,8192.0
ampere_sgemm_128x32_sliced1x4_nn,45,2147483648.0,4298637312.0,0,0,0.0,4298637312.0,4298637312.0,6931456.0,2164736.0,0.7620173364854216,276824064.0,262144.0,286.688,1012.7679999999999,1572864.0,2097152.0,2147483648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8650752.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",46,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,5632.0,0.0,278528.0,65536.0,2.496,1015.2639999999999,81920.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8704.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",47,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.24,1017.5039999999999,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",48,92228.0,306420.0,0,0,0.0,306420.0,306420.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,8.864,1026.368,92720.0,29244.0,92228.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2056.0
ampere_sgemm_128x32_sliced1x4_nn,49,1610612736.0,3232235520.0,0,0,0.0,3232235520.0,3232235520.0,5458944.0,1628160.0,0.7702644126571305,207618048.0,786432.0,229.856,1256.224,4718592.0,6291456.0,1610612736.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6488064.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",50,0.0,294912.0,0,0,0.0,294912.0,294912.0,0.0,16896.0,0.0,835584.0,196608.0,3.712,1259.936,245760.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,26112.0,6144.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",51,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,2.72,1262.656,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",52,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,2.656,1265.312,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",53,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,2.72,1268.032,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",54,524288.0,17416192.0,0,0,0.0,17416192.0,17416192.0,136192.0,256.0,0.99812382739212,196608.0,65536.0,19.488,1287.52,13172736.0,3194880.0,524288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
ampere_sgemm_128x32_sliced1x4_nn,55,536870912.0,1077411840.0,0,0,0.0,1077411840.0,1077411840.0,1819648.0,542720.0,0.7702644126571305,69206016.0,262144.0,75.968,1363.488,1572864.0,2097152.0,536870912.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2162688.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",56,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,5632.0,0.0,278528.0,65536.0,2.528,1366.016,81920.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8704.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",57,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.144,1368.16,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",58,92228.0,306420.0,0,0,0.0,306420.0,306420.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,8.64,1376.8000000000002,92720.0,29244.0,92228.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2056.0
ampere_sgemm_128x32_sliced1x4_nn,59,2148007936.0,4299685888.0,0,0,0.0,4299685888.0,4299685888.0,6931456.0,2166784.0,0.7618458075407991,277086208.0,262144.0,287.712,1664.5120000000002,1572864.0,2097152.0,2148007936.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8658944.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",60,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.4,1666.9120000000003,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",61,0.0,131072.0,0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.368,1669.2800000000002,0.0,131072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",62,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.432,1671.7120000000002,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",63,65536.0,131072.0,0,0,0.0,131072.0,131072.0,0.0,1536.0,0.0,524288.0,262144.0,2.72,1674.4320000000002,0.0,0.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16384.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",64,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.24,1676.6720000000003,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",65,355728.0,908064.0,0,0,0.0,908064.0,908064.0,0.0,1024.0,0.0,262144.0,262144.0,2.368,1679.0400000000002,65536.0,131072.0,355728.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",66,65536.0,131072.0,0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.272,1681.3120000000001,0.0,0.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",67,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,2.816,1684.1280000000002,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16384.0,8192.0
ampere_sgemm_128x32_sliced1x4_nn,68,2147483648.0,4298637312.0,0,0,0.0,4298637312.0,4298637312.0,6931456.0,2164736.0,0.7620173364854216,276824064.0,262144.0,287.488,1971.6160000000002,1572864.0,2097152.0,2147483648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8650752.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",69,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,5632.0,0.0,278528.0,65536.0,2.752,1974.3680000000002,81920.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8704.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",70,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.336,1976.7040000000002,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",71,92228.0,306420.0,0,0,0.0,306420.0,306420.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,8.576,1985.2800000000002,92720.0,29244.0,92228.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2056.0
ampere_sgemm_128x32_sliced1x4_nn,72,1610612736.0,3232235520.0,0,0,0.0,3232235520.0,3232235520.0,5458944.0,1628160.0,0.7702644126571305,207618048.0,786432.0,230.048,2215.3280000000004,4718592.0,6291456.0,1610612736.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6488064.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",73,0.0,294912.0,0,0,0.0,294912.0,294912.0,0.0,16896.0,0.0,835584.0,196608.0,3.648,2218.9760000000006,245760.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,26112.0,6144.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",74,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,2.784,2221.7600000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",75,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,2.688,2224.448000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",76,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,2.72,2227.1680000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",77,524288.0,17416192.0,0,0,0.0,17416192.0,17416192.0,136192.0,256.0,0.99812382739212,196608.0,65536.0,19.648,2246.8160000000007,13172736.0,3194880.0,524288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
ampere_sgemm_128x32_sliced1x4_nn,78,536870912.0,1077411840.0,0,0,0.0,1077411840.0,1077411840.0,1819648.0,542720.0,0.7702644126571305,69206016.0,262144.0,75.968,2322.7840000000006,1572864.0,2097152.0,536870912.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2162688.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",79,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,5632.0,0.0,278528.0,65536.0,2.528,2325.3120000000004,81920.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8704.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",80,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.336,2327.648,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",81,92228.0,306420.0,0,0,0.0,306420.0,306420.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,8.672,2336.32,92720.0,29244.0,92228.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2056.0
ampere_sgemm_128x32_sliced1x4_nn,82,2148007936.0,4299685888.0,0,0,0.0,4299685888.0,4299685888.0,6931456.0,2166784.0,0.7618458075407991,277086208.0,262144.0,289.664,2625.9840000000004,1572864.0,2097152.0,2148007936.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8658944.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",83,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.304,2628.2880000000005,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",84,0.0,131072.0,0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.24,2630.5280000000002,0.0,131072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",85,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.24,2632.768,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",86,65536.0,131072.0,0,0,0.0,131072.0,131072.0,0.0,1536.0,0.0,524288.0,262144.0,2.592,2635.36,0.0,0.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16384.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",87,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.432,2637.792,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",88,355792.0,908192.0,0,0,0.0,908192.0,908192.0,0.0,1024.0,0.0,262144.0,262144.0,2.432,2640.2239999999997,65536.0,131072.0,355792.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",89,65536.0,131072.0,0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.432,2642.6559999999995,0.0,0.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",90,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,2.688,2645.3439999999996,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16384.0,8192.0
ampere_sgemm_128x32_sliced1x4_nn,91,2147483648.0,4298637312.0,0,0,0.0,4298637312.0,4298637312.0,6931456.0,2164736.0,0.7620173364854216,276824064.0,262144.0,286.592,2931.9359999999997,1572864.0,2097152.0,2147483648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8650752.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",92,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,5632.0,0.0,278528.0,65536.0,2.528,2934.4639999999995,81920.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8704.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",93,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.176,2936.6399999999994,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",94,92228.0,306420.0,0,0,0.0,306420.0,306420.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,8.576,2945.2159999999994,92720.0,29244.0,92228.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2056.0
ampere_sgemm_128x32_sliced1x4_nn,95,1610612736.0,3232235520.0,0,0,0.0,3232235520.0,3232235520.0,5458944.0,1628160.0,0.7702644126571305,207618048.0,786432.0,230.432,3175.6479999999992,4718592.0,6291456.0,1610612736.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6488064.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",96,0.0,294912.0,0,0,0.0,294912.0,294912.0,0.0,16896.0,0.0,835584.0,196608.0,3.648,3179.2959999999994,245760.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,26112.0,6144.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",97,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,2.656,3181.9519999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",98,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,2.72,3184.671999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",99,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,2.72,3187.391999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",100,524288.0,17416192.0,0,0,0.0,17416192.0,17416192.0,136192.0,256.0,0.99812382739212,196608.0,65536.0,19.808,3207.199999999999,13172736.0,3194880.0,524288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
ampere_sgemm_128x32_sliced1x4_nn,101,536870912.0,1077411840.0,0,0,0.0,1077411840.0,1077411840.0,1819648.0,542720.0,0.7702644126571305,69206016.0,262144.0,76.224,3283.423999999999,1572864.0,2097152.0,536870912.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2162688.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",102,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,5632.0,0.0,278528.0,65536.0,2.688,3286.111999999999,81920.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8704.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",103,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.112,3288.2239999999993,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",104,92228.0,306420.0,0,0,0.0,306420.0,306420.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,8.864,3297.0879999999993,92720.0,29244.0,92228.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2056.0
ampere_sgemm_128x32_sliced1x4_nn,105,2148007936.0,4299685888.0,0,0,0.0,4299685888.0,4299685888.0,6931456.0,2166784.0,0.7618458075407991,277086208.0,262144.0,286.72,3583.807999999999,1572864.0,2097152.0,2148007936.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8658944.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",106,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.336,3586.143999999999,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",107,0.0,131072.0,0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.272,3588.415999999999,0.0,131072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",108,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.4,3590.815999999999,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",109,65536.0,131072.0,0,0,0.0,131072.0,131072.0,0.0,1536.0,0.0,524288.0,262144.0,2.72,3593.5359999999987,0.0,0.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16384.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",110,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.656,3596.1919999999986,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",111,356096.0,908800.0,0,0,0.0,908800.0,908800.0,0.0,1024.0,0.0,262144.0,262144.0,2.336,3598.5279999999984,65536.0,131072.0,356096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",112,65536.0,131072.0,0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.528,3601.055999999998,0.0,0.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",113,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,2.656,3603.711999999998,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16384.0,8192.0
ampere_sgemm_128x32_sliced1x4_nn,114,2147483648.0,4298637312.0,0,0,0.0,4298637312.0,4298637312.0,6931456.0,2164736.0,0.7620173364854216,276824064.0,262144.0,287.072,3890.7839999999983,1572864.0,2097152.0,2147483648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8650752.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",115,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,5632.0,0.0,278528.0,65536.0,2.592,3893.3759999999984,81920.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8704.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",116,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.144,3895.519999999998,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",117,92228.0,306420.0,0,0,0.0,306420.0,306420.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,8.544,3904.063999999998,92720.0,29244.0,92228.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2056.0
ampere_sgemm_128x32_sliced1x4_nn,118,1610612736.0,3232235520.0,0,0,0.0,3232235520.0,3232235520.0,5458944.0,1628160.0,0.7702644126571305,207618048.0,786432.0,230.752,4134.815999999998,4718592.0,6291456.0,1610612736.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6488064.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",119,0.0,294912.0,0,0,0.0,294912.0,294912.0,0.0,16896.0,0.0,835584.0,196608.0,3.616,4138.431999999998,245760.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,26112.0,6144.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",120,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,2.656,4141.087999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",121,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,2.688,4143.775999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",122,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,2.752,4146.527999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",123,524288.0,17416192.0,0,0,0.0,17416192.0,17416192.0,136192.0,256.0,0.99812382739212,196608.0,65536.0,19.392,4165.919999999998,13172736.0,3194880.0,524288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
ampere_sgemm_128x32_sliced1x4_nn,124,536870912.0,1077411840.0,0,0,0.0,1077411840.0,1077411840.0,1819648.0,542720.0,0.7702644126571305,69206016.0,262144.0,75.968,4241.887999999998,1572864.0,2097152.0,536870912.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2162688.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",125,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,5632.0,0.0,278528.0,65536.0,2.592,4244.479999999998,81920.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8704.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",126,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.144,4246.623999999998,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",127,92228.0,306420.0,0,0,0.0,306420.0,306420.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,8.64,4255.263999999998,92720.0,29244.0,92228.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2056.0
ampere_sgemm_128x32_sliced1x4_nn,128,2148007936.0,4299685888.0,0,0,0.0,4299685888.0,4299685888.0,6931456.0,2166784.0,0.7618458075407991,277086208.0,262144.0,287.488,4542.751999999999,1572864.0,2097152.0,2148007936.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8658944.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",129,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.304,4545.055999999999,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",130,0.0,131072.0,0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.272,4547.327999999999,0.0,131072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",131,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.272,4549.5999999999985,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",132,65536.0,131072.0,0,0,0.0,131072.0,131072.0,0.0,1536.0,0.0,524288.0,262144.0,2.656,4552.2559999999985,0.0,0.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16384.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",133,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.432,4554.687999999998,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",134,356364.0,909336.0,0,0,0.0,909336.0,909336.0,0.0,1024.0,0.0,262144.0,262144.0,2.336,4557.0239999999985,65536.0,131072.0,356364.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",135,65536.0,131072.0,0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.272,4559.2959999999985,0.0,0.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",136,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,2.72,4562.015999999999,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16384.0,8192.0
ampere_sgemm_128x32_sliced1x4_nn,137,2147483648.0,4298637312.0,0,0,0.0,4298637312.0,4298637312.0,6931456.0,2164736.0,0.7620173364854216,276824064.0,262144.0,286.528,4848.543999999999,1572864.0,2097152.0,2147483648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8650752.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",138,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,5632.0,0.0,278528.0,65536.0,2.688,4851.231999999999,81920.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8704.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",139,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.144,4853.375999999999,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",140,92228.0,306420.0,0,0,0.0,306420.0,306420.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,8.736,4862.111999999999,92720.0,29244.0,92228.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2056.0
ampere_sgemm_128x32_sliced1x4_nn,141,1610612736.0,3232235520.0,0,0,0.0,3232235520.0,3232235520.0,5458944.0,1628160.0,0.7702644126571305,207618048.0,786432.0,231.936,5094.047999999999,4718592.0,6291456.0,1610612736.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6488064.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",142,0.0,294912.0,0,0,0.0,294912.0,294912.0,0.0,16896.0,0.0,835584.0,196608.0,3.648,5097.695999999999,245760.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,26112.0,6144.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",143,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,2.72,5100.415999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",144,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,2.656,5103.071999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",145,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,2.816,5105.887999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",146,524288.0,17416192.0,0,0,0.0,17416192.0,17416192.0,136192.0,256.0,0.99812382739212,196608.0,65536.0,19.584,5125.471999999999,13172736.0,3194880.0,524288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
ampere_sgemm_128x32_sliced1x4_nn,147,536870912.0,1077411840.0,0,0,0.0,1077411840.0,1077411840.0,1819648.0,542720.0,0.7702644126571305,69206016.0,262144.0,76.192,5201.663999999999,1572864.0,2097152.0,536870912.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2162688.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",148,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,5632.0,0.0,278528.0,65536.0,2.496,5204.159999999999,81920.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8704.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",149,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.24,5206.399999999999,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",150,92228.0,306420.0,0,0,0.0,306420.0,306420.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,8.64,5215.039999999999,92720.0,29244.0,92228.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2056.0
ampere_sgemm_128x32_sliced1x4_nn,151,2148007936.0,4299685888.0,0,0,0.0,4299685888.0,4299685888.0,6931456.0,2166784.0,0.7618458075407991,277086208.0,262144.0,286.528,5501.567999999999,1572864.0,2097152.0,2148007936.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8658944.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",152,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.24,5503.807999999999,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",153,0.0,131072.0,0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.304,5506.111999999999,0.0,131072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",154,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.656,5508.767999999999,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",155,65536.0,131072.0,0,0,0.0,131072.0,131072.0,0.0,1536.0,0.0,524288.0,262144.0,2.784,5511.551999999999,0.0,0.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16384.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",156,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.432,5513.983999999999,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",157,356276.0,909160.0,0,0,0.0,909160.0,909160.0,0.0,1024.0,0.0,262144.0,262144.0,2.336,5516.319999999999,65536.0,131072.0,356276.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",158,65536.0,131072.0,0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.368,5518.687999999999,0.0,0.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",159,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,2.624,5521.311999999999,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16384.0,8192.0
ampere_sgemm_128x32_sliced1x4_nn,160,2147483648.0,4298637312.0,0,0,0.0,4298637312.0,4298637312.0,6931456.0,2164736.0,0.7620173364854216,276824064.0,262144.0,286.624,5807.935999999999,1572864.0,2097152.0,2147483648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8650752.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",161,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,5632.0,0.0,278528.0,65536.0,2.56,5810.495999999999,81920.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8704.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",162,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.176,5812.672,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",163,92228.0,306420.0,0,0,0.0,306420.0,306420.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,8.96,5821.632,92720.0,29244.0,92228.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2056.0
ampere_sgemm_128x32_sliced1x4_nn,164,1610612736.0,3232235520.0,0,0,0.0,3232235520.0,3232235520.0,5458944.0,1628160.0,0.7702644126571305,207618048.0,786432.0,230.272,6051.9039999999995,4718592.0,6291456.0,1610612736.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6488064.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",165,0.0,294912.0,0,0,0.0,294912.0,294912.0,0.0,16896.0,0.0,835584.0,196608.0,3.84,6055.744,245760.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,26112.0,6144.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",166,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,2.656,6058.4,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",167,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,2.688,6061.088,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",168,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,2.688,6063.776,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",169,524288.0,17416192.0,0,0,0.0,17416192.0,17416192.0,136192.0,256.0,0.99812382739212,196608.0,65536.0,19.68,6083.456,13172736.0,3194880.0,524288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
ampere_sgemm_128x32_sliced1x4_nn,170,536870912.0,1077411840.0,0,0,0.0,1077411840.0,1077411840.0,1819648.0,542720.0,0.7702644126571305,69206016.0,262144.0,76.32,6159.776,1572864.0,2097152.0,536870912.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2162688.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",171,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,5632.0,0.0,278528.0,65536.0,2.592,6162.3679999999995,81920.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8704.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",172,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.24,6164.607999999999,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",173,92228.0,306420.0,0,0,0.0,306420.0,306420.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,8.576,6173.183999999999,92720.0,29244.0,92228.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2056.0
ampere_sgemm_128x32_sliced1x4_nn,174,2148007936.0,4299685888.0,0,0,0.0,4299685888.0,4299685888.0,6931456.0,2166784.0,0.7618458075407991,277086208.0,262144.0,288.32,6461.503999999999,1572864.0,2097152.0,2148007936.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8658944.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",175,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.24,6463.743999999999,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",176,0.0,131072.0,0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.272,6466.015999999999,0.0,131072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",177,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.272,6468.287999999999,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",178,65536.0,131072.0,0,0,0.0,131072.0,131072.0,0.0,1536.0,0.0,524288.0,262144.0,2.592,6470.879999999998,0.0,0.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16384.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",179,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.272,6473.151999999998,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",180,356152.0,908912.0,0,0,0.0,908912.0,908912.0,0.0,1024.0,0.0,262144.0,262144.0,2.528,6475.6799999999985,65536.0,131072.0,356152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",181,65536.0,131072.0,0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.304,6477.983999999999,0.0,0.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",182,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,2.752,6480.735999999999,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16384.0,8192.0
ampere_sgemm_128x32_sliced1x4_nn,183,2147483648.0,4298637312.0,0,0,0.0,4298637312.0,4298637312.0,6931456.0,2164736.0,0.7620173364854216,276824064.0,262144.0,286.496,6767.231999999999,1572864.0,2097152.0,2147483648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8650752.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",184,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,5632.0,0.0,278528.0,65536.0,2.72,6769.951999999999,81920.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8704.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",185,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.176,6772.128,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",186,92228.0,306420.0,0,0,0.0,306420.0,306420.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,8.768,6780.896,92720.0,29244.0,92228.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2056.0
ampere_sgemm_128x32_sliced1x4_nn,187,1610612736.0,3232235520.0,0,0,0.0,3232235520.0,3232235520.0,5458944.0,1628160.0,0.7702644126571305,207618048.0,786432.0,229.984,7010.88,4718592.0,6291456.0,1610612736.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6488064.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",188,0.0,294912.0,0,0,0.0,294912.0,294912.0,0.0,16896.0,0.0,835584.0,196608.0,3.712,7014.592000000001,245760.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,26112.0,6144.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",189,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,2.72,7017.312000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",190,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,2.656,7019.968000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",191,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,2.688,7022.656000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",192,524288.0,17416192.0,0,0,0.0,17416192.0,17416192.0,136192.0,256.0,0.99812382739212,196608.0,65536.0,19.392,7042.048000000001,13172736.0,3194880.0,524288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
ampere_sgemm_128x32_sliced1x4_nn,193,536870912.0,1077411840.0,0,0,0.0,1077411840.0,1077411840.0,1819648.0,542720.0,0.7702644126571305,69206016.0,262144.0,76.192,7118.240000000001,1572864.0,2097152.0,536870912.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2162688.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",194,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,5632.0,0.0,278528.0,65536.0,2.56,7120.800000000001,81920.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8704.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",195,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.176,7122.9760000000015,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",196,92228.0,306420.0,0,0,0.0,306420.0,306420.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,8.608,7131.584000000002,92720.0,29244.0,92228.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2056.0
ampere_sgemm_128x32_sliced1x4_nn,197,2148007936.0,4299685888.0,0,0,0.0,4299685888.0,4299685888.0,6931456.0,2166784.0,0.7618458075407991,277086208.0,262144.0,286.976,7418.560000000001,1572864.0,2097152.0,2148007936.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8658944.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",198,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.4,7420.960000000001,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",199,0.0,131072.0,0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.368,7423.328000000001,0.0,131072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",200,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.336,7425.664000000002,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",201,65536.0,131072.0,0,0,0.0,131072.0,131072.0,0.0,1536.0,0.0,524288.0,262144.0,2.816,7428.480000000001,0.0,0.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16384.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",202,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.336,7430.816000000002,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",203,355808.0,908224.0,0,0,0.0,908224.0,908224.0,0.0,1024.0,0.0,262144.0,262144.0,2.496,7433.312000000002,65536.0,131072.0,355808.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",204,65536.0,131072.0,0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.24,7435.5520000000015,0.0,0.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",205,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,2.688,7438.240000000002,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16384.0,8192.0
ampere_sgemm_128x32_sliced1x4_nn,206,2147483648.0,4298637312.0,0,0,0.0,4298637312.0,4298637312.0,6931456.0,2164736.0,0.7620173364854216,276824064.0,262144.0,287.008,7725.248000000001,1572864.0,2097152.0,2147483648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8650752.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",207,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,5632.0,0.0,278528.0,65536.0,2.528,7727.776000000002,81920.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8704.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",208,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.24,7730.016000000001,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",209,92228.0,306420.0,0,0,0.0,306420.0,306420.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,8.608,7738.624000000002,92720.0,29244.0,92228.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2056.0
ampere_sgemm_128x32_sliced1x4_tn,210,6593445888.0,13231964160.0,0,0,0.0,13231964160.0,13231964160.0,22347552.0,6659248.0,0.7704245900961154,849166336.0,2466656.0,992.8,8731.424,19316736.0,25755648.0,6593445888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,26536448.0,77083.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",211,0.0,1005140.0,0,0,0.0,1005140.0,1005140.0,0.0,31420.0,0.0,3473664.0,828544.0,6.72,8738.144,804112.0,201028.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,108552.0,25892.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",212,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.664,8739.808,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",213,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,64.0,128.0,2.624,8742.432,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",214,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,8744.480000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",215,0.0,201028.0,0,0,0.0,201028.0,201028.0,0.0,3158.0,0.0,804128.0,804128.0,3.04,8747.520000000002,0.0,201028.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25129.0,25129.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",216,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,8749.216000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",217,0.0,0.0,0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813024.0,60096.0,3.776,8752.992000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25407.0,1878.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",218,0.0,0.0,0,0,0.0,0.0,0.0,14800.0,82608.0,0.15193823915900131,5134592.0,0.0,5.44,8758.432000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160456.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",219,0.0,0.0,0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813024.0,58368.0,3.744,8762.176000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25407.0,1824.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",220,0.0,0.0,0,0,0.0,0.0,0.0,14800.0,83008.0,0.1513168656960576,5134592.0,0.0,5.376,8767.552000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160456.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",221,0.0,0.0,0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813024.0,57152.0,3.648,8771.200000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25407.0,1786.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",222,0.0,0.0,0,0,0.0,0.0,0.0,14800.0,83208.0,0.1510080809729818,5134592.0,0.0,5.472,8776.672000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160456.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",223,0.0,0.0,0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813024.0,56704.0,3.776,8780.448000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25407.0,1772.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",224,0.0,0.0,0,0,0.0,0.0,0.0,14800.0,82808.0,0.1516269158265716,5134592.0,128.0,5.472,8785.920000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160456.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",225,0.0,0.0,0,0,0.0,0.0,0.0,0.0,21.0,0.0,6432.0,800.0,2.464,8788.384000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,201.0,25.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",226,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.728,8790.112000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",227,0.0,0.0,0,0,0.0,0.0,0.0,497.0,22.0,0.9576107899807321,800.0,0.0,3.68,8793.792000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",228,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.696,8795.488000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",229,0.0,0.0,0,0,0.0,0.0,0.0,497.0,22.0,0.9576107899807321,800.0,0.0,3.616,8799.104000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",230,0.0,0.0,0,0,0.0,0.0,0.0,74688.0,13020.0,0.8515528800109454,831456.0,8288.0,6.208,8805.312000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25983.0,259.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",231,0.0,0.0,0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,544.0,6.464,8811.776000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,80.0,17.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",232,0.0,0.0,0,0,0.0,0.0,0.0,0.0,18849.0,0.0,814496.0,87680.0,3.712,8815.488000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25453.0,2740.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",233,0.0,0.0,0,0,0.0,0.0,0.0,0.0,4737.0,0.0,1005184.0,0.0,3.392,8818.880000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,31412.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",234,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6283.0,0.0,0.0,1608224.0,2.688,8821.568000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,50257.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",235,0.0,0.0,0,0,0.0,0.0,0.0,98304.0,6283.0,0.9399256121697726,804128.0,0.0,4.288,8825.856000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25129.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",236,0.0,0.0,0,0,0.0,0.0,0.0,156.0,64.0,0.7090909090909091,8192.0,0.0,2.208,8828.064000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",237,0.0,0.0,0,0,0.0,0.0,0.0,79842.0,29741.0,0.7285984139875711,3099840.0,2050016.0,10.592,8838.656000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96870.0,64063.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",238,0.0,0.0,0,0,0.0,0.0,0.0,23142.0,36279.0,0.38945827232796487,3089856.0,2479936.0,8.576,8847.232000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96558.0,77498.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",239,0.0,0.0,0,0,0.0,0.0,0.0,23883.0,35289.0,0.4036199553843034,3100608.0,1888992.0,9.44,8856.672000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96894.0,59031.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",240,0.0,0.0,0,0,0.0,0.0,0.0,22983.0,35134.0,0.39546088063733503,3078848.0,2479936.0,9.184,8865.856000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96214.0,77498.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",241,0.0,0.0,0,0,0.0,0.0,0.0,14336.0,6283.0,0.6952810514573937,1608224.0,0.0,4.832,8870.688000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,50257.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",242,0.0,0.0,0,0,0.0,0.0,0.0,39.0,16.0,0.7090909090909091,2048.0,0.0,2.24,8872.928000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",243,0.0,0.0,0,0,0.0,0.0,0.0,20059.0,18037.0,0.5265382192356153,2104608.0,1385856.0,8.0,8880.928000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,65769.0,43308.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",244,0.0,0.0,0,0,0.0,0.0,0.0,0.0,25132.0,0.0,2427968.0,2412352.0,5.28,8886.208000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75874.0,75386.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",245,2814392.0,6655044.0,0,0,0.0,6655044.0,6655044.0,528.0,6704.0,0.07300884955752213,2283136.0,753728.0,23.968,8910.176000000003,825232.0,201028.0,2814392.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,71348.0,23554.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",246,0.0,1024200.0,0,0,0.0,1024200.0,1024200.0,112284.0,12568.0,0.8993368147887099,804480.0,627424.0,72.032,8982.208000000002,1024200.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25140.0,19607.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",247,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3158.0,0.0,804128.0,200800.0,3.168,8985.376000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25129.0,6275.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",248,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,1.952,8987.328000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",249,0.0,0.0,0,0,0.0,0.0,0.0,0.0,18849.0,0.0,1809280.0,87104.0,7.936,8995.264000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,56540.0,2722.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",250,0.0,0.0,0,0,0.0,0.0,0.0,0.0,4737.0,0.0,1005184.0,0.0,3.392,8998.656,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,31412.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",251,2814392.0,6655044.0,0,0,0.0,6655044.0,6655044.0,528.0,6704.0,0.07300884955752213,2275712.0,752960.0,23.84,9022.496000000001,825232.0,201028.0,2814392.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,71116.0,23530.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",252,0.0,0.0,0,0,0.0,0.0,0.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,6.432,9028.928000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",253,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,9031.072000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",254,0.0,0.0,0,0,0.0,0.0,0.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,6.208,9037.280000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",255,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.24,9039.520000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",256,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.176,9041.696000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",257,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.104,9044.800000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",258,0.0,220484.0,0,0,0.0,220484.0,220484.0,320.0,1582.0,0.16824395373291273,804224.0,128.0,11.84,9056.640000000001,220484.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25132.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",259,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.368,9059.008000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",260,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.744,9062.752000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",261,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,9064.768000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",262,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.976,9067.744000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",263,1769472.0,3941000.0,0,0,0.0,3941000.0,3941000.0,0.0,6283.0,0.0,0.0,804128.0,4.032,9071.776000000002,0.0,402056.0,1769472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,25129.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",264,1005140.0,2010280.0,0,0,0.0,2010280.0,2010280.0,0.0,4737.0,0.0,1608256.0,0.0,4.768,9076.544000000002,0.0,0.0,1005140.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,50258.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",265,0.0,0.0,0,0,0.0,0.0,0.0,640.0,1582.0,0.28802880288028804,804640.0,128.0,15.616,9092.160000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25145.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",266,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.24,9094.400000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",267,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,9096.416000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",268,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.208,9098.624000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",269,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.112,9100.736,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",270,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,64.0,128.0,2.592,9103.328000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",271,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.76,9105.088000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",272,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,9106.784000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",273,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.048,9108.832000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",274,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,9110.528000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",275,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,32.0,2.304,9112.832000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",276,0.0,0.0,0,0,0.0,0.0,0.0,0.0,5.0,0.0,32.0,32.0,4.608,9117.440000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",277,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.08,9119.520000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",278,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,9121.600000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",279,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.816,9124.416000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",280,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.2,9127.616000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",281,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,9129.696000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",282,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.176,9131.872000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",283,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,32.0,3.264,9135.136000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",284,0.0,0.0,0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,64.0,32.0,2.56,9137.696000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",285,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.08,9139.776000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",286,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,2.048,9141.824000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",287,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,0.0,2.08,9143.904000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",288,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,2.24,9146.144000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",289,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,66560.0,65536.0,5.44,9151.584000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2080.0,2048.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",290,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,17408.0,65536.0,3.52,9155.104000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,544.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",291,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.144,9157.248000000003,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",292,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,2.08,9159.328000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",293,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,9162.592000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",294,92228.0,306420.0,0,0,0.0,306420.0,306420.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,8.576,9171.168000000001,92720.0,29244.0,92228.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2056.0
ampere_sgemm_128x32_sliced1x4_nn,295,1610612736.0,3232235520.0,0,0,0.0,3232235520.0,3232235520.0,5458944.0,1628160.0,0.7702644126571305,207618048.0,786432.0,229.44,9400.608000000002,4718592.0,6291456.0,1610612736.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6488064.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",296,0.0,294912.0,0,0,0.0,294912.0,294912.0,0.0,16896.0,0.0,835584.0,196608.0,3.776,9404.384000000002,245760.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,26112.0,6144.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",297,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2048.0,0.0,131072.0,131072.0,4.032,9408.416000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",298,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2048.0,0.0,131072.0,131072.0,4.032,9412.448,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,4096.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",299,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,2.688,9415.136,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",300,524288.0,17432576.0,0,0,0.0,17432576.0,17432576.0,136192.0,256.0,0.99812382739212,327680.0,65536.0,20.704,9435.84,13189120.0,3194880.0,524288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,10240.0,2048.0
ampere_sgemm_128x32_sliced1x4_nn,301,536870912.0,1077411840.0,0,0,0.0,1077411840.0,1077411840.0,1819648.0,542720.0,0.7702644126571305,69206016.0,262144.0,76.384,9512.224,1572864.0,2097152.0,536870912.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2162688.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",302,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,5632.0,0.0,278528.0,65536.0,2.528,9514.752,81920.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8704.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",303,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.176,9516.928,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",304,92228.0,306420.0,0,0,0.0,306420.0,306420.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,8.608,9525.536,92720.0,29244.0,92228.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2056.0
ampere_sgemm_128x32_sliced1x4_nn,305,2148007936.0,4299685888.0,0,0,0.0,4299685888.0,4299685888.0,6931456.0,2166784.0,0.7618458075407991,277086208.0,262144.0,287.328,9812.864,1572864.0,2097152.0,2148007936.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8658944.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",306,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.24,9815.104,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",307,0.0,131072.0,0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.272,9817.376,0.0,131072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",308,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.24,9819.616,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",309,65536.0,131072.0,0,0,0.0,131072.0,131072.0,0.0,1536.0,0.0,524288.0,262144.0,2.784,9822.4,0.0,0.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16384.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",310,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.272,9824.672,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",311,356318.0,909244.0,0,0,0.0,909244.0,909244.0,0.0,1024.0,0.0,262144.0,262144.0,2.464,9827.136,65536.0,131072.0,356318.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",312,65536.0,131072.0,0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.24,9829.376,0.0,0.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",313,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,2.752,9832.128,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16384.0,8192.0
ampere_sgemm_128x32_sliced1x4_nn,314,2147483648.0,4298637312.0,0,0,0.0,4298637312.0,4298637312.0,6931456.0,2164736.0,0.7620173364854216,276824064.0,262144.0,286.688,10118.816,1572864.0,2097152.0,2147483648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8650752.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",315,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,5632.0,0.0,278528.0,65536.0,2.56,10121.376,81920.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8704.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",316,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.24,10123.616,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",317,92228.0,306420.0,0,0,0.0,306420.0,306420.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,8.736,10132.352,92720.0,29244.0,92228.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2056.0
ampere_sgemm_128x32_sliced1x4_nn,318,1610612736.0,3232235520.0,0,0,0.0,3232235520.0,3232235520.0,5458944.0,1628160.0,0.7702644126571305,207618048.0,786432.0,231.232,10363.584,4718592.0,6291456.0,1610612736.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6488064.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",319,0.0,294912.0,0,0,0.0,294912.0,294912.0,0.0,16896.0,0.0,835584.0,196608.0,3.712,10367.296,245760.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,26112.0,6144.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",320,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2048.0,0.0,131072.0,131072.0,4.032,10371.328,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",321,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2048.0,0.0,131072.0,131072.0,4.032,10375.359999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,4096.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",322,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,2.816,10378.176,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",323,524288.0,17432576.0,0,0,0.0,17432576.0,17432576.0,136192.0,256.0,0.99812382739212,327680.0,65536.0,20.0,10398.176,13189120.0,3194880.0,524288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,10240.0,2048.0
ampere_sgemm_128x32_sliced1x4_nn,324,536870912.0,1077411840.0,0,0,0.0,1077411840.0,1077411840.0,1819648.0,542720.0,0.7702644126571305,69206016.0,262144.0,76.0,10474.176,1572864.0,2097152.0,536870912.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2162688.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",325,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,5632.0,0.0,278528.0,65536.0,2.56,10476.735999999999,81920.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8704.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",326,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.144,10478.88,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",327,92228.0,306420.0,0,0,0.0,306420.0,306420.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,8.8,10487.679999999998,92720.0,29244.0,92228.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2056.0
ampere_sgemm_128x32_sliced1x4_nn,328,2148007936.0,4299685888.0,0,0,0.0,4299685888.0,4299685888.0,6931456.0,2166784.0,0.7618458075407991,277086208.0,262144.0,286.88,10774.559999999998,1572864.0,2097152.0,2148007936.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8658944.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",329,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.24,10776.799999999997,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",330,0.0,131072.0,0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.208,10779.007999999998,0.0,131072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",331,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.272,10781.279999999999,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",332,65536.0,131072.0,0,0,0.0,131072.0,131072.0,0.0,1536.0,0.0,524288.0,262144.0,2.656,10783.936,0.0,0.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16384.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",333,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.304,10786.24,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",334,356085.0,908778.0,0,0,0.0,908778.0,908778.0,0.0,1024.0,0.0,262144.0,262144.0,2.368,10788.608,65536.0,131072.0,356085.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",335,65536.0,131072.0,0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.272,10790.880000000001,0.0,0.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",336,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,2.656,10793.536000000002,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16384.0,8192.0
ampere_sgemm_128x32_sliced1x4_nn,337,2147483648.0,4298637312.0,0,0,0.0,4298637312.0,4298637312.0,6931456.0,2164736.0,0.7620173364854216,276824064.0,262144.0,286.72,11080.256000000001,1572864.0,2097152.0,2147483648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8650752.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",338,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,5632.0,0.0,278528.0,65536.0,2.528,11082.784000000001,81920.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8704.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",339,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.144,11084.928000000002,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",340,92228.0,306420.0,0,0,0.0,306420.0,306420.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,8.576,11093.504,92720.0,29244.0,92228.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2056.0
ampere_sgemm_128x32_sliced1x4_nn,341,1610612736.0,3232235520.0,0,0,0.0,3232235520.0,3232235520.0,5458944.0,1628160.0,0.7702644126571305,207618048.0,786432.0,233.312,11326.816,4718592.0,6291456.0,1610612736.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6488064.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",342,0.0,294912.0,0,0,0.0,294912.0,294912.0,0.0,16896.0,0.0,835584.0,196608.0,3.776,11330.592,245760.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,26112.0,6144.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",343,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2048.0,0.0,131072.0,131072.0,4.032,11334.624,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",344,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2048.0,0.0,131072.0,131072.0,4.064,11338.688,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,4096.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",345,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,2.688,11341.376,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",346,524288.0,17432576.0,0,0,0.0,17432576.0,17432576.0,136192.0,256.0,0.99812382739212,327680.0,65536.0,19.904,11361.28,13189120.0,3194880.0,524288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,10240.0,2048.0
ampere_sgemm_128x32_sliced1x4_nn,347,536870912.0,1077411840.0,0,0,0.0,1077411840.0,1077411840.0,1819648.0,542720.0,0.7702644126571305,69206016.0,262144.0,76.352,11437.632000000001,1572864.0,2097152.0,536870912.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2162688.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",348,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,5632.0,0.0,278528.0,65536.0,2.72,11440.352,81920.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8704.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",349,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.208,11442.560000000001,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",350,92228.0,306420.0,0,0,0.0,306420.0,306420.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,8.512,11451.072000000002,92720.0,29244.0,92228.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2056.0
ampere_sgemm_128x32_sliced1x4_nn,351,2148007936.0,4299685888.0,0,0,0.0,4299685888.0,4299685888.0,6931456.0,2166784.0,0.7618458075407991,277086208.0,262144.0,287.36,11738.432000000003,1572864.0,2097152.0,2148007936.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8658944.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",352,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.336,11740.768000000002,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",353,0.0,131072.0,0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.272,11743.040000000003,0.0,131072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",354,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.464,11745.504000000003,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",355,65536.0,131072.0,0,0,0.0,131072.0,131072.0,0.0,1536.0,0.0,524288.0,262144.0,2.624,11748.128000000002,0.0,0.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16384.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",356,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.464,11750.592000000002,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",357,355899.0,908406.0,0,0,0.0,908406.0,908406.0,0.0,1024.0,0.0,262144.0,262144.0,2.368,11752.960000000003,65536.0,131072.0,355899.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",358,65536.0,131072.0,0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.272,11755.232000000004,0.0,0.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",359,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,2.816,11758.048000000004,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16384.0,8192.0
ampere_sgemm_128x32_sliced1x4_nn,360,2147483648.0,4298637312.0,0,0,0.0,4298637312.0,4298637312.0,6931456.0,2164736.0,0.7620173364854216,276824064.0,262144.0,286.464,12044.512000000004,1572864.0,2097152.0,2147483648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8650752.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",361,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,5632.0,0.0,278528.0,65536.0,2.496,12047.008000000003,81920.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8704.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",362,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.176,12049.184000000003,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",363,92228.0,306420.0,0,0,0.0,306420.0,306420.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,8.64,12057.824000000002,92720.0,29244.0,92228.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2056.0
ampere_sgemm_128x32_sliced1x4_nn,364,1610612736.0,3232235520.0,0,0,0.0,3232235520.0,3232235520.0,5458944.0,1628160.0,0.7702644126571305,207618048.0,786432.0,227.488,12285.312000000002,4718592.0,6291456.0,1610612736.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6488064.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",365,0.0,294912.0,0,0,0.0,294912.0,294912.0,0.0,16896.0,0.0,835584.0,196608.0,3.68,12288.992000000002,245760.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,26112.0,6144.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",366,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2048.0,0.0,131072.0,131072.0,4.0,12292.992000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",367,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2048.0,0.0,131072.0,131072.0,4.032,12297.024000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,4096.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",368,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,2.848,12299.872000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",369,524288.0,17432576.0,0,0,0.0,17432576.0,17432576.0,136192.0,256.0,0.99812382739212,327680.0,65536.0,19.968,12319.840000000002,13189120.0,3194880.0,524288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,10240.0,2048.0
ampere_sgemm_128x32_sliced1x4_nn,370,536870912.0,1077411840.0,0,0,0.0,1077411840.0,1077411840.0,1819648.0,542720.0,0.7702644126571305,69206016.0,262144.0,76.096,12395.936000000002,1572864.0,2097152.0,536870912.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2162688.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",371,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,5632.0,0.0,278528.0,65536.0,2.528,12398.464000000002,81920.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8704.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",372,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.144,12400.608000000002,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",373,92228.0,306420.0,0,0,0.0,306420.0,306420.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,8.704,12409.312000000002,92720.0,29244.0,92228.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2056.0
ampere_sgemm_128x32_sliced1x4_nn,374,2148007936.0,4299685888.0,0,0,0.0,4299685888.0,4299685888.0,6931456.0,2166784.0,0.7618458075407991,277086208.0,262144.0,287.744,12697.056000000002,1572864.0,2097152.0,2148007936.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8658944.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",375,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.24,12699.296000000002,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",376,0.0,131072.0,0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.272,12701.568000000003,0.0,131072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",377,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.24,12703.808000000003,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",378,65536.0,131072.0,0,0,0.0,131072.0,131072.0,0.0,1536.0,0.0,524288.0,262144.0,2.72,12706.528000000002,0.0,0.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16384.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",379,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.432,12708.960000000003,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",380,356329.0,909266.0,0,0,0.0,909266.0,909266.0,0.0,1024.0,0.0,262144.0,262144.0,2.4,12711.360000000002,65536.0,131072.0,356329.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",381,65536.0,131072.0,0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.272,12713.632000000003,0.0,0.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",382,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,2.784,12716.416000000003,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16384.0,8192.0
ampere_sgemm_128x32_sliced1x4_nn,383,2147483648.0,4298637312.0,0,0,0.0,4298637312.0,4298637312.0,6931456.0,2164736.0,0.7620173364854216,276824064.0,262144.0,287.232,13003.648000000003,1572864.0,2097152.0,2147483648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8650752.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",384,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,5632.0,0.0,278528.0,65536.0,2.56,13006.208000000002,81920.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8704.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",385,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.144,13008.352000000003,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",386,92228.0,306420.0,0,0,0.0,306420.0,306420.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,8.512,13016.864000000003,92720.0,29244.0,92228.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2056.0
ampere_sgemm_128x32_sliced1x4_nn,387,1610612736.0,3232235520.0,0,0,0.0,3232235520.0,3232235520.0,5458944.0,1628160.0,0.7702644126571305,207618048.0,786432.0,231.488,13248.352000000003,4718592.0,6291456.0,1610612736.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6488064.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",388,0.0,294912.0,0,0,0.0,294912.0,294912.0,0.0,16896.0,0.0,835584.0,196608.0,3.84,13252.192000000003,245760.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,26112.0,6144.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",389,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2048.0,0.0,131072.0,131072.0,4.032,13256.224000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",390,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2048.0,0.0,131072.0,131072.0,4.064,13260.288000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,4096.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",391,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,2.656,13262.944000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",392,524288.0,17432576.0,0,0,0.0,17432576.0,17432576.0,136192.0,256.0,0.99812382739212,327680.0,65536.0,19.648,13282.592000000002,13189120.0,3194880.0,524288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,10240.0,2048.0
ampere_sgemm_128x32_sliced1x4_nn,393,536870912.0,1077411840.0,0,0,0.0,1077411840.0,1077411840.0,1819648.0,542720.0,0.7702644126571305,69206016.0,262144.0,75.968,13358.560000000003,1572864.0,2097152.0,536870912.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2162688.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",394,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,5632.0,0.0,278528.0,65536.0,2.496,13361.056000000002,81920.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8704.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",395,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.176,13363.232000000002,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",396,92228.0,306420.0,0,0,0.0,306420.0,306420.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,8.64,13371.872000000001,92720.0,29244.0,92228.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2056.0
ampere_sgemm_128x32_sliced1x4_nn,397,2148007936.0,4299685888.0,0,0,0.0,4299685888.0,4299685888.0,6931456.0,2166784.0,0.7618458075407991,277086208.0,262144.0,286.784,13658.656,1572864.0,2097152.0,2148007936.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8658944.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",398,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.272,13660.928000000002,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",399,0.0,131072.0,0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.432,13663.360000000002,0.0,131072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",400,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.272,13665.632000000003,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",401,65536.0,131072.0,0,0,0.0,131072.0,131072.0,0.0,1536.0,0.0,524288.0,262144.0,2.592,13668.224000000004,0.0,0.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16384.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",402,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.272,13670.496000000005,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",403,356220.0,909048.0,0,0,0.0,909048.0,909048.0,0.0,1024.0,0.0,262144.0,262144.0,2.336,13672.832000000004,65536.0,131072.0,356220.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",404,65536.0,131072.0,0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.272,13675.104000000005,0.0,0.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",405,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,2.848,13677.952000000005,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16384.0,8192.0
ampere_sgemm_128x32_sliced1x4_nn,406,2147483648.0,4298637312.0,0,0,0.0,4298637312.0,4298637312.0,6931456.0,2164736.0,0.7620173364854216,276824064.0,262144.0,287.136,13965.088000000005,1572864.0,2097152.0,2147483648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8650752.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",407,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,5632.0,0.0,278528.0,65536.0,2.528,13967.616000000005,81920.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8704.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",408,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.176,13969.792000000005,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",409,92228.0,306420.0,0,0,0.0,306420.0,306420.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,8.704,13978.496000000005,92720.0,29244.0,92228.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2056.0
ampere_sgemm_128x32_sliced1x4_nn,410,1610612736.0,3232235520.0,0,0,0.0,3232235520.0,3232235520.0,5458944.0,1628160.0,0.7702644126571305,207618048.0,786432.0,233.696,14212.192000000005,4718592.0,6291456.0,1610612736.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6488064.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",411,0.0,294912.0,0,0,0.0,294912.0,294912.0,0.0,16896.0,0.0,835584.0,196608.0,3.84,14216.032000000005,245760.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,26112.0,6144.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",412,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2048.0,0.0,131072.0,131072.0,4.032,14220.064000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",413,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2048.0,0.0,131072.0,131072.0,4.064,14224.128000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,4096.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",414,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,2.688,14226.816000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",415,524288.0,17432576.0,0,0,0.0,17432576.0,17432576.0,136192.0,256.0,0.99812382739212,327680.0,65536.0,19.552,14246.368000000004,13189120.0,3194880.0,524288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,10240.0,2048.0
ampere_sgemm_128x32_sliced1x4_nn,416,536870912.0,1077411840.0,0,0,0.0,1077411840.0,1077411840.0,1819648.0,542720.0,0.7702644126571305,69206016.0,262144.0,76.0,14322.368000000004,1572864.0,2097152.0,536870912.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2162688.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",417,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,5632.0,0.0,278528.0,65536.0,2.624,14324.992000000004,81920.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8704.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",418,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.08,14327.072000000004,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",419,92228.0,306420.0,0,0,0.0,306420.0,306420.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,8.576,14335.648000000003,92720.0,29244.0,92228.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2056.0
ampere_sgemm_128x32_sliced1x4_nn,420,2148007936.0,4299685888.0,0,0,0.0,4299685888.0,4299685888.0,6931456.0,2166784.0,0.7618458075407991,277086208.0,262144.0,288.672,14624.320000000003,1572864.0,2097152.0,2148007936.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8658944.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",421,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.368,14626.688000000004,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",422,0.0,131072.0,0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.336,14629.024000000003,0.0,131072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",423,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.432,14631.456000000004,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",424,65536.0,131072.0,0,0,0.0,131072.0,131072.0,0.0,1536.0,0.0,524288.0,262144.0,2.752,14634.208000000004,0.0,0.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16384.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",425,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.432,14636.640000000005,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",426,356373.0,909354.0,0,0,0.0,909354.0,909354.0,0.0,1024.0,0.0,262144.0,262144.0,2.272,14638.912000000006,65536.0,131072.0,356373.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",427,65536.0,131072.0,0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.208,14641.120000000006,0.0,0.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",428,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,2.88,14644.000000000005,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16384.0,8192.0
ampere_sgemm_128x32_sliced1x4_nn,429,2147483648.0,4298637312.0,0,0,0.0,4298637312.0,4298637312.0,6931456.0,2164736.0,0.7620173364854216,276824064.0,262144.0,287.104,14931.104000000005,1572864.0,2097152.0,2147483648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8650752.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",430,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,5632.0,0.0,278528.0,65536.0,2.592,14933.696000000005,81920.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8704.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",431,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.144,14935.840000000006,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",432,92228.0,306420.0,0,0,0.0,306420.0,306420.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,8.64,14944.480000000005,92720.0,29244.0,92228.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2056.0
ampere_sgemm_128x32_sliced1x4_nn,433,1610612736.0,3232235520.0,0,0,0.0,3232235520.0,3232235520.0,5458944.0,1628160.0,0.7702644126571305,207618048.0,786432.0,230.976,15175.456000000006,4718592.0,6291456.0,1610612736.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6488064.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",434,0.0,294912.0,0,0,0.0,294912.0,294912.0,0.0,16896.0,0.0,835584.0,196608.0,3.648,15179.104000000005,245760.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,26112.0,6144.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",435,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2048.0,0.0,131072.0,131072.0,3.968,15183.072000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",436,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2048.0,0.0,131072.0,131072.0,4.064,15187.136000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,4096.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",437,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,2.72,15189.856000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",438,524288.0,17432576.0,0,0,0.0,17432576.0,17432576.0,136192.0,256.0,0.99812382739212,327680.0,65536.0,20.096,15209.952000000005,13189120.0,3194880.0,524288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,10240.0,2048.0
ampere_sgemm_128x32_sliced1x4_nn,439,536870912.0,1077411840.0,0,0,0.0,1077411840.0,1077411840.0,1819648.0,542720.0,0.7702644126571305,69206016.0,262144.0,76.736,15286.688000000006,1572864.0,2097152.0,536870912.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2162688.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",440,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,5632.0,0.0,278528.0,65536.0,2.72,15289.408000000005,81920.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8704.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",441,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.176,15291.584000000004,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",442,92228.0,306420.0,0,0,0.0,306420.0,306420.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,8.544,15300.128000000004,92720.0,29244.0,92228.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2056.0
ampere_sgemm_128x32_sliced1x4_nn,443,2148007936.0,4299685888.0,0,0,0.0,4299685888.0,4299685888.0,6931456.0,2166784.0,0.7618458075407991,277086208.0,262144.0,287.52,15587.648000000005,1572864.0,2097152.0,2148007936.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8658944.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",444,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.304,15589.952000000005,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",445,0.0,131072.0,0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.304,15592.256000000005,0.0,131072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",446,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.24,15594.496000000005,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",447,65536.0,131072.0,0,0,0.0,131072.0,131072.0,0.0,1536.0,0.0,524288.0,262144.0,2.752,15597.248000000005,0.0,0.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16384.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",448,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.304,15599.552000000005,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",449,356266.0,909140.0,0,0,0.0,909140.0,909140.0,0.0,1024.0,0.0,262144.0,262144.0,2.304,15601.856000000005,65536.0,131072.0,356266.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",450,65536.0,131072.0,0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.208,15604.064000000006,0.0,0.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",451,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,2.816,15606.880000000006,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16384.0,8192.0
ampere_sgemm_128x32_sliced1x4_nn,452,2147483648.0,4298637312.0,0,0,0.0,4298637312.0,4298637312.0,6931456.0,2164736.0,0.7620173364854216,276824064.0,262144.0,288.0,15894.880000000006,1572864.0,2097152.0,2147483648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8650752.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",453,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,5632.0,0.0,278528.0,65536.0,2.656,15897.536000000007,81920.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8704.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",454,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.272,15899.808000000008,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",455,92228.0,306420.0,0,0,0.0,306420.0,306420.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,8.768,15908.576000000008,92720.0,29244.0,92228.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2056.0
ampere_sgemm_128x32_sliced1x4_nn,456,1610612736.0,3232235520.0,0,0,0.0,3232235520.0,3232235520.0,5458944.0,1628160.0,0.7702644126571305,207618048.0,786432.0,230.432,16139.008000000009,4718592.0,6291456.0,1610612736.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6488064.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",457,0.0,294912.0,0,0,0.0,294912.0,294912.0,0.0,16896.0,0.0,835584.0,196608.0,3.616,16142.624000000009,245760.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,26112.0,6144.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",458,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2048.0,0.0,131072.0,131072.0,3.968,16146.59200000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",459,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2048.0,0.0,131072.0,131072.0,4.032,16150.624000000009,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,4096.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",460,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,2.688,16153.312000000009,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",461,524288.0,17432576.0,0,0,0.0,17432576.0,17432576.0,136192.0,256.0,0.99812382739212,327680.0,65536.0,19.744,16173.05600000001,13189120.0,3194880.0,524288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,10240.0,2048.0
ampere_sgemm_128x32_sliced1x4_nn,462,536870912.0,1077411840.0,0,0,0.0,1077411840.0,1077411840.0,1819648.0,542720.0,0.7702644126571305,69206016.0,262144.0,76.416,16249.472000000009,1572864.0,2097152.0,536870912.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2162688.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",463,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,5632.0,0.0,278528.0,65536.0,2.496,16251.968000000008,81920.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8704.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",464,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.176,16254.144000000008,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",465,92228.0,306420.0,0,0,0.0,306420.0,306420.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,8.736,16262.880000000008,92720.0,29244.0,92228.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2056.0
ampere_sgemm_128x32_sliced1x4_nn,466,2148007936.0,4299685888.0,0,0,0.0,4299685888.0,4299685888.0,6931456.0,2166784.0,0.7618458075407991,277086208.0,262144.0,286.976,16549.856000000007,1572864.0,2097152.0,2148007936.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8658944.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",467,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.24,16552.09600000001,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",468,0.0,131072.0,0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.304,16554.40000000001,0.0,131072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",469,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.304,16556.70400000001,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",470,65536.0,131072.0,0,0,0.0,131072.0,131072.0,0.0,1536.0,0.0,524288.0,262144.0,2.656,16559.360000000008,0.0,0.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16384.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",471,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.24,16561.60000000001,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",472,356055.0,908718.0,0,0,0.0,908718.0,908718.0,0.0,1024.0,0.0,262144.0,262144.0,2.528,16564.128000000008,65536.0,131072.0,356055.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",473,65536.0,131072.0,0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.272,16566.40000000001,0.0,0.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",474,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,2.656,16569.056000000008,0.0,65536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16384.0,8192.0
ampere_sgemm_128x32_sliced1x4_nn,475,2147483648.0,4298637312.0,0,0,0.0,4298637312.0,4298637312.0,6931456.0,2164736.0,0.7620173364854216,276824064.0,262144.0,286.464,16855.520000000008,1572864.0,2097152.0,2147483648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8650752.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",476,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,5632.0,0.0,278528.0,65536.0,2.528,16858.048000000006,81920.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8704.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",477,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.208,16860.256000000005,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",478,92228.0,306420.0,0,0,0.0,306420.0,306420.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,8.64,16868.896000000004,92720.0,29244.0,92228.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2056.0
ampere_sgemm_128x32_sliced1x4_tn,479,6593445888.0,13231964160.0,0,0,0.0,13231964160.0,13231964160.0,22347552.0,6659248.0,0.7704245900961154,849166336.0,2464896.0,993.312,17862.208000000006,19316736.0,25755648.0,6593445888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,26536448.0,77028.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",480,0.0,1005140.0,0,0,0.0,1005140.0,1005140.0,0.0,31420.0,0.0,3467264.0,822560.0,6.976,17869.184000000005,804112.0,201028.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,108352.0,25705.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",481,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,17870.880000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",482,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,96.0,160.0,2.528,17873.408000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",483,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,17875.456000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",484,0.0,201028.0,0,0,0.0,201028.0,201028.0,0.0,3158.0,0.0,804128.0,804128.0,3.104,17878.56,0.0,201028.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25129.0,25129.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",485,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,17880.256,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",486,0.0,0.0,0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813024.0,57088.0,3.872,17884.128,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25407.0,1784.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",487,0.0,0.0,0,0,0.0,0.0,0.0,14800.0,82608.0,0.15193823915900131,5134592.0,0.0,5.504,17889.632,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160456.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",488,0.0,0.0,0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813024.0,56128.0,3.744,17893.376,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25407.0,1754.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",489,0.0,0.0,0,0,0.0,0.0,0.0,14800.0,82958.0,0.15139425929335706,5134592.0,0.0,5.536,17898.912,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160456.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",490,0.0,0.0,0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813024.0,56576.0,3.68,17902.592,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25407.0,1768.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",491,0.0,0.0,0,0,0.0,0.0,0.0,14800.0,82808.0,0.1516269158265716,5134592.0,0.0,5.792,17908.384000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160456.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",492,0.0,0.0,0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813024.0,55296.0,3.968,17912.352000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25407.0,1728.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",493,0.0,0.0,0,0,0.0,0.0,0.0,14800.0,82858.0,0.15154928423682648,5134592.0,128.0,5.664,17918.016000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160456.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",494,0.0,0.0,0,0,0.0,0.0,0.0,0.0,21.0,0.0,6432.0,800.0,2.432,17920.448000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,201.0,25.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",495,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.696,17922.144000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",496,0.0,0.0,0,0,0.0,0.0,0.0,497.0,22.0,0.9576107899807321,800.0,0.0,3.68,17925.824000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",497,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.632,17927.456000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",498,0.0,0.0,0,0,0.0,0.0,0.0,497.0,22.0,0.9576107899807321,800.0,0.0,3.648,17931.104000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",499,0.0,0.0,0,0,0.0,0.0,0.0,58272.0,13018.0,0.8173937438630944,831456.0,9216.0,6.08,17937.18400000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25983.0,288.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",500,0.0,0.0,0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,544.0,6.72,17943.90400000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,80.0,17.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",501,0.0,0.0,0,0,0.0,0.0,0.0,0.0,18849.0,0.0,814496.0,88416.0,4.032,17947.93600000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25453.0,2763.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",502,0.0,0.0,0,0,0.0,0.0,0.0,0.0,4737.0,0.0,1005184.0,0.0,3.296,17951.232000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,31412.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",503,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6283.0,0.0,0.0,1608224.0,2.656,17953.888000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,50257.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",504,0.0,0.0,0,0,0.0,0.0,0.0,98304.0,6283.0,0.9399256121697726,804128.0,0.0,4.512,17958.400000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25129.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",505,0.0,0.0,0,0,0.0,0.0,0.0,156.0,64.0,0.7090909090909091,8192.0,0.0,2.208,17960.608000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",506,0.0,0.0,0,0,0.0,0.0,0.0,79683.0,29282.0,0.7312715092002019,3097280.0,2005824.0,10.528,17971.136000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96790.0,62682.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",507,0.0,0.0,0,0,0.0,0.0,0.0,24042.0,36597.0,0.3964775144708851,3098304.0,1555968.0,9.344,17980.480000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96822.0,48624.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",508,0.0,0.0,0,0,0.0,0.0,0.0,23883.0,34486.0,0.4091726772773219,3069120.0,1884992.0,8.96,17989.440000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95910.0,58906.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",509,0.0,0.0,0,0,0.0,0.0,0.0,22983.0,37125.0,0.3823617488520663,3097024.0,2479936.0,9.28,17998.72,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96782.0,77498.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",510,0.0,0.0,0,0,0.0,0.0,0.0,14336.0,6283.0,0.6952810514573937,1608224.0,0.0,4.8,18003.52,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,50257.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",511,0.0,0.0,0,0,0.0,0.0,0.0,39.0,16.0,0.7090909090909091,2048.0,0.0,2.176,18005.696,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",512,0.0,0.0,0,0,0.0,0.0,0.0,20059.0,18052.0,0.5263309805567946,2117536.0,1388064.0,8.192,18013.888,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,66173.0,43377.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",513,0.0,0.0,0,0,0.0,0.0,0.0,0.0,25132.0,0.0,2427552.0,2412352.0,5.248,18019.136,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75861.0,75386.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",514,2814392.0,6655044.0,0,0,0.0,6655044.0,6655044.0,528.0,6704.0,0.07300884955752213,2279552.0,754112.0,23.744,18042.879999999997,825232.0,201028.0,2814392.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,71236.0,23566.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",515,0.0,1024200.0,0,0,0.0,1024200.0,1024200.0,112284.0,12568.0,0.8993368147887099,804320.0,629248.0,71.84,18114.719999999998,1024200.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25135.0,19664.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",516,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3158.0,0.0,804128.0,200800.0,3.264,18117.983999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25129.0,6275.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",517,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,1.92,18119.903999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",518,0.0,0.0,0,0,0.0,0.0,0.0,0.0,18849.0,0.0,1809280.0,87584.0,7.84,18127.743999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,56540.0,2737.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",519,0.0,0.0,0,0,0.0,0.0,0.0,0.0,4737.0,0.0,1005184.0,0.0,3.296,18131.039999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,31412.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",520,2814392.0,6655044.0,0,0,0.0,6655044.0,6655044.0,528.0,6704.0,0.07300884955752213,2276480.0,753024.0,23.744,18154.783999999992,825232.0,201028.0,2814392.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,71140.0,23532.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",521,0.0,0.0,0,0,0.0,0.0,0.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,6.08,18160.863999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",522,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.208,18163.071999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",523,0.0,0.0,0,0,0.0,0.0,0.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,6.144,18169.215999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",524,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,18171.359999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",525,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.08,18173.439999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",526,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.944,18176.383999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",527,0.0,220484.0,0,0,0.0,220484.0,220484.0,320.0,1582.0,0.16824395373291273,804320.0,128.0,10.944,18187.327999999994,220484.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25135.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",528,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,18189.375999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",529,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,18192.639999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",530,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,18194.68799999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",531,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.04,18197.727999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",532,1769472.0,3941000.0,0,0,0.0,3941000.0,3941000.0,0.0,6283.0,0.0,0.0,804128.0,3.968,18201.695999999993,0.0,402056.0,1769472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,25129.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",533,1005140.0,2010280.0,0,0,0.0,2010280.0,2010280.0,0.0,4737.0,0.0,1608256.0,0.0,4.896,18206.591999999993,0.0,0.0,1005140.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,50258.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",534,0.0,0.0,0,0,0.0,0.0,0.0,640.0,1582.0,0.28802880288028804,804416.0,128.0,16.0,18222.591999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25138.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",535,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,1.984,18224.575999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",536,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,18226.591999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",537,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.272,18228.863999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",538,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.112,18230.975999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",539,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,96.0,160.0,2.624,18233.599999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",540,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,18235.295999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",541,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,18236.991999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",542,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.08,18239.071999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",543,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,18240.767999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",544,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,128.0,32.0,2.304,18243.071999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",545,0.0,0.0,0,0,0.0,0.0,0.0,0.0,5.0,0.0,32.0,32.0,4.704,18247.775999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",546,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.08,18249.856,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",547,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,18251.904,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",548,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.848,18254.752,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",549,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.2,18257.952,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",550,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,18260.0,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
