Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.856,1.856,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,3.552,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",3,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.888,5.4399999999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",4,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,7.135999999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",5,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.664,8.799999999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",6,0.0,0.0,0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,2.432,11.232,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",7,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,13.248,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",8,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.176,15.424,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",9,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.112,17.536,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",10,0.0,0.0,0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,2.4,19.936,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",11,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,21.951999999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",12,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,23.967999999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",13,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,2.08,26.047999999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(detail::TensorInfo<T1, T3>, detail::TensorInfo<const T1, T3>, detail::TensorInfo<const T2, T3>, int, int, T3, long)",14,0.0,0.0,0,0,0.0,0.0,0.0,0.0,72.0,0.0,3264.0,3072.0,3.936,29.983999999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,102.0,96.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",15,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,32.51199999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",16,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.432,34.943999999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",17,0.0,128.0,0,0,0.0,128.0,128.0,8.0,6.0,0.5714285714285714,320.0,256.0,2.016,36.959999999999994,0.0,128.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,10.0,8.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",18,0.0,0.0,0,0,0.0,0.0,0.0,0.0,10.0,0.0,512.0,512.0,2.496,39.455999999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",19,1024.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,8.0,0.0,512.0,512.0,2.72,42.175999999999995,0.0,256.0,1024.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",20,0.0,128.0,0,0,0.0,128.0,128.0,0.0,8.0,0.0,512.0,512.0,2.016,44.19199999999999,0.0,128.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",21,896.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,8.0,0.0,512.0,512.0,2.784,46.97599999999999,0.0,256.0,896.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",22,0.0,128.0,0,0,0.0,128.0,128.0,0.0,8.0,0.0,512.0,512.0,2.016,48.99199999999999,0.0,128.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",23,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.08,51.07199999999999,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",24,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.488,54.55999999999999,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",25,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.952,56.511999999999986,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",26,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.952,58.463999999999984,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",27,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.688,61.15199999999999,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",28,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.144,63.295999999999985,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",29,591360.0,1207296.0,0,0,0.0,1207296.0,1207296.0,10752.0,37632.0,0.2222222222222222,2752512.0,10912.0,5.824,69.11999999999999,24576.0,0.0,591360.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86016.0,341.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",30,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2304.0,0.0,6144.0,3040.0,2.528,71.648,1536.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,95.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",31,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.304,73.952,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",32,591360.0,1207296.0,0,0,0.0,1207296.0,1207296.0,10752.0,37632.0,0.2222222222222222,2752512.0,11008.0,5.28,79.232,24576.0,0.0,591360.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86016.0,344.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",33,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2304.0,0.0,6144.0,2688.0,2.4,81.632,1536.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,84.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",34,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.272,83.90400000000001,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",35,591360.0,1207296.0,0,0,0.0,1207296.0,1207296.0,10752.0,37632.0,0.2222222222222222,2752512.0,10720.0,5.152,89.05600000000001,24576.0,0.0,591360.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86016.0,335.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",36,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2304.0,0.0,6144.0,3040.0,2.4,91.45600000000002,1536.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,95.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",37,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.368,93.82400000000001,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",38,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.624,96.44800000000001,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",39,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.624,99.072,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",40,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.136,102.208,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",41,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.752,104.96,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",42,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,107.136,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",43,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.656,109.792,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",44,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.656,112.44800000000001,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",45,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.136,115.584,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",46,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.624,118.208,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",47,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.208,120.416,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",48,12288.0,1103232.0,0,0,0.0,1103232.0,1103232.0,6240.0,12.0,0.9980806142034548,9216.0,3072.0,20.224,140.64,930048.0,148608.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",49,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,2144.0,5.312,145.952,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,67.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",50,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.112,148.064,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",51,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.112,150.176,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",52,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.488,153.664,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",53,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.016,155.67999999999998,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",54,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,157.72799999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",55,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.592,160.32,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",56,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.176,162.49599999999998,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",57,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4640.0,12.864,175.35999999999999,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,145.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",58,35328.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,48.0,0.0,12288.0,12288.0,2.208,177.56799999999998,3072.0,0.0,35328.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",59,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4640.0,13.056,190.624,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,145.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",60,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.144,192.768,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",61,2360064.0,4744704.0,0,0,0.0,4744704.0,4744704.0,13056.0,148224.0,0.08095238095238096,10030976.0,2336.0,12.928,205.696,24576.0,0.0,2360064.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313468.0,73.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",62,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,207.87199999999999,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",63,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.112,209.98399999999998,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",64,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.456,213.43999999999997,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",65,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.952,215.39199999999997,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",66,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,217.37599999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",67,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.624,219.99999999999997,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",68,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.176,222.17599999999996,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",69,591360.0,1207296.0,0,0,0.0,1207296.0,1207296.0,10752.0,37632.0,0.2222222222222222,2752512.0,11008.0,5.856,228.03199999999995,24576.0,0.0,591360.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86016.0,344.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",70,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2304.0,0.0,6144.0,2560.0,2.432,230.46399999999994,1536.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,80.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",71,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.432,232.89599999999993,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",72,591360.0,1207296.0,0,0,0.0,1207296.0,1207296.0,10752.0,37632.0,0.2222222222222222,2752512.0,10752.0,5.216,238.11199999999994,24576.0,0.0,591360.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86016.0,336.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",73,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2304.0,0.0,6144.0,2784.0,2.304,240.41599999999994,1536.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,87.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",74,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.272,242.68799999999993,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",75,591360.0,1207296.0,0,0,0.0,1207296.0,1207296.0,10752.0,37632.0,0.2222222222222222,2752512.0,10816.0,5.248,247.93599999999992,24576.0,0.0,591360.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86016.0,338.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",76,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2304.0,0.0,6144.0,2848.0,2.4,250.33599999999993,1536.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,89.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",77,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.4,252.73599999999993,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",78,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.592,255.32799999999995,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",79,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.624,257.95199999999994,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",80,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.136,261.08799999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",81,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.624,263.712,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",82,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.144,265.856,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",83,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.624,268.48,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",84,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.656,271.136,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",85,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.168,274.30400000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",86,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.656,276.96000000000004,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",87,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.144,279.10400000000004,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",88,12288.0,1103232.0,0,0,0.0,1103232.0,1103232.0,6240.0,12.0,0.9980806142034548,9216.0,3072.0,20.224,299.32800000000003,930048.0,148608.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",89,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,2080.0,5.568,304.896,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,65.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",90,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.112,307.00800000000004,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",91,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.112,309.12000000000006,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",92,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.424,312.54400000000004,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",93,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.984,314.528,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",94,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,316.576,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",95,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.56,319.136,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",96,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.176,321.312,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",97,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4736.0,12.8,334.112,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,148.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",98,35328.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,48.0,0.0,12288.0,12288.0,2.208,336.32000000000005,3072.0,0.0,35328.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",99,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4704.0,13.056,349.37600000000003,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,147.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",100,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.08,351.456,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",101,2360064.0,4744704.0,0,0,0.0,4744704.0,4744704.0,13056.0,148224.0,0.08095238095238096,10027008.0,2368.0,12.896,364.35200000000003,24576.0,0.0,2360064.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313344.0,74.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",102,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,366.528,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",103,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.24,368.76800000000003,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",104,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.456,372.22400000000005,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",105,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.952,374.17600000000004,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",106,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,376.16,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",107,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.592,378.752,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",108,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.176,380.928,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",109,591360.0,1207296.0,0,0,0.0,1207296.0,1207296.0,10752.0,37632.0,0.2222222222222222,2752512.0,11008.0,5.76,386.688,24576.0,0.0,591360.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86016.0,344.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",110,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2304.0,0.0,6144.0,2720.0,2.432,389.12,1536.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,85.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",111,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.336,391.456,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",112,591360.0,1207296.0,0,0,0.0,1207296.0,1207296.0,10752.0,37632.0,0.2222222222222222,2752512.0,11264.0,5.408,396.86400000000003,24576.0,0.0,591360.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86016.0,352.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",113,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2304.0,0.0,6144.0,2848.0,2.4,399.264,1536.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,89.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",114,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.304,401.568,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",115,591360.0,1207296.0,0,0,0.0,1207296.0,1207296.0,10752.0,37632.0,0.2222222222222222,2752512.0,10912.0,5.184,406.752,24576.0,0.0,591360.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86016.0,341.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",116,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2304.0,0.0,6144.0,3168.0,2.464,409.216,1536.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,99.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",117,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.368,411.584,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",118,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.656,414.24,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",119,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.688,416.928,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",120,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.168,420.096,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",121,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.624,422.72,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",122,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.112,424.83200000000005,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",123,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.624,427.4560000000001,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",124,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.656,430.1120000000001,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",125,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.168,433.2800000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",126,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.656,435.9360000000001,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",127,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.144,438.0800000000001,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",128,12288.0,1103232.0,0,0,0.0,1103232.0,1103232.0,6240.0,12.0,0.9980806142034548,9216.0,3072.0,20.224,458.3040000000001,930048.0,148608.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",129,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,2240.0,5.376,463.68000000000006,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,70.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",130,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.112,465.7920000000001,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",131,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.08,467.87200000000007,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",132,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.488,471.36000000000007,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",133,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.016,473.3760000000001,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",134,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,475.3920000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",135,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.624,478.01600000000013,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",136,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.176,480.1920000000001,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",137,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4768.0,12.704,492.89600000000013,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,149.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",138,35328.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,48.0,0.0,12288.0,12288.0,2.24,495.13600000000014,3072.0,0.0,35328.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",139,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4544.0,13.152,508.2880000000001,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,142.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",140,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.112,510.40000000000015,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",141,2360064.0,4744704.0,0,0,0.0,4744704.0,4744704.0,13056.0,148224.0,0.08095238095238096,10027136.0,2048.0,12.8,523.2000000000002,24576.0,0.0,2360064.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313348.0,64.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",142,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,525.3760000000002,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",143,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.08,527.4560000000002,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",144,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.456,530.9120000000003,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",145,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.952,532.8640000000003,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",146,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,534.8480000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",147,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.56,537.4080000000002,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",148,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.208,539.6160000000002,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",149,591360.0,1207296.0,0,0,0.0,1207296.0,1207296.0,10752.0,37632.0,0.2222222222222222,2752512.0,10944.0,5.408,545.0240000000002,24576.0,0.0,591360.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86016.0,342.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",150,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2304.0,0.0,6144.0,2688.0,2.432,547.4560000000002,1536.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,84.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",151,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.336,549.7920000000003,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",152,591360.0,1207296.0,0,0,0.0,1207296.0,1207296.0,10752.0,37632.0,0.2222222222222222,2752512.0,11104.0,5.28,555.0720000000002,24576.0,0.0,591360.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86016.0,347.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",153,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2304.0,0.0,6144.0,2592.0,2.368,557.4400000000003,1536.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,81.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",154,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.272,559.7120000000003,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",155,591360.0,1207296.0,0,0,0.0,1207296.0,1207296.0,10752.0,37632.0,0.2222222222222222,2752512.0,11040.0,5.28,564.9920000000003,24576.0,0.0,591360.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86016.0,345.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",156,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2304.0,0.0,6144.0,2432.0,2.4,567.3920000000003,1536.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,76.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",157,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.4,569.7920000000003,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",158,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.688,572.4800000000002,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",159,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.656,575.1360000000002,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",160,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.168,578.3040000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",161,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.656,580.9600000000002,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",162,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.08,583.0400000000002,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",163,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.624,585.6640000000002,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",164,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.656,588.3200000000002,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",165,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.168,591.4880000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",166,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.624,594.1120000000002,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",167,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.144,596.2560000000002,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",168,12288.0,1103232.0,0,0,0.0,1103232.0,1103232.0,6240.0,12.0,0.9980806142034548,9216.0,3072.0,20.16,616.4160000000002,930048.0,148608.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",169,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,2208.0,5.376,621.7920000000001,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,69.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",170,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.112,623.9040000000001,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",171,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.112,626.0160000000001,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",172,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.488,629.5040000000001,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",173,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.016,631.5200000000001,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",174,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,633.5360000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",175,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.592,636.128,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",176,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.176,638.3040000000001,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",177,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4416.0,12.704,651.008,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,138.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",178,35328.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,48.0,0.0,12288.0,12288.0,2.208,653.216,3072.0,0.0,35328.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",179,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4768.0,12.736,665.952,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,149.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",180,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.08,668.032,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",181,2360064.0,4744704.0,0,0,0.0,4744704.0,4744704.0,13056.0,148224.0,0.08095238095238096,10027392.0,2336.0,13.376,681.408,24576.0,0.0,2360064.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313356.0,73.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",182,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,683.5840000000001,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",183,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.144,685.7280000000001,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",184,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.68,689.408,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",185,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.984,691.392,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",186,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,693.3760000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",187,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.624,696.0000000000001,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",188,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.144,698.1440000000001,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",189,591360.0,1207296.0,0,0,0.0,1207296.0,1207296.0,10752.0,37632.0,0.2222222222222222,2752512.0,11136.0,5.28,703.4240000000001,24576.0,0.0,591360.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86016.0,348.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",190,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2304.0,0.0,6144.0,2528.0,2.528,705.9520000000001,1536.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,79.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",191,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.368,708.3200000000002,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",192,591360.0,1207296.0,0,0,0.0,1207296.0,1207296.0,10752.0,37632.0,0.2222222222222222,2752512.0,11008.0,5.312,713.6320000000002,24576.0,0.0,591360.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86016.0,344.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",193,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2304.0,0.0,6144.0,2912.0,2.336,715.9680000000002,1536.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,91.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",194,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.304,718.2720000000002,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",195,591360.0,1207296.0,0,0,0.0,1207296.0,1207296.0,10752.0,37632.0,0.2222222222222222,2752512.0,11136.0,5.376,723.6480000000001,24576.0,0.0,591360.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86016.0,348.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",196,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2304.0,0.0,6144.0,2752.0,2.432,726.0800000000002,1536.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,86.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",197,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.368,728.4480000000002,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",198,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.624,731.0720000000002,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",199,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.656,733.7280000000002,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",200,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.168,736.8960000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",201,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.784,739.6800000000002,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",202,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,741.8560000000002,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",203,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.592,744.4480000000002,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",204,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.688,747.1360000000002,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",205,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.168,750.3040000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",206,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.624,752.9280000000002,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",207,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,755.1040000000003,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",208,12288.0,1103232.0,0,0,0.0,1103232.0,1103232.0,6240.0,12.0,0.9980806142034548,9216.0,3072.0,20.192,775.2960000000003,930048.0,148608.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",209,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,1984.0,5.312,780.6080000000003,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,62.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",210,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.144,782.7520000000003,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",211,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.112,784.8640000000003,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",212,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.456,788.3200000000003,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",213,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.984,790.3040000000003,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",214,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,792.3520000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",215,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.56,794.9120000000003,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",216,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.208,797.1200000000002,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",217,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4512.0,12.672,809.7920000000003,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,141.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",218,35328.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,48.0,0.0,12288.0,12288.0,2.208,812.0000000000002,3072.0,0.0,35328.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",219,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4704.0,12.704,824.7040000000002,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,147.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",220,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.176,826.8800000000002,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",221,2360064.0,4744704.0,0,0,0.0,4744704.0,4744704.0,13056.0,148224.0,0.08095238095238096,10027008.0,2240.0,12.832,839.7120000000002,24576.0,0.0,2360064.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313344.0,70.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",222,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,841.8880000000003,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",223,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.112,844.0000000000002,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",224,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.456,847.4560000000002,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",225,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.952,849.4080000000002,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",226,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.952,851.3600000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",227,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.56,853.9200000000002,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",228,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.144,856.0640000000002,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",229,591360.0,1207296.0,0,0,0.0,1207296.0,1207296.0,10752.0,37632.0,0.2222222222222222,2752512.0,10976.0,5.6,861.6640000000002,24576.0,0.0,591360.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86016.0,343.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",230,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2304.0,0.0,6144.0,2816.0,2.4,864.0640000000002,1536.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,88.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",231,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.336,866.4000000000002,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",232,591360.0,1207296.0,0,0,0.0,1207296.0,1207296.0,10752.0,37632.0,0.2222222222222222,2752512.0,11072.0,5.44,871.8400000000003,24576.0,0.0,591360.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86016.0,346.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",233,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2304.0,0.0,6144.0,2496.0,2.56,874.4000000000002,1536.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,78.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",234,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.304,876.7040000000002,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",235,591360.0,1207296.0,0,0,0.0,1207296.0,1207296.0,10752.0,37632.0,0.2222222222222222,2752512.0,10944.0,5.312,882.0160000000002,24576.0,0.0,591360.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86016.0,342.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",236,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2304.0,0.0,6144.0,2368.0,2.56,884.5760000000001,1536.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,74.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",237,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.432,887.0080000000002,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",238,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.624,889.6320000000002,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",239,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.656,892.2880000000001,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",240,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.168,895.4560000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",241,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.624,898.0800000000002,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",242,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.112,900.1920000000001,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",243,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.656,902.8480000000001,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",244,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.656,905.504,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",245,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.168,908.672,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",246,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.752,911.424,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",247,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.144,913.568,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",248,12288.0,1103232.0,0,0,0.0,1103232.0,1103232.0,6240.0,12.0,0.9980806142034548,9216.0,3072.0,20.192,933.76,930048.0,148608.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",249,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,1984.0,5.6,939.36,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,62.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",250,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.144,941.504,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",251,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.112,943.616,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",252,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.488,947.104,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",253,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.112,949.216,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",254,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,951.264,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",255,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.56,953.824,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",256,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.176,956.0,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",257,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4608.0,12.768,968.768,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",258,35328.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,48.0,0.0,12288.0,12288.0,2.272,971.0400000000001,3072.0,0.0,35328.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",259,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4512.0,12.672,983.7120000000001,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,141.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",260,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.08,985.7920000000001,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",261,2360064.0,4744704.0,0,0,0.0,4744704.0,4744704.0,13056.0,148224.0,0.08095238095238096,10029312.0,2304.0,12.896,998.6880000000001,24576.0,0.0,2360064.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313416.0,72.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",262,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.144,1000.8320000000001,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",263,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.112,1002.9440000000001,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",264,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.456,1006.4000000000001,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",265,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.952,1008.3520000000001,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",266,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,1010.3360000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",267,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.56,1012.8960000000001,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",268,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.144,1015.0400000000001,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",269,591360.0,1207296.0,0,0,0.0,1207296.0,1207296.0,10752.0,37632.0,0.2222222222222222,2752512.0,11008.0,5.216,1020.2560000000001,24576.0,0.0,591360.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86016.0,344.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",270,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2304.0,0.0,6144.0,2720.0,2.4,1022.6560000000001,1536.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,85.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",271,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.304,1024.96,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",272,591360.0,1207296.0,0,0,0.0,1207296.0,1207296.0,10752.0,37632.0,0.2222222222222222,2752512.0,10784.0,5.344,1030.304,24576.0,0.0,591360.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86016.0,337.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",273,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2304.0,0.0,6144.0,2816.0,2.336,1032.64,1536.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,88.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",274,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.272,1034.912,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",275,591360.0,1207296.0,0,0,0.0,1207296.0,1207296.0,10752.0,37632.0,0.2222222222222222,2752512.0,10816.0,5.504,1040.416,24576.0,0.0,591360.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86016.0,338.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",276,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2304.0,0.0,6144.0,2720.0,2.4,1042.816,1536.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,85.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",277,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.4,1045.2160000000001,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",278,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.656,1047.872,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",279,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.656,1050.528,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",280,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.168,1053.696,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",281,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.784,1056.48,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",282,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.144,1058.624,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",283,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.624,1061.248,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",284,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.688,1063.9360000000001,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",285,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.136,1067.0720000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",286,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.656,1069.728,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",287,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,1071.904,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",288,12288.0,1103232.0,0,0,0.0,1103232.0,1103232.0,6240.0,12.0,0.9980806142034548,9216.0,3072.0,20.192,1092.096,930048.0,148608.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",289,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,2304.0,5.632,1097.728,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,72.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",290,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.144,1099.872,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",291,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.08,1101.952,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",292,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.424,1105.376,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",293,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.984,1107.36,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",294,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,1109.376,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",295,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.56,1111.936,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",296,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.144,1114.08,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",297,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4416.0,12.736,1126.816,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,138.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",298,35328.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,48.0,0.0,12288.0,12288.0,2.208,1129.0240000000001,3072.0,0.0,35328.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",299,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4576.0,12.736,1141.7600000000002,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,143.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",300,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.112,1143.8720000000003,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",301,2360064.0,4744704.0,0,0,0.0,4744704.0,4744704.0,13056.0,148224.0,0.08095238095238096,10034048.0,2368.0,12.928,1156.8000000000004,24576.0,0.0,2360064.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313564.0,74.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",302,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.144,1158.9440000000004,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",303,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.112,1161.0560000000005,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",304,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.456,1164.5120000000004,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",305,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.952,1166.4640000000004,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",306,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,1168.4480000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",307,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.56,1171.0080000000003,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",308,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.176,1173.1840000000002,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",309,591360.0,1207296.0,0,0,0.0,1207296.0,1207296.0,10752.0,37632.0,0.2222222222222222,2752512.0,10976.0,5.888,1179.0720000000001,24576.0,0.0,591360.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86016.0,343.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",310,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2304.0,0.0,6144.0,2656.0,2.432,1181.5040000000001,1536.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,83.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",311,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.368,1183.872,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",312,591360.0,1207296.0,0,0,0.0,1207296.0,1207296.0,10752.0,37632.0,0.2222222222222222,2752512.0,10816.0,5.376,1189.248,24576.0,0.0,591360.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86016.0,338.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",313,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2304.0,0.0,6144.0,2656.0,2.336,1191.584,1536.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,83.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",314,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.304,1193.8880000000001,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",315,591360.0,1207296.0,0,0,0.0,1207296.0,1207296.0,10752.0,37632.0,0.2222222222222222,2752512.0,10944.0,5.152,1199.0400000000002,24576.0,0.0,591360.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86016.0,342.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",316,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2304.0,0.0,6144.0,2592.0,2.4,1201.4400000000003,1536.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,81.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",317,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.432,1203.8720000000003,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",318,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.656,1206.5280000000002,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",319,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.656,1209.1840000000002,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",320,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.296,1212.4800000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",321,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.592,1215.0720000000003,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",322,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.144,1217.2160000000003,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",323,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.624,1219.8400000000004,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",324,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.656,1222.4960000000003,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",325,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.168,1225.6640000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",326,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.72,1228.3840000000002,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",327,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.144,1230.5280000000002,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",328,12288.0,1103232.0,0,0,0.0,1103232.0,1103232.0,6240.0,12.0,0.9980806142034548,9216.0,3072.0,20.384,1250.9120000000003,930048.0,148608.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",329,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,2144.0,5.504,1256.4160000000002,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,67.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",330,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.144,1258.5600000000002,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",331,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.112,1260.6720000000003,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",332,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.488,1264.1600000000003,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",333,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.984,1266.1440000000002,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",334,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,1268.1920000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",335,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.56,1270.7520000000002,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",336,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.304,1273.0560000000003,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",337,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4800.0,12.768,1285.8240000000003,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,150.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",338,35328.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,48.0,0.0,12288.0,12288.0,2.208,1288.0320000000004,3072.0,0.0,35328.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",339,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4640.0,12.96,1300.9920000000004,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,145.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",340,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.08,1303.0720000000003,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",341,2360064.0,4744704.0,0,0,0.0,4744704.0,4744704.0,13056.0,148224.0,0.08095238095238096,10030080.0,2592.0,13.024,1316.0960000000002,24576.0,0.0,2360064.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313440.0,81.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",342,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,1318.2720000000002,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",343,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.112,1320.3840000000002,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",344,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.488,1323.8720000000003,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",345,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.952,1325.8240000000003,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",346,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,1327.9680000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",347,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.56,1330.5280000000002,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",348,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.24,1332.7680000000003,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",349,116686848.0,255100544.0,0,0,0.0,255100544.0,255100544.0,4861952.0,4178240.0,0.5378151260504201,480282624.0,672672.0,496.192,1828.9600000000003,7140992.0,14585856.0,116686848.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,15008832.0,21021.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",350,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,1830.6880000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",351,0.0,0.0,0,0,0.0,0.0,0.0,0.0,4.0,0.0,64.0,64.0,2.592,1833.2800000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",352,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,1835.2960000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",353,0.0,151936.0,0,0,0.0,151936.0,151936.0,0.0,2392.0,0.0,607744.0,607744.0,2.752,1838.0480000000005,0.0,151936.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,18992.0,18992.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",354,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,1839.7440000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",355,0.0,0.0,0,0,0.0,0.0,0.0,2384.0,7132.0,0.2505254308532997,611840.0,42944.0,3.52,1843.2640000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,19120.0,1342.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",356,0.0,0.0,0,0,0.0,0.0,0.0,11026.0,179547.0,0.057857094131907455,9777824.0,0.0,8.544,1851.8080000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,305557.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",357,0.0,0.0,0,0,0.0,0.0,0.0,2384.0,7132.0,0.2505254308532997,611840.0,42624.0,3.456,1855.2640000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,19120.0,1332.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",358,0.0,0.0,0,0,0.0,0.0,0.0,11026.0,180441.0,0.05758694709793333,9777824.0,0.0,8.704,1863.9680000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,305557.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",359,0.0,0.0,0,0,0.0,0.0,0.0,2384.0,7132.0,0.2505254308532997,611840.0,42624.0,3.584,1867.5520000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,19120.0,1332.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",360,0.0,0.0,0,0,0.0,0.0,0.0,11026.0,179845.0,0.05776676394004328,9777824.0,0.0,8.768,1876.3200000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,305557.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",361,0.0,0.0,0,0,0.0,0.0,0.0,2384.0,7132.0,0.2505254308532997,611840.0,42752.0,3.456,1879.7760000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,19120.0,1336.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",362,0.0,0.0,0,0,0.0,0.0,0.0,11026.0,179398.0,0.05790236524807797,9777824.0,32.0,8.896,1888.6720000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,305557.0,1.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",363,0.0,0.0,0,0,0.0,0.0,0.0,0.0,15.0,0.0,4800.0,608.0,2.464,1891.1360000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,150.0,19.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",364,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.728,1892.8640000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",365,0.0,0.0,0,0,0.0,0.0,0.0,497.0,18.0,0.9650485436893204,608.0,0.0,3.456,1896.3200000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,19.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",366,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.696,1898.016,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",367,0.0,0.0,0,0,0.0,0.0,0.0,497.0,18.0,0.9650485436893204,608.0,0.0,3.488,1901.5040000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,19.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 1>(detail::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, detail::TensorInfo<T1, T2>, T2, detail::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",368,0.0,0.0,0,0,0.0,0.0,0.0,56448.0,9598.0,0.8546770432728704,625280.0,2624.0,5.76,1907.2640000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,19540.0,82.0
"void native::radixSortKVInPlace<(int)-2, (int)-1, 32, 4, float, long, unsigned int>(detail::TensorInfo<T5, T7>, T7, T7, T7, detail::TensorInfo<T6, T7>, T7, bool)",369,0.0,0.0,0,0,0.0,0.0,0.0,458.0,8.0,0.9828326180257511,640.0,0.0,5.92,1913.1840000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,20.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",370,0.0,0.0,0,0,0.0,0.0,0.0,0.0,14244.0,0.0,611840.0,65984.0,3.616,1916.8000000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,19120.0,2062.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",371,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3588.0,0.0,759680.0,0.0,3.104,1919.9040000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,23740.0,0.0
"native::<unnamed>::fill_reverse_indices_kernel(long *, int, detail::IntDivider<unsigned int>)",372,0.0,0.0,0,0,0.0,0.0,0.0,0.0,4748.0,0.0,0.0,1215488.0,2.592,1922.4960000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,37984.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",373,0.0,0.0,0,0,0.0,0.0,0.0,98304.0,4748.0,0.9539261731941155,607744.0,0.0,4.128,1926.6240000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,18992.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",374,0.0,0.0,0,0,0.0,0.0,0.0,156.0,64.0,0.7090909090909091,8192.0,0.0,2.144,1928.7680000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",375,0.0,0.0,0,0,0.0,0.0,0.0,43694.0,22585.0,0.6592435009580712,2260352.0,1491904.0,9.088,1937.8560000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,70636.0,46622.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",376,0.0,0.0,0,0,0.0,0.0,0.0,17750.0,23712.0,0.4281028411557571,2284672.0,1874432.0,7.84,1945.6960000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,71396.0,58576.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",377,0.0,0.0,0,0,0.0,0.0,0.0,18494.0,23941.0,0.4358194886296689,2292224.0,1874432.0,8.448,1954.1440000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,71632.0,58576.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",378,0.0,0.0,0,0,0.0,0.0,0.0,18494.0,23806.0,0.43721040189125293,2250112.0,1616000.0,8.288,1962.4320000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,70316.0,50500.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",379,2127104.0,5019168.0,0,0,0.0,5019168.0,5019168.0,132.0,4784.0,0.026851098454027666,1823232.0,607744.0,61.824,2024.2560000000003,613024.0,151936.0,2127104.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,56976.0,18992.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<float, 1>>(T1, int)",380,0.0,0.0,0,0,0.0,0.0,0.0,0.0,4.0,0.0,0.0,896.0,1.696,2025.9520000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,28.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<float, std::plus<float>>::Policy900, const float *, float *, at_cuda_detail::ScanTileState<float, 1>, std::plus<float>, at_cuda_detail::NullType, unsigned int, float, 0>(T2, T3, T4, int, T5, T6, T7)",381,0.0,406449.0,0,0,0.0,406449.0,406449.0,20797.0,10335.0,0.6680264679429526,669440.0,612704.0,5.248,2031.2000000000003,406449.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,20920.0,19147.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",382,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2392.0,0.0,607744.0,151744.0,2.912,2034.1120000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,18992.0,4742.0
"void native::unrolled_elementwise_kernel<native::FillFunctor<bool>, std::array<char *, 1>, 16, TrivialOffsetCalculator<0, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithoutCast, memory::StoreWithoutCast>(int, T1, T2, T4, T5, T6, T7)",383,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,2035.8080000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",384,0.0,0.0,0,0,0.0,0.0,0.0,0.0,14244.0,0.0,1367424.0,60064.0,7.776,2043.5840000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,42732.0,1877.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",385,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3588.0,0.0,759680.0,0.0,3.04,2046.6240000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,23740.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",386,2127104.0,5019168.0,0,0,0.0,5019168.0,5019168.0,132.0,4784.0,0.026851098454027666,1823232.0,607744.0,61.984,2108.608,613024.0,151936.0,2127104.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,56976.0,18992.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",387,0.0,0.0,0,0,0.0,0.0,0.0,1563.0,1208.0,0.564056297365572,607840.0,640.0,6.016,2114.6240000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,18995.0,20.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",388,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,2116.768,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",389,0.0,0.0,0,0,0.0,0.0,0.0,1563.0,1208.0,0.564056297365572,607840.0,640.0,6.208,2122.976,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,18995.0,20.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",390,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.176,2125.152,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",391,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.016,2127.168,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",392,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.912,2130.08,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",393,0.0,241939.0,0,0,0.0,241939.0,241939.0,1563.0,1208.0,0.564056297365572,607840.0,640.0,6.208,2136.288,241939.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,18995.0,20.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",394,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2138.304,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",395,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,2140.384,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",396,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.944,2143.328,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",397,1368576.0,3041024.0,0,0,0.0,3041024.0,3041024.0,0.0,4748.0,0.0,0.0,607744.0,3.616,2146.944,0.0,303872.0,1368576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,18992.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",398,759680.0,1519360.0,0,0,0.0,1519360.0,1519360.0,0.0,3588.0,0.0,1215488.0,0.0,4.32,2151.264,0.0,0.0,759680.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,37984.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",399,0.0,0.0,0,0,0.0,0.0,0.0,2803.0,1228.0,0.6953609526172165,608064.0,640.0,7.84,2159.1040000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,19002.0,20.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",400,0.0,0.0,0,0,0.0,0.0,0.0,0.0,4.0,0.0,64.0,64.0,2.592,2161.6960000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",401,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,2163.4240000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",402,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.76,2165.1840000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",403,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.048,2167.2320000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",404,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,2169.28,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",405,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.912,2172.192,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",406,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.168,2175.36,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",407,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,2177.344,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",408,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,2179.488,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",409,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.296,2182.7839999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",410,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.728,2184.5119999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",411,0.0,0.0,0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,2.848,2187.3599999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",412,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,2189.4399999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",413,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,2191.5199999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",414,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,2.048,2193.5679999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(detail::TensorInfo<T1, T3>, detail::TensorInfo<const T1, T3>, detail::TensorInfo<const T2, T3>, int, int, T3, long)",415,0.0,0.0,0,0,0.0,0.0,0.0,0.0,72.0,0.0,3264.0,3072.0,3.264,2196.8319999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,102.0,96.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",416,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.688,2199.5199999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",417,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,2202.8159999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",418,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.496,2205.3119999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",419,0.0,128.0,0,0,0.0,128.0,128.0,8.0,6.0,0.5714285714285714,320.0,256.0,2.144,2207.455999999999,0.0,128.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,10.0,8.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",420,0.0,0.0,0,0,0.0,0.0,0.0,0.0,10.0,0.0,512.0,512.0,2.56,2210.015999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",421,1024.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,8.0,0.0,512.0,512.0,2.688,2212.7039999999993,0.0,256.0,1024.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",422,0.0,128.0,0,0,0.0,128.0,128.0,0.0,8.0,0.0,512.0,512.0,1.984,2214.687999999999,0.0,128.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",423,900.0,2056.0,0,0,0.0,2056.0,2056.0,0.0,8.0,0.0,512.0,512.0,2.624,2217.311999999999,0.0,256.0,900.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",424,0.0,128.0,0,0,0.0,128.0,128.0,0.0,8.0,0.0,512.0,512.0,2.048,2219.3599999999988,0.0,128.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",425,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.112,2221.471999999999,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",426,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.456,2224.927999999999,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",427,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.952,2226.879999999999,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",428,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2228.8959999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",429,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.496,2231.3919999999994,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",430,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.176,2233.5679999999993,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",431,591360.0,1207296.0,0,0,0.0,1207296.0,1207296.0,10752.0,37632.0,0.2222222222222222,2752512.0,11296.0,5.344,2238.9119999999994,24576.0,0.0,591360.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86016.0,353.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",432,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2304.0,0.0,6144.0,2816.0,2.432,2241.343999999999,1536.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,88.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",433,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.368,2243.711999999999,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",434,591360.0,1207296.0,0,0,0.0,1207296.0,1207296.0,10752.0,37632.0,0.2222222222222222,2752512.0,11072.0,5.344,2249.055999999999,24576.0,0.0,591360.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86016.0,346.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",435,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2304.0,0.0,6144.0,3040.0,2.432,2251.487999999999,1536.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,95.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",436,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.592,2254.079999999999,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",437,591360.0,1207296.0,0,0,0.0,1207296.0,1207296.0,10752.0,37632.0,0.2222222222222222,2752512.0,11040.0,5.248,2259.327999999999,24576.0,0.0,591360.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86016.0,345.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",438,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2304.0,0.0,6144.0,2880.0,2.432,2261.759999999999,1536.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,90.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",439,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.336,2264.0959999999986,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",440,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.688,2266.7839999999987,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",441,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.656,2269.4399999999987,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",442,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.328,2272.7679999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",443,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.624,2275.3919999999985,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",444,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.144,2277.5359999999982,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",445,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.56,2280.095999999998,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",446,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.656,2282.751999999998,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",447,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.136,2285.887999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",448,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.848,2288.735999999998,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",449,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,2290.911999999998,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",450,0.0,0.0,0,0,0.0,0.0,0.0,0.0,60.0,0.0,6144.0,6144.0,2.56,2293.471999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",451,0.0,0.0,0,0,0.0,0.0,0.0,0.0,60.0,0.0,6144.0,6144.0,2.592,2296.063999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",452,12288.0,1103616.0,0,0,0.0,1103616.0,1103616.0,6240.0,12.0,0.9980806142034548,15360.0,3072.0,20.736,2316.799999999998,930432.0,148608.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",453,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,2048.0,5.504,2322.303999999998,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,64.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",454,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.144,2324.4479999999976,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",455,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.304,2326.7519999999977,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",456,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.52,2330.2719999999977,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",457,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.952,2332.223999999998,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",458,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2334.239999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",459,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.56,2336.799999999998,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",460,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.176,2338.975999999998,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",461,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4640.0,12.704,2351.679999999998,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,145.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",462,35328.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,48.0,0.0,12288.0,12288.0,2.272,2353.951999999998,3072.0,0.0,35328.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",463,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4576.0,12.672,2366.623999999998,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,143.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",464,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.112,2368.735999999998,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",465,2360064.0,4744704.0,0,0,0.0,4744704.0,4744704.0,13056.0,148224.0,0.08095238095238096,10027264.0,2272.0,12.8,2381.5359999999982,24576.0,0.0,2360064.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313352.0,71.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",466,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,2383.711999999998,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",467,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.144,2385.855999999998,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",468,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.424,2389.279999999998,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",469,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.92,2391.199999999998,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",470,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2393.215999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",471,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.592,2395.807999999998,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",472,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.208,2398.0159999999983,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",473,591360.0,1207296.0,0,0,0.0,1207296.0,1207296.0,10752.0,37632.0,0.2222222222222222,2752512.0,11264.0,5.536,2403.5519999999983,24576.0,0.0,591360.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86016.0,352.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",474,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2304.0,0.0,6144.0,2688.0,2.4,2405.9519999999984,1536.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,84.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",475,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.368,2408.3199999999983,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",476,591360.0,1207296.0,0,0,0.0,1207296.0,1207296.0,10752.0,37632.0,0.2222222222222222,2752512.0,10880.0,5.344,2413.6639999999984,24576.0,0.0,591360.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86016.0,340.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",477,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2304.0,0.0,6144.0,2752.0,2.4,2416.0639999999985,1536.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,86.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",478,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.368,2418.4319999999984,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",479,591360.0,1207296.0,0,0,0.0,1207296.0,1207296.0,10752.0,37632.0,0.2222222222222222,2752512.0,10880.0,5.376,2423.8079999999986,24576.0,0.0,591360.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86016.0,340.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",480,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2304.0,0.0,6144.0,2688.0,2.4,2426.2079999999987,1536.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,84.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",481,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.368,2428.5759999999987,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",482,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.656,2431.2319999999986,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",483,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.688,2433.9199999999987,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",484,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.136,2437.0559999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",485,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.592,2439.647999999999,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",486,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,2441.8239999999987,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",487,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.592,2444.415999999999,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",488,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.72,2447.1359999999986,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",489,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.104,2450.2399999999984,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",490,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.592,2452.8319999999985,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",491,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.208,2455.0399999999986,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",492,0.0,0.0,0,0,0.0,0.0,0.0,0.0,60.0,0.0,6144.0,6144.0,2.624,2457.6639999999984,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",493,0.0,0.0,0,0,0.0,0.0,0.0,0.0,60.0,0.0,6144.0,6144.0,2.56,2460.2239999999983,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",494,12288.0,1103616.0,0,0,0.0,1103616.0,1103616.0,6240.0,12.0,0.9980806142034548,15360.0,3072.0,20.672,2480.8959999999984,930432.0,148608.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",495,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,2112.0,5.568,2486.4639999999986,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,66.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",496,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.208,2488.6719999999987,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",497,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.144,2490.8159999999984,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",498,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.456,2494.2719999999986,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",499,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.984,2496.2559999999985,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",500,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2498.2719999999986,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",501,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.496,2500.7679999999987,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",502,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.144,2502.9119999999984,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",503,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4672.0,12.736,2515.6479999999983,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,146.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",504,35328.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,48.0,0.0,12288.0,12288.0,2.304,2517.9519999999984,3072.0,0.0,35328.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",505,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4416.0,12.768,2530.7199999999984,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,138.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",506,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.048,2532.767999999998,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",507,2360064.0,4744704.0,0,0,0.0,4744704.0,4744704.0,13056.0,148224.0,0.08095238095238096,10030336.0,2432.0,12.928,2545.695999999998,24576.0,0.0,2360064.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313448.0,76.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",508,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,2547.871999999998,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",509,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.08,2549.951999999998,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",510,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.488,2553.439999999998,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",511,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.984,2555.4239999999977,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",512,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,2557.4719999999975,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",513,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.624,2560.0959999999973,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",514,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.144,2562.239999999997,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",515,591360.0,1207296.0,0,0,0.0,1207296.0,1207296.0,10752.0,37632.0,0.2222222222222222,2752512.0,11072.0,5.312,2567.551999999997,24576.0,0.0,591360.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86016.0,346.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",516,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2304.0,0.0,6144.0,2752.0,2.368,2569.919999999997,1536.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,86.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",517,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.336,2572.2559999999967,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",518,591360.0,1207296.0,0,0,0.0,1207296.0,1207296.0,10752.0,37632.0,0.2222222222222222,2752512.0,10912.0,5.28,2577.535999999997,24576.0,0.0,591360.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86016.0,341.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",519,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2304.0,0.0,6144.0,2848.0,2.656,2580.191999999997,1536.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,89.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",520,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.368,2582.5599999999968,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",521,591360.0,1207296.0,0,0,0.0,1207296.0,1207296.0,10752.0,37632.0,0.2222222222222222,2752512.0,10912.0,5.312,2587.8719999999967,24576.0,0.0,591360.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86016.0,341.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",522,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2304.0,0.0,6144.0,3040.0,2.368,2590.2399999999966,1536.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,95.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",523,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.368,2592.6079999999965,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",524,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.624,2595.2319999999963,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",525,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.624,2597.855999999996,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",526,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.104,2600.959999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",527,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.624,2603.5839999999957,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",528,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.208,2605.791999999996,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",529,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.624,2608.4159999999956,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",530,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.656,2611.0719999999956,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",531,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.168,2614.2399999999957,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",532,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.624,2616.8639999999955,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",533,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.144,2619.0079999999953,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",534,0.0,0.0,0,0,0.0,0.0,0.0,0.0,60.0,0.0,6144.0,6144.0,2.56,2621.567999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",535,0.0,0.0,0,0,0.0,0.0,0.0,0.0,60.0,0.0,6144.0,6144.0,2.624,2624.191999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",536,12288.0,1103616.0,0,0,0.0,1103616.0,1103616.0,6240.0,12.0,0.9980806142034548,15360.0,3072.0,20.352,2644.543999999995,930432.0,148608.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",537,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,2048.0,5.568,2650.111999999995,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,64.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",538,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.144,2652.255999999995,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",539,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.112,2654.367999999995,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",540,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.424,2657.791999999995,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",541,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.888,2659.679999999995,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",542,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2661.695999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",543,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.56,2664.255999999995,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",544,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.176,2666.431999999995,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",545,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4544.0,12.8,2679.231999999995,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,142.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",546,35328.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,48.0,0.0,12288.0,12288.0,2.272,2681.503999999995,3072.0,0.0,35328.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",547,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4800.0,13.152,2694.655999999995,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,150.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",548,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.08,2696.735999999995,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",549,2360064.0,4744704.0,0,0,0.0,4744704.0,4744704.0,13056.0,148224.0,0.08095238095238096,10027264.0,2528.0,12.864,2709.599999999995,24576.0,0.0,2360064.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313352.0,79.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",550,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,2711.775999999995,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",551,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.144,2713.9199999999946,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",552,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.648,2717.5679999999948,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",553,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.984,2719.5519999999947,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",554,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2721.5679999999948,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",555,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.592,2724.159999999995,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",556,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.176,2726.335999999995,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",557,591360.0,1207296.0,0,0,0.0,1207296.0,1207296.0,10752.0,37632.0,0.2222222222222222,2752512.0,10720.0,5.152,2731.487999999995,24576.0,0.0,591360.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86016.0,335.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",558,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2304.0,0.0,6144.0,2720.0,2.4,2733.887999999995,1536.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,85.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",559,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.368,2736.255999999995,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",560,591360.0,1207296.0,0,0,0.0,1207296.0,1207296.0,10752.0,37632.0,0.2222222222222222,2752512.0,10848.0,5.344,2741.599999999995,24576.0,0.0,591360.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86016.0,339.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",561,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2304.0,0.0,6144.0,2592.0,2.432,2744.0319999999947,1536.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,81.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",562,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.368,2746.3999999999946,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",563,591360.0,1207296.0,0,0,0.0,1207296.0,1207296.0,10752.0,37632.0,0.2222222222222222,2752512.0,10720.0,5.28,2751.679999999995,24576.0,0.0,591360.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86016.0,335.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",564,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2304.0,0.0,6144.0,3040.0,2.368,2754.0479999999948,1536.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,95.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",565,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.304,2756.351999999995,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",566,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.688,2759.039999999995,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",567,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.656,2761.695999999995,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",568,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.168,2764.863999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",569,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.656,2767.519999999995,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",570,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,2769.695999999995,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",571,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.624,2772.3199999999947,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",572,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.624,2774.9439999999945,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",573,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.072,2778.0159999999946,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",574,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.752,2780.7679999999946,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",575,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.208,2782.9759999999947,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",576,0.0,0.0,0,0,0.0,0.0,0.0,0.0,60.0,0.0,6144.0,6144.0,2.56,2785.5359999999946,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",577,0.0,0.0,0,0,0.0,0.0,0.0,0.0,60.0,0.0,6144.0,6144.0,2.56,2788.0959999999945,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",578,12288.0,1103616.0,0,0,0.0,1103616.0,1103616.0,6240.0,12.0,0.9980806142034548,15360.0,3072.0,20.352,2808.4479999999944,930432.0,148608.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",579,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,1984.0,5.44,2813.8879999999945,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,62.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",580,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,2816.0639999999944,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",581,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.112,2818.1759999999945,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",582,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.424,2821.5999999999945,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",583,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.952,2823.5519999999947,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",584,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,2825.6319999999946,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",585,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.56,2828.1919999999946,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",586,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.24,2830.4319999999943,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",587,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4480.0,12.64,2843.071999999994,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,140.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",588,35328.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,48.0,0.0,12288.0,12288.0,2.368,2845.439999999994,3072.0,0.0,35328.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",589,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4608.0,12.608,2858.0479999999943,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",590,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.048,2860.095999999994,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",591,2360064.0,4744704.0,0,0,0.0,4744704.0,4744704.0,13056.0,148224.0,0.08095238095238096,10027008.0,2208.0,12.832,2872.927999999994,24576.0,0.0,2360064.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313344.0,69.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",592,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.208,2875.135999999994,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",593,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.112,2877.247999999994,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",594,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.456,2880.7039999999943,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",595,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.952,2882.6559999999945,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",596,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,2884.6399999999944,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",597,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.528,2887.167999999994,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",598,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.144,2889.311999999994,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",599,591360.0,1207296.0,0,0,0.0,1207296.0,1207296.0,10752.0,37632.0,0.2222222222222222,2752512.0,10944.0,5.184,2894.495999999994,24576.0,0.0,591360.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86016.0,342.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",600,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2304.0,0.0,6144.0,2720.0,2.432,2896.927999999994,1536.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,85.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",601,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.304,2899.231999999994,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",602,591360.0,1207296.0,0,0,0.0,1207296.0,1207296.0,10752.0,37632.0,0.2222222222222222,2752512.0,10912.0,5.344,2904.575999999994,24576.0,0.0,591360.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86016.0,341.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",603,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2304.0,0.0,6144.0,2912.0,2.464,2907.039999999994,1536.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,91.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",604,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.4,2909.439999999994,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",605,591360.0,1207296.0,0,0,0.0,1207296.0,1207296.0,10752.0,37632.0,0.2222222222222222,2752512.0,10944.0,5.28,2914.7199999999943,24576.0,0.0,591360.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86016.0,342.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",606,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2304.0,0.0,6144.0,2880.0,2.4,2917.1199999999944,1536.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,90.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",607,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.368,2919.4879999999944,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",608,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.656,2922.1439999999943,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",609,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.656,2924.7999999999943,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",610,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.072,2927.8719999999944,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",611,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.72,2930.591999999994,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",612,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,2932.767999999994,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",613,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.688,2935.455999999994,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",614,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.688,2938.1439999999943,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",615,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.2,2941.343999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",616,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.688,2944.0319999999942,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",617,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.208,2946.2399999999943,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",618,0.0,0.0,0,0,0.0,0.0,0.0,0.0,60.0,0.0,6144.0,6144.0,2.56,2948.7999999999943,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",619,0.0,0.0,0,0,0.0,0.0,0.0,0.0,60.0,0.0,6144.0,6144.0,2.56,2951.359999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",620,12288.0,1103616.0,0,0,0.0,1103616.0,1103616.0,6240.0,12.0,0.9980806142034548,15360.0,3072.0,20.416,2971.7759999999944,930432.0,148608.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",621,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,1824.0,5.632,2977.4079999999944,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,57.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",622,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.144,2979.551999999994,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",623,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.144,2981.695999999994,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",624,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.488,2985.183999999994,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",625,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.984,2987.1679999999938,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",626,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,2989.1519999999937,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",627,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.592,2991.743999999994,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",628,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.112,2993.855999999994,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",629,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4576.0,12.704,3006.559999999994,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,143.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",630,35328.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,48.0,0.0,12288.0,12288.0,2.208,3008.767999999994,3072.0,0.0,35328.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",631,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4416.0,12.928,3021.695999999994,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,138.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",632,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.112,3023.807999999994,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",633,2360064.0,4744704.0,0,0,0.0,4744704.0,4744704.0,13056.0,148224.0,0.08095238095238096,10029312.0,2368.0,12.8,3036.6079999999943,24576.0,0.0,2360064.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313416.0,74.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",634,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.144,3038.751999999994,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",635,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.176,3040.927999999994,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",636,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.456,3044.383999999994,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",637,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.92,3046.303999999994,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",638,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,3048.3199999999943,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",639,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.56,3050.879999999994,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",640,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.208,3053.0879999999943,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",641,591360.0,1207296.0,0,0,0.0,1207296.0,1207296.0,10752.0,37632.0,0.2222222222222222,2752512.0,11200.0,5.408,3058.495999999994,24576.0,0.0,591360.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86016.0,350.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",642,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2304.0,0.0,6144.0,2656.0,2.4,3060.8959999999943,1536.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,83.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",643,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.368,3063.263999999994,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",644,591360.0,1207296.0,0,0,0.0,1207296.0,1207296.0,10752.0,37632.0,0.2222222222222222,2752512.0,10880.0,5.376,3068.6399999999944,24576.0,0.0,591360.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86016.0,340.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",645,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2304.0,0.0,6144.0,2464.0,2.4,3071.0399999999945,1536.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,77.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",646,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.336,3073.3759999999943,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",647,591360.0,1207296.0,0,0,0.0,1207296.0,1207296.0,10752.0,37632.0,0.2222222222222222,2752512.0,11008.0,5.312,3078.687999999994,24576.0,0.0,591360.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86016.0,344.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",648,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2304.0,0.0,6144.0,2688.0,2.464,3081.151999999994,1536.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,84.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",649,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.368,3083.519999999994,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",650,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.624,3086.143999999994,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",651,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.656,3088.799999999994,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",652,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.136,3091.935999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",653,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.624,3094.5599999999936,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",654,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.304,3096.8639999999937,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",655,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.624,3099.4879999999935,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",656,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.656,3102.1439999999934,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",657,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.104,3105.247999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",658,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.624,3107.871999999993,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",659,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,3110.047999999993,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",660,0.0,0.0,0,0,0.0,0.0,0.0,0.0,60.0,0.0,6144.0,6144.0,2.528,3112.5759999999927,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",661,0.0,0.0,0,0,0.0,0.0,0.0,0.0,60.0,0.0,6144.0,6144.0,2.528,3115.1039999999925,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",662,12288.0,1103616.0,0,0,0.0,1103616.0,1103616.0,6240.0,12.0,0.9980806142034548,15360.0,3072.0,20.416,3135.5199999999927,930432.0,148608.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",663,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,2048.0,5.696,3141.2159999999926,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,64.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",664,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.336,3143.5519999999924,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",665,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.144,3145.695999999992,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",666,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.456,3149.1519999999923,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",667,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.952,3151.1039999999925,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",668,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,3153.0879999999925,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",669,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.56,3155.6479999999924,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",670,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.144,3157.791999999992,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",671,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4672.0,12.704,3170.4959999999924,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,146.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",672,35328.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,48.0,0.0,12288.0,12288.0,2.272,3172.7679999999923,3072.0,0.0,35328.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",673,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4736.0,12.8,3185.5679999999925,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,148.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",674,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.08,3187.6479999999924,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",675,2360064.0,4744704.0,0,0,0.0,4744704.0,4744704.0,13056.0,148224.0,0.08095238095238096,10027392.0,2368.0,12.928,3200.5759999999923,24576.0,0.0,2360064.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313356.0,74.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",676,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.144,3202.719999999992,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",677,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.112,3204.831999999992,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",678,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.456,3208.2879999999923,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",679,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.984,3210.271999999992,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",680,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,3212.319999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",681,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.592,3214.911999999992,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",682,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.144,3217.055999999992,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",683,591360.0,1207296.0,0,0,0.0,1207296.0,1207296.0,10752.0,37632.0,0.2222222222222222,2752512.0,11040.0,5.312,3222.3679999999918,24576.0,0.0,591360.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86016.0,345.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",684,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2304.0,0.0,6144.0,2752.0,2.336,3224.7039999999915,1536.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,86.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",685,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.464,3227.1679999999915,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",686,591360.0,1207296.0,0,0,0.0,1207296.0,1207296.0,10752.0,37632.0,0.2222222222222222,2752512.0,10976.0,5.312,3232.4799999999914,24576.0,0.0,591360.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86016.0,343.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",687,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2304.0,0.0,6144.0,2592.0,2.432,3234.911999999991,1536.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,81.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",688,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.4,3237.3119999999913,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",689,591360.0,1207296.0,0,0,0.0,1207296.0,1207296.0,10752.0,37632.0,0.2222222222222222,2752512.0,10976.0,5.312,3242.623999999991,24576.0,0.0,591360.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86016.0,343.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",690,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2304.0,0.0,6144.0,2976.0,2.4,3245.0239999999912,1536.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,93.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",691,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.4,3247.4239999999913,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",692,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.624,3250.047999999991,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",693,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.688,3252.7359999999912,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",694,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.104,3255.839999999991,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",695,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.688,3258.527999999991,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",696,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.208,3260.7359999999912,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",697,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.72,3263.455999999991,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",698,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.688,3266.143999999991,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",699,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.104,3269.247999999991,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",700,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.592,3271.839999999991,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",701,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.144,3273.983999999991,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",702,0.0,0.0,0,0,0.0,0.0,0.0,0.0,60.0,0.0,6144.0,6144.0,2.592,3276.575999999991,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",703,0.0,0.0,0,0,0.0,0.0,0.0,0.0,60.0,0.0,6144.0,6144.0,2.592,3279.167999999991,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",704,12288.0,1103616.0,0,0,0.0,1103616.0,1103616.0,6240.0,12.0,0.9980806142034548,15360.0,3072.0,20.416,3299.583999999991,930432.0,148608.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",705,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,1952.0,5.536,3305.1199999999913,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,61.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",706,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,3307.295999999991,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",707,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.144,3309.439999999991,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",708,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.488,3312.927999999991,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",709,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.92,3314.847999999991,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",710,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,3316.863999999991,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",711,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.56,3319.423999999991,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",712,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.208,3321.631999999991,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",713,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4416.0,12.8,3334.431999999991,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,138.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",714,35328.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,48.0,0.0,12288.0,12288.0,2.24,3336.671999999991,3072.0,0.0,35328.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",715,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4736.0,12.672,3349.343999999991,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,148.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",716,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.048,3351.3919999999907,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",717,2360064.0,4744704.0,0,0,0.0,4744704.0,4744704.0,13056.0,148224.0,0.08095238095238096,10027648.0,2240.0,12.832,3364.2239999999906,24576.0,0.0,2360064.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313364.0,70.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",718,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,3366.3999999999905,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",719,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.144,3368.5439999999903,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",720,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.488,3372.03199999999,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",721,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.016,3374.04799999999,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",722,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,3376.0639999999903,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",723,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.592,3378.6559999999904,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",724,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.176,3380.8319999999903,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",725,591360.0,1207296.0,0,0,0.0,1207296.0,1207296.0,10752.0,37632.0,0.2222222222222222,2752512.0,10816.0,5.344,3386.1759999999904,24576.0,0.0,591360.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86016.0,338.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",726,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2304.0,0.0,6144.0,2944.0,2.4,3388.5759999999905,1536.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,92.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",727,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.368,3390.9439999999904,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",728,591360.0,1207296.0,0,0,0.0,1207296.0,1207296.0,10752.0,37632.0,0.2222222222222222,2752512.0,10848.0,5.152,3396.0959999999905,24576.0,0.0,591360.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86016.0,339.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",729,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2304.0,0.0,6144.0,2688.0,2.432,3398.5279999999902,1536.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,84.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",730,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.336,3400.86399999999,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",731,591360.0,1207296.0,0,0,0.0,1207296.0,1207296.0,10752.0,37632.0,0.2222222222222222,2752512.0,10784.0,5.184,3406.04799999999,24576.0,0.0,591360.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86016.0,337.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",732,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2304.0,0.0,6144.0,2880.0,2.336,3408.38399999999,1536.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,90.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",733,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.336,3410.71999999999,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",734,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.592,3413.31199999999,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",735,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.656,3415.96799999999,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",736,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.136,3419.10399999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",737,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.688,3421.79199999999,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",738,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,3423.96799999999,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",739,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.656,3426.62399999999,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",740,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.624,3429.2479999999896,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",741,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.072,3432.3199999999897,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",742,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.624,3434.9439999999895,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",743,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,3437.1199999999894,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",744,0.0,0.0,0,0,0.0,0.0,0.0,0.0,60.0,0.0,6144.0,6144.0,2.688,3439.8079999999895,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",745,0.0,0.0,0,0,0.0,0.0,0.0,0.0,60.0,0.0,6144.0,6144.0,2.624,3442.4319999999893,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",746,12288.0,1103616.0,0,0,0.0,1103616.0,1103616.0,6240.0,12.0,0.9980806142034548,15360.0,3072.0,20.576,3463.0079999999894,930432.0,148608.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",747,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,2080.0,5.504,3468.5119999999893,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,65.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",748,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.144,3470.655999999989,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",749,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.08,3472.735999999989,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",750,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.488,3476.223999999989,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",751,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.984,3478.2079999999887,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",752,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,3480.2559999999885,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",753,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.592,3482.8479999999886,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",754,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.176,3485.0239999999885,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",755,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4416.0,12.864,3497.8879999999886,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,138.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",756,35328.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,48.0,0.0,12288.0,12288.0,2.272,3500.1599999999885,3072.0,0.0,35328.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",757,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4384.0,12.672,3512.8319999999885,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,137.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",758,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.048,3514.8799999999883,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",759,2360064.0,4744704.0,0,0,0.0,4744704.0,4744704.0,13056.0,148224.0,0.08095238095238096,10028416.0,2624.0,13.376,3528.2559999999885,24576.0,0.0,2360064.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313388.0,82.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",760,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.336,3530.5919999999883,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",761,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.144,3532.735999999988,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",762,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.456,3536.191999999988,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",763,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.984,3538.175999999988,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",764,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,3540.159999999988,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",765,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.592,3542.751999999988,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",766,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.144,3544.895999999988,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",767,116686848.0,255100544.0,0,0,0.0,255100544.0,255100544.0,4861952.0,4178240.0,0.5378151260504201,480301952.0,675072.0,501.088,4045.983999999988,7140992.0,14585856.0,116686848.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,15009436.0,21096.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",768,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,4047.711999999988,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",769,0.0,0.0,0,0,0.0,0.0,0.0,0.0,5.0,0.0,64.0,64.0,2.656,4050.367999999988,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",770,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,4052.415999999988,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",771,0.0,151936.0,0,0,0.0,151936.0,151936.0,0.0,2392.0,0.0,607744.0,607744.0,2.624,4055.0399999999877,0.0,151936.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,18992.0,18992.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",772,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.632,4056.6719999999877,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",773,0.0,0.0,0,0,0.0,0.0,0.0,2384.0,7132.0,0.2505254308532997,611840.0,43200.0,3.552,4060.223999999988,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,19120.0,1350.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",774,0.0,0.0,0,0,0.0,0.0,0.0,11026.0,179547.0,0.057857094131907455,9777824.0,0.0,8.64,4068.8639999999878,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,305557.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",775,0.0,0.0,0,0,0.0,0.0,0.0,2384.0,7132.0,0.2505254308532997,611840.0,42624.0,3.552,4072.415999999988,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,19120.0,1332.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",776,0.0,0.0,0,0,0.0,0.0,0.0,11026.0,180441.0,0.05758694709793333,9777824.0,0.0,8.736,4081.1519999999878,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,305557.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",777,0.0,0.0,0,0,0.0,0.0,0.0,2384.0,7132.0,0.2505254308532997,611840.0,41920.0,3.488,4084.6399999999876,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,19120.0,1310.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",778,0.0,0.0,0,0,0.0,0.0,0.0,11026.0,179845.0,0.05776676394004328,9777824.0,0.0,8.672,4093.3119999999876,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,305557.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",779,0.0,0.0,0,0,0.0,0.0,0.0,2384.0,7132.0,0.2505254308532997,611840.0,41984.0,4.032,4097.343999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,19120.0,1312.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",780,0.0,0.0,0,0,0.0,0.0,0.0,11026.0,180441.0,0.05758694709793333,9777824.0,32.0,8.416,4105.7599999999875,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,305557.0,1.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",781,0.0,0.0,0,0,0.0,0.0,0.0,0.0,15.0,0.0,4800.0,608.0,2.432,4108.191999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,150.0,19.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",782,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.696,4109.887999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",783,0.0,0.0,0,0,0.0,0.0,0.0,497.0,18.0,0.9650485436893204,608.0,0.0,3.616,4113.503999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,19.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",784,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.696,4115.199999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",785,0.0,0.0,0,0,0.0,0.0,0.0,497.0,18.0,0.9650485436893204,608.0,0.0,3.584,4118.783999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,19.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 1>(detail::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, detail::TensorInfo<T1, T2>, T2, detail::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",786,0.0,0.0,0,0,0.0,0.0,0.0,38784.0,9600.0,0.8015873015873016,625280.0,2880.0,5.696,4124.479999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,19540.0,90.0
"void native::radixSortKVInPlace<(int)-2, (int)-1, 32, 4, float, long, unsigned int>(detail::TensorInfo<T5, T7>, T7, T7, T7, detail::TensorInfo<T6, T7>, T7, bool)",787,0.0,0.0,0,0,0.0,0.0,0.0,458.0,8.0,0.9828326180257511,640.0,0.0,5.984,4130.463999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,20.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",788,0.0,0.0,0,0,0.0,0.0,0.0,0.0,14244.0,0.0,611840.0,67584.0,3.584,4134.047999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,19120.0,2112.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",789,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3588.0,0.0,759680.0,0.0,3.072,4137.119999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,23740.0,0.0
"native::<unnamed>::fill_reverse_indices_kernel(long *, int, detail::IntDivider<unsigned int>)",790,0.0,0.0,0,0,0.0,0.0,0.0,0.0,4748.0,0.0,0.0,1215488.0,2.592,4139.711999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,37984.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",791,0.0,0.0,0,0,0.0,0.0,0.0,98304.0,4748.0,0.9539261731941155,607744.0,0.0,4.224,4143.935999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,18992.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",792,0.0,0.0,0,0,0.0,0.0,0.0,156.0,64.0,0.7090909090909091,8192.0,0.0,2.144,4146.079999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",793,0.0,0.0,0,0,0.0,0.0,0.0,44594.0,22675.0,0.6629205131635671,2252928.0,1474688.0,9.152,4155.231999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,70404.0,46084.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",794,0.0,0.0,0,0,0.0,0.0,0.0,17750.0,23918.0,0.42598636843621,2283264.0,1874432.0,8.096,4163.327999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,71352.0,58576.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",795,0.0,0.0,0,0,0.0,0.0,0.0,18494.0,24403.0,0.4311257197473017,2272640.0,1874432.0,8.512,4171.8399999999865,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,71020.0,58576.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",796,0.0,0.0,0,0,0.0,0.0,0.0,18494.0,24145.0,0.43373437463355147,2269312.0,1614304.0,8.416,4180.255999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,70916.0,50447.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",797,2127104.0,5019168.0,0,0,0.0,5019168.0,5019168.0,132.0,4784.0,0.026851098454027666,1823232.0,607744.0,61.696,4241.951999999987,613024.0,151936.0,2127104.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,56976.0,18992.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<float, 1>>(T1, int)",798,0.0,0.0,0,0,0.0,0.0,0.0,0.0,4.0,0.0,0.0,896.0,1.696,4243.6479999999865,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,28.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<float, std::plus<float>>::Policy900, const float *, float *, at_cuda_detail::ScanTileState<float, 1>, std::plus<float>, at_cuda_detail::NullType, unsigned int, float, 0>(T2, T3, T4, int, T5, T6, T7)",799,0.0,405323.0,0,0,0.0,405323.0,405323.0,20797.0,10322.0,0.6683055368103088,660928.0,612704.0,4.992,4248.639999999987,405323.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,20654.0,19147.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",800,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2392.0,0.0,607744.0,151648.0,2.848,4251.487999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,18992.0,4739.0
"void native::unrolled_elementwise_kernel<native::FillFunctor<bool>, std::array<char *, 1>, 16, TrivialOffsetCalculator<0, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithoutCast, memory::StoreWithoutCast>(int, T1, T2, T4, T5, T6, T7)",801,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,4253.183999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",802,0.0,0.0,0,0,0.0,0.0,0.0,0.0,14244.0,0.0,1367424.0,61312.0,7.2,4260.383999999986,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,42732.0,1916.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",803,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3588.0,0.0,759680.0,0.0,3.04,4263.423999999986,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,23740.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",804,2127104.0,5019168.0,0,0,0.0,5019168.0,5019168.0,132.0,4784.0,0.026851098454027666,1823232.0,607744.0,62.08,4325.503999999986,613024.0,151936.0,2127104.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,56976.0,18992.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",805,0.0,0.0,0,0,0.0,0.0,0.0,1563.0,1208.0,0.564056297365572,607840.0,640.0,6.272,4331.775999999986,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,18995.0,20.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",806,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.176,4333.951999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",807,0.0,0.0,0,0,0.0,0.0,0.0,1563.0,1208.0,0.564056297365572,607840.0,640.0,6.08,4340.0319999999865,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,18995.0,20.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",808,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,4342.175999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",809,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.08,4344.255999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",810,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.944,4347.199999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",811,0.0,241939.0,0,0,0.0,241939.0,241939.0,1563.0,1208.0,0.564056297365572,607840.0,640.0,5.92,4353.119999999987,241939.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,18995.0,20.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",812,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,4355.135999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",813,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.112,4357.247999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",814,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.976,4360.2239999999865,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",815,1368576.0,3041024.0,0,0,0.0,3041024.0,3041024.0,0.0,4748.0,0.0,0.0,607744.0,3.584,4363.807999999986,0.0,303872.0,1368576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,18992.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",816,759680.0,1519360.0,0,0,0.0,1519360.0,1519360.0,0.0,3588.0,0.0,1215488.0,0.0,4.352,4368.159999999986,0.0,0.0,759680.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,37984.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",817,0.0,0.0,0,0,0.0,0.0,0.0,2803.0,1228.0,0.6953609526172165,608064.0,640.0,7.744,4375.903999999986,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,19002.0,20.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",818,0.0,0.0,0,0,0.0,0.0,0.0,0.0,5.0,0.0,64.0,64.0,2.592,4378.4959999999855,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",819,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,4380.1919999999855,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",820,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,4381.9199999999855,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",821,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.08,4383.999999999985,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",822,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,4386.047999999985,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",823,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.784,4388.831999999985,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",824,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.168,4391.9999999999845,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",825,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,4394.047999999984,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
