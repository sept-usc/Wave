Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.824,1.824,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,3.552,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.632,5.184,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.048,7.232,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.24,9.472000000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",6,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.304,11.776000000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",7,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.456,15.232000000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",8,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.2,18.432000000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",9,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,20.576,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",10,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.664,22.240000000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",11,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.664,23.904000000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.632,25.536000000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,0.0,0.0,0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,2.368,27.904000000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,29.952000000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",15,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.112,32.06400000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",16,0.0,0.0,0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,32.0,32.0,2.464,34.528000000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",17,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,36.51200000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",18,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,38.56000000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",19,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,2.048,40.60800000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",20,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1152.0,0.0,13056.0,49152.0,3.808,44.41600000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,408.0,1536.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",21,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.496,46.91200000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",22,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,50.240000000000016,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",23,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,52.768000000000015,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",24,0.0,512.0,0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,2.016,54.78400000000001,0.0,512.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",25,0.0,0.0,0,0,0.0,0.0,0.0,0.0,20.0,0.0,2048.0,2048.0,2.496,57.280000000000015,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",26,4096.0,9216.0,0,0,0.0,9216.0,9216.0,0.0,32.0,0.0,2048.0,2048.0,2.72,60.000000000000014,0.0,1024.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",27,0.0,512.0,0,0,0.0,512.0,512.0,0.0,32.0,0.0,2048.0,2048.0,2.048,62.048000000000016,0.0,512.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",28,3584.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,32.0,0.0,2048.0,2048.0,2.912,64.96000000000002,0.0,1024.0,3584.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",29,0.0,512.0,0,0,0.0,512.0,512.0,0.0,32.0,0.0,2048.0,2048.0,2.048,67.00800000000002,0.0,512.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",30,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.016,69.02400000000003,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",31,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,5.12,74.14400000000003,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",32,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.888,76.03200000000004,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",33,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.952,77.98400000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",34,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.656,80.64000000000004,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",35,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.72,83.36000000000004,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,36,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,50.368,133.72800000000004,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",37,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.4,136.12800000000004,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,38,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,49.28,185.40800000000004,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",39,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.4,187.80800000000005,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,40,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,49.216,237.02400000000006,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",41,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.4,239.42400000000006,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",42,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.816,242.24000000000007,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",43,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.528,244.76800000000006,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",44,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.0,248.76800000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",45,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.656,251.42400000000006,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",46,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.08,253.50400000000008,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",47,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.688,256.19200000000006,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",48,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.592,258.78400000000005,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",49,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,3.936,262.72,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",50,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.656,265.37600000000003,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",51,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.048,267.42400000000004,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",52,196608.0,17651712.0,0,0,0.0,17651712.0,17651712.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,20.48,287.90400000000005,14880768.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,53,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,48.704,336.60800000000006,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",54,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.624,339.2320000000001,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",55,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.08,341.31200000000007,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",56,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.016,343.3280000000001,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",57,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,5.088,348.4160000000001,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",58,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,350.3360000000001,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",59,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,352.3200000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",60,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.688,355.0080000000001,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",61,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.688,357.6960000000001,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",62,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,202591616.0,302496.0,168.448,526.1440000000001,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6330988.0,9453.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",63,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,2.4,528.5440000000001,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",64,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,205974400.0,295904.0,168.992,697.5360000000001,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6436700.0,9247.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",65,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.4,699.936,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_128x32_sliced1x4_tn,66,1245708288.0,2503802880.0,0,0,0.0,2503802880.0,2503802880.0,4344192.0,1261440.0,0.7749691738594328,169286464.0,884736.0,202.528,902.464,5308416.0,7077888.0,1245708288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5290202.0,27648.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",67,0.0,233472.0,0,0,0.0,233472.0,233472.0,0.0,7296.0,0.0,884736.0,49152.0,3.584,906.048,221184.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,27648.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",68,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,908.16,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",69,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.08,910.24,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",70,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,5.12,915.36,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",71,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.888,917.248,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",72,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.952,919.2,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",73,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.656,921.856,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",74,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.592,924.448,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,75,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,48.896,973.3439999999999,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",76,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.464,975.808,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,77,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,49.12,1024.9279999999999,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",78,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.432,1027.36,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,79,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,48.576,1075.936,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",80,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.464,1078.3999999999999,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",81,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.656,1081.0559999999998,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",82,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.752,1083.8079999999998,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",83,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,3.936,1087.7439999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",84,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.72,1090.4639999999997,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",85,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.144,1092.6079999999997,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",86,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.656,1095.2639999999997,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",87,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.688,1097.9519999999998,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",88,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,3.936,1101.8879999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",89,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.944,1104.8319999999997,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",90,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.08,1106.9119999999996,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",91,196608.0,17651712.0,0,0,0.0,17651712.0,17651712.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,20.576,1127.4879999999996,14880768.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,92,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,50.048,1177.5359999999996,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",93,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.432,1179.9679999999996,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",94,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.144,1182.1119999999996,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",95,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.016,1184.1279999999997,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",96,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,5.088,1189.2159999999997,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",97,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,1191.1679999999997,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",98,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.952,1193.1199999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",99,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.688,1195.8079999999998,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",100,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.688,1198.4959999999999,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",101,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,203132800.0,291808.0,170.208,1368.704,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6347900.0,9119.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",102,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,2.464,1371.168,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",103,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,205907584.0,296000.0,168.416,1539.5839999999998,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6434612.0,9250.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",104,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.528,1542.1119999999999,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_128x32_sliced1x4_tn,105,1245708288.0,2503802880.0,0,0,0.0,2503802880.0,2503802880.0,4344192.0,1261440.0,0.7749691738594328,169254880.0,884736.0,202.688,1744.7999999999997,5308416.0,7077888.0,1245708288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5289215.0,27648.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",106,0.0,233472.0,0,0,0.0,233472.0,233472.0,0.0,7296.0,0.0,884736.0,49152.0,3.52,1748.3199999999997,221184.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,27648.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",107,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.08,1750.3999999999996,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",108,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.048,1752.4479999999996,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",109,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,5.024,1757.4719999999995,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",110,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,1759.3919999999996,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",111,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,1761.3759999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",112,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.592,1763.9679999999996,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",113,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.656,1766.6239999999996,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,114,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,49.28,1815.9039999999995,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",115,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.4,1818.3039999999996,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,116,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,50.272,1868.5759999999996,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",117,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.432,1871.0079999999996,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,118,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,49.376,1920.3839999999996,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",119,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.464,1922.8479999999995,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",120,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.688,1925.5359999999996,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",121,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.656,1928.1919999999996,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",122,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,3.968,1932.1599999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",123,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.688,1934.8479999999997,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",124,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.144,1936.9919999999997,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",125,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.688,1939.6799999999998,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",126,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.56,1942.2399999999998,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",127,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,3.936,1946.1759999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",128,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.816,1948.9919999999997,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",129,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.08,1951.0719999999997,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",130,196608.0,17651712.0,0,0,0.0,17651712.0,17651712.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,20.48,1971.5519999999997,14880768.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,131,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,50.208,2021.7599999999998,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",132,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.464,2024.2239999999997,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",133,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.08,2026.3039999999996,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",134,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,1.984,2028.2879999999996,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",135,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,5.024,2033.3119999999994,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",136,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,2035.2319999999995,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",137,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,2037.2159999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",138,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.656,2039.8719999999994,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",139,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.624,2042.4959999999994,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",140,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,206829312.0,300448.0,168.352,2210.8479999999995,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6463416.0,9389.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",141,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,2.4,2213.2479999999996,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",142,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,204903424.0,298432.0,170.112,2383.3599999999997,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6403232.0,9326.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",143,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.368,2385.7279999999996,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_128x32_sliced1x4_tn,144,1245708288.0,2503802880.0,0,0,0.0,2503802880.0,2503802880.0,4344192.0,1261440.0,0.7749691738594328,169247648.0,884736.0,202.912,2588.6399999999994,5308416.0,7077888.0,1245708288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5288989.0,27648.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",145,0.0,233472.0,0,0,0.0,233472.0,233472.0,0.0,7296.0,0.0,884736.0,49152.0,3.712,2592.3519999999994,221184.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,27648.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",146,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.08,2594.4319999999993,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",147,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.016,2596.4479999999994,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",148,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,5.12,2601.5679999999993,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",149,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.888,2603.455999999999,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",150,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.952,2605.4079999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",151,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.656,2608.0639999999994,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",152,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.784,2610.8479999999995,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,153,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,48.64,2659.4879999999994,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",154,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.496,2661.9839999999995,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,155,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,50.56,2712.5439999999994,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",156,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.496,2715.0399999999995,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,157,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,48.384,2763.4239999999995,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",158,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.432,2765.8559999999993,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",159,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.688,2768.5439999999994,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",160,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.56,2771.1039999999994,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",161,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,3.936,2775.0399999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",162,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.688,2777.7279999999996,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",163,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.048,2779.7759999999994,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",164,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.816,2782.591999999999,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",165,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.592,2785.1839999999993,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",166,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.0,2789.1839999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",167,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.688,2791.8719999999994,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",168,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.08,2793.9519999999993,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",169,196608.0,17651712.0,0,0,0.0,17651712.0,17651712.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,20.544,2814.495999999999,14880768.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,170,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,50.304,2864.7999999999993,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",171,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.4,2867.1999999999994,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",172,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,2869.3119999999994,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",173,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.016,2871.3279999999995,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",174,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,5.088,2876.4159999999997,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",175,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.888,2878.3039999999996,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",176,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.952,2880.256,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",177,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.656,2882.912,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",178,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.624,2885.5359999999996,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",179,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,205408640.0,294464.0,169.184,3054.72,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6419020.0,9202.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",180,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,2.432,3057.1519999999996,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",181,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,206847488.0,296704.0,168.576,3225.7279999999996,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6463984.0,9272.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",182,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.336,3228.0639999999994,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_128x32_sliced1x4_tn,183,1245708288.0,2503802880.0,0,0,0.0,2503802880.0,2503802880.0,4344192.0,1261440.0,0.7749691738594328,169276480.0,884736.0,202.144,3430.2079999999996,5308416.0,7077888.0,1245708288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5289890.0,27648.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",184,0.0,233472.0,0,0,0.0,233472.0,233472.0,0.0,7296.0,0.0,884736.0,49152.0,3.68,3433.8879999999995,221184.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,27648.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",185,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,3435.9999999999995,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",186,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.016,3438.0159999999996,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",187,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,4.992,3443.008,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",188,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,3444.9919999999997,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",189,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.952,3446.944,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",190,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.624,3449.5679999999998,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",191,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.656,3452.2239999999997,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,192,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,48.48,3500.7039999999997,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",193,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.432,3503.1359999999995,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,194,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,49.888,3553.0239999999994,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",195,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.496,3555.5199999999995,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,196,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,48.576,3604.0959999999995,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",197,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.432,3606.5279999999993,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",198,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.688,3609.2159999999994,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",199,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.592,3611.8079999999995,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",200,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,3.936,3615.7439999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",201,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.72,3618.4639999999995,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",202,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.08,3620.5439999999994,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",203,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.688,3623.2319999999995,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",204,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.656,3625.8879999999995,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",205,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.16,3630.0479999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",206,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.688,3632.7359999999994,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",207,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.048,3634.783999999999,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",208,196608.0,17651712.0,0,0,0.0,17651712.0,17651712.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,20.48,3655.263999999999,14880768.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,209,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,49.696,3704.959999999999,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",210,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.432,3707.391999999999,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",211,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.048,3709.4399999999987,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",212,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.048,3711.4879999999985,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",213,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,5.152,3716.6399999999985,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",214,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,3718.5599999999986,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",215,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,3720.5439999999985,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",216,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.72,3723.2639999999983,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",217,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.72,3725.983999999998,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",218,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,206924160.0,297824.0,167.712,3893.695999999998,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6466380.0,9307.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",219,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,2.56,3896.255999999998,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",220,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,201942400.0,295296.0,169.44,4065.695999999998,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6310700.0,9228.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",221,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.56,4068.255999999998,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_128x32_sliced1x4_tn,222,1245708288.0,2503802880.0,0,0,0.0,2503802880.0,2503802880.0,4344192.0,1261440.0,0.7749691738594328,169268768.0,884736.0,202.016,4270.271999999998,5308416.0,7077888.0,1245708288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5289649.0,27648.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",223,0.0,233472.0,0,0,0.0,233472.0,233472.0,0.0,7296.0,0.0,884736.0,49152.0,3.584,4273.855999999998,221184.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,27648.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",224,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,4275.967999999998,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",225,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.016,4277.983999999998,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",226,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,5.184,4283.167999999998,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",227,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,4285.087999999998,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",228,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,4287.135999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",229,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.624,4289.7599999999975,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",230,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.656,4292.415999999997,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,231,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,48.832,4341.247999999998,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",232,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.432,4343.679999999998,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,233,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,49.728,4393.407999999998,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",234,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.56,4395.967999999998,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,235,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,48.064,4444.031999999998,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",236,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.464,4446.495999999998,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",237,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.72,4449.2159999999985,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",238,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.624,4451.839999999998,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",239,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,3.968,4455.807999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",240,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.752,4458.559999999999,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",241,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.24,4460.799999999998,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",242,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.656,4463.455999999998,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",243,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.56,4466.015999999999,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",244,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.032,4470.047999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",245,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.72,4472.767999999999,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",246,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,4474.879999999999,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",247,196608.0,17651712.0,0,0,0.0,17651712.0,17651712.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,20.544,4495.423999999999,14880768.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,248,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,50.112,4545.535999999999,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",249,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.496,4548.031999999999,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",250,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.048,4550.079999999999,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",251,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.176,4552.255999999999,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",252,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,5.056,4557.311999999999,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",253,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,4559.231999999999,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",254,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.952,4561.183999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",255,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.752,4563.936,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",256,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.624,4566.5599999999995,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",257,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,205874432.0,300000.0,169.184,4735.744,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6433576.0,9375.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",258,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,2.4,4738.143999999999,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",259,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,206458112.0,295808.0,168.032,4906.1759999999995,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6451816.0,9244.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",260,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.56,4908.736,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_128x32_sliced1x4_tn,261,1245708288.0,2503802880.0,0,0,0.0,2503802880.0,2503802880.0,4344192.0,1261440.0,0.7749691738594328,169311296.0,884736.0,202.56,5111.296,5308416.0,7077888.0,1245708288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5290978.0,27648.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",262,0.0,233472.0,0,0,0.0,233472.0,233472.0,0.0,7296.0,0.0,884736.0,49152.0,3.648,5114.944,221184.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,27648.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",263,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,5117.0560000000005,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",264,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.016,5119.072,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",265,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,5.088,5124.16,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",266,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.888,5126.048,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",267,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.952,5128.0,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",268,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.72,5130.72,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",269,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.624,5133.344,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,270,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,48.896,5182.24,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",271,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.496,5184.736,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,272,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,49.952,5234.688,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",273,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.464,5237.152,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,274,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,48.128,5285.28,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",275,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.4,5287.679999999999,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",276,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.72,5290.4,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",277,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.592,5292.991999999999,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",278,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,3.968,5296.959999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",279,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.72,5299.679999999999,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",280,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.08,5301.759999999999,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",281,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.688,5304.447999999999,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",282,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.592,5307.039999999999,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",283,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.0,5311.039999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",284,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.688,5313.727999999999,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",285,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.08,5315.807999999999,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",286,196608.0,17651712.0,0,0,0.0,17651712.0,17651712.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,20.512,5336.319999999999,14880768.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,287,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,50.784,5387.103999999998,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",288,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.4,5389.503999999998,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",289,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.048,5391.551999999998,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",290,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,1.984,5393.535999999998,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",291,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,4.96,5398.495999999998,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",292,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,5400.479999999999,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",293,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.952,5402.431999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",294,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.688,5405.119999999999,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",295,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.688,5407.807999999999,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",296,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,206069120.0,297152.0,167.712,5575.519999999999,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6439660.0,9286.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",297,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,2.528,5578.047999999999,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",298,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,206042624.0,302208.0,168.608,5746.655999999999,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6438832.0,9444.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",299,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.496,5749.151999999999,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_128x32_sliced1x4_tn,300,1245708288.0,2503802880.0,0,0,0.0,2503802880.0,2503802880.0,4344192.0,1261440.0,0.7749691738594328,169262848.0,884736.0,203.552,5952.703999999999,5308416.0,7077888.0,1245708288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5289464.0,27648.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",301,0.0,233472.0,0,0,0.0,233472.0,233472.0,0.0,7296.0,0.0,884736.0,49152.0,3.616,5956.319999999999,221184.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,27648.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",302,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.304,5958.623999999999,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",303,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.016,5960.6399999999985,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",304,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,5.088,5965.727999999998,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",305,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,5967.647999999998,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",306,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,5969.631999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",307,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.656,5972.287999999999,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",308,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.656,5974.943999999999,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,309,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,49.216,6024.159999999999,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",310,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.432,6026.591999999999,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,311,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,49.184,6075.775999999999,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",312,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.368,6078.143999999999,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,313,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,48.288,6126.431999999999,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",314,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.592,6129.0239999999985,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",315,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.72,6131.743999999999,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",316,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.624,6134.367999999999,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",317,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,3.968,6138.335999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",318,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.752,6141.087999999999,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",319,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.08,6143.167999999999,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",320,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.72,6145.887999999999,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",321,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.592,6148.479999999999,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",322,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,3.936,6152.415999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",323,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.72,6155.135999999999,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",324,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,6157.247999999999,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",325,196608.0,17651712.0,0,0,0.0,17651712.0,17651712.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,20.576,6177.823999999999,14880768.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,326,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,50.816,6228.6399999999985,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",327,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.592,6231.231999999998,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",328,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.08,6233.311999999998,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",329,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.016,6235.327999999998,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",330,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,5.184,6240.511999999998,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",331,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.888,6242.399999999998,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",332,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,6244.415999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",333,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.688,6247.1039999999975,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",334,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.656,6249.7599999999975,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",335,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,206321408.0,301696.0,169.792,6419.551999999998,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6447544.0,9428.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",336,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,2.368,6421.919999999998,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",337,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,206506752.0,306368.0,168.416,6590.335999999998,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6453336.0,9574.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",338,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.56,6592.895999999999,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_128x32_sliced1x4_tn,339,1245708288.0,2503802880.0,0,0,0.0,2503802880.0,2503802880.0,4344192.0,1261440.0,0.7749691738594328,169316416.0,884736.0,202.528,6795.423999999999,5308416.0,7077888.0,1245708288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5291138.0,27648.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",340,0.0,233472.0,0,0,0.0,233472.0,233472.0,0.0,7296.0,0.0,884736.0,49152.0,3.712,6799.1359999999995,221184.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,27648.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",341,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.08,6801.215999999999,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",342,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.016,6803.231999999999,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",343,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,4.992,6808.223999999999,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",344,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.888,6810.111999999999,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",345,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,6812.096,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",346,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.688,6814.784,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",347,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.624,6817.407999999999,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,348,3145728000.0,6298624000.0,0,0,0.0,6298624000.0,6298624000.0,14064000.0,3268000.0,0.8114470343872605,409881600.0,512000.0,455.68,7273.088,3072000.0,4096000.0,3145728000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12808800.0,16000.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",349,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.664,7274.7519999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",350,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,64.0,128.0,2.56,7277.312,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",351,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,7279.296,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",352,0.0,128000.0,0,0,0.0,128000.0,128000.0,0.0,2000.0,0.0,512000.0,512000.0,2.496,7281.792,0.0,128000.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,16000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",353,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.664,7283.456,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",354,0.0,0.0,0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,37952.0,3.552,7287.008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16128.0,1186.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",355,0.0,0.0,0,0,0.0,0.0,0.0,9472.0,34440.0,0.2157041355438149,2109440.0,0.0,4.192,7291.2,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",356,0.0,0.0,0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,37504.0,3.584,7294.784,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16128.0,1172.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",357,0.0,0.0,0,0,0.0,0.0,0.0,9472.0,34696.0,0.2144539032783916,2109440.0,0.0,4.288,7299.071999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",358,0.0,0.0,0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,37696.0,3.616,7302.687999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16128.0,1178.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",359,0.0,0.0,0,0,0.0,0.0,0.0,9472.0,34440.0,0.2157041355438149,2109440.0,0.0,4.224,7306.911999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",360,0.0,0.0,0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,38272.0,3.552,7310.463999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16128.0,1196.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",361,0.0,0.0,0,0,0.0,0.0,0.0,9472.0,35080.0,0.21260549470281917,2109440.0,128.0,4.224,7314.687999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,65920.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",362,0.0,0.0,0,0,0.0,0.0,0.0,0.0,12.0,0.0,4128.0,512.0,2.336,7317.023999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,129.0,16.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",363,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.728,7318.7519999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",364,0.0,0.0,0,0,0.0,0.0,0.0,497.0,16.0,0.9688109161793372,512.0,0.0,3.488,7322.24,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",365,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.632,7323.871999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",366,0.0,0.0,0,0,0.0,0.0,0.0,497.0,16.0,0.9688109161793372,512.0,0.0,3.488,7327.36,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",367,0.0,0.0,0,0,0.0,0.0,0.0,44736.0,8424.0,0.8415349887133183,527232.0,7264.0,5.824,7333.183999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16476.0,227.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",368,0.0,0.0,0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,544.0,6.4,7339.583999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,80.0,17.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",369,0.0,0.0,0,0,0.0,0.0,0.0,0.0,12000.0,0.0,520064.0,57440.0,3.744,7343.327999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16252.0,1795.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",370,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3000.0,0.0,640000.0,0.0,2.944,7346.271999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,20000.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",371,0.0,0.0,0,0,0.0,0.0,0.0,0.0,4000.0,0.0,0.0,1024000.0,2.24,7348.511999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,32000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",372,0.0,0.0,0,0,0.0,0.0,0.0,98304.0,4000.0,0.960900844541758,512000.0,0.0,4.128,7352.6399999999985,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",373,0.0,0.0,0,0,0.0,0.0,0.0,156.0,64.0,0.7090909090909091,8192.0,0.0,2.144,7354.783999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",374,0.0,0.0,0,0,0.0,0.0,0.0,50958.0,18726.0,0.7312726020320303,1912064.0,1288992.0,9.568,7364.351999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,59752.0,40281.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",375,0.0,0.0,0,0,0.0,0.0,0.0,15054.0,20311.0,0.4256751025024742,1879936.0,1579008.0,7.52,7371.871999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,58748.0,49344.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",376,0.0,0.0,0,0,0.0,0.0,0.0,15858.0,20414.0,0.43719673577415086,1896064.0,1205568.0,8.288,7380.159999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,59252.0,37674.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",377,0.0,0.0,0,0,0.0,0.0,0.0,14958.0,20334.0,0.42383543012580754,1878912.0,1579008.0,8.288,7388.4479999999985,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,58716.0,49344.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",378,0.0,0.0,0,0,0.0,0.0,0.0,14336.0,4000.0,0.7818499127399651,1024000.0,0.0,3.904,7392.351999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",379,0.0,0.0,0,0,0.0,0.0,0.0,39.0,16.0,0.7090909090909091,2048.0,0.0,2.144,7394.495999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",380,0.0,0.0,0,0,0.0,0.0,0.0,13650.0,10431.0,0.5668369253768532,1274496.0,887616.0,6.752,7401.248,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,39828.0,27738.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",381,0.0,0.0,0,0,0.0,0.0,0.0,0.0,16000.0,0.0,1548800.0,1536000.0,4.032,7405.28,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48400.0,48000.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",382,1792000.0,4245120.0,0,0,0.0,4245120.0,4245120.0,528.0,5248.0,0.09141274238227147,1036032.0,512000.0,17.088,7422.3679999999995,533120.0,128000.0,1792000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32376.0,16000.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",383,0.0,655488.0,0,0,0.0,655488.0,655488.0,71840.0,8000.0,0.8997995991983968,512000.0,512000.0,46.784,7469.151999999999,655488.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,16000.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",384,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2000.0,0.0,512000.0,128000.0,2.592,7471.743999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,4000.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",385,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,1.888,7473.631999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",386,0.0,0.0,0,0,0.0,0.0,0.0,0.0,12000.0,0.0,1152000.0,54432.0,7.552,7481.183999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,36000.0,1701.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",387,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3000.0,0.0,640000.0,0.0,2.88,7484.0639999999985,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,20000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",388,1792000.0,4245120.0,0,0,0.0,4245120.0,4245120.0,528.0,5248.0,0.09141274238227147,1034240.0,512000.0,16.96,7501.0239999999985,533120.0,128000.0,1792000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32320.0,16000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",389,0.0,0.0,0,0,0.0,0.0,0.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,21.984,7523.007999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",390,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.112,7525.119999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",391,0.0,0.0,0,0,0.0,0.0,0.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,22.176,7547.295999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",392,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,7549.375999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",393,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.08,7551.455999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",394,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.912,7554.3679999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",395,0.0,147456.0,0,0,0.0,147456.0,147456.0,320.0,1004.0,0.24169184290030213,512000.0,128.0,8.16,7562.527999999999,147456.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",396,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.952,7564.48,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",397,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,7567.744,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",398,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,7569.759999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",399,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.944,7572.704,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",400,1152000.0,2560000.0,0,0,0.0,2560000.0,2560000.0,0.0,4000.0,0.0,0.0,512000.0,3.232,7575.936,0.0,256000.0,1152000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,16000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",401,640000.0,1280000.0,0,0,0.0,1280000.0,1280000.0,0.0,3000.0,0.0,1024000.0,0.0,4.288,7580.223999999999,0.0,0.0,640000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",402,0.0,0.0,0,0,0.0,0.0,0.0,640.0,1004.0,0.38929440389294406,512000.0,128.0,12.032,7592.255999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",403,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,1.952,7594.208,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",404,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,7596.192,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",405,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.208,7598.4,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",406,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.016,7600.415999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",407,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,64.0,128.0,2.528,7602.9439999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",408,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.664,7604.607999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",409,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,7606.303999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",410,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.048,7608.351999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",411,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.664,7610.015999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",412,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,32.0,2.208,7612.223999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",413,0.0,0.0,0,0,0.0,0.0,0.0,0.0,5.0,0.0,32.0,32.0,4.8,7617.0239999999985,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",414,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.08,7619.103999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",415,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,7621.119999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",416,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.944,7624.0639999999985,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",417,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,7627.391999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",418,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,7629.4079999999985,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",419,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.112,7631.519999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",420,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,32.0,3.296,7634.815999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",421,0.0,0.0,0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,64.0,32.0,2.464,7637.279999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",422,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,1.984,7639.263999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",423,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,2.048,7641.311999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",424,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,0.0,2.112,7643.423999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",425,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,2.208,7645.631999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",426,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1152.0,0.0,37632.0,49152.0,4.928,7650.559999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1176.0,1536.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",427,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,2.592,7653.151999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",428,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,7656.415999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",429,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.464,7658.879999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",430,0.0,512.0,0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,1.952,7660.8319999999985,0.0,512.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",431,0.0,0.0,0,0,0.0,0.0,0.0,0.0,20.0,0.0,2048.0,2048.0,2.624,7663.455999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",432,4096.0,9216.0,0,0,0.0,9216.0,9216.0,0.0,32.0,0.0,2048.0,2048.0,2.912,7666.367999999999,0.0,1024.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",433,0.0,512.0,0,0,0.0,512.0,512.0,0.0,32.0,0.0,2048.0,2048.0,2.016,7668.383999999998,0.0,512.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",434,3600.0,8224.0,0,0,0.0,8224.0,8224.0,0.0,32.0,0.0,2048.0,2048.0,2.88,7671.263999999998,0.0,1024.0,3600.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",435,0.0,512.0,0,0,0.0,512.0,512.0,0.0,32.0,0.0,2048.0,2048.0,2.016,7673.279999999998,0.0,512.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",436,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.08,7675.359999999998,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",437,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,5.056,7680.415999999997,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",438,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,7682.3359999999975,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",439,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,7684.351999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",440,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.656,7687.007999999997,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",441,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.656,7689.663999999997,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,442,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,50.208,7739.871999999997,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",443,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.528,7742.399999999997,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,444,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,48.544,7790.943999999997,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",445,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.496,7793.439999999997,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,446,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,48.48,7841.919999999996,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",447,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.656,7844.575999999996,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",448,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.688,7847.2639999999965,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",449,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.592,7849.855999999996,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",450,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,3.904,7853.759999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",451,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.688,7856.447999999997,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",452,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.08,7858.527999999997,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",453,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.656,7861.183999999997,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",454,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.656,7863.8399999999965,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",455,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.0,7867.8399999999965,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",456,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.656,7870.4959999999965,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",457,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.08,7872.575999999996,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",458,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,2.72,7875.295999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",459,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,2.624,7877.919999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",460,196608.0,17657856.0,0,0,0.0,17657856.0,17657856.0,99840.0,192.0,0.9980806142034548,245760.0,49152.0,20.768,7898.6879999999965,14886912.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,461,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,47.936,7946.623999999996,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",462,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.432,7949.055999999996,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",463,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.176,7951.231999999996,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",464,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.016,7953.247999999996,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",465,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,5.088,7958.335999999996,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",466,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.888,7960.223999999996,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",467,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.952,7962.175999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",468,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.752,7964.927999999996,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",469,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.72,7967.6479999999965,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",470,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,202177664.0,301472.0,167.488,8135.135999999997,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6318052.0,9421.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",471,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,2.56,8137.695999999997,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",472,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,205454336.0,297024.0,168.128,8305.823999999997,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6420448.0,9282.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",473,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.528,8308.351999999997,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_128x32_sliced1x4_tn,474,1245708288.0,2503802880.0,0,0,0.0,2503802880.0,2503802880.0,4344192.0,1261440.0,0.7749691738594328,169263808.0,884736.0,200.288,8508.639999999998,5308416.0,7077888.0,1245708288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5289494.0,27648.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",475,0.0,233472.0,0,0,0.0,233472.0,233472.0,0.0,7296.0,0.0,884736.0,49152.0,3.52,8512.159999999998,221184.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,27648.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",476,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.08,8514.239999999998,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",477,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.016,8516.255999999998,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",478,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,4.96,8521.215999999997,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",479,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,8523.199999999997,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",480,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.92,8525.119999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",481,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.624,8527.743999999997,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",482,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.624,8530.367999999997,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,483,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,48.704,8579.071999999996,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",484,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.592,8581.663999999997,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,485,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,50.336,8631.999999999996,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",486,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.464,8634.463999999996,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,487,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,47.84,8682.303999999996,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",488,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.4,8684.703999999996,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",489,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.688,8687.391999999996,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",490,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.656,8690.047999999997,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",491,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,3.936,8693.983999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",492,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.688,8696.671999999997,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",493,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.08,8698.751999999997,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",494,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.688,8701.439999999997,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",495,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.624,8704.063999999997,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",496,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.0,8708.063999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",497,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.688,8710.751999999997,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",498,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.176,8712.927999999996,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",499,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,2.688,8715.615999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",500,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,2.784,8718.399999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",501,196608.0,17657856.0,0,0,0.0,17657856.0,17657856.0,99840.0,192.0,0.9980806142034548,245760.0,49152.0,20.704,8739.103999999996,14886912.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,502,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,50.048,8789.151999999996,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",503,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.528,8791.679999999997,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",504,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.08,8793.759999999997,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",505,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,1.984,8795.743999999997,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",506,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,5.088,8800.831999999997,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",507,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,8802.751999999997,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",508,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.952,8804.703999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",509,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.624,8807.327999999996,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",510,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.592,8809.919999999996,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",511,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,203312256.0,294432.0,169.792,8979.711999999996,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6353508.0,9201.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",512,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,2.368,8982.079999999996,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",513,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,206184448.0,299040.0,167.328,9149.407999999996,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6443264.0,9345.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",514,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.4,9151.807999999995,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_128x32_sliced1x4_tn,515,1245708288.0,2503802880.0,0,0,0.0,2503802880.0,2503802880.0,4344192.0,1261440.0,0.7749691738594328,169245600.0,884736.0,200.704,9352.511999999995,5308416.0,7077888.0,1245708288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5288925.0,27648.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",516,0.0,233472.0,0,0,0.0,233472.0,233472.0,0.0,7296.0,0.0,884736.0,49152.0,3.584,9356.095999999996,221184.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,27648.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",517,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,9358.207999999995,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",518,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.016,9360.223999999995,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",519,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,5.152,9365.375999999995,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",520,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.888,9367.263999999996,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",521,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.952,9369.215999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",522,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.656,9371.871999999996,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",523,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.656,9374.527999999997,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,524,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,48.384,9422.911999999997,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",525,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.592,9425.503999999997,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,526,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,49.76,9475.263999999997,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",527,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.432,9477.695999999998,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,528,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,48.0,9525.695999999998,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",529,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.432,9528.127999999999,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",530,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.88,9531.007999999998,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",531,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.56,9533.567999999997,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",532,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.0,9537.567999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",533,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.72,9540.287999999997,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",534,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.048,9542.335999999998,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",535,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.752,9545.087999999998,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",536,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.56,9547.647999999997,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",537,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,3.968,9551.615999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",538,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.688,9554.303999999998,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",539,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,9556.415999999997,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",540,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,2.72,9559.135999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",541,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,2.624,9561.759999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",542,196608.0,17657856.0,0,0,0.0,17657856.0,17657856.0,99840.0,192.0,0.9980806142034548,245760.0,49152.0,20.512,9582.271999999997,14886912.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,543,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,49.472,9631.743999999997,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",544,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.56,9634.303999999996,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",545,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.08,9636.383999999996,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",546,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,1.984,9638.367999999997,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",547,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,5.152,9643.519999999997,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",548,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,9645.439999999997,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",549,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,9647.583999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",550,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.72,9650.303999999996,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",551,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.688,9652.991999999997,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",552,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,205636096.0,291456.0,167.424,9820.415999999997,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6426128.0,9108.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",553,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,2.4,9822.815999999997,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",554,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,201203328.0,295840.0,168.768,9991.583999999997,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6287604.0,9245.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",555,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.656,9994.239999999998,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_128x32_sliced1x4_tn,556,1245708288.0,2503802880.0,0,0,0.0,2503802880.0,2503802880.0,4344192.0,1261440.0,0.7749691738594328,169263296.0,884736.0,203.104,10197.343999999997,5308416.0,7077888.0,1245708288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5289478.0,27648.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",557,0.0,233472.0,0,0,0.0,233472.0,233472.0,0.0,7296.0,0.0,884736.0,49152.0,3.712,10201.055999999997,221184.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,27648.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",558,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.08,10203.135999999997,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",559,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.048,10205.183999999997,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",560,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,5.024,10210.207999999997,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",561,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,10212.127999999997,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",562,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.952,10214.079999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",563,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.656,10216.735999999997,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",564,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.816,10219.551999999998,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,565,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,48.384,10267.935999999998,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",566,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.4,10270.335999999998,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,567,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,49.568,10319.903999999997,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",568,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.4,10322.303999999996,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,569,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,48.192,10370.495999999996,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",570,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.432,10372.927999999996,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",571,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.688,10375.615999999996,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",572,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.624,10378.239999999996,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",573,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,3.968,10382.207999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",574,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.688,10384.895999999997,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",575,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,10387.007999999996,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",576,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.688,10389.695999999996,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",577,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.592,10392.287999999997,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",578,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,3.968,10396.255999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",579,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.656,10398.911999999998,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",580,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.08,10400.991999999998,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",581,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,2.592,10403.583999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",582,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,2.656,10406.24,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",583,196608.0,17657856.0,0,0,0.0,17657856.0,17657856.0,99840.0,192.0,0.9980806142034548,245760.0,49152.0,20.544,10426.784,14886912.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,584,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,49.824,10476.608,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",585,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.432,10479.04,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",586,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.08,10481.12,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",587,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.016,10483.136,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",588,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,5.024,10488.16,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",589,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,10490.08,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",590,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.92,10492.0,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",591,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.72,10494.72,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",592,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.656,10497.376,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",593,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,205300736.0,296224.0,168.416,10665.792,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6415648.0,9257.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",594,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,2.656,10668.448,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",595,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,205968256.0,294496.0,169.184,10837.632,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6436508.0,9203.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",596,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.4,10840.032,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_128x32_sliced1x4_tn,597,1245708288.0,2503802880.0,0,0,0.0,2503802880.0,2503802880.0,4344192.0,1261440.0,0.7749691738594328,169300416.0,884736.0,202.496,11042.527999999998,5308416.0,7077888.0,1245708288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5290638.0,27648.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",598,0.0,233472.0,0,0,0.0,233472.0,233472.0,0.0,7296.0,0.0,884736.0,49152.0,3.616,11046.143999999998,221184.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,27648.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",599,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.144,11048.287999999999,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",600,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.016,11050.303999999998,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",601,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,5.056,11055.359999999999,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",602,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,11057.279999999999,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",603,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,11059.264,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",604,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.688,11061.952,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",605,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.624,11064.576,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,606,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,48.384,11112.96,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",607,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.464,11115.423999999999,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,608,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,49.024,11164.447999999999,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",609,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.496,11166.943999999998,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,610,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,47.808,11214.751999999999,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",611,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.4,11217.151999999998,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",612,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.688,11219.839999999998,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",613,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.656,11222.496,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",614,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.0,11226.496,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",615,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.784,11229.279999999999,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",616,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.08,11231.359999999999,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",617,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.688,11234.047999999999,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",618,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.592,11236.64,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",619,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,3.968,11240.608,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",620,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.816,11243.424,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",621,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.048,11245.472000000002,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",622,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,2.624,11248.096000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",623,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,2.688,11250.784000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",624,196608.0,17657856.0,0,0,0.0,17657856.0,17657856.0,99840.0,192.0,0.9980806142034548,245760.0,49152.0,20.544,11271.328000000001,14886912.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,625,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,49.632,11320.960000000001,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",626,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.368,11323.328000000001,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",627,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.08,11325.408000000001,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",628,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.048,11327.456000000002,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",629,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,5.056,11332.512000000002,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",630,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,11334.432000000003,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",631,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,11336.448000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",632,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.624,11339.072000000002,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",633,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.88,11341.952000000001,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",634,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,205367680.0,298464.0,167.776,11509.728000000001,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6417740.0,9327.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",635,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,2.4,11512.128,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",636,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,201757184.0,294016.0,169.696,11681.824,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6304912.0,9188.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",637,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.336,11684.16,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_128x32_sliced1x4_tn,638,1245708288.0,2503802880.0,0,0,0.0,2503802880.0,2503802880.0,4344192.0,1261440.0,0.7749691738594328,169274560.0,884736.0,202.24,11886.4,5308416.0,7077888.0,1245708288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5289830.0,27648.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",639,0.0,233472.0,0,0,0.0,233472.0,233472.0,0.0,7296.0,0.0,884736.0,49152.0,3.68,11890.08,221184.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,27648.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",640,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.048,11892.128,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",641,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,1.984,11894.112000000001,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",642,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,5.056,11899.168000000001,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",643,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,11901.088000000002,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",644,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.112,11903.2,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",645,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.688,11905.888,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",646,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.624,11908.512,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,647,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,48.256,11956.768,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",648,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.592,11959.36,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,649,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,48.896,12008.256000000001,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",650,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.432,12010.688000000002,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,651,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,47.904,12058.592000000002,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",652,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.496,12061.088000000002,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",653,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.784,12063.872000000001,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",654,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.656,12066.528000000002,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",655,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.096,12070.624000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",656,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.688,12073.312000000002,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",657,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,12075.424,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",658,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.688,12078.112000000001,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",659,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.56,12080.672,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",660,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.0,12084.672,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",661,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.688,12087.36,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",662,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,12089.472,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",663,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,2.688,12092.16,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",664,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,2.656,12094.816,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",665,196608.0,17657856.0,0,0,0.0,17657856.0,17657856.0,99840.0,192.0,0.9980806142034548,245760.0,49152.0,20.544,12115.36,14886912.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,666,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,50.272,12165.632000000001,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",667,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.464,12168.096000000001,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",668,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.272,12170.368000000002,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",669,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.016,12172.384000000002,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",670,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,5.024,12177.408000000001,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",671,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,12179.392000000002,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",672,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.952,12181.344000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",673,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.656,12184.000000000002,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",674,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.688,12186.688000000002,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",675,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,205657984.0,295968.0,168.544,12355.232000000002,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6426812.0,9249.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",676,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,2.4,12357.632000000001,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",677,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,205369856.0,300032.0,167.616,12525.248000000001,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6417808.0,9376.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",678,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.4,12527.648000000001,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_128x32_sliced1x4_tn,679,1245708288.0,2503802880.0,0,0,0.0,2503802880.0,2503802880.0,4344192.0,1261440.0,0.7749691738594328,169296352.0,884736.0,202.24,12729.888,5308416.0,7077888.0,1245708288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5290511.0,27648.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",680,0.0,233472.0,0,0,0.0,233472.0,233472.0,0.0,7296.0,0.0,884736.0,49152.0,3.552,12733.44,221184.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,27648.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",681,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,12735.552,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",682,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,1.984,12737.536,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",683,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,5.152,12742.688,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",684,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,12744.608,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",685,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,12746.592,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",686,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.816,12749.408000000001,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",687,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.688,12752.096000000001,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,688,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,48.576,12800.672,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",689,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.4,12803.072,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,690,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,49.344,12852.416,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",691,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.496,12854.911999999998,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,692,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,47.776,12902.687999999998,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",693,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.464,12905.151999999998,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",694,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.688,12907.839999999998,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",695,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.624,12910.463999999998,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",696,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,3.936,12914.399999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",697,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.752,12917.151999999998,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",698,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.304,12919.455999999998,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",699,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.656,12922.112,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",700,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.624,12924.735999999999,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",701,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.064,12928.8,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",702,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.656,12931.456,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",703,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.144,12933.6,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",704,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,2.688,12936.288,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",705,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,2.656,12938.944000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",706,196608.0,17657856.0,0,0,0.0,17657856.0,17657856.0,99840.0,192.0,0.9980806142034548,245760.0,49152.0,20.512,12959.456000000002,14886912.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,707,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,49.568,13009.024000000001,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",708,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.4,13011.424,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",709,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,13013.536,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",710,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.016,13015.552,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",711,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,5.248,13020.8,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",712,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,13022.72,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",713,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.952,13024.671999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",714,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.624,13027.295999999998,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",715,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.624,13029.919999999998,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",716,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,208784128.0,303104.0,167.904,13197.823999999999,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6524504.0,9472.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",717,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,2.4,13200.223999999998,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",718,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,205106816.0,304480.0,168.896,13369.119999999999,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6409588.0,9515.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",719,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.432,13371.552,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_128x32_sliced1x4_tn,720,1245708288.0,2503802880.0,0,0,0.0,2503802880.0,2503802880.0,4344192.0,1261440.0,0.7749691738594328,169248448.0,884736.0,202.464,13574.016,5308416.0,7077888.0,1245708288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5289014.0,27648.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",721,0.0,233472.0,0,0,0.0,233472.0,233472.0,0.0,7296.0,0.0,884736.0,49152.0,3.584,13577.6,221184.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,27648.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",722,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.08,13579.68,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",723,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.048,13581.728000000001,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",724,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,5.056,13586.784000000001,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",725,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,13588.704000000002,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",726,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.952,13590.656,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",727,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.816,13593.472000000002,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",728,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.656,13596.128000000002,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,729,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,48.512,13644.640000000003,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",730,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.496,13647.136000000002,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,731,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,48.96,13696.096000000001,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",732,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.464,13698.560000000001,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,733,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,48.128,13746.688000000002,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",734,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.4,13749.088000000002,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",735,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.752,13751.840000000002,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",736,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.688,13754.528000000002,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",737,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.0,13758.528000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",738,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.688,13761.216000000002,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",739,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.08,13763.296000000002,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",740,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.688,13765.984000000002,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",741,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.56,13768.544000000002,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",742,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,3.936,13772.480000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",743,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.72,13775.2,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",744,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,13777.312,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",745,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,2.656,13779.968,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",746,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,2.656,13782.624000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",747,196608.0,17657856.0,0,0,0.0,17657856.0,17657856.0,99840.0,192.0,0.9980806142034548,245760.0,49152.0,20.544,13803.168000000001,14886912.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,748,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,49.504,13852.672000000002,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",749,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,2.4,13855.072000000002,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",750,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.08,13857.152000000002,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",751,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.048,13859.200000000003,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",752,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,5.056,13864.256000000003,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",753,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,13866.176000000003,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",754,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,13868.160000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",755,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.624,13870.784000000003,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",756,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.624,13873.408000000003,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",757,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,206927616.0,302016.0,170.144,14043.552000000003,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6466488.0,9438.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",758,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,2.4,14045.952000000003,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",759,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,207859200.0,304320.0,167.328,14213.280000000002,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6495600.0,9510.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",760,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.4,14215.680000000002,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_128x32_sliced1x4_tn,761,1245708288.0,2503802880.0,0,0,0.0,2503802880.0,2503802880.0,4344192.0,1261440.0,0.7749691738594328,169335008.0,884736.0,202.208,14417.888000000003,5308416.0,7077888.0,1245708288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5291719.0,27648.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",762,0.0,233472.0,0,0,0.0,233472.0,233472.0,0.0,7296.0,0.0,884736.0,49152.0,3.904,14421.792000000003,221184.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,27648.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",763,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.08,14423.872000000003,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",764,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.016,14425.888000000003,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",765,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,5.184,14431.072000000002,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",766,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,14432.992000000002,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",767,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,14435.008000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",768,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.624,14437.632000000001,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",769,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.816,14440.448000000002,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,770,3145728000.0,6298624000.0,0,0,0.0,6298624000.0,6298624000.0,14064000.0,3268000.0,0.8114470343872605,410349312.0,512000.0,455.392,14895.840000000002,3072000.0,4096000.0,3145728000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12823416.0,16000.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",771,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.664,14897.504000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",772,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,96.0,160.0,2.528,14900.032000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",773,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,14902.016000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",774,0.0,128000.0,0,0,0.0,128000.0,128000.0,0.0,2000.0,0.0,512000.0,512000.0,2.72,14904.736000000003,0.0,128000.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,16000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",775,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.664,14906.400000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",776,0.0,0.0,0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,37696.0,3.616,14910.016000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16128.0,1178.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",777,0.0,0.0,0,0,0.0,0.0,0.0,9472.0,34440.0,0.2157041355438149,2109440.0,0.0,4.32,14914.336000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",778,0.0,0.0,0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,37952.0,3.52,14917.856000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16128.0,1186.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",779,0.0,0.0,0,0,0.0,0.0,0.0,9472.0,34696.0,0.2144539032783916,2109440.0,0.0,4.288,14922.144000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",780,0.0,0.0,0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,38272.0,3.552,14925.696000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16128.0,1196.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",781,0.0,0.0,0,0,0.0,0.0,0.0,9472.0,34472.0,0.21554705989441106,2109440.0,0.0,4.224,14929.920000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",782,0.0,0.0,0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,38336.0,3.744,14933.664000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16128.0,1198.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",783,0.0,0.0,0,0,0.0,0.0,0.0,9472.0,34504.0,0.21539021284336912,2109440.0,128.0,4.288,14937.952000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,65920.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",784,0.0,0.0,0,0,0.0,0.0,0.0,0.0,12.0,0.0,4128.0,512.0,2.368,14940.320000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,129.0,16.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",785,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.632,14941.952000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",786,0.0,0.0,0,0,0.0,0.0,0.0,497.0,16.0,0.9688109161793372,512.0,0.0,3.52,14945.472000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",787,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.664,14947.136000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",788,0.0,0.0,0,0,0.0,0.0,0.0,497.0,16.0,0.9688109161793372,512.0,0.0,3.488,14950.624000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",789,0.0,0.0,0,0,0.0,0.0,0.0,39024.0,8420.0,0.8225276114998735,527232.0,7328.0,5.76,14956.384000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16476.0,229.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",790,0.0,0.0,0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,544.0,6.496,14962.880000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,80.0,17.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",791,0.0,0.0,0,0,0.0,0.0,0.0,0.0,12000.0,0.0,520064.0,57184.0,3.648,14966.528000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16252.0,1787.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",792,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3000.0,0.0,640000.0,0.0,2.944,14969.472000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,20000.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",793,0.0,0.0,0,0,0.0,0.0,0.0,0.0,4000.0,0.0,0.0,1024000.0,2.24,14971.712000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,32000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",794,0.0,0.0,0,0,0.0,0.0,0.0,98304.0,4000.0,0.960900844541758,512000.0,0.0,4.16,14975.872000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",795,0.0,0.0,0,0,0.0,0.0,0.0,156.0,64.0,0.7090909090909091,8192.0,0.0,2.176,14978.048000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",796,0.0,0.0,0,0,0.0,0.0,0.0,51858.0,19324.0,0.728526874771712,1906048.0,1316672.0,9.888,14987.936000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,59564.0,41146.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",797,0.0,0.0,0,0,0.0,0.0,0.0,15054.0,19883.0,0.43088988751180696,1880448.0,1579008.0,7.424,14995.360000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,58764.0,49344.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",798,0.0,0.0,0,0,0.0,0.0,0.0,15858.0,19737.0,0.44551201011378,1904000.0,1205888.0,8.384,15003.744000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,59500.0,37684.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",799,0.0,0.0,0,0,0.0,0.0,0.0,14958.0,19879.0,0.4293710709877429,1871872.0,1579008.0,8.096,15011.840000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,58496.0,49344.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",800,0.0,0.0,0,0,0.0,0.0,0.0,14336.0,4000.0,0.7818499127399651,1024000.0,0.0,3.936,15015.776000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",801,0.0,0.0,0,0,0.0,0.0,0.0,39.0,16.0,0.7090909090909091,2048.0,0.0,2.176,15017.952000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",802,0.0,0.0,0,0,0.0,0.0,0.0,13650.0,10475.0,0.5658031088082901,1271296.0,883616.0,6.848,15024.800000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,39728.0,27613.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",803,0.0,0.0,0,0,0.0,0.0,0.0,0.0,16000.0,0.0,1549152.0,1536000.0,4.032,15028.832000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48411.0,48000.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",804,1792000.0,4245120.0,0,0,0.0,4245120.0,4245120.0,528.0,5248.0,0.09141274238227147,1026688.0,512000.0,17.152,15045.984000000002,533120.0,128000.0,1792000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32084.0,16000.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",805,0.0,655488.0,0,0,0.0,655488.0,655488.0,71840.0,8000.0,0.8997995991983968,512000.0,512000.0,47.104,15093.088000000002,655488.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,16000.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",806,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2000.0,0.0,512000.0,128000.0,2.624,15095.712000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,4000.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",807,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,1.856,15097.568000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",808,0.0,0.0,0,0,0.0,0.0,0.0,0.0,12000.0,0.0,1152000.0,53952.0,7.456,15105.024000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,36000.0,1686.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",809,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3000.0,0.0,640000.0,0.0,2.88,15107.904,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,20000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",810,1792000.0,4245120.0,0,0,0.0,4245120.0,4245120.0,528.0,5248.0,0.09141274238227147,1030144.0,512000.0,17.152,15125.056,533120.0,128000.0,1792000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32192.0,16000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",811,0.0,0.0,0,0,0.0,0.0,0.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,21.856,15146.912,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",812,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.176,15149.088,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",813,0.0,0.0,0,0,0.0,0.0,0.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,22.016,15171.104,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",814,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.112,15173.215999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",815,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.016,15175.231999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",816,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.912,15178.143999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",817,0.0,147456.0,0,0,0.0,147456.0,147456.0,320.0,1004.0,0.24169184290030213,512000.0,128.0,8.192,15186.335999999998,147456.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",818,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,15188.319999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",819,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,15191.583999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",820,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,15193.631999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",821,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.912,15196.543999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",822,1152000.0,2560000.0,0,0,0.0,2560000.0,2560000.0,0.0,4000.0,0.0,0.0,512000.0,3.36,15199.903999999999,0.0,256000.0,1152000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,16000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",823,640000.0,1280000.0,0,0,0.0,1280000.0,1280000.0,0.0,3000.0,0.0,1024000.0,0.0,4.256,15204.159999999998,0.0,0.0,640000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",824,0.0,0.0,0,0,0.0,0.0,0.0,640.0,1004.0,0.38929440389294406,512000.0,128.0,11.84,15215.999999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",825,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,1.952,15217.951999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",826,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,15219.967999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",827,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.208,15222.175999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",828,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.048,15224.223999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",829,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,96.0,160.0,2.688,15226.911999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",830,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.632,15228.543999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",831,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.664,15230.207999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",832,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.016,15232.223999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",833,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.664,15233.887999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",834,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,128.0,32.0,2.24,15236.127999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",835,0.0,0.0,0,0,0.0,0.0,0.0,0.0,5.0,0.0,32.0,32.0,4.736,15240.864,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",836,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.112,15242.975999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",837,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,15244.991999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",838,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.752,15247.743999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",839,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.2,15250.944,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",840,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,15252.96,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
