Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.856,1.856,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,3.584,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,5.312,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.016,7.328,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.336,9.664,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",6,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.304,11.968,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",7,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,15.264,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",8,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,18.528,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",9,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,21.055999999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",10,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,22.752,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",11,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,24.48,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.728,26.208000000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,0.0,0.0,0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,2.496,28.704,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,30.72,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",15,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.176,32.896,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",16,0.0,0.0,0,0,0.0,0.0,0.0,36.0,2.0,0.9473684210526315,32.0,32.0,2.496,35.392,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",17,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,37.408,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",18,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,39.488,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",19,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,2.112,41.6,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",20,0.0,0.0,0,0,0.0,0.0,0.0,0.0,144.0,0.0,3264.0,6144.0,3.392,44.992000000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,102.0,192.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",21,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.464,47.456,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",22,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,50.688,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",23,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.432,53.120000000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",24,0.0,256.0,0,0,0.0,256.0,256.0,16.0,12.0,0.5714285714285714,640.0,512.0,2.048,55.168000000000006,0.0,256.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,20.0,16.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",25,0.0,0.0,0,0,0.0,0.0,0.0,0.0,10.0,0.0,1024.0,1024.0,2.56,57.72800000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",26,2048.0,4608.0,0,0,0.0,4608.0,4608.0,0.0,16.0,0.0,1024.0,1024.0,2.752,60.48000000000001,0.0,512.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",27,0.0,256.0,0,0,0.0,256.0,256.0,0.0,16.0,0.0,1024.0,1024.0,2.048,62.52800000000001,0.0,256.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",28,1792.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,16.0,0.0,1024.0,1024.0,2.624,65.15200000000002,0.0,512.0,1792.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",29,0.0,256.0,0,0,0.0,256.0,256.0,0.0,16.0,0.0,1024.0,1024.0,2.016,67.16800000000002,0.0,256.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",30,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.048,69.21600000000002,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",31,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.776,72.99200000000002,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",32,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.952,74.94400000000002,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",33,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,76.96000000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",34,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.688,79.64800000000002,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",35,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.656,82.30400000000003,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",36,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,7.072,89.37600000000003,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",37,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.784,96.16000000000004,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",38,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.624,102.78400000000003,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",39,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.688,105.47200000000004,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",40,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.784,108.25600000000004,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",41,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.456,111.71200000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",42,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.752,114.46400000000004,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",43,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,116.54400000000004,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",44,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.72,119.26400000000004,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",45,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.688,121.95200000000004,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",46,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.392,125.34400000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",47,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.656,128.00000000000003,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",48,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.048,130.04800000000003,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",49,24576.0,2206464.0,0,0,0.0,2206464.0,2206464.0,12480.0,24.0,0.9980806142034548,18432.0,6144.0,20.416,150.46400000000003,1860096.0,297216.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",50,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.848,157.31200000000004,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",51,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.208,159.52000000000004,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",52,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.048,161.56800000000004,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",53,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.68,165.24800000000005,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",54,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.92,167.16800000000003,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",55,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,169.15200000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",56,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.688,171.84000000000003,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",57,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.72,174.56000000000003,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",58,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10223616.0,28128.0,13.312,187.87200000000004,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319488.0,879.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",59,70656.0,147456.0,0,0,0.0,147456.0,147456.0,0.0,96.0,0.0,24576.0,24576.0,2.304,190.17600000000004,6144.0,0.0,70656.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",60,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10227712.0,28832.0,14.112,204.28800000000004,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319616.0,901.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",61,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.112,206.40000000000003,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,62,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,76416.0,0.8317836010143702,9732096.0,49152.0,15.456,221.85600000000002,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,1536.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",63,0.0,13824.0,0,0,0.0,13824.0,13824.0,0.0,432.0,0.0,49152.0,6144.0,2.208,224.06400000000002,12288.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",64,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,226.14400000000003,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",65,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.048,228.19200000000004,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",66,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.84,232.03200000000004,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",67,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.952,233.98400000000004,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",68,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,235.96800000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",69,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.688,238.65600000000003,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",70,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.656,241.31200000000004,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",71,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.944,248.25600000000003,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",72,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.368,254.62400000000002,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",73,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.624,261.24800000000005,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",74,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.784,264.03200000000004,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",75,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.624,266.65600000000006,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",76,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.456,270.1120000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",77,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.72,272.8320000000001,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",78,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,274.9120000000001,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",79,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.72,277.6320000000001,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",80,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.656,280.2880000000001,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",81,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.488,283.7760000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",82,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.72,286.49600000000015,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",83,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.208,288.7040000000002,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",84,24576.0,2206464.0,0,0,0.0,2206464.0,2206464.0,12480.0,24.0,0.9980806142034548,18432.0,6144.0,20.256,308.96000000000015,1860096.0,297216.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",85,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.88,315.84000000000015,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",86,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,317.92000000000013,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",87,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.016,319.93600000000015,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",88,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.808,323.74400000000014,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",89,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.952,325.69600000000014,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",90,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,327.74400000000014,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",91,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.656,330.40000000000015,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",92,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.656,333.05600000000015,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",93,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10227584.0,30432.0,13.536,346.59200000000016,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319612.0,951.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",94,70656.0,147456.0,0,0,0.0,147456.0,147456.0,0.0,96.0,0.0,24576.0,24576.0,2.4,348.99200000000013,6144.0,0.0,70656.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",95,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10228096.0,28096.0,13.856,362.8480000000001,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319628.0,878.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",96,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.08,364.9280000000001,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,97,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,76416.0,0.8317836010143702,9732096.0,49152.0,15.36,380.2880000000001,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,1536.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",98,0.0,13824.0,0,0,0.0,13824.0,13824.0,0.0,432.0,0.0,49152.0,6144.0,2.176,382.4640000000001,12288.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",99,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.112,384.57600000000014,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",100,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.176,386.7520000000001,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",101,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.712,390.4640000000001,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",102,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.984,392.4480000000001,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",103,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.952,394.4000000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",104,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.624,397.0240000000001,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",105,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.656,399.6800000000001,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",106,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6176.0,6.976,406.6560000000001,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,193.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",107,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.688,413.3440000000001,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",108,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.624,419.96800000000013,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",109,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.688,422.6560000000001,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",110,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.624,425.28000000000014,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",111,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.488,428.76800000000014,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",112,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.72,431.48800000000017,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",113,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.112,433.6000000000002,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",114,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.72,436.3200000000002,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",115,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.656,438.9760000000002,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",116,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.392,442.3680000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",117,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.688,445.0560000000002,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",118,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,447.1360000000002,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",119,24576.0,2206464.0,0,0,0.0,2206464.0,2206464.0,12480.0,24.0,0.9980806142034548,18432.0,6144.0,20.32,467.4560000000002,1860096.0,297216.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",120,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.624,474.0800000000002,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",121,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,476.1600000000002,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",122,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.112,478.2720000000002,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",123,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.904,482.1760000000002,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",124,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.952,484.1280000000002,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",125,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,486.14400000000023,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",126,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.656,488.80000000000024,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",127,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.656,491.45600000000024,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",128,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10223616.0,30528.0,13.344,504.80000000000024,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319488.0,954.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",129,70656.0,147456.0,0,0,0.0,147456.0,147456.0,0.0,96.0,0.0,24576.0,24576.0,2.304,507.1040000000002,6144.0,0.0,70656.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",130,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10223616.0,29152.0,14.208,521.3120000000002,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319488.0,911.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",131,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.112,523.4240000000002,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,132,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,76416.0,0.8317836010143702,9732096.0,49152.0,15.616,539.0400000000002,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,1536.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",133,0.0,13824.0,0,0,0.0,13824.0,13824.0,0.0,432.0,0.0,49152.0,6144.0,2.208,541.2480000000002,12288.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",134,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.048,543.2960000000002,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",135,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.016,545.3120000000001,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",136,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.84,549.1520000000002,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",137,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.92,551.0720000000001,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",138,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,553.1200000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",139,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.656,555.7760000000001,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",140,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.656,558.432,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",141,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.688,565.12,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",142,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6176.0,6.752,571.872,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,193.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",143,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6176.0,6.496,578.3679999999999,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,193.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",144,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.72,581.088,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",145,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.656,583.7439999999999,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",146,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.584,587.3279999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",147,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.752,590.0799999999998,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",148,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.048,592.1279999999998,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",149,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.752,594.8799999999998,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",150,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.688,597.5679999999998,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",151,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.424,600.9919999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",152,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.656,603.6479999999997,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",153,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.112,605.7599999999996,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",154,24576.0,2206464.0,0,0,0.0,2206464.0,2206464.0,12480.0,24.0,0.9980806142034548,18432.0,6144.0,20.416,626.1759999999997,1860096.0,297216.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",155,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.816,632.9919999999997,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",156,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.048,635.0399999999997,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",157,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.112,637.1519999999997,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",158,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.808,640.9599999999997,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",159,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.888,642.8479999999997,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",160,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,644.8319999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",161,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.688,647.5199999999998,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",162,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.72,650.2399999999998,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",163,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10228608.0,28992.0,13.408,663.6479999999998,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319644.0,906.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",164,70656.0,147456.0,0,0,0.0,147456.0,147456.0,0.0,96.0,0.0,24576.0,24576.0,2.24,665.8879999999998,6144.0,0.0,70656.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",165,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10233344.0,29120.0,13.152,679.0399999999998,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319792.0,910.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",166,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.08,681.1199999999999,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,167,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,76416.0,0.8317836010143702,9732096.0,49152.0,15.456,696.5759999999999,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,1536.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",168,0.0,13824.0,0,0,0.0,13824.0,13824.0,0.0,432.0,0.0,49152.0,6144.0,2.144,698.7199999999999,12288.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",169,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.24,700.9599999999999,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",170,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.08,703.04,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",171,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.744,706.784,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",172,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.952,708.736,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",173,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,710.752,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",174,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.624,713.376,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",175,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.624,716.0,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",176,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.624,722.624,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",177,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.624,729.248,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",178,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.912,736.1600000000001,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",179,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.72,738.8800000000001,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",180,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.656,741.5360000000001,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",181,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.456,744.9920000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",182,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.656,747.648,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",183,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.048,749.696,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",184,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.688,752.384,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",185,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.688,755.072,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",186,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.52,758.592,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",187,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.72,761.312,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",188,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.144,763.456,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",189,24576.0,2206464.0,0,0,0.0,2206464.0,2206464.0,12480.0,24.0,0.9980806142034548,18432.0,6144.0,20.416,783.8720000000001,1860096.0,297216.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",190,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.72,790.5920000000001,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",191,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,792.6720000000001,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",192,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.048,794.7200000000001,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",193,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.712,798.4320000000001,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",194,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.952,800.3840000000001,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",195,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,802.4000000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",196,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.688,805.0880000000001,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",197,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.72,807.8080000000001,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",198,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10237952.0,29696.0,12.992,820.8000000000001,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319936.0,928.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",199,70656.0,147456.0,0,0,0.0,147456.0,147456.0,0.0,96.0,0.0,24576.0,24576.0,2.304,823.104,6144.0,0.0,70656.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",200,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10224768.0,29568.0,13.696,836.8000000000001,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319524.0,924.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",201,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.112,838.912,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,202,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,76416.0,0.8317836010143702,9732096.0,49152.0,15.552,854.464,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,1536.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",203,0.0,13824.0,0,0,0.0,13824.0,13824.0,0.0,432.0,0.0,49152.0,6144.0,2.208,856.672,12288.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",204,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,858.7520000000001,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",205,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.048,860.8000000000001,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",206,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.84,864.6400000000001,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",207,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.92,866.5600000000001,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",208,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,868.5440000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",209,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.656,871.2,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",210,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.72,873.9200000000001,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",211,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.624,880.5440000000001,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",212,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.464,887.0080000000002,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",213,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.592,893.6000000000001,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",214,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.688,896.2880000000001,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",215,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.592,898.8800000000001,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",216,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.456,902.3360000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",217,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.688,905.0240000000001,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",218,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.144,907.1680000000001,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",219,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.72,909.8880000000001,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",220,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.624,912.5120000000002,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",221,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.488,916.0000000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",222,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.656,918.6560000000002,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",223,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,920.7360000000002,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",224,24576.0,2206464.0,0,0,0.0,2206464.0,2206464.0,12480.0,24.0,0.9980806142034548,18432.0,6144.0,20.352,941.0880000000002,1860096.0,297216.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",225,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.688,947.7760000000002,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",226,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.144,949.9200000000002,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",227,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.08,952.0000000000002,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",228,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.808,955.8080000000002,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",229,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.952,957.7600000000002,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",230,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,959.7440000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",231,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.624,962.3680000000003,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",232,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.656,965.0240000000002,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",233,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10226816.0,28608.0,13.248,978.2720000000003,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319588.0,894.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",234,70656.0,147456.0,0,0,0.0,147456.0,147456.0,0.0,96.0,0.0,24576.0,24576.0,2.368,980.6400000000003,6144.0,0.0,70656.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",235,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10232576.0,28384.0,13.536,994.1760000000003,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319768.0,887.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",236,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.08,996.2560000000003,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,237,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,76416.0,0.8317836010143702,9732096.0,49152.0,15.392,1011.6480000000004,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,1536.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",238,0.0,13824.0,0,0,0.0,13824.0,13824.0,0.0,432.0,0.0,49152.0,6144.0,2.144,1013.7920000000004,12288.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",239,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.048,1015.8400000000004,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",240,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.048,1017.8880000000004,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",241,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.744,1021.6320000000004,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",242,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.984,1023.6160000000004,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",243,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,1025.6320000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",244,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.624,1028.2560000000005,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",245,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.816,1031.0720000000006,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",246,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.784,1037.8560000000007,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",247,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.656,1044.5120000000006,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",248,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.528,1051.0400000000006,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",249,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.72,1053.7600000000007,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",250,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.656,1056.4160000000006,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",251,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.488,1059.9040000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",252,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.688,1062.5920000000008,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",253,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,1064.6720000000007,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",254,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.752,1067.4240000000007,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",255,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.624,1070.0480000000007,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",256,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.456,1073.5040000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",257,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.72,1076.2240000000006,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",258,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.144,1078.3680000000006,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",259,24576.0,2206464.0,0,0,0.0,2206464.0,2206464.0,12480.0,24.0,0.9980806142034548,18432.0,6144.0,20.416,1098.7840000000006,1860096.0,297216.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",260,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.592,1105.3760000000007,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",261,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.112,1107.4880000000007,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",262,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.048,1109.5360000000007,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",263,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.68,1113.2160000000008,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",264,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.92,1115.1360000000009,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",265,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,1117.152000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",266,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.72,1119.872000000001,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",267,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.688,1122.560000000001,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",268,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10234624.0,29120.0,13.184,1135.744000000001,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319832.0,910.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",269,70656.0,147456.0,0,0,0.0,147456.0,147456.0,0.0,96.0,0.0,24576.0,24576.0,2.304,1138.0480000000011,6144.0,0.0,70656.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",270,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10227200.0,28768.0,13.664,1151.7120000000011,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319600.0,899.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",271,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.048,1153.7600000000011,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,272,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,76416.0,0.8317836010143702,9732096.0,49152.0,15.328,1169.088000000001,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,1536.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",273,0.0,13824.0,0,0,0.0,13824.0,13824.0,0.0,432.0,0.0,49152.0,6144.0,2.208,1171.2960000000012,12288.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",274,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.144,1173.4400000000012,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",275,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.112,1175.5520000000013,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",276,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.872,1179.4240000000013,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",277,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.984,1181.4080000000013,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",278,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,1183.4240000000013,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",279,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.624,1186.0480000000014,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",280,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.656,1188.7040000000013,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",281,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.528,1195.2320000000013,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",282,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.688,1201.9200000000014,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",283,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6208.0,6.88,1208.8000000000015,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,194.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",284,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.72,1211.5200000000016,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",285,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.656,1214.1760000000015,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",286,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.488,1217.6640000000016,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",287,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.656,1220.3200000000015,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",288,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.112,1222.4320000000016,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",289,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.688,1225.1200000000017,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",290,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.656,1227.7760000000017,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",291,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.456,1231.2320000000016,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",292,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.688,1233.9200000000017,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",293,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.112,1236.0320000000017,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",294,24576.0,2206464.0,0,0,0.0,2206464.0,2206464.0,12480.0,24.0,0.9980806142034548,18432.0,6144.0,20.384,1256.4160000000018,1860096.0,297216.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",295,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.688,1263.1040000000019,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",296,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,1265.1840000000018,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",297,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.08,1267.2640000000017,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",298,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.84,1271.1040000000016,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",299,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.984,1273.0880000000016,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",300,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,1275.1040000000016,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",301,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.688,1277.7920000000017,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",302,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.656,1280.4480000000017,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",303,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10230144.0,28896.0,13.344,1293.7920000000017,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319692.0,903.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",304,70656.0,147456.0,0,0,0.0,147456.0,147456.0,0.0,96.0,0.0,24576.0,24576.0,2.272,1296.0640000000017,6144.0,0.0,70656.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",305,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10230528.0,29760.0,13.568,1309.6320000000017,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319704.0,930.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",306,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.144,1311.7760000000017,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,307,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,76416.0,0.8317836010143702,9732096.0,49152.0,15.296,1327.0720000000017,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,1536.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",308,0.0,13824.0,0,0,0.0,13824.0,13824.0,0.0,432.0,0.0,49152.0,6144.0,2.176,1329.2480000000016,12288.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",309,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.112,1331.3600000000017,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",310,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.016,1333.3760000000018,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",311,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.776,1337.1520000000019,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",312,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.92,1339.072000000002,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",313,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,1341.088000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",314,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.688,1343.776000000002,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",315,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.72,1346.4960000000021,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",316,49152000.0,108544000.0,0,0,0.0,108544000.0,108544000.0,1200000.0,992000.0,0.5474452554744526,102270080.0,314048.0,106.784,1453.2800000000022,4096000.0,6144000.0,49152000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3195940.0,9814.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",317,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,1455.0080000000023,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",318,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,64.0,64.0,2.592,1457.6000000000024,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",319,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,1459.5840000000023,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",320,0.0,64000.0,0,0,0.0,64000.0,64000.0,0.0,1024.0,0.0,256000.0,256000.0,2.56,1462.1440000000023,0.0,64000.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8000.0,8000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",321,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,1463.8720000000023,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",322,0.0,0.0,0,0,0.0,0.0,0.0,1024.0,3024.0,0.25296442687747034,258048.0,18560.0,3.584,1467.4560000000024,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,580.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",323,0.0,0.0,0,0,0.0,0.0,0.0,4736.0,17220.0,0.2157041355438149,1054720.0,0.0,4.224,1471.6800000000023,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32960.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",324,0.0,0.0,0,0,0.0,0.0,0.0,1024.0,3024.0,0.25296442687747034,258048.0,18880.0,3.392,1475.0720000000024,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,590.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",325,0.0,0.0,0,0,0.0,0.0,0.0,4736.0,17604.0,0.21199641897940913,1054720.0,0.0,4.448,1479.5200000000025,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32960.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",326,0.0,0.0,0,0,0.0,0.0,0.0,1024.0,3024.0,0.25296442687747034,258048.0,18880.0,3.36,1482.8800000000024,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,590.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",327,0.0,0.0,0,0,0.0,0.0,0.0,4736.0,17220.0,0.2157041355438149,1054720.0,0.0,4.288,1487.1680000000024,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32960.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",328,0.0,0.0,0,0,0.0,0.0,0.0,1024.0,3024.0,0.25296442687747034,258048.0,18752.0,3.424,1490.5920000000024,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,586.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",329,0.0,0.0,0,0,0.0,0.0,0.0,4736.0,17156.0,0.216334734149461,1054720.0,64.0,4.448,1495.0400000000025,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32960.0,2.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",330,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,2080.0,256.0,2.368,1497.4080000000024,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,65.0,8.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",331,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.696,1499.1040000000023,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",332,0.0,0.0,0,0,0.0,0.0,0.0,497.0,12.0,0.9764243614931237,256.0,0.0,3.424,1502.5280000000023,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",333,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.664,1504.1920000000023,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",334,0.0,0.0,0,0,0.0,0.0,0.0,497.0,12.0,0.9764243614931237,256.0,0.0,3.392,1507.5840000000023,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",335,0.0,0.0,0,0,0.0,0.0,0.0,20736.0,4212.0,0.8311688311688312,263616.0,3680.0,5.568,1513.1520000000023,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8238.0,115.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",336,0.0,0.0,0,0,0.0,0.0,0.0,916.0,16.0,0.9828326180257511,1280.0,192.0,6.528,1519.6800000000023,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,40.0,6.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",337,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6000.0,0.0,260032.0,25312.0,3.616,1523.2960000000023,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8126.0,791.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",338,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,320000.0,0.0,3.04,1526.3360000000023,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,10000.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",339,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2000.0,0.0,0.0,512000.0,2.016,1528.3520000000024,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,16000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",340,0.0,0.0,0,0,0.0,0.0,0.0,98304.0,2000.0,0.9800606157281864,256000.0,0.0,3.968,1532.3200000000024,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",341,0.0,0.0,0,0,0.0,0.0,0.0,156.0,64.0,0.7090909090909091,8192.0,0.0,2.208,1534.5280000000025,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",342,0.0,0.0,0,0,0.0,0.0,0.0,25929.0,9359.0,0.7347823622761278,905984.0,629504.0,8.768,1543.2960000000026,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,28312.0,19672.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",343,0.0,0.0,0,0,0.0,0.0,0.0,9777.0,9360.0,0.5108951246276846,916096.0,643392.0,7.232,1550.5280000000025,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,28628.0,20106.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",344,0.0,0.0,0,0,0.0,0.0,0.0,8829.0,9314.0,0.4866339635120983,894208.0,789504.0,7.456,1557.9840000000024,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,27944.0,24672.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",345,0.0,0.0,0,0,0.0,0.0,0.0,8829.0,9328.0,0.4862587431844468,901376.0,704288.0,7.52,1565.5040000000024,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,28168.0,22009.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",346,0.0,0.0,0,0,0.0,0.0,0.0,14336.0,2000.0,0.8775710088148874,512000.0,0.0,3.52,1569.0240000000024,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",347,0.0,0.0,0,0,0.0,0.0,0.0,39.0,16.0,0.7090909090909091,2048.0,0.0,2.24,1571.2640000000024,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",348,0.0,0.0,0,0,0.0,0.0,0.0,6825.0,4954.0,0.5794210034807709,602368.0,472800.0,6.144,1577.4080000000024,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,18824.0,14775.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",349,0.0,0.0,0,0,0.0,0.0,0.0,0.0,8000.0,0.0,774496.0,768000.0,3.2,1580.6080000000024,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24203.0,24000.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",350,896000.0,2122560.0,0,0,0.0,2122560.0,2122560.0,264.0,2624.0,0.09141274238227147,507520.0,256000.0,17.152,1597.7600000000025,266560.0,64000.0,896000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,15860.0,8000.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",351,0.0,327744.0,0,0,0.0,327744.0,327744.0,35920.0,4000.0,0.8997995991983968,256000.0,256000.0,46.912,1644.6720000000025,327744.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8000.0,8000.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",352,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,256000.0,63616.0,2.368,1647.0400000000025,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8000.0,1988.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",353,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,64.0,1.952,1648.9920000000025,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,2.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",354,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6000.0,0.0,576000.0,25536.0,7.52,1656.5120000000024,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,18000.0,798.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",355,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,320000.0,0.0,3.168,1659.6800000000023,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,10000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",356,896000.0,2122560.0,0,0,0.0,2122560.0,2122560.0,264.0,2624.0,0.09141274238227147,500736.0,256000.0,16.704,1676.3840000000023,266560.0,64000.0,896000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,15648.0,8000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",357,0.0,0.0,0,0,0.0,0.0,0.0,62.0,501.0,0.11012433392539965,256000.0,32.0,13.056,1689.4400000000023,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",358,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.176,1691.6160000000023,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",359,0.0,0.0,0,0,0.0,0.0,0.0,62.0,501.0,0.11012433392539965,256000.0,32.0,12.8,1704.4160000000022,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",360,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.176,1706.5920000000021,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",361,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.08,1708.672000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",362,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.976,1711.6480000000022,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",363,0.0,73600.0,0,0,0.0,73600.0,73600.0,152.0,502.0,0.2324159021406728,256000.0,64.0,8.064,1719.7120000000023,73600.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8000.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",364,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,1721.6960000000022,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",365,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,1724.9280000000022,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",366,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,1727.008000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",367,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.04,1730.048000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",368,576000.0,1280000.0,0,0,0.0,1280000.0,1280000.0,0.0,2000.0,0.0,0.0,256000.0,2.592,1732.6400000000021,0.0,128000.0,576000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,8000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",369,320000.0,640000.0,0,0,0.0,640000.0,640000.0,0.0,1536.0,0.0,512000.0,0.0,3.68,1736.3200000000022,0.0,0.0,320000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",370,0.0,0.0,0,0,0.0,0.0,0.0,304.0,502.0,0.3771712158808933,256000.0,64.0,11.776,1748.0960000000023,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8000.0,2.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",371,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.016,1750.1120000000024,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",372,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.208,1752.3200000000024,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",373,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.24,1754.5600000000024,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",374,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.048,1756.6080000000024,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",375,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,64.0,64.0,2.656,1759.2640000000024,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",376,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,1760.9920000000025,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",377,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,1762.6880000000024,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",378,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.112,1764.8000000000025,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",379,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.664,1766.4640000000024,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",380,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.272,1768.7360000000024,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<256, 2, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",381,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,32.0,32.0,3.712,1772.4480000000024,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",382,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.144,1774.5920000000024,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",383,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,1776.6720000000023,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",384,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.912,1779.5840000000023,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",385,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,1782.8160000000023,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",386,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,1784.8640000000023,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",387,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.176,1787.0400000000022,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",388,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.392,1790.4320000000023,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",389,0.0,0.0,0,0,0.0,0.0,0.0,36.0,2.0,0.9473684210526315,32.0,32.0,2.592,1793.0240000000024,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",390,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,1795.0720000000024,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",391,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,1797.1520000000023,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",392,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,2.112,1799.2640000000024,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",393,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.24,1801.5040000000024,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",394,0.0,0.0,0,0,0.0,0.0,0.0,0.0,144.0,0.0,6336.0,6144.0,3.808,1805.3120000000024,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",395,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.688,1808.0000000000025,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",396,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,1811.3280000000025,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",397,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,1813.9520000000025,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",398,0.0,256.0,0,0,0.0,256.0,256.0,16.0,12.0,0.5714285714285714,640.0,512.0,2.048,1816.0000000000025,0.0,256.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,20.0,16.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",399,0.0,0.0,0,0,0.0,0.0,0.0,0.0,10.0,0.0,1024.0,1024.0,2.528,1818.5280000000025,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",400,2048.0,4608.0,0,0,0.0,4608.0,4608.0,0.0,16.0,0.0,1024.0,1024.0,2.752,1821.2800000000025,0.0,512.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",401,0.0,256.0,0,0,0.0,256.0,256.0,0.0,16.0,0.0,1024.0,1024.0,1.984,1823.2640000000024,0.0,256.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",402,1800.0,4112.0,0,0,0.0,4112.0,4112.0,0.0,16.0,0.0,1024.0,1024.0,2.656,1825.9200000000023,0.0,512.0,1800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",403,0.0,256.0,0,0,0.0,256.0,256.0,0.0,16.0,0.0,1024.0,1024.0,2.016,1827.9360000000024,0.0,256.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",404,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.048,1829.9840000000024,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",405,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.84,1833.8240000000023,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",406,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.984,1835.8080000000023,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",407,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,1837.7920000000022,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",408,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.72,1840.5120000000022,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",409,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.752,1843.2640000000022,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",410,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.976,1850.2400000000023,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",411,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.816,1857.0560000000023,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",412,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.816,1863.8720000000023,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",413,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.752,1866.6240000000023,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",414,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.656,1869.2800000000022,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",415,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.424,1872.7040000000022,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",416,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.72,1875.4240000000023,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",417,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.048,1877.4720000000023,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",418,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.688,1880.1600000000024,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",419,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.656,1882.8160000000023,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",420,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.424,1886.2400000000023,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",421,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.72,1888.9600000000023,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",422,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,1891.0400000000022,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",423,0.0,0.0,0,0,0.0,0.0,0.0,0.0,120.0,0.0,12288.0,12288.0,2.528,1893.5680000000023,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",424,0.0,0.0,0,0,0.0,0.0,0.0,0.0,120.0,0.0,12288.0,12288.0,2.56,1896.1280000000022,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",425,24576.0,2207232.0,0,0,0.0,2207232.0,2207232.0,12480.0,24.0,0.9980806142034548,30720.0,6144.0,20.384,1916.5120000000022,1860864.0,297216.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,960.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",426,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.656,1923.1680000000022,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",427,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,1925.248000000002,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",428,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.08,1927.328000000002,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",429,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.872,1931.200000000002,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",430,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.984,1933.184000000002,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",431,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,1935.200000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",432,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.688,1937.8880000000022,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",433,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.656,1940.5440000000021,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",434,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10224128.0,29152.0,14.016,1954.5600000000022,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319504.0,911.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",435,70656.0,147456.0,0,0,0.0,147456.0,147456.0,0.0,96.0,0.0,24576.0,24576.0,2.272,1956.8320000000022,6144.0,0.0,70656.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",436,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10230272.0,29632.0,13.152,1969.9840000000022,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319696.0,926.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",437,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.144,1972.1280000000022,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,438,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,76416.0,0.8317836010143702,9732096.0,49152.0,15.456,1987.584000000002,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,1536.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",439,0.0,13824.0,0,0,0.0,13824.0,13824.0,0.0,432.0,0.0,49152.0,6144.0,2.144,1989.728000000002,12288.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",440,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.112,1991.8400000000022,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",441,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.048,1993.8880000000022,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",442,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.68,1997.5680000000023,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",443,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.952,1999.5200000000023,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",444,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2001.5360000000023,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",445,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.688,2004.2240000000024,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",446,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.688,2006.9120000000025,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",447,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.528,2013.4400000000026,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",448,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.688,2020.1280000000027,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",449,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6176.0,6.656,2026.7840000000026,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,193.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",450,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.656,2029.4400000000026,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",451,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.624,2032.0640000000026,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",452,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.456,2035.5200000000025,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",453,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.72,2038.2400000000025,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",454,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,2040.3200000000024,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",455,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.72,2043.0400000000025,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",456,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.656,2045.6960000000024,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",457,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.424,2049.1200000000026,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",458,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.752,2051.8720000000026,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",459,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,2053.9520000000025,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",460,0.0,0.0,0,0,0.0,0.0,0.0,0.0,120.0,0.0,12288.0,12288.0,2.624,2056.5760000000023,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",461,0.0,0.0,0,0,0.0,0.0,0.0,0.0,120.0,0.0,12288.0,12288.0,2.72,2059.296000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",462,24576.0,2207232.0,0,0,0.0,2207232.0,2207232.0,12480.0,24.0,0.9980806142034548,30720.0,6144.0,20.416,2079.7120000000023,1860864.0,297216.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,960.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",463,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.592,2086.3040000000024,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",464,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,2088.3840000000023,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",465,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.016,2090.4000000000024,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",466,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.744,2094.1440000000025,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",467,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.048,2096.1920000000023,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",468,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2098.2080000000024,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",469,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.688,2100.8960000000025,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",470,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.688,2103.5840000000026,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",471,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10223616.0,29952.0,13.376,2116.9600000000028,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319488.0,936.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",472,70656.0,147456.0,0,0,0.0,147456.0,147456.0,0.0,96.0,0.0,24576.0,24576.0,2.272,2119.2320000000027,6144.0,0.0,70656.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",473,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10227712.0,29600.0,13.408,2132.6400000000026,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319616.0,925.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",474,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.048,2134.6880000000024,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,475,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,76416.0,0.8317836010143702,9732096.0,49152.0,15.424,2150.1120000000024,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,1536.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",476,0.0,13824.0,0,0,0.0,13824.0,13824.0,0.0,432.0,0.0,49152.0,6144.0,2.272,2152.3840000000023,12288.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",477,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.144,2154.528000000002,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",478,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.048,2156.576000000002,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",479,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.84,2160.416000000002,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",480,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.984,2162.400000000002,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",481,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2164.416000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",482,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.624,2167.040000000002,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",483,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.656,2169.6960000000017,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",484,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.912,2176.6080000000015,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",485,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.816,2183.4240000000013,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",486,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,7.008,2190.432000000001,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",487,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.688,2193.1200000000013,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",488,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.72,2195.840000000001,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",489,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.424,2199.264000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",490,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.656,2201.920000000001,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",491,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.24,2204.1600000000008,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",492,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.752,2206.9120000000007,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",493,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.688,2209.600000000001,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",494,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.456,2213.056000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",495,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.688,2215.744000000001,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",496,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,2217.824000000001,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",497,0.0,0.0,0,0,0.0,0.0,0.0,0.0,120.0,0.0,12288.0,12288.0,2.56,2220.384000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",498,0.0,0.0,0,0,0.0,0.0,0.0,0.0,120.0,0.0,12288.0,12288.0,2.528,2222.9120000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",499,24576.0,2207232.0,0,0,0.0,2207232.0,2207232.0,12480.0,24.0,0.9980806142034548,30720.0,6144.0,20.256,2243.1680000000006,1860864.0,297216.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,960.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",500,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.784,2249.9520000000007,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",501,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.144,2252.0960000000005,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",502,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.08,2254.1760000000004,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",503,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.808,2257.9840000000004,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",504,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.984,2259.9680000000003,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",505,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2261.9840000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",506,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.592,2264.5760000000005,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",507,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.656,2267.2320000000004,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",508,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10224640.0,27488.0,14.048,2281.28,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319520.0,859.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",509,70656.0,147456.0,0,0,0.0,147456.0,147456.0,0.0,96.0,0.0,24576.0,24576.0,2.304,2283.5840000000003,6144.0,0.0,70656.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",510,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10225920.0,30176.0,13.536,2297.1200000000003,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319560.0,943.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",511,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.112,2299.2320000000004,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,512,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,76416.0,0.8317836010143702,9732096.0,49152.0,15.488,2314.7200000000003,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,1536.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",513,0.0,13824.0,0,0,0.0,13824.0,13824.0,0.0,432.0,0.0,49152.0,6144.0,2.144,2316.864,12288.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",514,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.016,2318.88,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",515,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.08,2320.96,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",516,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.712,2324.672,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",517,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.984,2326.656,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",518,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,2328.736,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",519,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.688,2331.424,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",520,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.688,2334.112,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",521,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.496,2340.608,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",522,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.624,2347.232,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",523,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.528,2353.7599999999998,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",524,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.72,2356.4799999999996,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",525,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.688,2359.1679999999997,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",526,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.392,2362.5599999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",527,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.784,2365.3439999999996,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",528,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.112,2367.4559999999997,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",529,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.688,2370.144,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",530,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.688,2372.832,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",531,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.456,2376.288,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",532,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.688,2378.976,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",533,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.112,2381.088,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",534,0.0,0.0,0,0,0.0,0.0,0.0,0.0,120.0,0.0,12288.0,12288.0,2.592,2383.6800000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",535,0.0,0.0,0,0,0.0,0.0,0.0,0.0,120.0,0.0,12288.0,12288.0,2.528,2386.208,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",536,24576.0,2207232.0,0,0,0.0,2207232.0,2207232.0,12480.0,24.0,0.9980806142034548,30720.0,6144.0,20.352,2406.56,1860864.0,297216.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,960.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",537,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.656,2413.216,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",538,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.048,2415.2639999999997,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",539,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.016,2417.2799999999997,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",540,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.744,2421.024,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",541,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.016,2423.04,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",542,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,2425.0879999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",543,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.688,2427.776,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",544,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.688,2430.464,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",545,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10235776.0,29728.0,13.344,2443.808,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319868.0,929.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",546,70656.0,147456.0,0,0,0.0,147456.0,147456.0,0.0,96.0,0.0,24576.0,24576.0,2.208,2446.016,6144.0,0.0,70656.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",547,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10229376.0,29280.0,13.12,2459.136,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319668.0,915.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",548,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.176,2461.312,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,549,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,76416.0,0.8317836010143702,9732096.0,49152.0,15.552,2476.864,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,1536.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",550,0.0,13824.0,0,0,0.0,13824.0,13824.0,0.0,432.0,0.0,49152.0,6144.0,2.24,2479.104,12288.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",551,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,2481.1839999999997,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",552,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.048,2483.2319999999995,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",553,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.808,2487.0399999999995,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",554,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.92,2488.9599999999996,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",555,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2490.9759999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",556,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.688,2493.6639999999998,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",557,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.72,2496.3839999999996,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",558,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.688,2503.0719999999997,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",559,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.624,2509.6959999999995,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",560,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.72,2516.4159999999993,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",561,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.688,2519.1039999999994,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",562,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.592,2521.6959999999995,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",563,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.392,2525.0879999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",564,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.688,2527.7759999999994,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",565,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.112,2529.8879999999995,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",566,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.72,2532.6079999999993,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",567,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.592,2535.1999999999994,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",568,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.584,2538.783999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",569,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.784,2541.5679999999993,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",570,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.016,2543.5839999999994,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",571,0.0,0.0,0,0,0.0,0.0,0.0,0.0,120.0,0.0,12288.0,12288.0,2.752,2546.3359999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",572,0.0,0.0,0,0,0.0,0.0,0.0,0.0,120.0,0.0,12288.0,12288.0,2.592,2548.9279999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",573,24576.0,2207232.0,0,0,0.0,2207232.0,2207232.0,12480.0,24.0,0.9980806142034548,30720.0,6144.0,20.384,2569.3119999999994,1860864.0,297216.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,960.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",574,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6176.0,6.592,2575.9039999999995,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,193.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",575,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.112,2578.0159999999996,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",576,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.048,2580.0639999999994,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",577,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.744,2583.8079999999995,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",578,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.92,2585.7279999999996,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",579,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,2587.8079999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",580,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.656,2590.4639999999995,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",581,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.752,2593.2159999999994,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",582,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10243584.0,29760.0,13.344,2606.5599999999995,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,320112.0,930.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",583,70656.0,147456.0,0,0,0.0,147456.0,147456.0,0.0,96.0,0.0,24576.0,24576.0,2.272,2608.8319999999994,6144.0,0.0,70656.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",584,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10236160.0,28736.0,13.184,2622.0159999999996,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319880.0,898.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",585,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.08,2624.0959999999995,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,586,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,76416.0,0.8317836010143702,9732096.0,49152.0,15.424,2639.5199999999995,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,1536.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",587,0.0,13824.0,0,0,0.0,13824.0,13824.0,0.0,432.0,0.0,49152.0,6144.0,2.144,2641.6639999999993,12288.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",588,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.112,2643.7759999999994,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",589,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.08,2645.8559999999993,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",590,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.712,2649.5679999999993,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",591,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.984,2651.551999999999,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",592,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,2653.599999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",593,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.656,2656.255999999999,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",594,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.72,2658.9759999999987,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",595,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.624,2665.5999999999985,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",596,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.624,2672.2239999999983,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",597,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.72,2678.943999999998,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",598,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.688,2681.6319999999982,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",599,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.688,2684.3199999999983,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",600,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.616,2687.9359999999983,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",601,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.784,2690.7199999999984,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",602,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.016,2692.7359999999985,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",603,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.688,2695.4239999999986,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",604,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.624,2698.0479999999984,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",605,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.456,2701.5039999999985,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",606,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.816,2704.3199999999983,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",607,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.048,2706.367999999998,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",608,0.0,0.0,0,0,0.0,0.0,0.0,0.0,120.0,0.0,12288.0,12288.0,2.624,2708.991999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",609,0.0,0.0,0,0,0.0,0.0,0.0,0.0,120.0,0.0,12288.0,12288.0,2.624,2711.6159999999977,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",610,24576.0,2207232.0,0,0,0.0,2207232.0,2207232.0,12480.0,24.0,0.9980806142034548,30720.0,6144.0,20.416,2732.031999999998,1860864.0,297216.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,960.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",611,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.624,2738.6559999999977,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",612,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.112,2740.7679999999978,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",613,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.08,2742.8479999999977,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",614,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.68,2746.5279999999975,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",615,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.984,2748.5119999999974,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",616,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,2750.559999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",617,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.592,2753.1519999999973,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",618,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.688,2755.8399999999974,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",619,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10232448.0,30528.0,13.088,2768.9279999999976,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319764.0,954.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",620,70656.0,147456.0,0,0,0.0,147456.0,147456.0,0.0,96.0,0.0,24576.0,24576.0,2.272,2771.1999999999975,6144.0,0.0,70656.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",621,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10229120.0,28960.0,13.44,2784.6399999999976,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319660.0,905.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",622,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.176,2786.8159999999975,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,623,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,76416.0,0.8317836010143702,9732096.0,49152.0,15.392,2802.2079999999974,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,1536.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",624,0.0,13824.0,0,0,0.0,13824.0,13824.0,0.0,432.0,0.0,49152.0,6144.0,2.272,2804.4799999999973,12288.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",625,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,2806.559999999997,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",626,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.016,2808.5759999999973,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",627,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.776,2812.351999999997,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",628,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.984,2814.335999999997,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",629,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,2816.415999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",630,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.656,2819.071999999997,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",631,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.656,2821.727999999997,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",632,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.88,2828.607999999997,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",633,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6176.0,6.592,2835.199999999997,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,193.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",634,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.88,2842.079999999997,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",635,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.688,2844.7679999999973,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",636,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.688,2847.4559999999974,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",637,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.52,2850.9759999999974,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",638,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.72,2853.695999999997,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",639,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.048,2855.743999999997,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",640,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.848,2858.591999999997,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",641,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.592,2861.183999999997,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",642,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.392,2864.575999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",643,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.688,2867.263999999997,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",644,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,2869.343999999997,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",645,0.0,0.0,0,0,0.0,0.0,0.0,0.0,120.0,0.0,12288.0,12288.0,2.624,2871.9679999999967,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",646,0.0,0.0,0,0,0.0,0.0,0.0,0.0,120.0,0.0,12288.0,12288.0,2.592,2874.5599999999968,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",647,24576.0,2207232.0,0,0,0.0,2207232.0,2207232.0,12480.0,24.0,0.9980806142034548,30720.0,6144.0,20.288,2894.847999999997,1860864.0,297216.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,960.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",648,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.816,2901.6639999999966,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",649,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,2903.7439999999965,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",650,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,1.984,2905.7279999999964,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",651,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.84,2909.5679999999966,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",652,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.984,2911.5519999999965,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",653,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,2913.6319999999964,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",654,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.656,2916.2879999999964,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",655,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.624,2918.911999999996,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",656,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10223616.0,28224.0,13.344,2932.255999999996,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319488.0,882.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",657,70656.0,147456.0,0,0,0.0,147456.0,147456.0,0.0,96.0,0.0,24576.0,24576.0,2.24,2934.495999999996,6144.0,0.0,70656.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",658,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10224640.0,28832.0,13.824,2948.319999999996,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319520.0,901.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",659,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.08,2950.399999999996,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,660,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,76416.0,0.8317836010143702,9732096.0,49152.0,15.456,2965.855999999996,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,1536.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",661,0.0,13824.0,0,0,0.0,13824.0,13824.0,0.0,432.0,0.0,49152.0,6144.0,2.208,2968.063999999996,12288.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",662,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.112,2970.1759999999963,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",663,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.08,2972.255999999996,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",664,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.712,2975.967999999996,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",665,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.984,2977.951999999996,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",666,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2979.967999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",667,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.688,2982.6559999999963,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",668,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.656,2985.3119999999963,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",669,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.592,2991.9039999999964,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",670,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.848,2998.7519999999963,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",671,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6176.0,6.688,3005.4399999999964,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,193.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",672,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.72,3008.159999999996,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",673,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.656,3010.815999999996,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",674,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.392,3014.207999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",675,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.688,3016.895999999996,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",676,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,3018.975999999996,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",677,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.72,3021.695999999996,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",678,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.656,3024.3519999999958,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",679,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.424,3027.7759999999957,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",680,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.688,3030.463999999996,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",681,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.048,3032.5119999999956,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",682,0.0,0.0,0,0,0.0,0.0,0.0,0.0,120.0,0.0,12288.0,12288.0,2.528,3035.0399999999954,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",683,0.0,0.0,0,0,0.0,0.0,0.0,0.0,120.0,0.0,12288.0,12288.0,2.56,3037.5999999999954,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",684,24576.0,2207232.0,0,0,0.0,2207232.0,2207232.0,12480.0,24.0,0.9980806142034548,30720.0,6144.0,20.32,3057.9199999999955,1860864.0,297216.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,960.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",685,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.528,3064.4479999999953,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",686,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.112,3066.5599999999954,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",687,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.016,3068.5759999999955,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",688,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.68,3072.2559999999953,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",689,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.952,3074.2079999999955,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",690,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,3076.2239999999956,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",691,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.72,3078.9439999999954,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",692,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.656,3081.5999999999954,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",693,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10223616.0,28384.0,13.568,3095.1679999999956,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319488.0,887.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",694,70656.0,147456.0,0,0,0.0,147456.0,147456.0,0.0,96.0,0.0,24576.0,24576.0,2.304,3097.4719999999957,6144.0,0.0,70656.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",695,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10223744.0,29856.0,13.76,3111.231999999996,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319492.0,933.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",696,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.112,3113.343999999996,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,697,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,76416.0,0.8317836010143702,9732096.0,49152.0,15.392,3128.735999999996,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,1536.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",698,0.0,13824.0,0,0,0.0,13824.0,13824.0,0.0,432.0,0.0,49152.0,6144.0,2.272,3131.0079999999957,12288.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",699,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,3133.0879999999956,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",700,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.048,3135.1359999999954,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",701,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.872,3139.0079999999953,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",702,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.984,3140.991999999995,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",703,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,3143.039999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",704,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.656,3145.695999999995,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",705,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.688,3148.383999999995,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",706,49152000.0,108544000.0,0,0,0.0,108544000.0,108544000.0,1200000.0,992000.0,0.5474452554744526,102212224.0,314432.0,106.688,3255.071999999995,4096000.0,6144000.0,49152000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3194132.0,9826.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",707,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,3256.767999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",708,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,64.0,64.0,2.624,3259.391999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",709,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,3261.4719999999948,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",710,0.0,64000.0,0,0,0.0,64000.0,64000.0,0.0,1024.0,0.0,256000.0,256000.0,2.272,3263.7439999999947,0.0,64000.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8000.0,8000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",711,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,3265.4719999999948,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",712,0.0,0.0,0,0,0.0,0.0,0.0,1024.0,3024.0,0.25296442687747034,258048.0,17792.0,3.776,3269.2479999999946,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,556.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",713,0.0,0.0,0,0,0.0,0.0,0.0,4736.0,17220.0,0.2157041355438149,1054720.0,0.0,4.16,3273.4079999999944,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32960.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",714,0.0,0.0,0,0,0.0,0.0,0.0,1024.0,3024.0,0.25296442687747034,258048.0,18368.0,3.584,3276.9919999999943,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,574.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",715,0.0,0.0,0,0,0.0,0.0,0.0,4736.0,17604.0,0.21199641897940913,1054720.0,0.0,4.32,3281.3119999999944,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32960.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",716,0.0,0.0,0,0,0.0,0.0,0.0,1024.0,3024.0,0.25296442687747034,258048.0,18240.0,3.616,3284.9279999999944,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,570.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",717,0.0,0.0,0,0,0.0,0.0,0.0,4736.0,17220.0,0.2157041355438149,1054720.0,0.0,4.224,3289.1519999999946,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32960.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",718,0.0,0.0,0,0,0.0,0.0,0.0,1024.0,3024.0,0.25296442687747034,258048.0,19008.0,3.648,3292.7999999999947,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,594.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",719,0.0,0.0,0,0,0.0,0.0,0.0,4736.0,17380.0,0.21414360643877736,1054720.0,64.0,4.16,3296.9599999999946,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32960.0,2.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",720,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,2080.0,256.0,2.304,3299.2639999999947,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,65.0,8.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",721,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.632,3300.8959999999947,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",722,0.0,0.0,0,0,0.0,0.0,0.0,497.0,12.0,0.9764243614931237,256.0,0.0,3.552,3304.447999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",723,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.696,3306.143999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",724,0.0,0.0,0,0,0.0,0.0,0.0,497.0,12.0,0.9764243614931237,256.0,0.0,3.552,3309.695999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",725,0.0,0.0,0,0,0.0,0.0,0.0,16608.0,4210.0,0.797771159573446,263616.0,3808.0,5.664,3315.359999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8238.0,119.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",726,0.0,0.0,0,0,0.0,0.0,0.0,916.0,16.0,0.9828326180257511,1280.0,192.0,6.496,3321.855999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,40.0,6.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",727,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6000.0,0.0,260032.0,26880.0,3.712,3325.567999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8126.0,840.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",728,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,320000.0,0.0,3.072,3328.6399999999953,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,10000.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",729,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2000.0,0.0,0.0,512000.0,2.08,3330.7199999999953,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,16000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",730,0.0,0.0,0,0,0.0,0.0,0.0,98304.0,2000.0,0.9800606157281864,256000.0,0.0,4.032,3334.7519999999954,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",731,0.0,0.0,0,0,0.0,0.0,0.0,156.0,64.0,0.7090909090909091,8192.0,0.0,2.24,3336.991999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",732,0.0,0.0,0,0,0.0,0.0,0.0,25929.0,9382.0,0.7343037580357396,905088.0,652096.0,8.768,3345.759999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,28284.0,20378.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",733,0.0,0.0,0,0,0.0,0.0,0.0,7977.0,9357.0,0.4601938386985116,905472.0,789504.0,7.008,3352.767999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,28296.0,24672.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",734,0.0,0.0,0,0,0.0,0.0,0.0,8829.0,9320.0,0.4864730839164692,893312.0,789504.0,7.616,3360.383999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,27916.0,24672.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",735,0.0,0.0,0,0,0.0,0.0,0.0,8829.0,9316.0,0.48658032515844585,899840.0,705696.0,7.616,3367.999999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,28120.0,22053.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",736,0.0,0.0,0,0,0.0,0.0,0.0,14336.0,2000.0,0.8775710088148874,512000.0,0.0,3.552,3371.551999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",737,0.0,0.0,0,0,0.0,0.0,0.0,39.0,16.0,0.7090909090909091,2048.0,0.0,2.208,3373.759999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",738,0.0,0.0,0,0,0.0,0.0,0.0,6825.0,4952.0,0.5795194022246752,602112.0,471904.0,6.048,3379.807999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,18816.0,14747.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",739,0.0,0.0,0,0,0.0,0.0,0.0,0.0,8000.0,0.0,774624.0,768000.0,3.136,3382.943999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24207.0,24000.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",740,896000.0,2122560.0,0,0,0.0,2122560.0,2122560.0,264.0,2624.0,0.09141274238227147,505088.0,256000.0,17.536,3400.479999999995,266560.0,64000.0,896000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,15784.0,8000.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",741,0.0,327744.0,0,0,0.0,327744.0,327744.0,35920.0,4000.0,0.8997995991983968,256000.0,256000.0,46.688,3447.167999999995,327744.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8000.0,8000.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",742,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,256000.0,63616.0,2.336,3449.503999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8000.0,1988.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",743,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,64.0,2.048,3451.5519999999947,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,2.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",744,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6000.0,0.0,576000.0,25824.0,7.52,3459.0719999999947,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,18000.0,807.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",745,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,320000.0,0.0,3.168,3462.239999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,10000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",746,896000.0,2122560.0,0,0,0.0,2122560.0,2122560.0,264.0,2624.0,0.09141274238227147,530560.0,256000.0,17.024,3479.2639999999947,266560.0,64000.0,896000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16580.0,8000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",747,0.0,0.0,0,0,0.0,0.0,0.0,62.0,501.0,0.11012433392539965,256000.0,32.0,12.576,3491.8399999999947,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",748,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,3493.9839999999945,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",749,0.0,0.0,0,0,0.0,0.0,0.0,62.0,501.0,0.11012433392539965,256000.0,32.0,12.544,3506.5279999999943,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",750,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,3508.671999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",751,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.048,3510.719999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",752,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.976,3513.695999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",753,0.0,73600.0,0,0,0.0,73600.0,73600.0,152.0,502.0,0.2324159021406728,256000.0,64.0,8.224,3521.919999999994,73600.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8000.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",754,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,3523.967999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",755,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,3527.199999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",756,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,3529.2479999999937,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",757,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.976,3532.223999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",758,576000.0,1280000.0,0,0,0.0,1280000.0,1280000.0,0.0,2000.0,0.0,0.0,256000.0,2.528,3534.7519999999936,0.0,128000.0,576000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,8000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",759,320000.0,640000.0,0,0,0.0,640000.0,640000.0,0.0,1536.0,0.0,512000.0,0.0,3.456,3538.2079999999937,0.0,0.0,320000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",760,0.0,0.0,0,0,0.0,0.0,0.0,304.0,502.0,0.3771712158808933,256000.0,64.0,11.872,3550.0799999999936,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8000.0,2.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",761,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.048,3552.1279999999933,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",762,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,3554.2079999999933,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",763,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.272,3556.479999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",764,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.08,3558.559999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",765,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,64.0,64.0,2.656,3561.215999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",766,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,3562.911999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",767,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.76,3564.671999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",768,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.08,3566.751999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",769,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,3568.479999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",770,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,32.0,2.304,3570.7839999999933,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,1.0
"void native::reduce_kernel<256, 2, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",771,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,32.0,32.0,3.68,3574.463999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",772,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.176,3576.639999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",773,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,3578.655999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",774,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.816,3581.471999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",775,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.136,3584.607999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",776,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.112,3586.719999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
