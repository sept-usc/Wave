Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.824,1.824,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,3.52,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",3,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.496,6.016,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",4,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,9.408,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",5,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.136,12.544,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",6,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.176,14.72,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",7,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.824,16.544,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",8,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.76,18.304000000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",9,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.728,20.032000000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",10,0.0,0.0,0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,2.496,22.528000000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",11,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,24.608000000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",12,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,26.752000000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",13,0.0,0.0,0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,32.0,32.0,2.528,29.28,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,31.36,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",15,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.112,33.472,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",16,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,2.144,35.616,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",17,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,4352.0,16384.0,3.904,39.519999999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,136.0,512.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",18,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,42.08,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",19,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.104,45.184,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",20,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.496,47.68,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",21,0.0,512.0,0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,2.048,49.728,0.0,512.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",22,0.0,0.0,0,0,0.0,0.0,0.0,0.0,20.0,0.0,2048.0,2048.0,2.624,52.352000000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",23,4096.0,9216.0,0,0,0.0,9216.0,9216.0,0.0,32.0,0.0,2048.0,2048.0,2.976,55.328,0.0,1024.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",24,0.0,512.0,0,0,0.0,512.0,512.0,0.0,32.0,0.0,2048.0,2048.0,2.016,57.344,0.0,512.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",25,3584.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,32.0,0.0,2048.0,2048.0,2.976,60.32,0.0,1024.0,3584.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",26,0.0,512.0,0,0,0.0,512.0,512.0,0.0,32.0,0.0,2048.0,2048.0,2.08,62.4,0.0,512.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",27,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,1.984,64.384,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",28,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,4.032,68.416,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",29,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,70.368,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",30,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,72.416,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",31,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.656,75.072,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",32,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.656,77.72800000000001,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,33,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.28,87.00800000000001,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",34,0.0,40960.0,0,0,0.0,40960.0,40960.0,0.0,1920.0,0.0,135168.0,16384.0,2.336,89.34400000000001,36864.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4224.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,35,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.12,98.46400000000001,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",36,0.0,40960.0,0,0,0.0,40960.0,40960.0,0.0,1920.0,0.0,135168.0,16384.0,2.336,100.80000000000001,36864.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4224.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,37,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.152,109.95200000000001,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",38,0.0,40960.0,0,0,0.0,40960.0,40960.0,0.0,1920.0,0.0,135168.0,16384.0,2.4,112.35200000000002,36864.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4224.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",39,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.752,115.10400000000001,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",40,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.656,117.76000000000002,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",41,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.032,121.79200000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",42,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.688,124.48000000000002,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",43,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.048,126.52800000000002,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",44,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.752,129.28000000000003,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",45,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.624,131.90400000000002,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",46,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.032,135.93600000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",47,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.72,138.65600000000003,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",48,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.048,140.70400000000004,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",49,65536.0,5883904.0,0,0,0.0,5883904.0,5883904.0,33280.0,64.0,0.9980806142034548,49152.0,16384.0,20.032,160.73600000000005,4960256.0,792576.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,50,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.184,169.92000000000004,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",51,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.208,172.12800000000004,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",52,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.24,174.36800000000005,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",53,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.016,176.38400000000004,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",54,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.936,180.32000000000005,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",55,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,182.30400000000006,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",56,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,184.32000000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",57,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.656,186.97600000000006,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",58,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.656,189.63200000000006,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_64x32_sliced1x4_tn,59,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,171916.0,0.7911562477222479,18015488.0,135168.0,25.376,215.00800000000007,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,562984.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",60,188416.0,393216.0,0,0,0.0,393216.0,393216.0,0.0,256.0,0.0,65536.0,65536.0,2.304,217.31200000000007,16384.0,0.0,188416.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,61,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,172121.0,0.7909592717865883,18013216.0,135168.0,25.248,242.56000000000006,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,562913.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",62,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.208,244.76800000000006,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,63,134217728.0,270270464.0,0,0,0.0,270270464.0,270270464.0,651264.0,140288.0,0.8227684346701164,17825792.0,131072.0,23.168,267.93600000000004,786432.0,1048576.0,134217728.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,557056.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",64,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.24,270.17600000000004,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",65,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.08,272.25600000000003,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",66,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.016,274.27200000000005,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",67,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.84,278.112,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",68,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,280.064,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",69,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,282.08000000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",70,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.72,284.80000000000007,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",71,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.752,287.5520000000001,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,72,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.088,296.6400000000001,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",73,0.0,40960.0,0,0,0.0,40960.0,40960.0,0.0,1920.0,0.0,135168.0,16384.0,2.464,299.1040000000001,36864.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4224.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,74,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,8.896,308.0000000000001,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",75,0.0,40960.0,0,0,0.0,40960.0,40960.0,0.0,1920.0,0.0,135168.0,16384.0,2.592,310.5920000000001,36864.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4224.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,76,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.184,319.7760000000001,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",77,0.0,40960.0,0,0,0.0,40960.0,40960.0,0.0,1920.0,0.0,135168.0,16384.0,2.56,322.3360000000001,36864.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4224.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",78,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.72,325.05600000000015,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",79,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.688,327.74400000000014,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",80,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.032,331.7760000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",81,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.688,334.4640000000001,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",82,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.08,336.5440000000001,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",83,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.72,339.2640000000001,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",84,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.656,341.92000000000013,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",85,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.032,345.9520000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",86,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.752,348.7040000000001,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",87,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.08,350.7840000000001,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",88,65536.0,5883904.0,0,0,0.0,5883904.0,5883904.0,33280.0,64.0,0.9980806142034548,49152.0,16384.0,20.064,370.8480000000001,4960256.0,792576.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,89,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.12,379.96800000000013,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",90,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.208,382.17600000000016,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",91,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.048,384.22400000000016,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",92,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,1.984,386.20800000000014,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",93,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.872,390.08000000000015,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",94,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,392.06400000000014,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",95,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,394.08000000000015,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",96,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.624,396.7040000000002,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",97,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.688,399.39200000000017,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_64x32_sliced1x4_tn,98,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,172028.0,0.7910486194448628,18014624.0,135168.0,25.248,424.64000000000016,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,562957.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",99,188416.0,393216.0,0,0,0.0,393216.0,393216.0,0.0,256.0,0.0,65536.0,65536.0,2.304,426.94400000000013,16384.0,0.0,188416.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,100,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,171944.0,0.791129337907309,18017280.0,135168.0,25.472,452.4160000000001,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,563040.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",101,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.176,454.5920000000001,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,102,134217728.0,270270464.0,0,0,0.0,270270464.0,270270464.0,651264.0,140288.0,0.8227684346701164,17825792.0,131072.0,22.464,477.0560000000001,786432.0,1048576.0,134217728.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,557056.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",103,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.272,479.3280000000001,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",104,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.048,481.3760000000001,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",105,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.048,483.4240000000001,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",106,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.872,487.2960000000001,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",107,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,489.2160000000001,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",108,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,491.23200000000014,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",109,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.656,493.88800000000015,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",110,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.688,496.57600000000014,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,111,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.056,505.6320000000001,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",112,0.0,40960.0,0,0,0.0,40960.0,40960.0,0.0,1920.0,0.0,135168.0,16384.0,2.528,508.16000000000014,36864.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4224.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,113,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.184,517.3440000000002,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",114,0.0,40960.0,0,0,0.0,40960.0,40960.0,0.0,1920.0,0.0,135168.0,16384.0,2.368,519.7120000000002,36864.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4224.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,115,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,8.832,528.5440000000002,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",116,0.0,40960.0,0,0,0.0,40960.0,40960.0,0.0,1920.0,0.0,135168.0,16384.0,2.368,530.9120000000003,36864.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4224.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",117,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.656,533.5680000000002,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",118,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.688,536.2560000000002,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",119,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.032,540.2880000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",120,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.688,542.9760000000002,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",121,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.112,545.0880000000002,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",122,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.688,547.7760000000002,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",123,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.592,550.3680000000002,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",124,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.032,554.4000000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",125,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.688,557.0880000000002,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",126,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.112,559.2000000000002,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",127,65536.0,5883904.0,0,0,0.0,5883904.0,5883904.0,33280.0,64.0,0.9980806142034548,49152.0,16384.0,20.064,579.2640000000001,4960256.0,792576.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,128,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.152,588.4160000000002,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",129,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.272,590.6880000000002,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",130,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.08,592.7680000000003,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",131,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.048,594.8160000000003,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",132,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.872,598.6880000000002,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",133,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,600.6400000000002,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",134,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.24,602.8800000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",135,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.72,605.6000000000003,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",136,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.656,608.2560000000002,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_64x32_sliced1x4_tn,137,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,171593.0,0.791466804074098,18016800.0,135168.0,25.696,633.9520000000002,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,563025.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",138,188416.0,393216.0,0,0,0.0,393216.0,393216.0,0.0,256.0,0.0,65536.0,65536.0,2.272,636.2240000000003,16384.0,0.0,188416.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,139,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,171966.0,0.7911081957654604,18015552.0,135168.0,25.28,661.5040000000002,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,562986.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",140,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.176,663.6800000000003,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,141,134217728.0,270270464.0,0,0,0.0,270270464.0,270270464.0,651264.0,140288.0,0.8227684346701164,17825792.0,131072.0,22.88,686.5600000000003,786432.0,1048576.0,134217728.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,557056.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",142,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.272,688.8320000000003,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",143,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.08,690.9120000000004,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",144,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.048,692.9600000000004,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",145,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.872,696.8320000000003,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",146,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,698.7840000000003,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",147,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,700.7680000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",148,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.656,703.4240000000003,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",149,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.688,706.1120000000003,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,150,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,8.992,715.1040000000003,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",151,0.0,40960.0,0,0,0.0,40960.0,40960.0,0.0,1920.0,0.0,135168.0,16384.0,2.4,717.5040000000002,36864.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4224.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,152,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.12,726.6240000000003,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",153,0.0,40960.0,0,0,0.0,40960.0,40960.0,0.0,1920.0,0.0,135168.0,16384.0,2.4,729.0240000000002,36864.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4224.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,154,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.12,738.1440000000002,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",155,0.0,40960.0,0,0,0.0,40960.0,40960.0,0.0,1920.0,0.0,135168.0,16384.0,2.336,740.4800000000002,36864.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4224.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",156,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.656,743.1360000000002,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",157,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.656,745.7920000000001,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",158,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.096,749.8880000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",159,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.688,752.5760000000001,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",160,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.08,754.6560000000002,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",161,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.72,757.3760000000002,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",162,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.624,760.0000000000002,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",163,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,3.968,763.9680000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",164,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.784,766.7520000000002,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",165,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.048,768.8000000000002,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",166,65536.0,5883904.0,0,0,0.0,5883904.0,5883904.0,33280.0,64.0,0.9980806142034548,49152.0,16384.0,20.128,788.9280000000002,4960256.0,792576.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,167,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,8.928,797.8560000000002,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",168,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.24,800.0960000000002,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",169,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.208,802.3040000000002,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",170,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.144,804.4480000000002,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",171,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.872,808.3200000000002,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",172,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,810.2720000000002,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",173,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,812.2880000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",174,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.784,815.0720000000001,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",175,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.688,817.7600000000001,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_64x32_sliced1x4_tn,176,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,172426.0,0.7906663914822324,18009504.0,135168.0,25.28,843.0400000000001,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,562797.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",177,188416.0,393216.0,0,0,0.0,393216.0,393216.0,0.0,256.0,0.0,65536.0,65536.0,2.336,845.3760000000001,16384.0,0.0,188416.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,178,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,171817.0,0.7912514078201295,18015904.0,135168.0,25.312,870.6880000000001,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,562997.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",179,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.144,872.8320000000001,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,180,134217728.0,270270464.0,0,0,0.0,270270464.0,270270464.0,651264.0,140288.0,0.8227684346701164,17825792.0,131072.0,22.784,895.6160000000001,786432.0,1048576.0,134217728.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,557056.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",181,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.272,897.8880000000001,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",182,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.144,900.0320000000002,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",183,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.048,902.0800000000002,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",184,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.84,905.9200000000002,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",185,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,907.9040000000002,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",186,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,909.9200000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",187,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.624,912.5440000000002,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",188,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.688,915.2320000000002,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,189,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,8.96,924.1920000000002,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",190,0.0,40960.0,0,0,0.0,40960.0,40960.0,0.0,1920.0,0.0,135168.0,16384.0,2.4,926.5920000000002,36864.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4224.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,191,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.152,935.7440000000003,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",192,0.0,40960.0,0,0,0.0,40960.0,40960.0,0.0,1920.0,0.0,135168.0,16384.0,2.496,938.2400000000002,36864.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4224.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,193,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.312,947.5520000000002,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",194,0.0,40960.0,0,0,0.0,40960.0,40960.0,0.0,1920.0,0.0,135168.0,16384.0,2.528,950.0800000000003,36864.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4224.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",195,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.656,952.7360000000002,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",196,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.656,955.3920000000002,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",197,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.032,959.4240000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",198,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.784,962.2080000000002,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",199,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.112,964.3200000000002,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",200,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.656,966.9760000000001,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",201,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.688,969.6640000000001,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",202,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.0,973.6640000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",203,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.656,976.32,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",204,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.048,978.368,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",205,65536.0,5883904.0,0,0,0.0,5883904.0,5883904.0,33280.0,64.0,0.9980806142034548,49152.0,16384.0,20.064,998.432,4960256.0,792576.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,206,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.184,1007.616,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",207,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.272,1009.888,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",208,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.08,1011.9680000000001,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",209,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.048,1014.0160000000001,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",210,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.968,1017.984,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",211,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.888,1019.8720000000001,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",212,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,1021.888,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",213,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.72,1024.608,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",214,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.688,1027.296,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_64x32_sliced1x4_tn,215,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,171916.0,0.7911562477222479,18014880.0,135168.0,25.12,1052.416,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,562965.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",216,188416.0,393216.0,0,0,0.0,393216.0,393216.0,0.0,256.0,0.0,65536.0,65536.0,2.304,1054.72,16384.0,0.0,188416.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,217,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,171416.0,0.791637088539894,18018560.0,135168.0,25.536,1080.256,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,563080.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",218,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.176,1082.432,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,219,134217728.0,270270464.0,0,0,0.0,270270464.0,270270464.0,651264.0,140288.0,0.8227684346701164,17825792.0,131072.0,22.656,1105.088,786432.0,1048576.0,134217728.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,557056.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",220,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.208,1107.296,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",221,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.112,1109.4080000000001,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",222,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.112,1111.5200000000002,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",223,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.904,1115.4240000000002,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",224,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,1117.3760000000002,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",225,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,1119.4240000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",226,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.656,1122.0800000000002,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",227,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.624,1124.7040000000002,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,228,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.088,1133.7920000000001,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",229,0.0,40960.0,0,0,0.0,40960.0,40960.0,0.0,1920.0,0.0,135168.0,16384.0,2.4,1136.1920000000002,36864.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4224.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,230,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.152,1145.3440000000003,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",231,0.0,40960.0,0,0,0.0,40960.0,40960.0,0.0,1920.0,0.0,135168.0,16384.0,2.4,1147.7440000000004,36864.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4224.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,232,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.152,1156.8960000000004,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",233,0.0,40960.0,0,0,0.0,40960.0,40960.0,0.0,1920.0,0.0,135168.0,16384.0,2.4,1159.2960000000005,36864.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4224.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",234,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.688,1161.9840000000006,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",235,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.624,1164.6080000000006,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",236,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.0,1168.6080000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",237,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.816,1171.4240000000007,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",238,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.144,1173.5680000000007,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",239,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.848,1176.4160000000006,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",240,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.592,1179.0080000000007,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",241,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.032,1183.0400000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",242,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.688,1185.7280000000007,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",243,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.048,1187.7760000000007,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",244,65536.0,5883904.0,0,0,0.0,5883904.0,5883904.0,33280.0,64.0,0.9980806142034548,49152.0,16384.0,20.064,1207.8400000000008,4960256.0,792576.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,245,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.184,1217.0240000000008,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",246,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.272,1219.2960000000007,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",247,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.08,1221.3760000000007,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",248,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.016,1223.3920000000007,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",249,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,4.064,1227.4560000000008,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",250,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,1229.3760000000009,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",251,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.952,1231.3280000000009,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",252,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.72,1234.048000000001,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",253,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.752,1236.8000000000009,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_64x32_sliced1x4_tn,254,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,171735.0,0.7913302446297018,18011808.0,135168.0,25.504,1262.3040000000008,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,562869.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",255,188416.0,393216.0,0,0,0.0,393216.0,393216.0,0.0,256.0,0.0,65536.0,65536.0,2.4,1264.7040000000009,16384.0,0.0,188416.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,256,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,171869.0,0.7912014218844342,18027328.0,135168.0,25.344,1290.048000000001,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,563354.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",257,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.336,1292.384000000001,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,258,134217728.0,270270464.0,0,0,0.0,270270464.0,270270464.0,651264.0,140288.0,0.8227684346701164,17825792.0,131072.0,22.784,1315.168000000001,786432.0,1048576.0,134217728.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,557056.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",259,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.304,1317.4720000000011,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",260,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.048,1319.5200000000011,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",261,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.048,1321.5680000000011,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",262,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.936,1325.504000000001,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",263,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,1327.488000000001,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",264,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,1329.504000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",265,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.656,1332.160000000001,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",266,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.688,1334.848000000001,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,267,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.12,1343.968000000001,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",268,0.0,40960.0,0,0,0.0,40960.0,40960.0,0.0,1920.0,0.0,135168.0,16384.0,2.368,1346.336000000001,36864.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4224.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,269,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.024,1355.3600000000008,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",270,0.0,40960.0,0,0,0.0,40960.0,40960.0,0.0,1920.0,0.0,135168.0,16384.0,2.4,1357.760000000001,36864.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4224.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,271,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,8.96,1366.720000000001,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",272,0.0,40960.0,0,0,0.0,40960.0,40960.0,0.0,1920.0,0.0,135168.0,16384.0,2.368,1369.0880000000009,36864.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4224.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",273,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.72,1371.808000000001,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",274,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.656,1374.4640000000009,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",275,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.0,1378.4640000000009,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",276,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.72,1381.1840000000009,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",277,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.112,1383.296000000001,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",278,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.688,1385.984000000001,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",279,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.688,1388.6720000000012,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",280,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.0,1392.6720000000012,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",281,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.72,1395.3920000000012,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",282,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.112,1397.5040000000013,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",283,65536.0,5883904.0,0,0,0.0,5883904.0,5883904.0,33280.0,64.0,0.9980806142034548,49152.0,16384.0,20.0,1417.5040000000013,4960256.0,792576.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,284,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.088,1426.5920000000012,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",285,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.304,1428.8960000000013,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",286,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.112,1431.0080000000014,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",287,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.048,1433.0560000000014,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",288,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.872,1436.9280000000015,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",289,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,1438.9120000000014,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",290,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,1440.9280000000015,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",291,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.624,1443.5520000000015,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",292,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.72,1446.2720000000015,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_64x32_sliced1x4_tn,293,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,172181.0,0.7909016388465532,18017408.0,135168.0,25.216,1471.4880000000014,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,563044.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",294,188416.0,393216.0,0,0,0.0,393216.0,393216.0,0.0,256.0,0.0,65536.0,65536.0,2.336,1473.8240000000014,16384.0,0.0,188416.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,295,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,171475.0,0.7915803189103713,18015296.0,135168.0,25.632,1499.4560000000015,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,562978.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",296,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.176,1501.6320000000014,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,297,134217728.0,270270464.0,0,0,0.0,270270464.0,270270464.0,651264.0,140288.0,0.8227684346701164,17825792.0,131072.0,22.464,1524.0960000000014,786432.0,1048576.0,134217728.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,557056.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",298,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.432,1526.5280000000014,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",299,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.176,1528.7040000000013,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",300,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,1.984,1530.6880000000012,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",301,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.872,1534.5600000000013,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",302,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,1536.5440000000012,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",303,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,1538.5920000000012,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",304,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.624,1541.2160000000013,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",305,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.688,1543.9040000000014,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,306,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.12,1553.0240000000013,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",307,0.0,40960.0,0,0,0.0,40960.0,40960.0,0.0,1920.0,0.0,135168.0,16384.0,2.4,1555.4240000000013,36864.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4224.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,308,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.312,1564.7360000000012,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",309,0.0,40960.0,0,0,0.0,40960.0,40960.0,0.0,1920.0,0.0,135168.0,16384.0,2.4,1567.1360000000013,36864.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4224.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,310,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.248,1576.3840000000014,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",311,0.0,40960.0,0,0,0.0,40960.0,40960.0,0.0,1920.0,0.0,135168.0,16384.0,2.4,1578.7840000000015,36864.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4224.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",312,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.656,1581.4400000000014,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",313,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.688,1584.1280000000015,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",314,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,3.968,1588.0960000000016,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",315,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.656,1590.7520000000015,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",316,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.08,1592.8320000000015,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",317,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.752,1595.5840000000014,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",318,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.656,1598.2400000000014,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",319,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.032,1602.2720000000013,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",320,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.688,1604.9600000000014,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",321,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.08,1607.0400000000013,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",322,65536.0,5883904.0,0,0,0.0,5883904.0,5883904.0,33280.0,64.0,0.9980806142034548,49152.0,16384.0,20.064,1627.1040000000014,4960256.0,792576.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,323,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.088,1636.1920000000014,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",324,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.24,1638.4320000000014,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",325,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.08,1640.5120000000013,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",326,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.08,1642.5920000000012,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",327,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.872,1646.4640000000013,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",328,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,1648.4160000000013,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",329,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,1650.4640000000013,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",330,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.656,1653.1200000000013,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",331,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.656,1655.7760000000012,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_64x32_sliced1x4_tn,332,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,171573.0,0.7914860415853929,18014816.0,135168.0,25.152,1680.9280000000012,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,562963.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",333,188416.0,393216.0,0,0,0.0,393216.0,393216.0,0.0,256.0,0.0,65536.0,65536.0,2.336,1683.2640000000013,16384.0,0.0,188416.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,334,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,171474.0,0.7915812810396505,18009504.0,135168.0,25.6,1708.8640000000012,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,562797.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",335,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.336,1711.2000000000012,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,336,134217728.0,270270464.0,0,0,0.0,270270464.0,270270464.0,651264.0,140288.0,0.8227684346701164,17825792.0,131072.0,22.976,1734.1760000000013,786432.0,1048576.0,134217728.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,557056.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",337,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.304,1736.4800000000014,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",338,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.08,1738.5600000000013,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",339,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,1.952,1740.5120000000013,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",340,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.872,1744.3840000000014,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",341,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,1746.3360000000014,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",342,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,1748.3840000000014,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",343,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.784,1751.1680000000015,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",344,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.656,1753.8240000000014,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_64x32_sliced1x4_tn,345,4978638848.0,9991311360.0,0,0,0.0,9991311360.0,9991311360.0,23018304.0,5184816.0,0.8161616161616162,650779264.0,2430976.0,697.312,2451.1360000000013,14585856.0,19447808.0,4978638848.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,20336852.0,75968.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",346,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,2452.8320000000012,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",347,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,64.0,128.0,2.56,2455.392000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",348,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,2457.440000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",349,0.0,607744.0,0,0,0.0,607744.0,607744.0,0.0,9520.0,0.0,2430976.0,2430976.0,4.864,2462.304000000001,0.0,607744.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75968.0,75968.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",350,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,2464.000000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",351,0.0,0.0,0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435072.0,169856.0,5.024,2469.024000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76096.0,5308.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",352,0.0,0.0,0,0,0.0,0.0,0.0,44104.0,718188.0,0.057857094131907455,27417472.0,928.0,13.248,2482.272000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,856796.0,29.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",353,0.0,0.0,0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435072.0,170048.0,4.96,2487.232000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76096.0,5314.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",354,0.0,0.0,0,0,0.0,0.0,0.0,44104.0,721168.0,0.057631796276356645,27493856.0,672.0,13.12,2500.3520000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,859183.0,21.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",355,0.0,0.0,0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435072.0,164736.0,5.216,2505.5680000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76096.0,5148.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",356,0.0,0.0,0,0,0.0,0.0,0.0,44104.0,719380.0,0.05776676394004328,27413344.0,896.0,13.024,2518.5920000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,856667.0,28.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",357,0.0,0.0,0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435072.0,166848.0,4.96,2523.5520000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76096.0,5214.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",358,0.0,0.0,0,0,0.0,0.0,0.0,44104.0,717592.0,0.05790236524807797,27380416.0,1056.0,12.896,2536.448000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,855638.0,33.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",359,0.0,0.0,0,0,0.0,0.0,0.0,0.0,57.0,0.0,19104.0,2400.0,3.168,2539.616000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,597.0,75.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",360,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.664,2541.280000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",361,0.0,0.0,0,0,0.0,0.0,0.0,497.0,46.0,0.9152854511970534,2400.0,0.0,3.552,2544.8320000000012,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",362,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.696,2546.528000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",363,0.0,0.0,0,0,0.0,0.0,0.0,497.0,46.0,0.9152854511970534,2400.0,0.0,3.52,2550.048000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",364,0.0,0.0,0,0,0.0,0.0,0.0,157248.0,38400.0,0.803729146221786,2472160.0,10112.0,6.976,2557.0240000000013,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,77255.0,316.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",365,0.0,0.0,0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,544.0,6.432,2563.456000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,80.0,17.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",366,0.0,0.0,0,0,0.0,0.0,0.0,0.0,56976.0,0.0,2445120.0,251200.0,5.024,2568.480000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76410.0,7850.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",367,0.0,0.0,0,0,0.0,0.0,0.0,0.0,14280.0,0.0,3038720.0,256.0,5.76,2574.240000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,94960.0,8.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",368,0.0,0.0,0,0,0.0,0.0,0.0,0.0,18992.0,0.0,0.0,4861952.0,4.384,2578.624000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,151936.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",369,0.0,0.0,0,0,0.0,0.0,0.0,98304.0,18992.0,0.8380848451780112,2430976.0,0.0,5.792,2584.416000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75968.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",370,0.0,0.0,0,0,0.0,0.0,0.0,156.0,64.0,0.7090909090909091,8192.0,0.0,2.208,2586.624000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",371,0.0,0.0,0,0,0.0,0.0,0.0,184626.0,95789.0,0.6584027245332811,9434496.0,6121568.0,17.536,2604.160000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,294828.0,191299.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",372,0.0,0.0,0,0,0.0,0.0,0.0,67626.0,110806.0,0.3790015243902439,9566208.0,7495680.0,15.232,2619.392000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,298944.0,234240.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",373,0.0,0.0,0,0,0.0,0.0,0.0,68478.0,110344.0,0.38293945935063917,9516544.0,7495680.0,16.16,2635.552000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,297392.0,234240.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",374,0.0,0.0,0,0,0.0,0.0,0.0,68478.0,110628.0,0.3823322501758735,9549824.0,5690112.0,16.192,2651.744000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,298432.0,177816.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",375,0.0,0.0,0,0,0.0,0.0,0.0,14336.0,18992.0,0.4301488238118099,4861952.0,0.0,7.84,2659.584000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,151936.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",376,0.0,0.0,0,0,0.0,0.0,0.0,39.0,16.0,0.7090909090909091,2048.0,0.0,2.176,2661.760000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",377,0.0,0.0,0,0,0.0,0.0,0.0,55759.0,135525.0,0.29149850484096945,7474560.0,4234880.0,14.24,2676.000000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,233580.0,132340.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",378,0.0,0.0,0,0,0.0,0.0,0.0,0.0,75968.0,0.0,7322784.0,7292928.0,10.336,2686.3360000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,228837.0,227904.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",379,8508416.0,20076672.0,0,0,0.0,20076672.0,20076672.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,62.56,2748.8960000000006,2452096.0,607744.0,8508416.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,227904.0,75968.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",380,0.0,3052116.0,0,0,0.0,3052116.0,3052116.0,334872.0,37984.0,0.8981268908103933,2430976.0,2430976.0,211.136,2960.0320000000006,3052116.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75968.0,75968.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",381,0.0,0.0,0,0,0.0,0.0,0.0,0.0,9520.0,0.0,2430976.0,607360.0,4.8,2964.832000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75968.0,18980.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",382,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,1.92,2966.752000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",383,0.0,0.0,0,0,0.0,0.0,0.0,0.0,56976.0,0.0,5469696.0,267456.0,10.048,2976.8000000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,170928.0,8358.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",384,0.0,0.0,0,0,0.0,0.0,0.0,0.0,14280.0,0.0,3038720.0,0.0,5.888,2982.6880000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,94960.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",385,8508416.0,20076672.0,0,0,0.0,20076672.0,20076672.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,62.016,3044.7040000000006,2452096.0,607744.0,8508416.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,227904.0,75968.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",386,0.0,0.0,0,0,0.0,0.0,0.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,7.744,3052.448000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",387,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,3054.5920000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",388,0.0,0.0,0,0,0.0,0.0,0.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,7.712,3062.3040000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",389,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.112,3064.4160000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",390,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.048,3066.4640000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",391,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.008,3069.472,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",392,0.0,990796.0,0,0,0.0,990796.0,990796.0,7692.0,4832.0,0.6141807729160013,2431392.0,2560.0,7.488,3076.96,990796.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75981.0,80.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",393,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,3078.976,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",394,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,3082.208,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",395,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.176,3084.384,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",396,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.912,3087.296,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",397,1769472.0,4754432.0,0,0,0.0,4754432.0,4754432.0,0.0,18992.0,0.0,0.0,2430976.0,4.16,3091.4559999999997,0.0,1215488.0,1769472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,75968.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",398,3038720.0,6077440.0,0,0,0.0,6077440.0,6077440.0,0.0,14280.0,0.0,4861952.0,0.0,8.384,3099.8399999999997,0.0,0.0,3038720.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,151936.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",399,0.0,0.0,0,0,0.0,0.0,0.0,14092.0,4912.0,0.7415280993475057,2432256.0,2784.0,9.344,3109.1839999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76008.0,87.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",400,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,64.0,128.0,2.592,3111.776,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",401,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,3113.4719999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",402,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,3115.2,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",403,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.048,3117.2479999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",404,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,3119.2319999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",405,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.912,3122.1439999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",406,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.2,3125.343999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",407,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.112,3127.455999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",408,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.176,3129.631999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",409,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,32.0,3.296,3132.927999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",410,0.0,0.0,0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,64.0,32.0,2.56,3135.487999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",411,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,1.984,3137.471999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",412,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,2.016,3139.487999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",413,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,0.0,2.08,3141.567999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",414,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,2.304,3143.871999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",415,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,16640.0,16384.0,5.568,3149.439999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,520.0,512.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",416,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,2.592,3152.0319999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",417,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,3155.2959999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",418,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.496,3157.7919999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",419,0.0,512.0,0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,2.048,3159.8399999999992,0.0,512.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",420,0.0,0.0,0,0,0.0,0.0,0.0,0.0,20.0,0.0,2048.0,2048.0,2.656,3162.495999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",421,4096.0,9216.0,0,0,0.0,9216.0,9216.0,0.0,32.0,0.0,2048.0,2048.0,2.912,3165.407999999999,0.0,1024.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",422,0.0,512.0,0,0,0.0,512.0,512.0,0.0,32.0,0.0,2048.0,2048.0,2.08,3167.487999999999,0.0,512.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",423,3600.0,8224.0,0,0,0.0,8224.0,8224.0,0.0,32.0,0.0,2048.0,2048.0,3.008,3170.4959999999987,0.0,1024.0,3600.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",424,0.0,512.0,0,0,0.0,512.0,512.0,0.0,32.0,0.0,2048.0,2048.0,2.048,3172.5439999999985,0.0,512.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",425,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.048,3174.5919999999983,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",426,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.872,3178.463999999998,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",427,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,3180.383999999998,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",428,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,3182.3999999999983,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",429,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.688,3185.0879999999984,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",430,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.72,3187.807999999998,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,431,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.184,3196.9919999999984,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",432,0.0,40960.0,0,0,0.0,40960.0,40960.0,0.0,1920.0,0.0,135168.0,16384.0,2.368,3199.3599999999983,36864.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4224.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,433,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.152,3208.5119999999984,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",434,0.0,40960.0,0,0,0.0,40960.0,40960.0,0.0,1920.0,0.0,135168.0,16384.0,2.368,3210.8799999999983,36864.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4224.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,435,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.056,3219.9359999999983,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",436,0.0,40960.0,0,0,0.0,40960.0,40960.0,0.0,1920.0,0.0,135168.0,16384.0,2.432,3222.367999999998,36864.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4224.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",437,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.656,3225.023999999998,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",438,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.72,3227.743999999998,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",439,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.0,3231.743999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",440,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.656,3234.399999999998,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",441,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.112,3236.511999999998,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",442,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.656,3239.167999999998,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",443,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.624,3241.7919999999976,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",444,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.032,3245.823999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",445,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.784,3248.607999999998,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",446,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.144,3250.7519999999977,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",447,0.0,0.0,0,0,0.0,0.0,0.0,0.0,320.0,0.0,32768.0,32768.0,2.656,3253.4079999999976,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",448,0.0,0.0,0,0,0.0,0.0,0.0,0.0,320.0,0.0,32768.0,32768.0,2.592,3255.9999999999977,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",449,65536.0,5885952.0,0,0,0.0,5885952.0,5885952.0,33280.0,64.0,0.9980806142034548,81920.0,16384.0,20.288,3276.2879999999977,4962304.0,792576.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2560.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,450,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.088,3285.375999999998,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",451,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.208,3287.583999999998,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",452,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.144,3289.727999999998,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",453,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.048,3291.7759999999976,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",454,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.872,3295.6479999999974,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",455,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,3297.6319999999973,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",456,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,3299.6479999999974,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",457,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.656,3302.3039999999974,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",458,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.656,3304.9599999999973,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_64x32_sliced1x4_tn,459,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,171999.0,0.7910764846713626,18015392.0,135168.0,25.184,3330.1439999999975,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,562981.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",460,188416.0,393216.0,0,0,0.0,393216.0,393216.0,0.0,256.0,0.0,65536.0,65536.0,2.304,3332.4479999999976,16384.0,0.0,188416.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,461,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,171989.0,0.791086093825349,18012672.0,135168.0,25.12,3357.5679999999975,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,562896.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",462,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.208,3359.7759999999976,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,463,134217728.0,270270464.0,0,0,0.0,270270464.0,270270464.0,651264.0,140288.0,0.8227684346701164,17825792.0,131072.0,22.432,3382.2079999999974,786432.0,1048576.0,134217728.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,557056.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",464,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.272,3384.4799999999973,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",465,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.112,3386.5919999999974,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",466,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,1.984,3388.5759999999973,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",467,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.84,3392.4159999999974,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",468,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,3394.3999999999974,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",469,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,3396.4159999999974,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",470,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.688,3399.1039999999975,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",471,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.656,3401.7599999999975,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,472,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.12,3410.8799999999974,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",473,0.0,40960.0,0,0,0.0,40960.0,40960.0,0.0,1920.0,0.0,135168.0,16384.0,2.4,3413.2799999999975,36864.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4224.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,474,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.088,3422.3679999999977,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",475,0.0,40960.0,0,0,0.0,40960.0,40960.0,0.0,1920.0,0.0,135168.0,16384.0,2.4,3424.7679999999978,36864.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4224.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,476,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.28,3434.047999999998,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",477,0.0,40960.0,0,0,0.0,40960.0,40960.0,0.0,1920.0,0.0,135168.0,16384.0,2.4,3436.447999999998,36864.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4224.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",478,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.848,3439.295999999998,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",479,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.656,3441.951999999998,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",480,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.0,3445.951999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",481,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.72,3448.6719999999978,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",482,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.016,3450.687999999998,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",483,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.72,3453.4079999999976,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",484,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.656,3456.0639999999976,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",485,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.032,3460.0959999999977,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",486,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.784,3462.879999999998,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",487,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.08,3464.9599999999978,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",488,0.0,0.0,0,0,0.0,0.0,0.0,0.0,320.0,0.0,32768.0,32768.0,2.72,3467.6799999999976,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",489,0.0,0.0,0,0,0.0,0.0,0.0,0.0,320.0,0.0,32768.0,32768.0,2.624,3470.3039999999974,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",490,65536.0,5885952.0,0,0,0.0,5885952.0,5885952.0,33280.0,64.0,0.9980806142034548,81920.0,16384.0,20.256,3490.559999999997,4962304.0,792576.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2560.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,491,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.248,3499.8079999999973,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",492,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.24,3502.047999999997,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",493,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.08,3504.127999999997,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",494,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.048,3506.1759999999967,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",495,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.936,3510.111999999997,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",496,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,3512.063999999997,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",497,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,3514.079999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",498,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.656,3516.735999999997,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",499,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.784,3519.5199999999973,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_64x32_sliced1x4_tn,500,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,171922.0,0.7911504811792232,18023360.0,135168.0,25.44,3544.9599999999973,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,563230.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",501,188416.0,393216.0,0,0,0.0,393216.0,393216.0,0.0,256.0,0.0,65536.0,65536.0,2.56,3547.5199999999973,16384.0,0.0,188416.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,502,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,171967.0,0.7911072347858621,18015616.0,135168.0,25.728,3573.2479999999973,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,562988.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",503,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.24,3575.487999999997,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,504,134217728.0,270270464.0,0,0,0.0,270270464.0,270270464.0,651264.0,140288.0,0.8227684346701164,17825792.0,131072.0,22.688,3598.175999999997,786432.0,1048576.0,134217728.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,557056.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",505,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.272,3600.447999999997,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",506,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.08,3602.527999999997,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",507,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,1.952,3604.4799999999973,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",508,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.872,3608.351999999997,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",509,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,3610.335999999997,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",510,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.112,3612.447999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",511,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.656,3615.103999999997,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",512,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.624,3617.727999999997,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,513,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.056,3626.783999999997,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",514,0.0,40960.0,0,0,0.0,40960.0,40960.0,0.0,1920.0,0.0,135168.0,16384.0,2.336,3629.1199999999967,36864.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4224.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,515,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.216,3638.3359999999966,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",516,0.0,40960.0,0,0,0.0,40960.0,40960.0,0.0,1920.0,0.0,135168.0,16384.0,2.336,3640.6719999999964,36864.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4224.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,517,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.024,3649.6959999999963,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",518,0.0,40960.0,0,0,0.0,40960.0,40960.0,0.0,1920.0,0.0,135168.0,16384.0,2.4,3652.0959999999964,36864.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4224.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",519,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.72,3654.815999999996,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",520,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.656,3657.471999999996,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",521,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.064,3661.535999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",522,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.688,3664.223999999996,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",523,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.048,3666.271999999996,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",524,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.688,3668.959999999996,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",525,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.688,3671.647999999996,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",526,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.064,3675.711999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",527,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.688,3678.399999999996,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",528,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.08,3680.479999999996,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",529,0.0,0.0,0,0,0.0,0.0,0.0,0.0,320.0,0.0,32768.0,32768.0,2.656,3683.135999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",530,0.0,0.0,0,0,0.0,0.0,0.0,0.0,320.0,0.0,32768.0,32768.0,2.592,3685.727999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",531,65536.0,5885952.0,0,0,0.0,5885952.0,5885952.0,33280.0,64.0,0.9980806142034548,81920.0,16384.0,20.192,3705.919999999996,4962304.0,792576.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2560.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,532,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.152,3715.071999999996,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",533,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.464,3717.535999999996,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",534,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.112,3719.647999999996,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",535,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.016,3721.663999999996,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",536,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.904,3725.567999999996,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",537,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,3727.551999999996,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",538,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,3729.535999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",539,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.592,3732.127999999996,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",540,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.688,3734.815999999996,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_64x32_sliced1x4_tn,541,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,171336.0,0.7917140773158279,18014176.0,135168.0,25.184,3759.9999999999964,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,562943.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",542,188416.0,393216.0,0,0,0.0,393216.0,393216.0,0.0,256.0,0.0,65536.0,65536.0,2.336,3762.335999999996,16384.0,0.0,188416.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,543,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,171859.0,0.7912110340738869,18015584.0,135168.0,25.216,3787.551999999996,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,562987.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",544,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.304,3789.855999999996,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,545,134217728.0,270270464.0,0,0,0.0,270270464.0,270270464.0,651264.0,140288.0,0.8227684346701164,17825792.0,131072.0,22.592,3812.4479999999962,786432.0,1048576.0,134217728.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,557056.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",546,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.24,3814.687999999996,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",547,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.048,3816.735999999996,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",548,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.016,3818.751999999996,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",549,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.936,3822.687999999996,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",550,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.016,3824.703999999996,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",551,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,3826.847999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",552,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.592,3829.439999999996,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",553,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.816,3832.2559999999958,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,554,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.152,3841.407999999996,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",555,0.0,40960.0,0,0,0.0,40960.0,40960.0,0.0,1920.0,0.0,135168.0,16384.0,2.528,3843.9359999999956,36864.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4224.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,556,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.088,3853.023999999996,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",557,0.0,40960.0,0,0,0.0,40960.0,40960.0,0.0,1920.0,0.0,135168.0,16384.0,2.4,3855.423999999996,36864.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4224.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,558,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.216,3864.639999999996,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",559,0.0,40960.0,0,0,0.0,40960.0,40960.0,0.0,1920.0,0.0,135168.0,16384.0,2.4,3867.039999999996,36864.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4224.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",560,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.688,3869.727999999996,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",561,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.72,3872.447999999996,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",562,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.096,3876.543999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",563,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.72,3879.2639999999956,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",564,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.08,3881.3439999999955,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",565,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.688,3884.0319999999956,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",566,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.656,3886.6879999999956,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",567,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.064,3890.7519999999954,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",568,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.72,3893.471999999995,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",569,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.112,3895.5839999999953,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",570,0.0,0.0,0,0,0.0,0.0,0.0,0.0,320.0,0.0,32768.0,32768.0,2.688,3898.2719999999954,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",571,0.0,0.0,0,0,0.0,0.0,0.0,0.0,320.0,0.0,32768.0,32768.0,2.624,3900.895999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",572,65536.0,5885952.0,0,0,0.0,5885952.0,5885952.0,33280.0,64.0,0.9980806142034548,81920.0,16384.0,20.032,3920.9279999999953,4962304.0,792576.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2560.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,573,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.216,3930.1439999999952,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",574,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.304,3932.4479999999953,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",575,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.112,3934.5599999999954,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",576,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.016,3936.5759999999955,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",577,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.968,3940.5439999999953,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",578,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,3942.4959999999955,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",579,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,3944.5759999999955,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",580,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.656,3947.2319999999954,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",581,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.688,3949.9199999999955,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_64x32_sliced1x4_tn,582,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,172066.0,0.7910121093607666,18012512.0,135168.0,25.184,3975.1039999999957,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,562891.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",583,188416.0,393216.0,0,0,0.0,393216.0,393216.0,0.0,256.0,0.0,65536.0,65536.0,2.432,3977.5359999999955,16384.0,0.0,188416.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,584,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,171608.0,0.7914523765543122,18023648.0,135168.0,25.28,4002.8159999999957,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,563239.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",585,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.176,4004.9919999999956,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,586,134217728.0,270270464.0,0,0,0.0,270270464.0,270270464.0,651264.0,140288.0,0.8227684346701164,17825792.0,131072.0,22.464,4027.4559999999956,786432.0,1048576.0,134217728.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,557056.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",587,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.24,4029.6959999999954,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",588,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.08,4031.7759999999953,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",589,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.048,4033.823999999995,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",590,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.904,4037.727999999995,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",591,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,4039.711999999995,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",592,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,4041.727999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",593,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.656,4044.383999999995,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",594,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.656,4047.039999999995,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,595,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,8.928,4055.967999999995,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",596,0.0,40960.0,0,0,0.0,40960.0,40960.0,0.0,1920.0,0.0,135168.0,16384.0,2.336,4058.3039999999946,36864.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4224.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,597,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.216,4067.5199999999945,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",598,0.0,40960.0,0,0,0.0,40960.0,40960.0,0.0,1920.0,0.0,135168.0,16384.0,2.4,4069.9199999999946,36864.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4224.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,599,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.376,4079.295999999995,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",600,0.0,40960.0,0,0,0.0,40960.0,40960.0,0.0,1920.0,0.0,135168.0,16384.0,2.336,4081.6319999999946,36864.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4224.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",601,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.752,4084.3839999999946,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",602,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.656,4087.0399999999945,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",603,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,3.968,4091.0079999999944,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",604,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.656,4093.6639999999943,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",605,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.112,4095.7759999999944,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",606,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.72,4098.495999999995,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",607,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.688,4101.183999999995,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",608,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.032,4105.215999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",609,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.752,4107.967999999995,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",610,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.048,4110.015999999995,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",611,0.0,0.0,0,0,0.0,0.0,0.0,0.0,320.0,0.0,32768.0,32768.0,2.624,4112.639999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",612,0.0,0.0,0,0,0.0,0.0,0.0,0.0,320.0,0.0,32768.0,32768.0,2.656,4115.295999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",613,65536.0,5885952.0,0,0,0.0,5885952.0,5885952.0,33280.0,64.0,0.9980806142034548,81920.0,16384.0,20.128,4135.4239999999945,4962304.0,792576.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2560.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,614,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.216,4144.639999999995,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",615,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.272,4146.911999999995,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",616,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.08,4148.991999999995,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",617,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.048,4151.0399999999945,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",618,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.872,4154.911999999995,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",619,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,4156.831999999995,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",620,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,4158.879999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",621,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.656,4161.535999999995,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",622,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.688,4164.223999999995,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_64x32_sliced1x4_tn,623,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,171805.0,0.7912629439330117,18011648.0,135168.0,25.216,4189.439999999995,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,562864.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",624,188416.0,393216.0,0,0,0.0,393216.0,393216.0,0.0,256.0,0.0,65536.0,65536.0,2.336,4191.775999999995,16384.0,0.0,188416.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,625,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,172077.0,0.7910015412811946,18015680.0,135168.0,25.216,4216.991999999996,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,562990.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",626,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.144,4219.135999999996,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,627,134217728.0,270270464.0,0,0,0.0,270270464.0,270270464.0,651264.0,140288.0,0.8227684346701164,17825792.0,131072.0,22.688,4241.823999999996,786432.0,1048576.0,134217728.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,557056.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",628,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.24,4244.063999999996,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",629,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.112,4246.175999999996,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",630,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.048,4248.223999999996,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",631,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.904,4252.127999999996,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",632,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,4254.079999999996,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",633,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,4256.095999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",634,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.624,4258.719999999996,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",635,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.656,4261.375999999996,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,636,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,8.992,4270.367999999996,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",637,0.0,40960.0,0,0,0.0,40960.0,40960.0,0.0,1920.0,0.0,135168.0,16384.0,2.592,4272.9599999999955,36864.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4224.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,638,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.184,4282.143999999996,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",639,0.0,40960.0,0,0,0.0,40960.0,40960.0,0.0,1920.0,0.0,135168.0,16384.0,2.432,4284.5759999999955,36864.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4224.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,640,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,8.928,4293.503999999995,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",641,0.0,40960.0,0,0,0.0,40960.0,40960.0,0.0,1920.0,0.0,135168.0,16384.0,2.432,4295.935999999995,36864.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4224.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",642,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.688,4298.623999999995,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",643,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.656,4301.279999999995,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",644,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,3.968,4305.247999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",645,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.784,4308.031999999995,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",646,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.144,4310.175999999995,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",647,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.848,4313.023999999995,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",648,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.784,4315.8079999999945,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",649,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.0,4319.8079999999945,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",650,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.656,4322.4639999999945,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",651,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.016,4324.479999999994,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",652,0.0,0.0,0,0,0.0,0.0,0.0,0.0,320.0,0.0,32768.0,32768.0,2.624,4327.103999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",653,0.0,0.0,0,0,0.0,0.0,0.0,0.0,320.0,0.0,32768.0,32768.0,2.624,4329.727999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",654,65536.0,5885952.0,0,0,0.0,5885952.0,5885952.0,33280.0,64.0,0.9980806142034548,81920.0,16384.0,20.192,4349.919999999994,4962304.0,792576.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2560.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,655,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.056,4358.975999999993,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",656,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.208,4361.183999999993,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",657,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.08,4363.263999999993,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",658,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,1.984,4365.247999999993,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",659,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,4.0,4369.247999999993,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",660,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,4371.231999999994,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",661,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,4373.247999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",662,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.752,4375.999999999994,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",663,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.72,4378.719999999994,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_64x32_sliced1x4_tn,664,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,171998.0,0.7910774455762564,18015392.0,135168.0,25.728,4404.447999999994,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,562981.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",665,188416.0,393216.0,0,0,0.0,393216.0,393216.0,0.0,256.0,0.0,65536.0,65536.0,2.368,4406.815999999994,16384.0,0.0,188416.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,666,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,172232.0,0.7908526574506737,18008352.0,135168.0,25.248,4432.063999999994,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,562761.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",667,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.144,4434.207999999994,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,668,134217728.0,270270464.0,0,0,0.0,270270464.0,270270464.0,651264.0,140288.0,0.8227684346701164,17825792.0,131072.0,22.432,4456.639999999994,786432.0,1048576.0,134217728.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,557056.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",669,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.304,4458.943999999994,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",670,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.112,4461.055999999994,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",671,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.016,4463.071999999994,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",672,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.84,4466.911999999994,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",673,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,4468.895999999994,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",674,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,4470.879999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",675,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.592,4473.471999999994,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",676,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.688,4476.159999999994,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,677,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.184,4485.343999999995,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",678,0.0,40960.0,0,0,0.0,40960.0,40960.0,0.0,1920.0,0.0,135168.0,16384.0,2.4,4487.743999999994,36864.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4224.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,679,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.056,4496.799999999994,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",680,0.0,40960.0,0,0,0.0,40960.0,40960.0,0.0,1920.0,0.0,135168.0,16384.0,2.368,4499.167999999994,36864.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4224.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,681,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.184,4508.351999999994,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",682,0.0,40960.0,0,0,0.0,40960.0,40960.0,0.0,1920.0,0.0,135168.0,16384.0,2.336,4510.687999999995,36864.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4224.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",683,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.656,4513.343999999995,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",684,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.72,4516.063999999995,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",685,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.032,4520.095999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",686,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.688,4522.783999999995,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",687,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.144,4524.927999999995,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",688,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.688,4527.615999999995,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",689,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.656,4530.271999999995,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",690,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.0,4534.271999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",691,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.72,4536.991999999996,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",692,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.048,4539.039999999995,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",693,0.0,0.0,0,0,0.0,0.0,0.0,0.0,320.0,0.0,32768.0,32768.0,2.624,4541.663999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",694,0.0,0.0,0,0,0.0,0.0,0.0,0.0,320.0,0.0,32768.0,32768.0,2.816,4544.479999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",695,65536.0,5885952.0,0,0,0.0,5885952.0,5885952.0,33280.0,64.0,0.9980806142034548,81920.0,16384.0,19.968,4564.447999999995,4962304.0,792576.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2560.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,696,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.28,4573.727999999995,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",697,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.368,4576.095999999995,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",698,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.144,4578.239999999995,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",699,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,1.984,4580.223999999996,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",700,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.904,4584.127999999996,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",701,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.016,4586.143999999996,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",702,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,4588.1919999999955,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",703,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.656,4590.847999999995,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",704,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.656,4593.503999999995,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_64x32_sliced1x4_tn,705,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,171853.0,0.7912168014996653,18011808.0,135168.0,25.216,4618.719999999996,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,562869.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",706,188416.0,393216.0,0,0,0.0,393216.0,393216.0,0.0,256.0,0.0,65536.0,65536.0,2.304,4621.023999999996,16384.0,0.0,188416.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,707,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,171304.0,0.791744877019286,18010880.0,135168.0,25.344,4646.367999999996,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,562840.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",708,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.336,4648.703999999996,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,709,134217728.0,270270464.0,0,0,0.0,270270464.0,270270464.0,651264.0,140288.0,0.8227684346701164,17825792.0,131072.0,22.56,4671.2639999999965,786432.0,1048576.0,134217728.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,557056.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",710,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.496,4673.759999999997,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",711,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.112,4675.871999999997,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",712,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.016,4677.887999999996,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",713,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.904,4681.791999999997,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",714,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,4683.775999999997,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",715,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.952,4685.727999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",716,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.656,4688.383999999997,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",717,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.656,4691.039999999997,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,718,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.248,4700.287999999997,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",719,0.0,40960.0,0,0,0.0,40960.0,40960.0,0.0,1920.0,0.0,135168.0,16384.0,2.56,4702.847999999997,36864.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4224.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,720,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.216,4712.063999999998,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",721,0.0,40960.0,0,0,0.0,40960.0,40960.0,0.0,1920.0,0.0,135168.0,16384.0,2.528,4714.591999999998,36864.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4224.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,722,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.12,4723.711999999998,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",723,0.0,40960.0,0,0,0.0,40960.0,40960.0,0.0,1920.0,0.0,135168.0,16384.0,2.336,4726.047999999998,36864.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4224.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",724,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.688,4728.735999999998,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",725,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.688,4731.423999999998,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",726,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.096,4735.519999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",727,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.688,4738.207999999998,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",728,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.08,4740.287999999998,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",729,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.688,4742.975999999998,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",730,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,128.0,0.0,8192.0,8192.0,2.656,4745.631999999998,2048.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",731,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,3.968,4749.599999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",732,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,24576.0,16384.0,2.688,4752.287999999998,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",733,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.08,4754.367999999998,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",734,0.0,0.0,0,0,0.0,0.0,0.0,0.0,320.0,0.0,32768.0,32768.0,2.688,4757.055999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",735,0.0,0.0,0,0,0.0,0.0,0.0,0.0,320.0,0.0,32768.0,32768.0,2.656,4759.711999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",736,65536.0,5885952.0,0,0,0.0,5885952.0,5885952.0,33280.0,64.0,0.9980806142034548,81920.0,16384.0,20.064,4779.775999999998,4962304.0,792576.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2560.0,512.0
ampere_sgemm_32x32_sliced1x4_tn,737,33554432.0,68943872.0,0,0,0.0,68943872.0,68943872.0,229376.0,37888.0,0.8582375478927203,4718592.0,131072.0,9.28,4789.055999999998,786432.0,1048576.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,147456.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",738,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.24,4791.295999999998,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",739,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.24,4793.535999999997,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",740,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.016,4795.551999999997,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",741,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.904,4799.455999999997,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",742,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,4801.439999999998,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",743,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,4803.455999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",744,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.72,4806.175999999998,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",745,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.688,4808.863999999998,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_64x32_sliced1x4_tn,746,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,171773.0,0.7912937085453023,18014112.0,135168.0,25.216,4834.079999999998,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,562941.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",747,188416.0,393216.0,0,0,0.0,393216.0,393216.0,0.0,256.0,0.0,65536.0,65536.0,2.272,4836.351999999998,16384.0,0.0,188416.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,748,134348800.0,270532608.0,0,0,0.0,270532608.0,270532608.0,651264.0,171755.0,0.7913110146910338,18014752.0,135168.0,25.344,4861.695999999998,786432.0,1048576.0,134348800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,562961.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",749,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.176,4863.8719999999985,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,750,134217728.0,270270464.0,0,0,0.0,270270464.0,270270464.0,651264.0,140288.0,0.8227684346701164,17825792.0,131072.0,22.496,4886.367999999999,786432.0,1048576.0,134217728.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,557056.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",751,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,131072.0,16384.0,2.272,4888.6399999999985,32768.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",752,4096.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.112,4890.751999999999,0.0,0.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",753,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.016,4892.767999999998,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",754,0.0,8580.0,0,0,0.0,8580.0,8580.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.904,4896.671999999999,8576.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",755,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,4898.655999999999,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",756,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,4900.671999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",757,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,16896.0,16384.0,2.656,4903.327999999999,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",758,0.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,384.0,0.0,32768.0,16384.0,2.72,4906.047999999999,0.0,4096.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,512.0
ampere_sgemm_64x32_sliced1x4_tn,759,4978638848.0,9991311360.0,0,0,0.0,9991311360.0,9991311360.0,23018304.0,5184816.0,0.8161616161616162,650717312.0,2430976.0,697.92,5603.967999999999,14585856.0,19447808.0,4978638848.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,20334916.0,75968.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",760,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,5605.695999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",761,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,96.0,160.0,2.624,5608.319999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",762,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,5610.367999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",763,0.0,607744.0,0,0,0.0,607744.0,607744.0,0.0,9520.0,0.0,2430976.0,2430976.0,4.736,5615.103999999998,0.0,607744.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75968.0,75968.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",764,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,5616.799999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",765,0.0,0.0,0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435072.0,168768.0,5.216,5622.015999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76096.0,5274.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",766,0.0,0.0,0,0,0.0,0.0,0.0,44104.0,718188.0,0.057857094131907455,27385376.0,1088.0,12.384,5634.399999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,855793.0,34.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",767,0.0,0.0,0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435072.0,169600.0,5.28,5639.6799999999985,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76096.0,5300.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",768,0.0,0.0,0,0,0.0,0.0,0.0,44104.0,721168.0,0.057631796276356645,27457504.0,960.0,12.64,5652.319999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,858047.0,30.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",769,0.0,0.0,0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435072.0,167168.0,5.28,5657.5999999999985,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76096.0,5224.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",770,0.0,0.0,0,0,0.0,0.0,0.0,44104.0,719380.0,0.05776676394004328,27440640.0,1216.0,12.48,5670.079999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,857520.0,38.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",771,0.0,0.0,0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435072.0,167616.0,5.152,5675.231999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76096.0,5238.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",772,0.0,0.0,0,0,0.0,0.0,0.0,44104.0,720125.0,0.05771045066334829,27482816.0,1184.0,12.448,5687.6799999999985,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,858838.0,37.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",773,0.0,0.0,0,0,0.0,0.0,0.0,0.0,57.0,0.0,19104.0,2400.0,3.136,5690.815999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,597.0,75.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",774,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.728,5692.543999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",775,0.0,0.0,0,0,0.0,0.0,0.0,497.0,46.0,0.9152854511970534,2400.0,0.0,3.584,5696.127999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",776,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.696,5697.823999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",777,0.0,0.0,0,0,0.0,0.0,0.0,497.0,46.0,0.9152854511970534,2400.0,0.0,3.648,5701.471999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",778,0.0,0.0,0,0,0.0,0.0,0.0,156960.0,38400.0,0.8034398034398035,2472160.0,9728.0,7.008,5708.479999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,77255.0,304.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",779,0.0,0.0,0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,544.0,6.432,5714.911999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,80.0,17.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",780,0.0,0.0,0,0,0.0,0.0,0.0,0.0,56976.0,0.0,2445120.0,250048.0,5.216,5720.127999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76410.0,7814.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",781,0.0,0.0,0,0,0.0,0.0,0.0,0.0,14280.0,0.0,3038720.0,0.0,5.664,5725.791999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,94960.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",782,0.0,0.0,0,0,0.0,0.0,0.0,0.0,18992.0,0.0,0.0,4861952.0,4.352,5730.143999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,151936.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",783,0.0,0.0,0,0,0.0,0.0,0.0,98304.0,18992.0,0.8380848451780112,2430976.0,0.0,5.824,5735.967999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75968.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",784,0.0,0.0,0,0,0.0,0.0,0.0,156.0,64.0,0.7090909090909091,8192.0,0.0,2.208,5738.175999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",785,0.0,0.0,0,0,0.0,0.0,0.0,180126.0,100394.0,0.6421146442321403,9359232.0,6109440.0,17.152,5755.327999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,292476.0,190920.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",786,0.0,0.0,0,0,0.0,0.0,0.0,67626.0,112688.0,0.37504575351886155,9486848.0,7495680.0,15.072,5770.399999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,296464.0,234240.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",787,0.0,0.0,0,0,0.0,0.0,0.0,68478.0,115644.0,0.37191644670381596,9535104.0,7495680.0,16.192,5786.591999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,297972.0,234240.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",788,0.0,0.0,0,0,0.0,0.0,0.0,68478.0,114269.0,0.37471476959950095,9508992.0,5690784.0,16.128,5802.7199999999975,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,297156.0,177837.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",789,0.0,0.0,0,0,0.0,0.0,0.0,14336.0,18992.0,0.4301488238118099,4861952.0,0.0,7.872,5810.591999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,151936.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",790,0.0,0.0,0,0,0.0,0.0,0.0,39.0,16.0,0.7090909090909091,2048.0,0.0,2.24,5812.831999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",791,0.0,0.0,0,0,0.0,0.0,0.0,55759.0,139844.0,0.2850620900497436,7467264.0,4257824.0,14.016,5826.847999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,233352.0,133057.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",792,0.0,0.0,0,0,0.0,0.0,0.0,0.0,75968.0,0.0,7324768.0,7292928.0,10.208,5837.055999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,228899.0,227904.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",793,8508416.0,20076672.0,0,0,0.0,20076672.0,20076672.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,62.304,5899.359999999997,2452096.0,607744.0,8508416.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,227904.0,75968.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",794,0.0,3052116.0,0,0,0.0,3052116.0,3052116.0,334872.0,37984.0,0.8981268908103933,2430976.0,2430976.0,210.752,6110.111999999997,3052116.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75968.0,75968.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",795,0.0,0.0,0,0,0.0,0.0,0.0,0.0,9520.0,0.0,2430976.0,607360.0,4.832,6114.943999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75968.0,18980.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",796,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,1.92,6116.863999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",797,0.0,0.0,0,0,0.0,0.0,0.0,0.0,56976.0,0.0,5469696.0,267520.0,10.112,6126.975999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,170928.0,8360.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",798,0.0,0.0,0,0,0.0,0.0,0.0,0.0,14280.0,0.0,3038720.0,0.0,6.048,6133.023999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,94960.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",799,8508416.0,20076672.0,0,0,0.0,20076672.0,20076672.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,62.112,6195.135999999998,2452096.0,607744.0,8508416.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,227904.0,75968.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",800,0.0,0.0,0,0,0.0,0.0,0.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,7.584,6202.7199999999975,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",801,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.176,6204.895999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",802,0.0,0.0,0,0,0.0,0.0,0.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,7.392,6212.287999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",803,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.112,6214.399999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",804,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.048,6216.447999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",805,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.944,6219.391999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",806,0.0,990796.0,0,0,0.0,990796.0,990796.0,7692.0,4832.0,0.6141807729160013,2431392.0,2560.0,7.744,6227.135999999998,990796.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75981.0,80.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",807,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.112,6229.247999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",808,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,6232.479999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",809,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,6234.495999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",810,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.976,6237.471999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",811,1769472.0,4754432.0,0,0,0.0,4754432.0,4754432.0,0.0,18992.0,0.0,0.0,2430976.0,4.16,6241.631999999997,0.0,1215488.0,1769472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,75968.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",812,3038720.0,6077440.0,0,0,0.0,6077440.0,6077440.0,0.0,14280.0,0.0,4861952.0,4608.0,8.352,6249.983999999997,0.0,0.0,3038720.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,151936.0,144.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",813,0.0,0.0,0,0,0.0,0.0,0.0,14092.0,4912.0,0.7415280993475057,2432256.0,2784.0,9.184,6259.167999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76008.0,87.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",814,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,96.0,160.0,2.592,6261.759999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",815,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.76,6263.519999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",816,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,6265.247999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",817,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.048,6267.295999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",818,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,6269.343999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",819,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.816,6272.159999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",820,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,6275.391999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",821,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,6277.439999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
