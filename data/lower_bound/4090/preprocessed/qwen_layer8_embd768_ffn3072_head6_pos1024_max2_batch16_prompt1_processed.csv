Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,1.856,1.856,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,4.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,1.696,3.552,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,4.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",3,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,160.0,32.0,2.528,6.08,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",4,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,128.0,3.552,9.632,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,4.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",5,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,32.0,3.2,12.832,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",6,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.176,15.008000000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",7,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,1.792,16.8,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,4.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",8,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,18.528000000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",9,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.728,20.256000000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",10,0.0,0.0,0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,2.432,22.688000000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",11,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,24.704,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",12,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,26.848,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",13,0.0,0.0,0,0,0.0,0.0,0.0,176.0,16.0,0.9166666666666666,128.0,32.0,2.816,29.663999999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,128.0,2.08,31.744,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",15,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,32.0,2.08,33.824,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",16,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,160.0,0.0,2.112,35.936,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",17,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1152.0,0.0,3840.0,49152.0,6.816,42.752,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,120.0,1536.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",18,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,32.0,2.624,45.376000000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",19,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,48.672000000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",20,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,64.0,2.432,51.104000000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,2.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",21,0.0,2048.0,0,0,0.0,2048.0,2048.0,128.0,96.0,0.5714285714285714,5120.0,4096.0,2.112,53.21600000000001,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",22,0.0,0.0,0,0,0.0,0.0,0.0,0.0,80.0,0.0,8192.0,8192.0,2.592,55.80800000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",23,16384.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,32.0,0.0,8192.0,8192.0,2.752,58.56000000000001,0.0,4096.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",24,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.016,60.57600000000001,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",25,14336.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,32.0,0.0,8192.0,8192.0,2.656,63.232000000000006,0.0,4096.0,14336.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",26,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.016,65.248,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",27,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.24,67.488,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",28,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,5.12,72.608,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",29,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.984,74.592,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",30,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.144,76.736,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",31,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.688,79.424,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",32,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.688,82.11200000000001,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,33,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3698208.0,245760.0,8.256,90.36800000000001,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115569.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",34,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,3456.0,0.0,248832.0,49152.0,2.944,93.31200000000001,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7776.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,35,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3704512.0,245760.0,7.936,101.24800000000002,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115766.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",36,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,3456.0,0.0,248832.0,49152.0,3.04,104.28800000000003,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7776.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,37,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3702080.0,245760.0,7.872,112.16000000000003,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115690.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",38,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,3456.0,0.0,248832.0,49152.0,3.04,115.20000000000003,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7776.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",39,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.752,117.95200000000003,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",40,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.656,120.60800000000003,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",41,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.032,124.64000000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",42,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.72,127.36000000000003,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",43,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.144,129.50400000000002,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",44,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.72,132.22400000000002,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",45,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.624,134.848,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",46,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.064,138.912,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",47,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.752,141.66400000000002,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",48,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,143.776,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",49,196608.0,17651712.0,0,0,0.0,17651712.0,17651712.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,20.64,164.416,14880768.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,50,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3701856.0,245760.0,7.808,172.224,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115683.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",51,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.656,174.88,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",52,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,176.992,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",53,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.048,179.04,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",54,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,5.024,184.064,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",55,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.984,186.048,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",56,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.016,188.064,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",57,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.656,190.72,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",58,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.688,193.408,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,59,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.552,208.95999999999998,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",60,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.04,211.99999999999997,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",61,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,2.464,214.46399999999997,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,62,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.776,230.23999999999998,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",63,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.232,233.47199999999998,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",64,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.432,235.90399999999997,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,65,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,95232.0,0.7987012987012987,11796480.0,393216.0,15.776,251.67999999999998,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",66,0.0,110592.0,0,0,0.0,110592.0,110592.0,0.0,3456.0,0.0,393216.0,49152.0,2.496,254.176,98304.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",67,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.08,256.256,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",68,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.048,258.304,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",69,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,4.928,263.23199999999997,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",70,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,2.016,265.248,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",71,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.08,267.328,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",72,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.688,270.01599999999996,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",73,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.752,272.768,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,74,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3698880.0,245760.0,8.32,281.08799999999997,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115590.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",75,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,3456.0,0.0,248832.0,49152.0,3.008,284.09599999999995,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7776.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,76,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3705728.0,245760.0,7.712,291.80799999999994,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115804.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",77,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,3456.0,0.0,248832.0,49152.0,3.04,294.84799999999996,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7776.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,78,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3703424.0,245760.0,7.904,302.75199999999995,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115732.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",79,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,3456.0,0.0,248832.0,49152.0,3.072,305.82399999999996,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7776.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",80,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.784,308.60799999999995,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",81,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.656,311.26399999999995,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",82,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.032,315.29599999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",83,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.688,317.9839999999999,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",84,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.272,320.2559999999999,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",85,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.688,322.9439999999999,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",86,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.656,325.5999999999999,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",87,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.032,329.6319999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",88,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.72,332.3519999999999,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",89,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.176,334.5279999999999,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",90,196608.0,17651712.0,0,0,0.0,17651712.0,17651712.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,20.448,354.9759999999999,14880768.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,91,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3700640.0,245760.0,7.904,362.8799999999999,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115645.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",92,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.624,365.5039999999999,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",93,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.144,367.6479999999999,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",94,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.08,369.7279999999999,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",95,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,5.024,374.7519999999999,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",96,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,2.016,376.7679999999999,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",97,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.048,378.8159999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",98,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.656,381.4719999999999,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",99,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.656,384.12799999999993,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,100,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.456,399.58399999999995,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",101,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.168,402.75199999999995,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",102,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,2.464,405.21599999999995,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,103,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.712,420.92799999999994,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",104,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.2,424.12799999999993,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",105,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.624,426.75199999999995,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,106,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,95232.0,0.7987012987012987,11796480.0,393216.0,15.808,442.55999999999995,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",107,0.0,110592.0,0,0,0.0,110592.0,110592.0,0.0,3456.0,0.0,393216.0,49152.0,2.528,445.08799999999997,98304.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",108,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,447.2,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",109,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.048,449.248,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",110,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,4.992,454.24,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",111,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.984,456.224,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",112,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.048,458.272,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",113,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.72,460.992,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",114,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.656,463.648,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,115,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3695296.0,245760.0,8.192,471.84000000000003,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115478.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",116,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,3456.0,0.0,248832.0,49152.0,3.008,474.848,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7776.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,117,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3699968.0,245760.0,7.808,482.656,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115624.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",118,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,3456.0,0.0,248832.0,49152.0,3.072,485.728,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7776.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,119,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3703264.0,245760.0,7.84,493.568,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115727.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",120,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,3456.0,0.0,248832.0,49152.0,3.008,496.57599999999996,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7776.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",121,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.72,499.296,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",122,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.656,501.952,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",123,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.0,505.952,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",124,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.752,508.704,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",125,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.144,510.848,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",126,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.752,513.6,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",127,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.688,516.288,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",128,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.096,520.384,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",129,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.912,523.296,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",130,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.272,525.5680000000001,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",131,196608.0,17651712.0,0,0,0.0,17651712.0,17651712.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,20.448,546.0160000000001,14880768.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,132,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3697856.0,245760.0,7.936,553.9520000000001,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115558.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",133,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.688,556.6400000000001,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",134,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.176,558.8160000000001,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",135,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.112,560.9280000000001,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",136,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,4.96,565.8880000000001,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",137,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.984,567.8720000000002,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",138,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.048,569.9200000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",139,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.656,572.5760000000001,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",140,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.656,575.2320000000001,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,141,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.552,590.7840000000001,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",142,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.36,594.1440000000001,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",143,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,2.432,596.5760000000001,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,144,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.776,612.3520000000001,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",145,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.072,615.4240000000001,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",146,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.4,617.8240000000001,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,147,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,95232.0,0.7987012987012987,11796480.0,393216.0,16.064,633.888,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",148,0.0,110592.0,0,0,0.0,110592.0,110592.0,0.0,3456.0,0.0,393216.0,49152.0,2.496,636.384,98304.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",149,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,638.496,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",150,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.144,640.64,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",151,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,4.896,645.536,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",152,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.984,647.52,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",153,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.048,649.568,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",154,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.72,652.288,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",155,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.624,654.912,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,156,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3698528.0,245760.0,7.744,662.6560000000001,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115579.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",157,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,3456.0,0.0,248832.0,49152.0,3.104,665.7600000000001,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7776.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,158,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3704960.0,245760.0,8.064,673.8240000000001,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115780.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",159,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,3456.0,0.0,248832.0,49152.0,3.04,676.864,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7776.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,160,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3703424.0,245760.0,7.936,684.8000000000001,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115732.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",161,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,3456.0,0.0,248832.0,49152.0,3.072,687.8720000000001,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7776.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",162,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.72,690.5920000000001,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",163,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.592,693.1840000000001,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",164,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.064,697.248,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",165,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.72,699.9680000000001,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",166,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.304,702.272,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",167,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.688,704.96,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",168,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.624,707.5840000000001,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",169,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.032,711.6160000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",170,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.688,714.3040000000001,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",171,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.208,716.5120000000001,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",172,196608.0,17651712.0,0,0,0.0,17651712.0,17651712.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,20.512,737.0240000000001,14880768.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,173,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3700256.0,245760.0,7.776,744.8000000000001,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115633.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",174,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.656,747.456,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",175,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,749.568,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",176,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.048,751.616,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",177,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,4.992,756.608,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",178,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,2.048,758.656,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",179,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,1.984,760.64,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",180,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.688,763.328,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",181,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.656,765.9839999999999,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,182,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.488,781.472,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",183,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.2,784.672,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",184,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,2.4,787.072,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,185,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.712,802.784,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",186,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.04,805.824,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",187,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.4,808.2239999999999,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,188,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,95232.0,0.7987012987012987,11796480.0,393216.0,16.384,824.608,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",189,0.0,110592.0,0,0,0.0,110592.0,110592.0,0.0,3456.0,0.0,393216.0,49152.0,2.624,827.232,98304.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",190,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.176,829.408,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",191,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.08,831.488,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",192,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,5.088,836.576,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",193,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.984,838.5600000000001,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",194,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.016,840.576,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",195,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.752,843.328,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",196,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.88,846.208,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,197,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3696480.0,245760.0,7.744,853.952,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115515.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",198,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,3456.0,0.0,248832.0,49152.0,3.04,856.992,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7776.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,199,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3707584.0,245760.0,7.904,864.896,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115862.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",200,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,3456.0,0.0,248832.0,49152.0,3.008,867.904,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7776.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,201,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3702560.0,245760.0,7.968,875.872,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115705.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",202,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,3456.0,0.0,248832.0,49152.0,2.976,878.848,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7776.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",203,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.688,881.536,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",204,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.656,884.1919999999999,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",205,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.0,888.1919999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",206,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.752,890.9439999999998,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",207,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,893.0559999999998,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",208,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.72,895.7759999999998,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",209,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.688,898.4639999999998,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",210,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.064,902.5279999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",211,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.72,905.2479999999998,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",212,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.176,907.4239999999999,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",213,196608.0,17651712.0,0,0,0.0,17651712.0,17651712.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,20.448,927.8719999999998,14880768.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,214,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3697728.0,245760.0,7.744,935.6159999999999,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115554.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",215,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.72,938.3359999999999,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",216,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.208,940.5439999999999,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",217,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.112,942.6559999999998,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",218,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,5.056,947.7119999999999,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",219,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.984,949.6959999999999,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",220,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.016,951.7119999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",221,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.752,954.4639999999998,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",222,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.848,957.3119999999998,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,223,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.552,972.8639999999998,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",224,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.008,975.8719999999998,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",225,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,2.464,978.3359999999999,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,226,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.968,994.3039999999999,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",227,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.136,997.4399999999998,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",228,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.624,1000.0639999999999,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,229,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,95232.0,0.7987012987012987,11796480.0,393216.0,16.128,1016.1919999999999,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",230,0.0,110592.0,0,0,0.0,110592.0,110592.0,0.0,3456.0,0.0,393216.0,49152.0,2.56,1018.7519999999998,98304.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",231,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.176,1020.9279999999999,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",232,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.144,1023.0719999999999,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",233,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,4.928,1028.0,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",234,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.984,1029.984,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",235,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,1.984,1031.9679999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",236,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.688,1034.656,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",237,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.72,1037.376,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,238,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3696960.0,245760.0,7.968,1045.344,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115530.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",239,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,3456.0,0.0,248832.0,49152.0,3.04,1048.384,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7776.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,240,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3704960.0,245760.0,7.872,1056.256,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115780.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",241,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,3456.0,0.0,248832.0,49152.0,3.072,1059.328,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7776.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,242,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3702944.0,245760.0,7.712,1067.04,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115717.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",243,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,3456.0,0.0,248832.0,49152.0,2.976,1070.016,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7776.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",244,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.656,1072.672,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",245,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.624,1075.296,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",246,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.064,1079.3600000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",247,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.784,1082.1440000000002,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",248,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,1084.2560000000003,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",249,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.752,1087.0080000000003,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",250,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.624,1089.6320000000003,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",251,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,3.968,1093.6000000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",252,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.912,1096.5120000000004,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",253,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.272,1098.7840000000003,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",254,196608.0,17651712.0,0,0,0.0,17651712.0,17651712.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,20.512,1119.2960000000003,14880768.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,255,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3696672.0,245760.0,7.712,1127.0080000000003,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115521.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",256,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.592,1129.6000000000004,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",257,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.144,1131.7440000000004,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",258,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.048,1133.7920000000004,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",259,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,4.928,1138.7200000000005,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",260,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.984,1140.7040000000004,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",261,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.016,1142.7200000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",262,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.752,1145.4720000000004,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",263,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.688,1148.1600000000005,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,264,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.424,1163.5840000000005,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",265,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.104,1166.6880000000006,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",266,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,2.432,1169.1200000000006,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,267,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.36,1184.4800000000005,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",268,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.072,1187.5520000000004,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",269,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.4,1189.9520000000005,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,270,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,95232.0,0.7987012987012987,11796480.0,393216.0,16.704,1206.6560000000004,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",271,0.0,110592.0,0,0,0.0,110592.0,110592.0,0.0,3456.0,0.0,393216.0,49152.0,2.56,1209.2160000000003,98304.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",272,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.144,1211.3600000000004,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",273,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.08,1213.4400000000003,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",274,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,5.088,1218.5280000000002,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",275,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.952,1220.4800000000002,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",276,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.048,1222.5280000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",277,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.72,1225.2480000000003,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",278,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.784,1228.0320000000004,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,279,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3697408.0,245760.0,7.712,1235.7440000000004,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115544.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",280,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,3456.0,0.0,248832.0,49152.0,3.04,1238.7840000000003,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7776.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,281,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3701376.0,245760.0,7.808,1246.5920000000003,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115668.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",282,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,3456.0,0.0,248832.0,49152.0,3.04,1249.6320000000003,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7776.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,283,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3702144.0,245760.0,7.616,1257.2480000000003,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115692.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",284,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,3456.0,0.0,248832.0,49152.0,3.008,1260.2560000000003,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7776.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",285,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.72,1262.9760000000003,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",286,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.688,1265.6640000000004,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",287,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.032,1269.6960000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",288,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.72,1272.4160000000004,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",289,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.144,1274.5600000000004,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",290,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.688,1277.2480000000005,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",291,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.592,1279.8400000000006,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",292,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.032,1283.8720000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",293,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.72,1286.5920000000006,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",294,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.144,1288.7360000000006,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",295,196608.0,17651712.0,0,0,0.0,17651712.0,17651712.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,20.384,1309.1200000000006,14880768.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,296,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3702080.0,245760.0,7.776,1316.8960000000006,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115690.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",297,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.656,1319.5520000000006,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",298,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.24,1321.7920000000006,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",299,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.016,1323.8080000000007,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",300,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,5.12,1328.9280000000006,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",301,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.952,1330.8800000000006,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",302,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.08,1332.9600000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",303,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.656,1335.6160000000004,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",304,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.72,1338.3360000000005,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,305,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.392,1353.7280000000005,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",306,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.04,1356.7680000000005,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",307,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,2.368,1359.1360000000004,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,308,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.328,1374.4640000000004,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",309,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.136,1377.6000000000004,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",310,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.624,1380.2240000000004,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,311,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,95232.0,0.7987012987012987,11796480.0,393216.0,16.0,1396.2240000000004,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",312,0.0,110592.0,0,0,0.0,110592.0,110592.0,0.0,3456.0,0.0,393216.0,49152.0,2.688,1398.9120000000005,98304.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",313,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.144,1401.0560000000005,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",314,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.08,1403.1360000000004,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",315,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,4.864,1408.0000000000005,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",316,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.984,1409.9840000000004,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",317,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.016,1412.0000000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",318,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.688,1414.6880000000006,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",319,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.72,1417.4080000000006,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,320,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3696096.0,245760.0,8.064,1425.4720000000007,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115503.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",321,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,3456.0,0.0,248832.0,49152.0,3.04,1428.5120000000006,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7776.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,322,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3700480.0,245760.0,8.032,1436.5440000000006,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115640.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",323,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,3456.0,0.0,248832.0,49152.0,3.008,1439.5520000000006,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7776.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,324,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3706560.0,245760.0,7.808,1447.3600000000006,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115830.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",325,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,3456.0,0.0,248832.0,49152.0,3.072,1450.4320000000005,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7776.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",326,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.848,1453.2800000000004,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",327,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.656,1455.9360000000004,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",328,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.032,1459.9680000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",329,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.752,1462.7200000000003,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",330,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,1464.8320000000003,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",331,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.72,1467.5520000000004,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",332,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.816,1470.3680000000004,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",333,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.032,1474.4000000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",334,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.752,1477.1520000000003,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",335,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,1479.2640000000004,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",336,196608.0,17651712.0,0,0,0.0,17651712.0,17651712.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,20.512,1499.7760000000003,14880768.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,337,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3699840.0,245760.0,7.84,1507.6160000000002,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115620.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",338,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.624,1510.2400000000002,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",339,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.144,1512.3840000000002,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",340,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.048,1514.4320000000002,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",341,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,4.96,1519.3920000000003,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",342,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,2.048,1521.4400000000003,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",343,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.016,1523.4560000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",344,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.656,1526.1120000000003,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",345,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.688,1528.8000000000004,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,346,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.456,1544.2560000000003,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",347,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.168,1547.4240000000002,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",348,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,2.432,1549.8560000000002,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,349,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.52,1565.3760000000002,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",350,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.072,1568.448,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",351,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.592,1571.0400000000002,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,352,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,95232.0,0.7987012987012987,11796480.0,393216.0,16.256,1587.2960000000003,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",353,0.0,110592.0,0,0,0.0,110592.0,110592.0,0.0,3456.0,0.0,393216.0,49152.0,2.72,1590.0160000000003,98304.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",354,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,1592.1280000000004,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",355,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.016,1594.1440000000005,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",356,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,4.96,1599.1040000000005,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",357,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.984,1601.0880000000004,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",358,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.048,1603.1360000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",359,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.656,1605.7920000000004,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",360,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.656,1608.4480000000003,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,361,3733979136.0,7501991936.0,0,0,0.0,7501991936.0,7501991936.0,17548608.0,4634048.0,0.791095890410959,550348672.0,9723904.0,530.464,2138.9120000000003,14585856.0,19447808.0,3733979136.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,17198396.0,303872.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",362,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,1.696,2140.608,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,4.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",363,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,256.0,512.0,2.528,2143.136,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8.0,16.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",364,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2145.152,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",365,0.0,2430976.0,0,0,0.0,2430976.0,2430976.0,0.0,37984.0,0.0,9723904.0,9723904.0,13.568,2158.7200000000003,0.0,2430976.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,303872.0,303872.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",366,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,64.0,1.728,2160.4480000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,2.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",367,0.0,0.0,0,0,0.0,0.0,0.0,11776.0,87744.0,0.11832797427652733,9732000.0,212864.0,12.992,2173.4400000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304125.0,6652.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",368,0.0,0.0,0,0,0.0,0.0,0.0,54464.0,280448.0,0.16262182304605388,10374464.0,928.0,7.008,2180.4480000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,324202.0,29.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",369,0.0,0.0,0,0,0.0,0.0,0.0,11776.0,87744.0,0.11832797427652733,9732000.0,216512.0,12.864,2193.3120000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304125.0,6766.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",370,0.0,0.0,0,0,0.0,0.0,0.0,54464.0,284864.0,0.16050546963410034,10378624.0,800.0,7.04,2200.3520000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,324332.0,25.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",371,0.0,0.0,0,0,0.0,0.0,0.0,11776.0,87744.0,0.11832797427652733,9732000.0,214016.0,13.088,2213.4400000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304125.0,6688.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",372,0.0,0.0,0,0,0.0,0.0,0.0,54464.0,281920.0,0.161910197869102,10375936.0,896.0,6.944,2220.3840000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,324248.0,28.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",373,0.0,0.0,0,0,0.0,0.0,0.0,11776.0,87744.0,0.11832797427652733,9732000.0,212352.0,12.992,2233.3760000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304125.0,6636.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",374,0.0,0.0,0,0,0.0,0.0,0.0,54464.0,279712.0,0.16297998659389065,10372224.0,1056.0,6.816,2240.1920000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,324132.0,33.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",375,0.0,0.0,0,0,0.0,0.0,0.0,0.0,69.0,0.0,23616.0,2944.0,3.584,2243.7760000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,738.0,92.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",376,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.728,2245.5040000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",377,0.0,0.0,0,0,0.0,0.0,0.0,497.0,54.0,0.9019963702359347,2944.0,0.0,3.584,2249.088,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",378,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.76,2250.8480000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",379,0.0,0.0,0,0,0.0,0.0,0.0,497.0,54.0,0.9019963702359347,2944.0,0.0,3.648,2254.4960000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",380,0.0,0.0,0,0,0.0,0.0,0.0,903168.0,100832.0,0.8995697211155379,9774976.0,23360.0,17.312,2271.8080000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,305468.0,730.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",381,0.0,0.0,0,0,0.0,0.0,0.0,7328.0,128.0,0.9828326180257511,10240.0,2080.0,6.496,2278.3040000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,320.0,65.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",382,0.0,0.0,0,0,0.0,0.0,0.0,0.0,227904.0,0.0,9776704.0,988992.0,13.28,2291.5840000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,305522.0,30906.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",383,0.0,0.0,0,0,0.0,0.0,0.0,0.0,56976.0,0.0,12154880.0,440576.0,16.0,2307.5840000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,379840.0,13768.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",384,0.0,0.0,0,0,0.0,0.0,0.0,0.0,75968.0,0.0,0.0,19447808.0,12.032,2319.616000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,607744.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",385,0.0,0.0,0,0,0.0,0.0,0.0,98304.0,75968.0,0.5640837311788469,9723904.0,0.0,14.048,2333.6640000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,303872.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",386,0.0,0.0,0,0,0.0,0.0,0.0,156.0,64.0,0.7090909090909091,8192.0,0.0,2.208,2335.8720000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",387,0.0,0.0,0,0,0.0,0.0,0.0,696204.0,383297.0,0.6449313154874335,35582592.0,24172992.0,45.088,2380.960000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1111956.0,755406.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",388,0.0,0.0,0,0,0.0,0.0,0.0,267804.0,431253.0,0.3830932241576867,36541184.0,29982976.0,39.808,2420.768000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1141912.0,936968.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",389,0.0,0.0,0,0,0.0,0.0,0.0,268512.0,436113.0,0.38107078233102715,36439424.0,29982848.0,39.968,2460.736000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1138732.0,936964.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",390,0.0,0.0,0,0,0.0,0.0,0.0,268512.0,430407.0,0.38418185798354315,36441600.0,29982720.0,40.064,2500.8000000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1138800.0,936960.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",391,0.0,0.0,0,0,0.0,0.0,0.0,14336.0,75968.0,0.15875265768958186,19447808.0,0.0,23.008,2523.8080000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,607744.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",392,0.0,0.0,0,0,0.0,0.0,0.0,39.0,16.0,0.7090909090909091,2048.0,0.0,2.272,2526.0800000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",393,0.0,0.0,0,0,0.0,0.0,0.0,223430.0,330215.0,0.40356184919939675,32672768.0,18123840.0,33.12,2559.2000000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1021024.0,566370.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",394,0.0,0.0,0,0,0.0,0.0,0.0,0.0,303872.0,0.0,29316992.0,29171712.0,33.28,2592.4800000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,916156.0,911616.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",395,34033664.0,80306688.0,0,0,0.0,80306688.0,80306688.0,2112.0,76544.0,0.026851098454027666,29171712.0,9723904.0,64.224,2656.7040000000006,9808384.0,2430976.0,34033664.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,911616.0,303872.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",396,0.0,12208464.0,0,0,0.0,12208464.0,12208464.0,1339488.0,151936.0,0.8981268908103933,9723904.0,9723904.0,212.16,2868.8640000000005,12208464.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,303872.0,303872.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",397,0.0,0.0,0,0,0.0,0.0,0.0,0.0,37984.0,0.0,9723904.0,2430976.0,12.288,2881.1520000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,303872.0,75968.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",398,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,512.0,1.92,2883.0720000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,16.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",399,0.0,0.0,0,0,0.0,0.0,0.0,0.0,227904.0,0.0,21878784.0,1083936.0,26.72,2909.7920000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,683712.0,33873.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",400,0.0,0.0,0,0,0.0,0.0,0.0,0.0,56976.0,0.0,12154880.0,360320.0,16.096,2925.8880000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,379840.0,11260.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",401,34033664.0,80306688.0,0,0,0.0,80306688.0,80306688.0,2112.0,76544.0,0.026851098454027666,29171712.0,9723904.0,64.48,2990.3680000000004,9808384.0,2430976.0,34033664.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,911616.0,303872.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",402,0.0,0.0,0,0,0.0,0.0,0.0,23525.0,19300.0,0.5493286631640397,9725120.0,9536.0,15.648,3006.0160000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,303910.0,298.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",403,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,3008.1600000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",404,0.0,0.0,0,0,0.0,0.0,0.0,23525.0,19300.0,0.5493286631640397,9725120.0,9536.0,15.84,3024.0000000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,303910.0,298.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",405,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.176,3026.1760000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",406,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.048,3028.224,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",407,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.944,3031.168,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",408,0.0,3871024.0,0,0,0.0,3871024.0,3871024.0,19888.0,19328.0,0.5071399428804569,9725568.0,10048.0,15.712,3046.88,3871024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,303924.0,314.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",409,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,1.984,3048.864,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",410,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,3052.16,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",411,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,3054.2079999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",412,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.976,3057.1839999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",413,4128768.0,13119488.0,0,0,0.0,13119488.0,13119488.0,0.0,75968.0,0.0,0.0,9723904.0,7.904,3065.0879999999997,0.0,4861952.0,4128768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,303872.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",414,12154880.0,24309760.0,0,0,0.0,24309760.0,24309760.0,0.0,56976.0,0.0,19447808.0,2329344.0,24.0,3089.0879999999997,0.0,0.0,12154880.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,607744.0,72792.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",415,0.0,0.0,0,0,0.0,0.0,0.0,34608.0,19648.0,0.637864936596874,9729024.0,11488.0,17.728,3106.816,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304032.0,359.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",416,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,256.0,512.0,2.624,3109.4399999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8.0,16.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",417,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,3111.1359999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",418,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,3112.8639999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",419,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.112,3114.9759999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",420,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,3117.0559999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",421,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,160.0,128.0,2.752,3119.8079999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5.0,4.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",422,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,32.0,3.264,3123.0719999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",423,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,3125.0559999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",424,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.112,3127.1679999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",425,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,288.0,128.0,3.264,3130.432,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,9.0,4.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",426,0.0,0.0,0,0,0.0,0.0,0.0,176.0,16.0,0.9166666666666666,256.0,96.0,2.72,3133.1519999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8.0,3.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",427,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,256.0,256.0,2.048,3135.1999999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8.0,8.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",428,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,256.0,32.0,2.08,3137.2799999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",429,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,288.0,0.0,2.016,3139.2959999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,9.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",430,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,256.0,128.0,2.208,3141.5039999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8.0,4.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",431,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1152.0,0.0,40704.0,49152.0,11.648,3153.1519999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1272.0,1536.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",432,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,256.0,32.0,2.464,3155.6159999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",433,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.456,3159.0719999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",434,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,64.0,2.432,3161.5039999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,2.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",435,0.0,2048.0,0,0,0.0,2048.0,2048.0,128.0,96.0,0.5714285714285714,5120.0,4096.0,2.08,3163.5839999999994,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",436,0.0,0.0,0,0,0.0,0.0,0.0,0.0,80.0,0.0,8192.0,8192.0,2.592,3166.1759999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",437,16384.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,32.0,0.0,8192.0,8192.0,2.752,3168.9279999999994,0.0,4096.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",438,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,1.984,3170.9119999999994,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",439,14400.0,32896.0,0,0,0.0,32896.0,32896.0,0.0,32.0,0.0,8192.0,8192.0,2.784,3173.6959999999995,0.0,4096.0,14400.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",440,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.016,3175.7119999999995,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",441,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.08,3177.7919999999995,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",442,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,4.928,3182.7199999999993,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",443,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.92,3184.6399999999994,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",444,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.016,3186.6559999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",445,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.656,3189.3119999999994,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",446,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.752,3192.0639999999994,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,447,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3697920.0,245760.0,7.744,3199.8079999999995,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115560.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",448,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,3456.0,0.0,248832.0,49152.0,3.072,3202.8799999999997,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7776.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,449,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3705344.0,245760.0,7.84,3210.72,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115792.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",450,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,3456.0,0.0,248832.0,49152.0,3.072,3213.792,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7776.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,451,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3704704.0,245760.0,7.904,3221.696,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115772.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",452,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,3456.0,0.0,248832.0,49152.0,3.072,3224.768,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7776.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",453,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.784,3227.552,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",454,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.656,3230.208,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",455,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,3.968,3234.176,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",456,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.752,3236.928,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",457,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,3239.04,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",458,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.752,3241.792,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",459,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.752,3244.544,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",460,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.096,3248.64,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",461,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.688,3251.328,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",462,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.144,3253.4719999999998,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",463,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,2.656,3256.1279999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",464,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,2.752,3258.8799999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",465,130048.0,17483142.0,0,0,0.0,17483142.0,17483142.0,100686.0,192.0,0.9980967108784868,245760.0,49152.0,20.864,3279.7439999999997,14851552.0,2371494.0,130048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,466,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3700032.0,245760.0,7.936,3287.68,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115626.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",467,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.592,3290.272,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",468,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.144,3292.4159999999997,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",469,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.24,3294.6559999999995,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",470,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,4.896,3299.5519999999997,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",471,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.952,3301.504,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",472,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.016,3303.52,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",473,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.72,3306.24,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",474,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.688,3308.928,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,475,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.552,3324.48,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",476,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.264,3327.744,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",477,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,2.432,3330.176,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,478,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.648,3345.824,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",479,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.104,3348.928,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",480,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.4,3351.328,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,481,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,95232.0,0.7987012987012987,11796480.0,393216.0,16.16,3367.488,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",482,0.0,110592.0,0,0,0.0,110592.0,110592.0,0.0,3456.0,0.0,393216.0,49152.0,2.56,3370.048,98304.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",483,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.176,3372.2239999999997,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",484,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.08,3374.3039999999996,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",485,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,5.024,3379.3279999999995,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",486,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.888,3381.2159999999994,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",487,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.016,3383.2319999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",488,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.656,3385.8879999999995,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",489,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.816,3388.7039999999993,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,490,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3700544.0,245760.0,7.744,3396.4479999999994,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115642.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",491,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,3456.0,0.0,248832.0,49152.0,3.008,3399.455999999999,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7776.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,492,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3706496.0,245760.0,8.032,3407.4879999999994,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115828.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",493,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,3456.0,0.0,248832.0,49152.0,3.008,3410.495999999999,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7776.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,494,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3703488.0,245760.0,7.776,3418.271999999999,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115734.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",495,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,3456.0,0.0,248832.0,49152.0,3.008,3421.279999999999,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7776.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",496,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.72,3423.9999999999986,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",497,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.656,3426.6559999999986,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",498,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.032,3430.6879999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",499,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.72,3433.4079999999985,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",500,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.144,3435.5519999999983,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",501,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.88,3438.4319999999984,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",502,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.592,3441.0239999999985,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",503,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.032,3445.0559999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",504,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.752,3447.8079999999986,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",505,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.144,3449.9519999999984,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",506,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,2.848,3452.7999999999984,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",507,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,2.688,3455.4879999999985,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",508,173824.0,17598048.0,0,0,0.0,17598048.0,17598048.0,100608.0,192.0,0.9980952380952381,245760.0,49152.0,20.608,3476.0959999999986,14874808.0,2375592.0,173824.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,509,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3698272.0,245760.0,7.904,3483.9999999999986,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115571.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",510,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.656,3486.6559999999986,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",511,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.144,3488.7999999999984,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",512,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.08,3490.8799999999983,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",513,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,4.928,3495.807999999998,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",514,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.952,3497.7599999999984,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",515,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.016,3499.7759999999985,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",516,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.72,3502.4959999999983,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",517,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.656,3505.151999999998,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,518,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.616,3520.767999999998,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",519,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.232,3523.999999999998,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",520,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,2.528,3526.527999999998,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,521,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.456,3541.983999999998,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",522,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.168,3545.151999999998,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",523,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.432,3547.583999999998,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,524,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,95232.0,0.7987012987012987,11796480.0,393216.0,15.712,3563.295999999998,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",525,0.0,110592.0,0,0,0.0,110592.0,110592.0,0.0,3456.0,0.0,393216.0,49152.0,2.528,3565.823999999998,98304.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",526,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.272,3568.0959999999977,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",527,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.048,3570.1439999999975,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",528,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,4.96,3575.1039999999975,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",529,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.984,3577.0879999999975,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",530,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.048,3579.1359999999972,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",531,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.688,3581.8239999999973,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",532,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.688,3584.5119999999974,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,533,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3696352.0,245760.0,8.096,3592.6079999999974,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115511.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",534,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,3456.0,0.0,248832.0,49152.0,3.04,3595.6479999999974,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7776.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,535,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3703776.0,245760.0,7.968,3603.6159999999973,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115743.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",536,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,3456.0,0.0,248832.0,49152.0,3.072,3606.6879999999974,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7776.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,537,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3702816.0,245760.0,7.936,3614.6239999999975,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115713.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",538,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,3456.0,0.0,248832.0,49152.0,3.04,3617.6639999999975,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7776.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",539,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.848,3620.5119999999974,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",540,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.656,3623.1679999999974,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",541,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.032,3627.1999999999975,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",542,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.688,3629.8879999999976,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",543,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.176,3632.0639999999976,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",544,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.72,3634.7839999999974,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",545,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.72,3637.503999999997,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",546,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.096,3641.599999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",547,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.72,3644.319999999997,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",548,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.144,3646.4639999999968,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",549,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,2.912,3649.3759999999966,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",550,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,2.688,3652.0639999999967,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",551,196608.0,17657856.0,0,0,0.0,17657856.0,17657856.0,99840.0,192.0,0.9980806142034548,245760.0,49152.0,20.704,3672.767999999997,14886912.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,552,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3699648.0,245760.0,7.776,3680.5439999999967,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115614.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",553,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.656,3683.1999999999966,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",554,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.144,3685.3439999999964,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",555,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.048,3687.391999999996,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",556,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,4.992,3692.3839999999964,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",557,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.952,3694.3359999999966,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",558,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.016,3696.3519999999967,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",559,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.72,3699.0719999999965,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",560,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.752,3701.8239999999964,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,561,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.456,3717.2799999999966,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",562,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.136,3720.4159999999965,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",563,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,2.496,3722.9119999999966,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,564,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.488,3738.3999999999965,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",565,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.04,3741.4399999999964,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",566,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.4,3743.8399999999965,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,567,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,95232.0,0.7987012987012987,11796480.0,393216.0,16.256,3760.0959999999964,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",568,0.0,110592.0,0,0,0.0,110592.0,110592.0,0.0,3456.0,0.0,393216.0,49152.0,2.72,3762.815999999996,98304.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",569,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.208,3765.0239999999962,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",570,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.048,3767.071999999996,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",571,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,5.024,3772.095999999996,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",572,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.952,3774.047999999996,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",573,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.112,3776.159999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",574,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.656,3778.815999999996,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",575,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.784,3781.5999999999963,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,576,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3705440.0,245760.0,7.904,3789.5039999999963,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115795.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",577,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,3456.0,0.0,248832.0,49152.0,3.008,3792.511999999996,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7776.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,578,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3710528.0,245760.0,7.84,3800.351999999996,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115954.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",579,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,3456.0,0.0,248832.0,49152.0,3.008,3803.359999999996,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7776.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,580,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3705600.0,245760.0,7.712,3811.071999999996,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115800.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",581,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,3456.0,0.0,248832.0,49152.0,3.008,3814.079999999996,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7776.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",582,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.688,3816.767999999996,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",583,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.688,3819.455999999996,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",584,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.064,3823.519999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",585,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.88,3826.399999999996,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",586,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.944,3829.343999999996,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",587,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.72,3832.0639999999958,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",588,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.688,3834.751999999996,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",589,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.032,3838.783999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",590,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.688,3841.471999999996,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",591,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.08,3843.551999999996,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",592,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,2.784,3846.335999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",593,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,2.688,3849.0239999999962,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",594,196608.0,17657856.0,0,0,0.0,17657856.0,17657856.0,99840.0,192.0,0.9980806142034548,245760.0,49152.0,20.48,3869.5039999999963,14886912.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,595,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3696672.0,245760.0,7.776,3877.279999999996,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115521.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",596,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.656,3879.935999999996,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",597,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,3882.047999999996,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",598,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.016,3884.063999999996,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",599,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,5.312,3889.375999999996,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",600,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.952,3891.3279999999963,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",601,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.016,3893.3439999999964,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",602,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.72,3896.063999999996,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",603,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.688,3898.7519999999963,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,604,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.584,3914.335999999996,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",605,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.104,3917.439999999996,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",606,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,2.4,3919.839999999996,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,607,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.424,3935.263999999996,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",608,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.104,3938.367999999996,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",609,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.592,3940.959999999996,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,610,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,95232.0,0.7987012987012987,11796480.0,393216.0,16.192,3957.151999999996,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",611,0.0,110592.0,0,0,0.0,110592.0,110592.0,0.0,3456.0,0.0,393216.0,49152.0,2.528,3959.6799999999957,98304.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",612,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.432,3962.1119999999955,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",613,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.208,3964.3199999999956,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",614,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,4.864,3969.1839999999956,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",615,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.952,3971.135999999996,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",616,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.016,3973.151999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",617,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.72,3975.8719999999958,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",618,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.752,3978.6239999999957,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,619,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3695008.0,245760.0,7.744,3986.367999999996,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115469.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",620,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,3456.0,0.0,248832.0,49152.0,3.072,3989.439999999996,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7776.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,621,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3702304.0,245760.0,7.744,3997.183999999996,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115697.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",622,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,3456.0,0.0,248832.0,49152.0,3.04,4000.223999999996,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7776.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,623,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3701984.0,245760.0,7.808,4008.031999999996,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115687.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",624,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,3456.0,0.0,248832.0,49152.0,3.008,4011.039999999996,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7776.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",625,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.816,4013.8559999999957,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",626,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.688,4016.543999999996,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",627,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.0,4020.543999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",628,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.752,4023.2959999999957,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",629,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,4025.407999999996,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",630,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.688,4028.095999999996,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",631,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.624,4030.7199999999957,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",632,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.032,4034.751999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",633,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.784,4037.535999999996,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",634,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,4039.647999999996,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",635,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,2.688,4042.335999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",636,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,2.688,4045.0239999999962,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",637,196608.0,17657856.0,0,0,0.0,17657856.0,17657856.0,99840.0,192.0,0.9980806142034548,245760.0,49152.0,20.576,4065.5999999999963,14886912.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,638,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3699968.0,245760.0,7.776,4073.375999999996,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115624.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",639,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.784,4076.159999999996,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",640,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.24,4078.399999999996,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",641,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.112,4080.511999999996,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",642,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,4.992,4085.5039999999963,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",643,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.952,4087.4559999999965,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",644,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.016,4089.4719999999966,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",645,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.688,4092.1599999999967,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",646,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.656,4094.8159999999966,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,647,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.328,4110.143999999997,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",648,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.232,4113.375999999997,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",649,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,2.656,4116.0319999999965,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,650,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.392,4131.423999999996,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",651,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.008,4134.431999999996,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",652,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.432,4136.863999999996,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,653,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,95232.0,0.7987012987012987,11796480.0,393216.0,16.384,4153.247999999996,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",654,0.0,110592.0,0,0,0.0,110592.0,110592.0,0.0,3456.0,0.0,393216.0,49152.0,2.56,4155.807999999996,98304.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",655,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,4157.919999999996,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",656,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.048,4159.967999999996,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",657,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,5.088,4165.055999999996,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",658,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.984,4167.039999999996,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",659,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.016,4169.055999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",660,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.752,4171.807999999996,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",661,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.656,4174.463999999996,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,662,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3696896.0,245760.0,7.776,4182.239999999996,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115528.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",663,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,3456.0,0.0,248832.0,49152.0,2.976,4185.215999999996,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7776.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,664,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3704096.0,245760.0,7.712,4192.927999999996,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115753.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",665,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,3456.0,0.0,248832.0,49152.0,3.136,4196.063999999997,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7776.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,666,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3703840.0,245760.0,7.936,4203.999999999996,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115745.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",667,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,3456.0,0.0,248832.0,49152.0,2.976,4206.975999999996,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7776.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",668,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.752,4209.727999999996,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",669,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.624,4212.351999999996,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",670,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.032,4216.383999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",671,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.72,4219.103999999997,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",672,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,4221.215999999997,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",673,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.88,4224.095999999997,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",674,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.688,4226.783999999997,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",675,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.064,4230.847999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",676,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.848,4233.695999999997,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",677,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,4235.807999999997,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",678,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,2.784,4238.591999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",679,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,2.656,4241.247999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",680,196608.0,17657856.0,0,0,0.0,17657856.0,17657856.0,99840.0,192.0,0.9980806142034548,245760.0,49152.0,20.48,4261.727999999996,14886912.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,681,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3700384.0,245760.0,8.032,4269.759999999997,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115637.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",682,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.688,4272.447999999997,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",683,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,4274.559999999997,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",684,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.176,4276.735999999997,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",685,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,4.992,4281.727999999997,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",686,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.92,4283.647999999997,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",687,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.016,4285.663999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",688,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.72,4288.383999999997,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",689,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.688,4291.071999999997,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,690,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.872,4306.943999999998,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",691,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,2.976,4309.919999999997,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",692,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,2.464,4312.383999999997,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,693,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.392,4327.775999999997,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",694,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.104,4330.879999999997,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",695,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.496,4333.3759999999975,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,696,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,95232.0,0.7987012987012987,11796480.0,393216.0,16.064,4349.439999999998,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",697,0.0,110592.0,0,0,0.0,110592.0,110592.0,0.0,3456.0,0.0,393216.0,49152.0,2.752,4352.191999999998,98304.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",698,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.144,4354.335999999998,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",699,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.048,4356.383999999998,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",700,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,4.928,4361.311999999998,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",701,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.92,4363.231999999998,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",702,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,1.952,4365.183999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",703,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.688,4367.8719999999985,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",704,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.848,4370.719999999998,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,705,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3698848.0,245760.0,8.128,4378.847999999998,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115589.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",706,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,3456.0,0.0,248832.0,49152.0,3.072,4381.919999999998,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7776.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,707,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3703360.0,245760.0,7.904,4389.823999999999,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115730.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",708,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,3456.0,0.0,248832.0,49152.0,3.072,4392.895999999999,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7776.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,709,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3702208.0,245760.0,7.68,4400.575999999999,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115694.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",710,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,3456.0,0.0,248832.0,49152.0,3.008,4403.583999999999,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7776.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",711,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.848,4406.431999999999,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",712,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.624,4409.055999999999,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",713,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.064,4413.119999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",714,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.72,4415.839999999999,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",715,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,4417.951999999999,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",716,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.784,4420.735999999999,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",717,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.656,4423.391999999999,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",718,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.0,4427.391999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",719,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.688,4430.079999999999,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",720,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,4432.191999999999,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",721,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,2.752,4434.9439999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",722,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,2.688,4437.632,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",723,196608.0,17657856.0,0,0,0.0,17657856.0,17657856.0,99840.0,192.0,0.9980806142034548,245760.0,49152.0,20.704,4458.335999999999,14886912.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,724,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3699456.0,245760.0,7.84,4466.1759999999995,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115608.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",725,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.656,4468.831999999999,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",726,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,4470.9439999999995,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",727,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.08,4473.023999999999,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",728,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,5.024,4478.048,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",729,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,2.08,4480.128,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",730,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.016,4482.143999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",731,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.688,4484.831999999999,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",732,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.688,4487.5199999999995,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,733,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.488,4503.008,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",734,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.2,4506.208,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",735,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,2.496,4508.704,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,736,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.328,4524.032,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",737,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.104,4527.136,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",738,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.432,4529.568,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,739,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,95232.0,0.7987012987012987,11796480.0,393216.0,15.904,4545.472000000001,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",740,0.0,110592.0,0,0,0.0,110592.0,110592.0,0.0,3456.0,0.0,393216.0,49152.0,2.592,4548.064,98304.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",741,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.272,4550.336,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",742,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.016,4552.352,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",743,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,5.088,4557.44,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",744,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.952,4559.392,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",745,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.048,4561.44,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",746,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.656,4564.096,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",747,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.72,4566.816,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,748,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3694240.0,245760.0,8.0,4574.816,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115445.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",749,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,3456.0,0.0,248832.0,49152.0,2.976,4577.7919999999995,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7776.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,750,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3705824.0,245760.0,7.808,4585.599999999999,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115807.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",751,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,3456.0,0.0,248832.0,49152.0,3.008,4588.607999999999,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7776.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,752,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3702048.0,245760.0,7.84,4596.447999999999,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115689.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",753,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,3456.0,0.0,248832.0,49152.0,3.136,4599.584,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7776.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",754,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.752,4602.336,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",755,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.656,4604.992,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",756,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.032,4609.024,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",757,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.72,4611.744000000001,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",758,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.176,4613.920000000001,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",759,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.72,4616.640000000001,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",760,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.752,4619.392000000002,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",761,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.064,4623.456000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",762,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.688,4626.144000000002,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",763,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,4628.256000000002,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",764,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,2.72,4630.976000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",765,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,2.624,4633.600000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",766,196608.0,17657856.0,0,0,0.0,17657856.0,17657856.0,99840.0,192.0,0.9980806142034548,245760.0,49152.0,20.576,4654.176000000002,14886912.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,767,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3699168.0,245760.0,7.808,4661.984000000002,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115599.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",768,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.688,4664.672000000002,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",769,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.144,4666.8160000000025,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",770,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.048,4668.864000000002,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",771,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,4.992,4673.8560000000025,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",772,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.952,4675.808000000003,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",773,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,1.984,4677.792000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",774,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.688,4680.480000000003,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",775,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.688,4683.168000000003,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,776,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.584,4698.752000000003,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",777,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.104,4701.856000000003,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",778,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,2.464,4704.320000000003,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,779,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.552,4719.872000000003,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",780,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.2,4723.072000000003,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",781,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.688,4725.760000000003,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,782,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,95232.0,0.7987012987012987,11796480.0,393216.0,16.064,4741.824000000003,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",783,0.0,110592.0,0,0,0.0,110592.0,110592.0,0.0,3456.0,0.0,393216.0,49152.0,2.528,4744.3520000000035,98304.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",784,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,4746.464000000004,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",785,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.08,4748.5440000000035,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",786,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,4.928,4753.472000000003,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",787,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.952,4755.424000000004,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",788,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.016,4757.440000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",789,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.752,4760.192000000004,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",790,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.656,4762.848000000004,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,791,3733979136.0,7501991936.0,0,0,0.0,7501991936.0,7501991936.0,17548608.0,4634048.0,0.791095890410959,549892224.0,9723904.0,530.624,5293.472000000003,14585856.0,19447808.0,3733979136.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,17184132.0,303872.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",792,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,1.696,5295.168000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,4.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",793,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,384.0,640.0,2.624,5297.792000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12.0,20.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",794,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,5299.840000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",795,0.0,2430976.0,0,0,0.0,2430976.0,2430976.0,0.0,37984.0,0.0,9723904.0,9723904.0,13.152,5312.992000000003,0.0,2430976.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,303872.0,303872.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",796,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,64.0,1.696,5314.688000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,2.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",797,0.0,0.0,0,0,0.0,0.0,0.0,11776.0,87744.0,0.11832797427652733,9732000.0,212800.0,12.992,5327.680000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304125.0,6650.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",798,0.0,0.0,0,0,0.0,0.0,0.0,54464.0,280448.0,0.16262182304605388,10372896.0,928.0,6.912,5334.592000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,324153.0,29.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",799,0.0,0.0,0,0,0.0,0.0,0.0,11776.0,87744.0,0.11832797427652733,9732000.0,213568.0,13.088,5347.680000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304125.0,6674.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",800,0.0,0.0,0,0,0.0,0.0,0.0,54464.0,284864.0,0.16050546963410034,10379776.0,1184.0,7.04,5354.720000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,324368.0,37.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",801,0.0,0.0,0,0,0.0,0.0,0.0,11776.0,87744.0,0.11832797427652733,9732000.0,214208.0,12.96,5367.680000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304125.0,6694.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",802,0.0,0.0,0,0,0.0,0.0,0.0,54464.0,282472.0,0.16164494147256453,10374368.0,736.0,7.008,5374.688000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,324199.0,23.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",803,0.0,0.0,0,0,0.0,0.0,0.0,11776.0,87744.0,0.11832797427652733,9732000.0,216576.0,12.96,5387.648000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304125.0,6768.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",804,0.0,0.0,0,0,0.0,0.0,0.0,54464.0,282886.0,0.16144656884541278,10373728.0,1088.0,6.944,5394.592000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,324179.0,34.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",805,0.0,0.0,0,0,0.0,0.0,0.0,0.0,69.0,0.0,23616.0,2944.0,3.424,5398.016000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,738.0,92.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",806,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.696,5399.712000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",807,0.0,0.0,0,0,0.0,0.0,0.0,497.0,54.0,0.9019963702359347,2944.0,0.0,3.68,5403.3920000000035,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",808,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.728,5405.1200000000035,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",809,0.0,0.0,0,0,0.0,0.0,0.0,497.0,54.0,0.9019963702359347,2944.0,0.0,3.616,5408.7360000000035,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",810,0.0,0.0,0,0,0.0,0.0,0.0,692784.0,100854.0,0.8729219115012135,9774976.0,24608.0,17.536,5426.272000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,305468.0,769.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",811,0.0,0.0,0,0,0.0,0.0,0.0,7328.0,128.0,0.9828326180257511,10240.0,2080.0,6.496,5432.768000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,320.0,65.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",812,0.0,0.0,0,0,0.0,0.0,0.0,0.0,227904.0,0.0,9775872.0,974752.0,13.184,5445.952000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,305496.0,30461.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",813,0.0,0.0,0,0,0.0,0.0,0.0,0.0,56976.0,0.0,12154880.0,483328.0,15.872,5461.824000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,379840.0,15104.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",814,0.0,0.0,0,0,0.0,0.0,0.0,0.0,75968.0,0.0,0.0,19447808.0,12.096,5473.920000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,607744.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",815,0.0,0.0,0,0,0.0,0.0,0.0,98304.0,75968.0,0.5640837311788469,9723904.0,0.0,14.048,5487.9680000000035,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,303872.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",816,0.0,0.0,0,0,0.0,0.0,0.0,156.0,64.0,0.7090909090909091,8192.0,0.0,2.208,5490.176000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",817,0.0,0.0,0,0,0.0,0.0,0.0,715104.0,381036.0,0.6523838195850895,35604864.0,24205632.0,45.248,5535.424000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1112652.0,756426.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",818,0.0,0.0,0,0,0.0,0.0,0.0,267804.0,434317.0,0.38142143590634664,36604544.0,29982720.0,40.576,5576.000000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1143892.0,936960.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",819,0.0,0.0,0,0,0.0,0.0,0.0,268512.0,432724.0,0.38291245743230523,36366464.0,29982720.0,39.776,5615.776000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1136452.0,936960.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",820,0.0,0.0,0,0,0.0,0.0,0.0,268512.0,433849.0,0.3822991310736217,36554496.0,29982720.0,40.224,5656.000000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1142328.0,936960.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",821,0.0,0.0,0,0,0.0,0.0,0.0,14336.0,75968.0,0.15875265768958186,19447808.0,0.0,22.976,5678.976000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,607744.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",822,0.0,0.0,0,0,0.0,0.0,0.0,39.0,16.0,0.7090909090909091,2048.0,0.0,2.176,5681.152000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",823,0.0,0.0,0,0,0.0,0.0,0.0,223430.0,338851.0,0.39736359578218006,32563200.0,18095296.0,32.704,5713.8560000000025,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1017600.0,565478.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",824,0.0,0.0,0,0,0.0,0.0,0.0,0.0,303872.0,0.0,29319808.0,29171712.0,33.184,5747.040000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,916244.0,911616.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",825,34033664.0,80306688.0,0,0,0.0,80306688.0,80306688.0,2112.0,76544.0,0.026851098454027666,29171712.0,9723904.0,64.288,5811.328000000002,9808384.0,2430976.0,34033664.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,911616.0,303872.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",826,0.0,12208464.0,0,0,0.0,12208464.0,12208464.0,1339488.0,151936.0,0.8981268908103933,9723904.0,9723904.0,212.0,6023.328000000002,12208464.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,303872.0,303872.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",827,0.0,0.0,0,0,0.0,0.0,0.0,0.0,37984.0,0.0,9723904.0,2430976.0,12.256,6035.584000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,303872.0,75968.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",828,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,512.0,1.92,6037.504000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,16.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",829,0.0,0.0,0,0,0.0,0.0,0.0,0.0,227904.0,0.0,21878784.0,1104256.0,26.72,6064.224000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,683712.0,34508.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",830,0.0,0.0,0,0,0.0,0.0,0.0,0.0,56976.0,0.0,12154880.0,353280.0,16.256,6080.480000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,379840.0,11040.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",831,34033664.0,80306688.0,0,0,0.0,80306688.0,80306688.0,2112.0,76544.0,0.026851098454027666,29171712.0,9723904.0,64.48,6144.960000000003,9808384.0,2430976.0,34033664.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,911616.0,303872.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",832,0.0,0.0,0,0,0.0,0.0,0.0,23525.0,19300.0,0.5493286631640397,9725120.0,9504.0,15.776,6160.736000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,303910.0,297.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",833,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,6162.880000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",834,0.0,0.0,0,0,0.0,0.0,0.0,23525.0,19300.0,0.5493286631640397,9725120.0,9504.0,15.744,6178.6240000000025,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,303910.0,297.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",835,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,6180.768000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",836,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.08,6182.848000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",837,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.008,6185.8560000000025,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",838,0.0,3871024.0,0,0,0.0,3871024.0,3871024.0,19888.0,19328.0,0.5071399428804569,9725568.0,10112.0,15.648,6201.504000000003,3871024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,303924.0,316.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",839,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,2.016,6203.520000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",840,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,6206.848000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",841,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,6208.8960000000025,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",842,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.944,6211.840000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",843,4128768.0,13119488.0,0,0,0.0,13119488.0,13119488.0,0.0,75968.0,0.0,0.0,9723904.0,7.936,6219.776000000003,0.0,4861952.0,4128768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,303872.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",844,12154880.0,24309760.0,0,0,0.0,24309760.0,24309760.0,0.0,56976.0,0.0,19447808.0,2797824.0,24.064,6243.840000000003,0.0,0.0,12154880.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,607744.0,87432.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",845,0.0,0.0,0,0,0.0,0.0,0.0,34608.0,19648.0,0.637864936596874,9729024.0,11168.0,17.568,6261.408000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304032.0,349.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",846,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,384.0,640.0,2.592,6264.000000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12.0,20.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",847,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.664,6265.6640000000025,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",848,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,6267.360000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",849,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.048,6269.408000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",850,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,6271.424000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",851,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,160.0,128.0,2.816,6274.240000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5.0,4.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",852,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,32.0,3.232,6277.472000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",853,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.112,6279.584000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
