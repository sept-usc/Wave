Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.888,1.888,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,3.5839999999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,5.311999999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.016,7.327999999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.336,9.664,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",6,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,11.36,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",7,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,13.088,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",8,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.696,14.783999999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",9,0.0,0.0,0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,2.432,17.215999999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",10,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,19.199999999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",11,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.176,21.375999999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.728,23.104,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,0.0,0.0,0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,2.432,25.535999999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,27.583999999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",15,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,29.631999999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",16,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,2.112,31.744,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(detail::TensorInfo<T1, T3>, detail::TensorInfo<const T1, T3>, detail::TensorInfo<const T2, T3>, int, int, T3, long)",17,0.0,0.0,0,0,0.0,0.0,0.0,0.0,72.0,0.0,3264.0,3072.0,3.968,35.712,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,102.0,96.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",18,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,38.304,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",19,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.496,40.800000000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",20,0.0,128.0,0,0,0.0,128.0,128.0,8.0,6.0,0.5714285714285714,320.0,256.0,2.496,43.29600000000001,0.0,128.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,10.0,8.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",21,0.0,0.0,0,0,0.0,0.0,0.0,0.0,10.0,0.0,512.0,512.0,2.528,45.824000000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",22,1024.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,8.0,0.0,512.0,512.0,2.656,48.480000000000004,0.0,256.0,1024.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",23,0.0,128.0,0,0,0.0,128.0,128.0,0.0,8.0,0.0,512.0,512.0,1.952,50.432,0.0,128.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",24,896.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,8.0,0.0,512.0,512.0,2.688,53.120000000000005,0.0,256.0,896.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",25,0.0,128.0,0,0,0.0,128.0,128.0,0.0,8.0,0.0,512.0,512.0,2.016,55.136,0.0,128.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",26,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.144,57.28,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",27,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.52,60.800000000000004,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",28,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.952,62.752,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",29,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,64.736,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",30,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.56,67.296,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",31,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.144,69.44000000000001,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",32,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,1920.0,5.728,75.168,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,60.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",33,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,1856.0,5.44,80.608,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,58.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",34,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,2176.0,5.568,86.176,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,68.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",35,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.624,88.8,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",36,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.624,91.42399999999999,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",37,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.104,94.52799999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",38,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.624,97.15199999999999,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",39,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,99.32799999999999,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",40,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.688,102.01599999999999,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",41,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.72,104.73599999999999,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",42,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.232,107.96799999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",43,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.72,110.68799999999999,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",44,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,112.86399999999999,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",45,12288.0,1103232.0,0,0,0.0,1103232.0,1103232.0,6240.0,12.0,0.9980806142034548,9216.0,3072.0,20.288,133.152,930048.0,148608.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",46,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,1792.0,5.44,138.59199999999998,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,56.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",47,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.144,140.736,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",48,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.176,142.91199999999998,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",49,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.52,146.432,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",50,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.984,148.416,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",51,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,150.4,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",52,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.592,152.99200000000002,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",53,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.112,155.104,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",54,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4608.0,12.672,167.776,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",55,35328.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,48.0,0.0,12288.0,12288.0,2.24,170.01600000000002,3072.0,0.0,35328.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",56,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4704.0,13.088,183.104,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,147.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",57,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.112,185.216,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",58,2360064.0,4744704.0,0,0,0.0,4744704.0,4744704.0,13056.0,148224.0,0.08095238095238096,10029696.0,2464.0,12.832,198.048,24576.0,0.0,2360064.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313428.0,77.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",59,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.208,200.256,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",60,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.176,202.432,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",61,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.52,205.952,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",62,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.856,207.808,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",63,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,209.792,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",64,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.592,212.38400000000001,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",65,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.336,214.72000000000003,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",66,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,2080.0,6.08,220.80000000000004,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,65.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",67,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,1888.0,5.568,226.36800000000005,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,59.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",68,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,2048.0,5.632,232.00000000000006,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,64.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",69,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.624,234.62400000000005,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",70,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.56,237.18400000000005,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",71,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.072,240.25600000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",72,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.72,242.97600000000006,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",73,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,245.15200000000004,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",74,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.624,247.77600000000004,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",75,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.656,250.43200000000004,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",76,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.104,253.53600000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",77,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.624,256.1600000000001,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",78,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.144,258.3040000000001,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",79,12288.0,1103232.0,0,0,0.0,1103232.0,1103232.0,6240.0,12.0,0.9980806142034548,9216.0,3072.0,20.32,278.6240000000001,930048.0,148608.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",80,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,2080.0,5.376,284.00000000000006,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,65.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",81,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.24,286.24000000000007,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",82,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.176,288.41600000000005,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",83,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.488,291.90400000000005,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",84,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.952,293.85600000000005,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",85,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,295.87200000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",86,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.496,298.36800000000005,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",87,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.144,300.51200000000006,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",88,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4736.0,12.704,313.21600000000007,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,148.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",89,35328.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,48.0,0.0,12288.0,12288.0,2.272,315.48800000000006,3072.0,0.0,35328.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",90,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4832.0,13.056,328.54400000000004,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,151.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",91,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.048,330.59200000000004,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",92,2360064.0,4744704.0,0,0,0.0,4744704.0,4744704.0,13056.0,148224.0,0.08095238095238096,10029824.0,2400.0,13.024,343.61600000000004,24576.0,0.0,2360064.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313432.0,75.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",93,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.144,345.76000000000005,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",94,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.08,347.84000000000003,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",95,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.552,351.39200000000005,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",96,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.952,353.34400000000005,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",97,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.112,355.4560000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",98,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.56,358.0160000000001,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",99,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.176,360.19200000000006,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",100,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,2080.0,5.792,365.98400000000004,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,65.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",101,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,2016.0,5.632,371.61600000000004,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,63.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",102,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,2112.0,5.472,377.088,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,66.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",103,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.688,379.776,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",104,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.656,382.432,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",105,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.168,385.6,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",106,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.624,388.22400000000005,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",107,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.208,390.4320000000001,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",108,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.624,393.0560000000001,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",109,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.624,395.6800000000001,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",110,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.04,398.72000000000014,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",111,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.624,401.34400000000016,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",112,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.208,403.5520000000002,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",113,12288.0,1103232.0,0,0,0.0,1103232.0,1103232.0,6240.0,12.0,0.9980806142034548,9216.0,3072.0,20.352,423.90400000000017,930048.0,148608.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",114,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,2080.0,5.44,429.34400000000016,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,65.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",115,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,431.52000000000015,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",116,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.144,433.66400000000016,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",117,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.488,437.15200000000016,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",118,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.952,439.10400000000016,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",119,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,441.08800000000014,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",120,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.688,443.7760000000001,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",121,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.208,445.98400000000015,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",122,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4640.0,12.8,458.78400000000016,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,145.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",123,35328.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,48.0,0.0,12288.0,12288.0,2.304,461.08800000000014,3072.0,0.0,35328.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",124,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4672.0,13.088,474.17600000000016,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,146.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",125,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.048,476.22400000000016,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",126,2360064.0,4744704.0,0,0,0.0,4744704.0,4744704.0,13056.0,148224.0,0.08095238095238096,10027008.0,2336.0,12.864,489.08800000000014,24576.0,0.0,2360064.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313344.0,73.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",127,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,491.2640000000001,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",128,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.144,493.40800000000013,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",129,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.52,496.9280000000001,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",130,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.952,498.8800000000001,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",131,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,500.89600000000013,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",132,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.592,503.4880000000001,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",133,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.176,505.6640000000001,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",134,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,2016.0,5.76,511.4240000000001,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,63.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",135,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,1984.0,5.344,516.7680000000001,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,62.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",136,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,1952.0,5.44,522.2080000000002,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,61.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",137,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.656,524.8640000000001,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",138,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.624,527.4880000000002,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",139,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.104,530.5920000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",140,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.752,533.3440000000002,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",141,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.144,535.4880000000002,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",142,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.56,538.0480000000001,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",143,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.624,540.6720000000001,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",144,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.136,543.8080000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",145,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.72,546.5280000000001,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",146,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.144,548.6720000000001,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",147,12288.0,1103232.0,0,0,0.0,1103232.0,1103232.0,6240.0,12.0,0.9980806142034548,9216.0,3072.0,20.32,568.9920000000002,930048.0,148608.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",148,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,2016.0,5.312,574.3040000000002,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,63.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",149,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,576.4800000000002,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",150,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.08,578.5600000000003,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",151,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.52,582.0800000000003,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",152,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.952,584.0320000000003,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",153,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,586.0800000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",154,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.592,588.6720000000003,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",155,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.176,590.8480000000003,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",156,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4512.0,12.704,603.5520000000002,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,141.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",157,35328.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,48.0,0.0,12288.0,12288.0,2.24,605.7920000000003,3072.0,0.0,35328.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",158,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4576.0,12.704,618.4960000000002,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,143.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",159,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.08,620.5760000000002,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",160,2360064.0,4744704.0,0,0,0.0,4744704.0,4744704.0,13056.0,148224.0,0.08095238095238096,10027008.0,2400.0,12.864,633.4400000000003,24576.0,0.0,2360064.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313344.0,75.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",161,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.336,635.7760000000003,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",162,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.144,637.9200000000003,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",163,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.52,641.4400000000003,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",164,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.952,643.3920000000003,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",165,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,645.4080000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",166,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.528,647.9360000000003,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",167,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.176,650.1120000000003,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",168,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,1920.0,5.536,655.6480000000003,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,60.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",169,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,2080.0,5.728,661.3760000000002,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,65.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",170,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,2336.0,5.44,666.8160000000003,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,73.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",171,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.624,669.4400000000003,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",172,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.656,672.0960000000002,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",173,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.392,675.4880000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",174,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.56,678.0480000000002,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",175,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,680.2240000000003,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",176,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.656,682.8800000000002,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",177,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.752,685.6320000000002,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",178,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.2,688.8320000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",179,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.656,691.4880000000002,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",180,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,693.6640000000002,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",181,12288.0,1103232.0,0,0,0.0,1103232.0,1103232.0,6240.0,12.0,0.9980806142034548,9216.0,3072.0,20.32,713.9840000000003,930048.0,148608.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",182,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,1984.0,5.472,719.4560000000002,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,62.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",183,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.336,721.7920000000003,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",184,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.144,723.9360000000003,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",185,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.744,727.6800000000003,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",186,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.952,729.6320000000003,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",187,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,731.6160000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",188,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.624,734.2400000000004,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",189,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.144,736.3840000000004,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",190,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4480.0,12.864,749.2480000000004,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,140.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",191,35328.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,48.0,0.0,12288.0,12288.0,2.24,751.4880000000004,3072.0,0.0,35328.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",192,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4544.0,12.736,764.2240000000004,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,142.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",193,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.144,766.3680000000004,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",194,2360064.0,4744704.0,0,0,0.0,4744704.0,4744704.0,13056.0,148224.0,0.08095238095238096,10027008.0,2336.0,12.832,779.2000000000004,24576.0,0.0,2360064.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313344.0,73.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",195,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.208,781.4080000000004,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",196,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.144,783.5520000000004,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",197,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.52,787.0720000000003,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",198,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.888,788.9600000000004,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",199,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,790.9760000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",200,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.592,793.5680000000003,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",201,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.208,795.7760000000003,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",202,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,2144.0,5.888,801.6640000000003,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,67.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",203,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,1952.0,5.408,807.0720000000003,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,61.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",204,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,1952.0,5.6,812.6720000000004,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,61.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",205,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.624,815.2960000000004,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",206,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.56,817.8560000000003,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",207,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.104,820.9600000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",208,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.592,823.5520000000004,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",209,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.208,825.7600000000003,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",210,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.592,828.3520000000003,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",211,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.688,831.0400000000003,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",212,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.136,834.1760000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",213,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.72,836.8960000000003,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",214,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.112,839.0080000000003,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",215,12288.0,1103232.0,0,0,0.0,1103232.0,1103232.0,6240.0,12.0,0.9980806142034548,9216.0,3072.0,20.352,859.3600000000002,930048.0,148608.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",216,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,2144.0,5.728,865.0880000000002,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,67.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",217,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.208,867.2960000000002,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",218,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.144,869.4400000000002,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",219,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.52,872.9600000000002,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",220,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.952,874.9120000000001,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",221,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,876.9280000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",222,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.56,879.488,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",223,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.176,881.6640000000001,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",224,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4320.0,12.672,894.3360000000001,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,135.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",225,35328.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,48.0,0.0,12288.0,12288.0,2.336,896.6720000000001,3072.0,0.0,35328.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",226,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4384.0,12.64,909.3120000000001,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,137.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",227,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.08,911.3920000000002,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",228,2360064.0,4744704.0,0,0,0.0,4744704.0,4744704.0,13056.0,148224.0,0.08095238095238096,10032768.0,2400.0,12.768,924.1600000000002,24576.0,0.0,2360064.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313524.0,75.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",229,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,926.3360000000002,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",230,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.08,928.4160000000003,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",231,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.52,931.9360000000003,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",232,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.92,933.8560000000002,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",233,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,935.9360000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",234,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.56,938.4960000000002,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",235,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.208,940.7040000000002,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",236,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,2080.0,5.728,946.4320000000001,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,65.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",237,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,2176.0,5.408,951.8400000000001,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,68.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",238,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,2016.0,5.472,957.3120000000001,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,63.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",239,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.624,959.9360000000001,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",240,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.624,962.5600000000002,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",241,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.136,965.6960000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",242,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.688,968.3840000000001,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",243,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.144,970.5280000000001,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",244,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.72,973.2480000000002,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",245,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.656,975.9040000000001,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",246,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.104,979.0080000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",247,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.624,981.6320000000002,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",248,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,983.8080000000002,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",249,12288.0,1103232.0,0,0,0.0,1103232.0,1103232.0,6240.0,12.0,0.9980806142034548,9216.0,3072.0,20.352,1004.1600000000002,930048.0,148608.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",250,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,1984.0,5.6,1009.7600000000002,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,62.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",251,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.144,1011.9040000000002,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",252,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.176,1014.0800000000003,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",253,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.52,1017.6000000000003,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",254,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.984,1019.5840000000003,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",255,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,1021.5680000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",256,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.592,1024.1600000000003,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",257,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.176,1026.3360000000002,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",258,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4928.0,13.088,1039.4240000000002,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,154.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",259,35328.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,48.0,0.0,12288.0,12288.0,2.24,1041.6640000000002,3072.0,0.0,35328.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",260,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4672.0,13.152,1054.8160000000003,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,146.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",261,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.048,1056.8640000000003,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",262,2360064.0,4744704.0,0,0,0.0,4744704.0,4744704.0,13056.0,148224.0,0.08095238095238096,10027392.0,2336.0,12.768,1069.6320000000003,24576.0,0.0,2360064.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313356.0,73.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",263,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,1071.8080000000002,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",264,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.144,1073.9520000000002,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",265,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.584,1077.5360000000003,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",266,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.952,1079.4880000000003,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",267,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,1081.4720000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",268,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.624,1084.0960000000002,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",269,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.144,1086.2400000000002,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",270,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,2016.0,5.44,1091.6800000000003,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,63.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",271,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,2016.0,5.472,1097.1520000000003,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,63.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",272,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,1824.0,5.472,1102.6240000000003,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,57.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",273,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.688,1105.3120000000004,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",274,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.624,1107.9360000000004,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",275,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.136,1111.0720000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",276,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.624,1113.6960000000004,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",277,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,1115.8720000000003,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",278,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.56,1118.4320000000002,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",279,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.624,1121.0560000000003,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",280,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.104,1124.1600000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",281,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.656,1126.8160000000003,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",282,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,1128.9920000000002,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",283,12288.0,1103232.0,0,0,0.0,1103232.0,1103232.0,6240.0,12.0,0.9980806142034548,9216.0,3072.0,20.384,1149.3760000000002,930048.0,148608.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",284,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,2080.0,5.6,1154.976,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,65.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",285,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,1157.152,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",286,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.112,1159.2640000000001,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",287,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.552,1162.816,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",288,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.92,1164.736,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",289,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,1166.7520000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",290,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.656,1169.4080000000001,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",291,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.144,1171.5520000000001,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",292,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4832.0,12.576,1184.1280000000002,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,151.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",293,35328.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,48.0,0.0,12288.0,12288.0,2.24,1186.3680000000002,3072.0,0.0,35328.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",294,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4736.0,12.96,1199.3280000000002,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,148.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",295,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.08,1201.4080000000001,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",296,2360064.0,4744704.0,0,0,0.0,4744704.0,4744704.0,13056.0,148224.0,0.08095238095238096,10030976.0,2304.0,13.024,1214.432,24576.0,0.0,2360064.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313468.0,72.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",297,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.24,1216.672,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",298,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.112,1218.784,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",299,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.552,1222.336,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",300,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.92,1224.256,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",301,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.952,1226.208,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",302,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.528,1228.736,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",303,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.144,1230.88,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",304,24608000.0,49472000.0,0,0,0.0,49472000.0,49472000.0,88000.0,1544000.0,0.05392156862745098,99084096.0,162816.0,107.744,1338.624,256000.0,0.0,24608000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3096378.0,5088.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",305,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.76,1340.384,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",306,0.0,0.0,0,0,0.0,0.0,0.0,0.0,4.0,0.0,64.0,64.0,2.688,1343.0720000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",307,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,1345.152,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",308,0.0,32000.0,0,0,0.0,32000.0,32000.0,0.0,512.0,0.0,128000.0,128000.0,2.144,1347.296,0.0,32000.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4000.0,4000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",309,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.664,1348.96,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",310,0.0,0.0,0,0,0.0,0.0,0.0,512.0,1512.0,0.25296442687747034,129024.0,8768.0,3.456,1352.416,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4032.0,274.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",311,0.0,0.0,0,0,0.0,0.0,0.0,2368.0,8610.0,0.2157041355438149,527360.0,0.0,3.968,1356.384,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16480.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",312,0.0,0.0,0,0,0.0,0.0,0.0,512.0,1512.0,0.25296442687747034,129024.0,8832.0,3.456,1359.84,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4032.0,276.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",313,0.0,0.0,0,0,0.0,0.0,0.0,2368.0,8802.0,0.21199641897940913,527360.0,0.0,3.904,1363.744,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16480.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",314,0.0,0.0,0,0,0.0,0.0,0.0,512.0,1512.0,0.25296442687747034,129024.0,8832.0,3.296,1367.04,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4032.0,276.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",315,0.0,0.0,0,0,0.0,0.0,0.0,2368.0,8610.0,0.2157041355438149,527360.0,0.0,3.872,1370.912,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16480.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",316,0.0,0.0,0,0,0.0,0.0,0.0,512.0,1512.0,0.25296442687747034,129024.0,8320.0,3.296,1374.208,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4032.0,260.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",317,0.0,0.0,0,0,0.0,0.0,0.0,2368.0,8578.0,0.216334734149461,527360.0,32.0,4.064,1378.2720000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16480.0,1.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",318,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,1056.0,128.0,2.368,1380.64,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,33.0,4.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",319,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.696,1382.336,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",320,0.0,0.0,0,0,0.0,0.0,0.0,497.0,10.0,0.980276134122288,128.0,0.0,3.456,1385.792,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",321,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.728,1387.52,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",322,0.0,0.0,0,0,0.0,0.0,0.0,497.0,10.0,0.980276134122288,128.0,0.0,3.456,1390.9759999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 1>(detail::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, detail::TensorInfo<T1, T2>, T2, detail::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",323,0.0,0.0,0,0,0.0,0.0,0.0,10368.0,2106.0,0.8311688311688312,131808.0,1888.0,5.6,1396.5759999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4119.0,59.0
"void native::radixSortKVInPlace<(int)-2, (int)-1, 32, 4, float, long, unsigned int>(detail::TensorInfo<T5, T7>, T7, T7, T7, detail::TensorInfo<T6, T7>, T7, bool)",324,0.0,0.0,0,0,0.0,0.0,0.0,458.0,8.0,0.9828326180257511,640.0,0.0,5.984,1402.5599999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,20.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",325,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3000.0,0.0,130016.0,11456.0,3.392,1405.9519999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4063.0,358.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",326,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,160000.0,0.0,2.432,1408.3839999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5000.0,0.0
"native::<unnamed>::fill_reverse_indices_kernel(long *, int, detail::IntDivider<unsigned int>)",327,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1000.0,0.0,0.0,256000.0,2.048,1410.4319999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,8000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",328,0.0,0.0,0,0,0.0,0.0,0.0,98304.0,1000.0,0.9899299121888343,128000.0,0.0,3.968,1414.3999999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",329,0.0,0.0,0,0,0.0,0.0,0.0,156.0,64.0,0.7090909090909091,8192.0,0.0,2.144,1416.5439999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",330,0.0,0.0,0,0,0.0,0.0,0.0,13439.0,4558.0,0.7467355670389509,438144.0,327456.0,7.968,1424.512,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,13692.0,10233.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",331,0.0,0.0,0,0,0.0,0.0,0.0,4607.0,4568.0,0.502125340599455,437632.0,395264.0,6.976,1431.488,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,13676.0,12352.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",332,0.0,0.0,0,0,0.0,0.0,0.0,5339.0,4527.0,0.5411514291506183,434176.0,395264.0,6.912,1438.4,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,13568.0,12352.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",333,0.0,0.0,0,0,0.0,0.0,0.0,5339.0,4528.0,0.5410965845748454,434688.0,344448.0,7.008,1445.4080000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,13584.0,10764.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",334,448000.0,1061280.0,0,0,0.0,1061280.0,1061280.0,132.0,1312.0,0.09141274238227147,257792.0,128000.0,17.12,1462.528,133280.0,32000.0,448000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8056.0,4000.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<float, 1>>(T1, int)",335,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,416.0,1.696,1464.224,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,13.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<float, std::plus<float>>::Policy900, const float *, float *, at_cuda_detail::ScanTileState<float, 1>, std::plus<float>, at_cuda_detail::NullType, unsigned int, float, 0>(T2, T3, T4, int, T5, T6, T7)",336,0.0,84379.0,0,0,0.0,84379.0,84379.0,4417.0,2087.0,0.6791205412054121,136128.0,129024.0,3.552,1467.7759999999998,84379.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4254.0,4032.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",337,0.0,0.0,0,0,0.0,0.0,0.0,0.0,512.0,0.0,128000.0,31808.0,2.272,1470.0479999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4000.0,994.0
"void native::unrolled_elementwise_kernel<native::FillFunctor<bool>, std::array<char *, 1>, 16, TrivialOffsetCalculator<0, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithoutCast, memory::StoreWithoutCast>(int, T1, T2, T4, T5, T6, T7)",338,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,1471.7439999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",339,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3000.0,0.0,288000.0,12352.0,7.104,1478.8479999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,9000.0,386.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",340,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,160000.0,0.0,2.368,1481.2159999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",341,448000.0,1061280.0,0,0,0.0,1061280.0,1061280.0,132.0,1312.0,0.09141274238227147,270720.0,128000.0,17.248,1498.4639999999997,133280.0,32000.0,448000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8460.0,4000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",342,0.0,0.0,0,0,0.0,0.0,0.0,62.0,251.0,0.19808306709265175,128000.0,32.0,8.064,1506.5279999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",343,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.176,1508.7039999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",344,0.0,0.0,0,0,0.0,0.0,0.0,62.0,251.0,0.19808306709265175,128000.0,32.0,8.128,1516.8319999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",345,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.176,1519.0079999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",346,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.112,1521.1199999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",347,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.976,1524.0959999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",348,0.0,36576.0,0,0,0.0,36576.0,36576.0,62.0,251.0,0.19808306709265175,128000.0,32.0,7.872,1531.9679999999998,36576.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4000.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",349,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,1533.984,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",350,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.112,1536.096,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",351,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.976,1539.0720000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",352,288000.0,640000.0,0,0,0.0,640000.0,640000.0,0.0,1000.0,0.0,0.0,128000.0,2.24,1541.3120000000001,0.0,64000.0,288000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,4000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",353,160000.0,320000.0,0,0,0.0,320000.0,320000.0,0.0,768.0,0.0,256000.0,0.0,3.456,1544.768,0.0,0.0,160000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",354,0.0,0.0,0,0,0.0,0.0,0.0,124.0,251.0,0.33066666666666666,128000.0,32.0,12.0,1556.768,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4000.0,1.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",355,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,1.984,1558.752,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",356,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,1560.8,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",357,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.016,1562.816,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",358,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.112,1564.928,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",359,0.0,0.0,0,0,0.0,0.0,0.0,0.0,4.0,0.0,64.0,64.0,2.656,1567.584,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",360,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,1569.3120000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",361,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,1571.0400000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",362,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.048,1573.0880000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",363,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.664,1574.7520000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithoutCast, memory::StoreWithoutCast>(int, T1, T2, T4, T5, T6, T7)",364,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.016,1576.7680000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",365,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.144,1578.9120000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",366,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,1580.9280000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",367,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.624,1583.5520000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",368,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.2,1586.7520000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",369,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,1588.7680000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",370,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.176,1590.9440000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",371,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.296,1594.2400000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",372,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.728,1595.9680000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",373,0.0,0.0,0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,2.432,1598.4000000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",374,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,1600.4480000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",375,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,1602.5280000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",376,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,2.048,1604.5760000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(detail::TensorInfo<T1, T3>, detail::TensorInfo<const T1, T3>, detail::TensorInfo<const T2, T3>, int, int, T3, long)",377,0.0,0.0,0,0,0.0,0.0,0.0,0.0,72.0,0.0,3264.0,3072.0,3.232,1607.8080000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,102.0,96.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",378,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,1610.4000000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",379,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.168,1613.5680000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",380,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.432,1616.0000000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",381,0.0,128.0,0,0,0.0,128.0,128.0,8.0,6.0,0.5714285714285714,320.0,256.0,2.08,1618.0800000000004,0.0,128.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,10.0,8.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",382,0.0,0.0,0,0,0.0,0.0,0.0,0.0,10.0,0.0,512.0,512.0,2.528,1620.6080000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",383,1024.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,8.0,0.0,512.0,512.0,2.688,1623.2960000000005,0.0,256.0,1024.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",384,0.0,128.0,0,0,0.0,128.0,128.0,0.0,8.0,0.0,512.0,512.0,1.952,1625.2480000000005,0.0,128.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",385,900.0,2056.0,0,0,0.0,2056.0,2056.0,0.0,8.0,0.0,512.0,512.0,2.592,1627.8400000000006,0.0,256.0,900.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",386,0.0,128.0,0,0,0.0,128.0,128.0,0.0,8.0,0.0,512.0,512.0,1.984,1629.8240000000005,0.0,128.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",387,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.176,1632.0000000000005,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",388,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.52,1635.5200000000004,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",389,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.016,1637.5360000000005,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",390,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,1639.5200000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",391,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.624,1642.1440000000005,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",392,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.24,1644.3840000000005,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",393,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,1920.0,5.28,1649.6640000000004,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,60.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",394,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,2048.0,5.472,1655.1360000000004,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,64.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",395,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,1952.0,5.504,1660.6400000000003,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,61.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",396,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.624,1663.2640000000004,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",397,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.656,1665.9200000000003,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",398,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.136,1669.0560000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",399,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.624,1671.6800000000003,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",400,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.112,1673.7920000000004,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",401,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.688,1676.4800000000005,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",402,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.688,1679.1680000000006,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",403,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.168,1682.3360000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",404,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.656,1684.9920000000004,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",405,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.304,1687.2960000000005,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",406,0.0,0.0,0,0,0.0,0.0,0.0,0.0,60.0,0.0,6144.0,6144.0,2.528,1689.8240000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",407,0.0,0.0,0,0,0.0,0.0,0.0,0.0,60.0,0.0,6144.0,6144.0,2.56,1692.3840000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",408,11776.0,1102278.0,0,0,0.0,1102278.0,1102278.0,6258.0,12.0,0.9980861244019139,15360.0,3072.0,20.288,1712.6720000000005,930160.0,148566.0,11776.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",409,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,2048.0,5.568,1718.2400000000005,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,64.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",410,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.208,1720.4480000000005,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",411,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.112,1722.5600000000006,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",412,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.488,1726.0480000000007,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",413,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.984,1728.0320000000006,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",414,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,1730.0480000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",415,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.56,1732.6080000000006,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",416,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.144,1734.7520000000006,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",417,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4544.0,12.928,1747.6800000000007,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,142.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",418,35328.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,48.0,0.0,12288.0,12288.0,2.304,1749.9840000000008,3072.0,0.0,35328.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",419,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4512.0,12.736,1762.720000000001,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,141.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",420,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.08,1764.8000000000009,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",421,2360064.0,4744704.0,0,0,0.0,4744704.0,4744704.0,13056.0,148224.0,0.08095238095238096,10027136.0,2400.0,13.152,1777.952000000001,24576.0,0.0,2360064.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313348.0,75.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",422,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.144,1780.096000000001,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",423,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.112,1782.208000000001,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",424,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.52,1785.728000000001,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",425,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.984,1787.712000000001,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",426,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,1789.760000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",427,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.592,1792.352000000001,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",428,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.112,1794.464000000001,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",429,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,2208.0,5.376,1799.840000000001,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,69.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",430,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,1920.0,5.472,1805.312000000001,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,60.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",431,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,2016.0,5.44,1810.752000000001,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,63.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",432,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.656,1813.408000000001,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",433,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.656,1816.064000000001,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",434,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.168,1819.2320000000009,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",435,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.656,1821.8880000000008,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",436,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.112,1824.000000000001,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",437,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.656,1826.6560000000009,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",438,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.688,1829.344000000001,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",439,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.104,1832.448000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",440,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.656,1835.104000000001,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",441,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,1837.2800000000009,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",442,0.0,0.0,0,0,0.0,0.0,0.0,0.0,60.0,0.0,6144.0,6144.0,2.56,1839.8400000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",443,0.0,0.0,0,0,0.0,0.0,0.0,0.0,60.0,0.0,6144.0,6144.0,2.592,1842.432000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",444,11968.0,1102776.0,0,0,0.0,1102776.0,1102776.0,6249.0,12.0,0.9980833732630571,15360.0,3072.0,20.416,1862.8480000000009,930262.0,148578.0,11968.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",445,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,1952.0,5.632,1868.480000000001,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,61.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",446,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,1870.6560000000009,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",447,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.08,1872.7360000000008,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",448,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.488,1876.2240000000008,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",449,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.016,1878.240000000001,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",450,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.112,1880.352000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",451,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.656,1883.008000000001,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",452,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.176,1885.1840000000009,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",453,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4640.0,12.768,1897.952000000001,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,145.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",454,35328.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,48.0,0.0,12288.0,12288.0,2.208,1900.160000000001,3072.0,0.0,35328.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",455,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4384.0,12.672,1912.832000000001,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,137.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",456,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.048,1914.880000000001,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",457,2360064.0,4744704.0,0,0,0.0,4744704.0,4744704.0,13056.0,148224.0,0.08095238095238096,10027904.0,2560.0,13.184,1928.064000000001,24576.0,0.0,2360064.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313372.0,80.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",458,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.208,1930.272000000001,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",459,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.112,1932.3840000000012,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",460,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.488,1935.8720000000012,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",461,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.016,1937.8880000000013,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",462,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,1939.9040000000014,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",463,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.528,1942.4320000000014,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",464,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.144,1944.5760000000014,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",465,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,1888.0,5.536,1950.1120000000014,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,59.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",466,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,1920.0,5.472,1955.5840000000014,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,60.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",467,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,2208.0,5.408,1960.9920000000013,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,69.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",468,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.656,1963.6480000000013,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",469,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.688,1966.3360000000014,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",470,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.104,1969.4400000000014,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",471,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.656,1972.0960000000014,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",472,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.144,1974.2400000000014,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",473,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.816,1977.0560000000014,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",474,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.656,1979.7120000000014,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",475,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.168,1982.8800000000012,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",476,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.816,1985.6960000000013,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",477,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.304,1988.0000000000014,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",478,0.0,0.0,0,0,0.0,0.0,0.0,0.0,60.0,0.0,6144.0,6144.0,2.56,1990.5600000000013,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",479,0.0,0.0,0,0,0.0,0.0,0.0,0.0,60.0,0.0,6144.0,6144.0,2.528,1993.0880000000013,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",480,12288.0,1103616.0,0,0,0.0,1103616.0,1103616.0,6240.0,12.0,0.9980806142034548,15360.0,3072.0,20.352,2013.4400000000014,930432.0,148608.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",481,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,2080.0,5.6,2019.0400000000013,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,65.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",482,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,2021.2160000000013,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",483,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.144,2023.3600000000013,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",484,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.488,2026.8480000000013,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",485,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.016,2028.8640000000014,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",486,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2030.8800000000015,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",487,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.56,2033.4400000000014,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",488,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.144,2035.5840000000014,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",489,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4480.0,12.608,2048.1920000000014,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,140.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",490,35328.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,48.0,0.0,12288.0,12288.0,2.304,2050.4960000000015,3072.0,0.0,35328.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",491,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4352.0,12.736,2063.2320000000013,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,136.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",492,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.144,2065.376000000001,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",493,2360064.0,4744704.0,0,0,0.0,4744704.0,4744704.0,13056.0,148224.0,0.08095238095238096,10028928.0,2560.0,12.992,2078.3680000000013,24576.0,0.0,2360064.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313404.0,80.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",494,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.208,2080.5760000000014,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",495,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.048,2082.624000000001,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",496,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.52,2086.144000000001,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",497,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.016,2088.160000000001,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",498,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,2090.208000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",499,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.592,2092.800000000001,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",500,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.144,2094.944000000001,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",501,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,2080.0,5.28,2100.224000000001,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,65.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",502,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,1984.0,5.344,2105.568000000001,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,62.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",503,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,2016.0,5.504,2111.072000000001,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,63.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",504,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.656,2113.728000000001,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",505,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.656,2116.384000000001,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",506,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.136,2119.520000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",507,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.624,2122.1440000000007,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",508,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.144,2124.2880000000005,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",509,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.656,2126.9440000000004,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",510,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.624,2129.568,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",511,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.104,2132.672,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",512,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.688,2135.36,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",513,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,2137.536,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",514,0.0,0.0,0,0,0.0,0.0,0.0,0.0,60.0,0.0,6144.0,6144.0,2.624,2140.16,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",515,0.0,0.0,0,0,0.0,0.0,0.0,0.0,60.0,0.0,6144.0,6144.0,2.56,2142.72,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",516,12288.0,1103616.0,0,0,0.0,1103616.0,1103616.0,6240.0,12.0,0.9980806142034548,15360.0,3072.0,20.32,2163.04,930432.0,148608.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",517,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,2016.0,5.408,2168.448,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,63.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",518,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.144,2170.5919999999996,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",519,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.08,2172.6719999999996,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",520,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.488,2176.1599999999994,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",521,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.984,2178.1439999999993,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",522,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,2180.2239999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",523,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.592,2182.8159999999993,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",524,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.144,2184.959999999999,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",525,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4704.0,12.672,2197.631999999999,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,147.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",526,35328.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,48.0,0.0,12288.0,12288.0,2.24,2199.871999999999,3072.0,0.0,35328.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",527,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4608.0,12.736,2212.607999999999,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",528,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.144,2214.7519999999986,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",529,2360064.0,4744704.0,0,0,0.0,4744704.0,4744704.0,13056.0,148224.0,0.08095238095238096,10027008.0,2592.0,12.832,2227.5839999999985,24576.0,0.0,2360064.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313344.0,81.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",530,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.208,2229.7919999999986,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",531,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.144,2231.9359999999983,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",532,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.488,2235.423999999998,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",533,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.984,2237.407999999998,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",534,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2239.423999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",535,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.528,2241.951999999998,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",536,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.144,2244.0959999999977,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",537,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,2016.0,5.44,2249.535999999998,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,63.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",538,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,1856.0,5.664,2255.199999999998,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,58.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",539,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,1984.0,5.504,2260.703999999998,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,62.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",540,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.688,2263.391999999998,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",541,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.688,2266.079999999998,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",542,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.136,2269.215999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",543,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.656,2271.871999999998,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",544,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,2274.047999999998,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",545,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.656,2276.703999999998,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",546,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.688,2279.391999999998,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",547,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.232,2282.623999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",548,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.624,2285.247999999998,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",549,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,2287.4239999999977,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",550,0.0,0.0,0,0,0.0,0.0,0.0,0.0,60.0,0.0,6144.0,6144.0,2.56,2289.9839999999976,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",551,0.0,0.0,0,0,0.0,0.0,0.0,0.0,60.0,0.0,6144.0,6144.0,2.528,2292.5119999999974,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",552,12288.0,1103616.0,0,0,0.0,1103616.0,1103616.0,6240.0,12.0,0.9980806142034548,15360.0,3072.0,20.352,2312.8639999999973,930432.0,148608.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",553,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,2112.0,5.568,2318.4319999999975,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,66.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",554,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.208,2320.6399999999976,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",555,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.112,2322.7519999999977,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",556,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.488,2326.2399999999975,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",557,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.016,2328.2559999999976,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",558,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2330.2719999999977,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",559,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.56,2332.8319999999976,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",560,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.144,2334.9759999999974,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",561,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4448.0,12.704,2347.6799999999976,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,139.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",562,35328.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,48.0,0.0,12288.0,12288.0,2.336,2350.0159999999973,3072.0,0.0,35328.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",563,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4512.0,12.8,2362.8159999999975,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,141.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",564,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.08,2364.8959999999975,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",565,2360064.0,4744704.0,0,0,0.0,4744704.0,4744704.0,13056.0,148224.0,0.08095238095238096,10027264.0,2368.0,12.864,2377.7599999999975,24576.0,0.0,2360064.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313352.0,74.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",566,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.144,2379.9039999999973,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",567,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.08,2381.983999999997,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",568,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.488,2385.471999999997,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",569,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.984,2387.455999999997,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",570,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,2389.5039999999967,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",571,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.56,2392.0639999999967,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",572,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.208,2394.2719999999968,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",573,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,2208.0,5.44,2399.711999999997,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,69.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",574,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,2048.0,5.344,2405.055999999997,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,64.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",575,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,2112.0,5.568,2410.623999999997,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,66.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",576,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.656,2413.279999999997,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",577,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.688,2415.967999999997,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",578,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.136,2419.103999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",579,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.656,2421.759999999997,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",580,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.144,2423.903999999997,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",581,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.656,2426.5599999999968,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",582,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.656,2429.2159999999967,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",583,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.04,2432.2559999999967,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",584,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.752,2435.0079999999966,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",585,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,2437.1839999999966,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",586,0.0,0.0,0,0,0.0,0.0,0.0,0.0,60.0,0.0,6144.0,6144.0,2.592,2439.7759999999967,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",587,0.0,0.0,0,0,0.0,0.0,0.0,0.0,60.0,0.0,6144.0,6144.0,2.624,2442.3999999999965,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",588,12288.0,1103616.0,0,0,0.0,1103616.0,1103616.0,6240.0,12.0,0.9980806142034548,15360.0,3072.0,20.32,2462.7199999999966,930432.0,148608.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",589,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,2080.0,5.568,2468.287999999997,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,65.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",590,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.144,2470.4319999999966,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",591,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.08,2472.5119999999965,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",592,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.488,2475.9999999999964,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",593,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.952,2477.9519999999966,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",594,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,2480.0319999999965,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",595,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.592,2482.6239999999966,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",596,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.144,2484.7679999999964,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",597,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4672.0,12.768,2497.5359999999964,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,146.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",598,35328.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,48.0,0.0,12288.0,12288.0,2.24,2499.775999999996,3072.0,0.0,35328.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",599,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4512.0,12.736,2512.511999999996,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,141.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",600,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.112,2514.623999999996,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",601,2360064.0,4744704.0,0,0,0.0,4744704.0,4744704.0,13056.0,148224.0,0.08095238095238096,10027264.0,2400.0,12.8,2527.4239999999963,24576.0,0.0,2360064.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313352.0,75.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",602,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.208,2529.6319999999964,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",603,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.144,2531.775999999996,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",604,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.584,2535.359999999996,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",605,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.984,2537.343999999996,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",606,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2539.359999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",607,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.528,2541.887999999996,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",608,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.144,2544.0319999999956,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",609,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,1952.0,5.536,2549.5679999999957,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,61.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",610,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,1952.0,5.472,2555.039999999996,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,61.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",611,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,2208.0,5.568,2560.607999999996,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,69.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",612,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.688,2563.295999999996,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",613,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.688,2565.9839999999963,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",614,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.232,2569.2159999999963,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",615,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.592,2571.8079999999964,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",616,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,2573.9839999999963,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",617,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.688,2576.6719999999964,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",618,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.656,2579.3279999999963,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",619,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.104,2582.431999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",620,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.784,2585.2159999999963,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",621,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,2587.391999999996,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",622,0.0,0.0,0,0,0.0,0.0,0.0,0.0,60.0,0.0,6144.0,6144.0,2.528,2589.919999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",623,0.0,0.0,0,0,0.0,0.0,0.0,0.0,60.0,0.0,6144.0,6144.0,2.528,2592.447999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",624,12256.0,1103532.0,0,0,0.0,1103532.0,1103532.0,6243.0,12.0,0.9980815347721822,15360.0,3072.0,20.576,2613.023999999996,930415.0,148605.0,12256.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",625,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,2080.0,5.536,2618.559999999996,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,65.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",626,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.208,2620.767999999996,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",627,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.144,2622.9119999999957,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",628,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.488,2626.3999999999955,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",629,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.984,2628.3839999999955,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",630,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2630.3999999999955,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",631,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.56,2632.9599999999955,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",632,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.144,2635.1039999999953,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",633,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4448.0,12.864,2647.9679999999953,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,139.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",634,35328.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,48.0,0.0,12288.0,12288.0,2.272,2650.2399999999952,3072.0,0.0,35328.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",635,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4448.0,12.768,2663.0079999999953,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,139.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",636,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.08,2665.087999999995,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",637,2360064.0,4744704.0,0,0,0.0,4744704.0,4744704.0,13056.0,148224.0,0.08095238095238096,10027008.0,2592.0,13.056,2678.1439999999952,24576.0,0.0,2360064.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313344.0,81.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",638,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.144,2680.287999999995,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",639,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.08,2682.367999999995,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",640,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.584,2685.9519999999948,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",641,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.952,2687.903999999995,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",642,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,2689.9519999999948,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",643,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.72,2692.6719999999946,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",644,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.24,2694.9119999999944,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",645,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,1984.0,5.536,2700.4479999999944,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,62.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",646,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,2272.0,5.632,2706.0799999999945,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,71.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",647,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,2144.0,5.408,2711.4879999999944,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,67.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",648,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.656,2714.1439999999943,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",649,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.656,2716.7999999999943,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",650,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.136,2719.9359999999942,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",651,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.688,2722.6239999999943,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",652,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.144,2724.767999999994,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",653,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.816,2727.583999999994,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",654,0.0,384.0,0,0,0.0,384.0,384.0,0.0,24.0,0.0,1536.0,1536.0,2.656,2730.239999999994,384.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",655,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,3072.0,3072.0,3.104,2733.3439999999937,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",656,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,4608.0,3072.0,2.624,2735.9679999999935,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",657,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.144,2738.1119999999933,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",658,0.0,0.0,0,0,0.0,0.0,0.0,0.0,60.0,0.0,6144.0,6144.0,2.592,2740.7039999999934,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",659,0.0,0.0,0,0,0.0,0.0,0.0,0.0,60.0,0.0,6144.0,6144.0,2.624,2743.327999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",660,12288.0,1103616.0,0,0,0.0,1103616.0,1103616.0,6240.0,12.0,0.9980806142034548,15360.0,3072.0,20.448,2763.775999999993,930432.0,148608.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",661,590592.0,1205760.0,0,0,0.0,1205760.0,1205760.0,13056.0,37632.0,0.25757575757575757,2506752.0,1888.0,5.408,2769.183999999993,24576.0,0.0,590592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,78336.0,59.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",662,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.144,2771.3279999999927,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",663,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.08,2773.4079999999926,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",664,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.488,2776.8959999999925,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",665,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.952,2778.8479999999927,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",666,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2780.8639999999928,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",667,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.592,2783.455999999993,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",668,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.144,2785.5999999999926,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",669,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4608.0,12.736,2798.3359999999925,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",670,35328.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,48.0,0.0,12288.0,12288.0,2.208,2800.5439999999926,3072.0,0.0,35328.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",671,2362368.0,4773888.0,0,0,0.0,4773888.0,4773888.0,21504.0,148992.0,0.12612612612612611,9732096.0,4480.0,12.672,2813.2159999999926,49152.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,140.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",672,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.048,2815.2639999999924,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",673,2360064.0,4744704.0,0,0,0.0,4744704.0,4744704.0,13056.0,148224.0,0.08095238095238096,10027136.0,2464.0,13.024,2828.2879999999923,24576.0,0.0,2360064.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313348.0,77.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",674,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.24,2830.527999999992,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",675,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.144,2832.671999999992,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",676,0.0,1889.0,0,0,0.0,1889.0,1889.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.456,2836.127999999992,1888.0,1.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",677,1.0,2.0,0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,1.984,2838.111999999992,0.0,0.0,1.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",678,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2840.127999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",679,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,3168.0,3072.0,2.56,2842.687999999992,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",680,0.0,768.0,0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.144,2844.8319999999917,0.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",681,24608000.0,49472000.0,0,0,0.0,49472000.0,49472000.0,88000.0,1544000.0,0.05392156862745098,99080832.0,161536.0,107.584,2952.4159999999915,256000.0,0.0,24608000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3096276.0,5048.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",682,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.76,2954.1759999999917,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",683,0.0,0.0,0,0,0.0,0.0,0.0,0.0,5.0,0.0,64.0,64.0,2.656,2956.8319999999917,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",684,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2958.8479999999918,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",685,0.0,32000.0,0,0,0.0,32000.0,32000.0,0.0,512.0,0.0,128000.0,128000.0,2.272,2961.1199999999917,0.0,32000.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4000.0,4000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",686,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.664,2962.783999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",687,0.0,0.0,0,0,0.0,0.0,0.0,512.0,1512.0,0.25296442687747034,129024.0,8512.0,3.456,2966.239999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4032.0,266.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",688,0.0,0.0,0,0,0.0,0.0,0.0,2368.0,8610.0,0.2157041355438149,527360.0,0.0,4.128,2970.367999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16480.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",689,0.0,0.0,0,0,0.0,0.0,0.0,512.0,1512.0,0.25296442687747034,129024.0,8896.0,3.36,2973.7279999999923,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4032.0,278.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",690,0.0,0.0,0,0,0.0,0.0,0.0,2368.0,8802.0,0.21199641897940913,527360.0,0.0,3.936,2977.6639999999925,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16480.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",691,0.0,0.0,0,0,0.0,0.0,0.0,512.0,1512.0,0.25296442687747034,129024.0,8768.0,3.264,2980.9279999999926,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4032.0,274.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",692,0.0,0.0,0,0,0.0,0.0,0.0,2368.0,8642.0,0.2150772025431426,527360.0,0.0,4.0,2984.9279999999926,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16480.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",693,0.0,0.0,0,0,0.0,0.0,0.0,512.0,1512.0,0.25296442687747034,129024.0,8832.0,3.488,2988.4159999999924,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4032.0,276.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",694,0.0,0.0,0,0,0.0,0.0,0.0,2368.0,8738.0,0.2132180803169458,527360.0,32.0,3.84,2992.2559999999926,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16480.0,1.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",695,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,1056.0,128.0,2.304,2994.5599999999927,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,33.0,4.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",696,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.696,2996.2559999999926,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",697,0.0,0.0,0,0,0.0,0.0,0.0,497.0,10.0,0.980276134122288,128.0,0.0,3.488,2999.7439999999924,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",698,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.696,3001.4399999999923,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",699,0.0,0.0,0,0,0.0,0.0,0.0,497.0,10.0,0.980276134122288,128.0,0.0,3.456,3004.8959999999925,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 1>(detail::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, detail::TensorInfo<T1, T2>, T2, detail::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",700,0.0,0.0,0,0,0.0,0.0,0.0,7248.0,2104.0,0.7750213857998289,131808.0,2048.0,5.696,3010.5919999999924,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4119.0,64.0
"void native::radixSortKVInPlace<(int)-2, (int)-1, 32, 4, float, long, unsigned int>(detail::TensorInfo<T5, T7>, T7, T7, T7, detail::TensorInfo<T6, T7>, T7, bool)",701,0.0,0.0,0,0,0.0,0.0,0.0,458.0,8.0,0.9828326180257511,640.0,0.0,6.016,3016.6079999999924,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,20.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",702,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3000.0,0.0,130016.0,11008.0,3.36,3019.9679999999926,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4063.0,344.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",703,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,160000.0,0.0,2.464,3022.4319999999925,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5000.0,0.0
"native::<unnamed>::fill_reverse_indices_kernel(long *, int, detail::IntDivider<unsigned int>)",704,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1000.0,0.0,0.0,256000.0,2.048,3024.4799999999923,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,8000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",705,0.0,0.0,0,0,0.0,0.0,0.0,98304.0,1000.0,0.9899299121888343,128000.0,0.0,4.0,3028.4799999999923,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",706,0.0,0.0,0,0,0.0,0.0,0.0,156.0,64.0,0.7090909090909091,8192.0,0.0,2.176,3030.655999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",707,0.0,0.0,0,0,0.0,0.0,0.0,13439.0,4564.0,0.7464866966616674,437248.0,331200.0,7.936,3038.5919999999924,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,13664.0,10350.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",708,0.0,0.0,0,0,0.0,0.0,0.0,4607.0,4556.0,0.5027829313543599,437248.0,395264.0,7.072,3045.6639999999925,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,13664.0,12352.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",709,0.0,0.0,0,0,0.0,0.0,0.0,5339.0,4527.0,0.5411514291506183,434176.0,395264.0,7.04,3052.7039999999924,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,13568.0,12352.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",710,0.0,0.0,0,0,0.0,0.0,0.0,5339.0,4528.0,0.5410965845748454,434176.0,345248.0,7.008,3059.7119999999923,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,13568.0,10789.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",711,448000.0,1061280.0,0,0,0.0,1061280.0,1061280.0,132.0,1312.0,0.09141274238227147,259456.0,128000.0,16.992,3076.7039999999924,133280.0,32000.0,448000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8108.0,4000.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<float, 1>>(T1, int)",712,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,416.0,1.696,3078.3999999999924,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,13.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<float, std::plus<float>>::Policy900, const float *, float *, at_cuda_detail::ScanTileState<float, 1>, std::plus<float>, at_cuda_detail::NullType, unsigned int, float, 0>(T2, T3, T4, int, T5, T6, T7)",713,0.0,84379.0,0,0,0.0,84379.0,84379.0,4417.0,2095.0,0.6782862407862408,136704.0,129024.0,3.52,3081.9199999999923,84379.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4272.0,4032.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",714,0.0,0.0,0,0,0.0,0.0,0.0,0.0,512.0,0.0,128000.0,31808.0,2.272,3084.1919999999923,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4000.0,994.0
"void native::unrolled_elementwise_kernel<native::FillFunctor<bool>, std::array<char *, 1>, 16, TrivialOffsetCalculator<0, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithoutCast, memory::StoreWithoutCast>(int, T1, T2, T4, T5, T6, T7)",715,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,3085.887999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",716,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3000.0,0.0,288000.0,12704.0,7.072,3092.9599999999923,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,9000.0,397.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",717,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,160000.0,0.0,2.368,3095.3279999999922,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",718,448000.0,1061280.0,0,0,0.0,1061280.0,1061280.0,132.0,1312.0,0.09141274238227147,258944.0,128000.0,17.184,3112.5119999999924,133280.0,32000.0,448000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8092.0,4000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",719,0.0,0.0,0,0,0.0,0.0,0.0,62.0,251.0,0.19808306709265175,128000.0,32.0,8.16,3120.6719999999923,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",720,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.208,3122.8799999999924,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",721,0.0,0.0,0,0,0.0,0.0,0.0,62.0,251.0,0.19808306709265175,128000.0,32.0,8.064,3130.9439999999922,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",722,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,3133.087999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",723,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.08,3135.167999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",724,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.008,3138.1759999999917,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",725,0.0,36576.0,0,0,0.0,36576.0,36576.0,62.0,251.0,0.19808306709265175,128000.0,32.0,7.712,3145.8879999999917,36576.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4000.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",726,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,3147.903999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",727,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,3149.9839999999917,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",728,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.976,3152.959999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",729,288000.0,640000.0,0,0,0.0,640000.0,640000.0,0.0,1000.0,0.0,0.0,128000.0,2.272,3155.231999999992,0.0,64000.0,288000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,4000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",730,160000.0,320000.0,0,0,0.0,320000.0,320000.0,0.0,768.0,0.0,256000.0,0.0,3.296,3158.5279999999916,0.0,0.0,160000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",731,0.0,0.0,0,0,0.0,0.0,0.0,124.0,251.0,0.33066666666666666,128000.0,32.0,11.808,3170.3359999999916,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4000.0,1.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",732,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.048,3172.3839999999914,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",733,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,3174.431999999991,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",734,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.08,3176.511999999991,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",735,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.112,3178.623999999991,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",736,0.0,0.0,0,0,0.0,0.0,0.0,0.0,5.0,0.0,64.0,64.0,2.688,3181.3119999999913,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",737,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,3183.007999999991,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",738,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,3184.7359999999912,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",739,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.048,3186.783999999991,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",740,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.664,3188.447999999991,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",741,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.048,3190.495999999991,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",742,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.112,3192.607999999991,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",743,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,3194.655999999991,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",744,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.816,3197.4719999999907,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",745,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.2,3200.6719999999905,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",746,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,3202.6879999999906,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
