Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,4.064,4.064,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,4.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,1.696,5.76,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,7.4879999999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.048,9.536,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.336,11.872,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",6,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,160.0,32.0,2.368,14.24,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",7,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,128.0,3.456,17.696,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,4.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",8,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,32.0,3.296,20.992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",9,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.208,23.200000000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",10,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,1.696,24.896000000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,4.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",11,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,26.624000000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.728,28.352000000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,0.0,0.0,0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,2.464,30.816000000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,32.83200000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",15,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.176,35.00800000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",16,0.0,0.0,0,0,0.0,0.0,0.0,176.0,16.0,0.9166666666666666,128.0,32.0,2.624,37.63200000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",17,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,128.0,2.048,39.680000000000014,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",18,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,32.0,2.08,41.76000000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",19,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,160.0,0.0,2.176,43.936000000000014,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",20,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1152.0,0.0,3840.0,49152.0,6.816,50.75200000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,120.0,1536.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",21,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1152.0,0.0,3840.0,49152.0,6.784,57.536000000000016,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,120.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",22,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.08,59.616000000000014,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",23,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,32.0,2.016,61.63200000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",24,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.488,65.12000000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",25,102672.0,373712.0,0,0,0.0,373712.0,373712.0,320.0,1088.0,0.22727272727272727,147456.0,50176.0,4.224,69.34400000000002,104640.0,63728.0,102672.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1568.0
ampere_sgemm_32x32_sliced1x4_nn,26,56623104.0,114794496.0,0,0,0.0,114794496.0,114794496.0,331776.0,86400.0,0.7933884297520661,10616832.0,442368.0,12.48,81.82400000000003,663552.0,884736.0,56623104.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,13824.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",27,0.0,184320.0,0,0,0.0,184320.0,184320.0,0.0,8064.0,0.0,451584.0,147456.0,2.976,84.80000000000003,147456.0,36864.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,14112.0,4608.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",28,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.656,87.45600000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",29,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.72,90.17600000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",30,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.688,92.86400000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",31,393216.0,13062144.0,0,0,0.0,13062144.0,13062144.0,102144.0,192.0,0.99812382739212,147456.0,49152.0,18.656,111.52000000000004,9879552.0,2396160.0,393216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_32x32_sliced1x4_nn,32,18874368.0,38436864.0,0,0,0.0,38436864.0,38436864.0,116736.0,29184.0,0.8,3538944.0,196608.0,8.352,119.87200000000004,294912.0,393216.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,110592.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",33,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,3072.0,0.0,199680.0,49152.0,2.784,122.65600000000005,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6240.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",34,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.208,124.86400000000005,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",35,102672.0,373712.0,0,0,0.0,373712.0,373712.0,320.0,1088.0,0.22727272727272727,147456.0,50176.0,4.192,129.05600000000004,104640.0,63728.0,102672.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1568.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),36,75497472.0,151486464.0,0,0,0.0,151486464.0,151486464.0,253344.0,7680.0,0.9705774181684442,10616832.0,983040.0,14.336,143.39200000000005,0.0,491520.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,30720.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",37,0.0,344064.0,0,0,0.0,344064.0,344064.0,0.0,13824.0,0.0,995328.0,196608.0,3.616,147.00800000000007,294912.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,31104.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",38,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.24,149.24800000000008,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",39,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.176,151.42400000000006,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",40,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.368,153.79200000000006,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",41,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,2.496,156.28800000000007,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",42,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.24,158.52800000000008,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",43,286128.0,719712.0,0,0,0.0,719712.0,719712.0,0.0,768.0,0.0,196608.0,196608.0,2.56,161.08800000000008,49152.0,98304.0,286128.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",44,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.336,163.4240000000001,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",45,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.624,166.0480000000001,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_32x32_sliced1x4_nn,46,77070336.0,155344896.0,0,0,0.0,155344896.0,155344896.0,419328.0,114048.0,0.7861771058315334,14436544.0,344064.0,16.192,182.2400000000001,516096.0,688128.0,77070336.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,451142.0,10752.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",47,0.0,110592.0,0,0,0.0,110592.0,110592.0,0.0,4224.0,0.0,347136.0,49152.0,3.296,185.5360000000001,98304.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,10848.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",48,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,187.64800000000008,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",49,102672.0,373712.0,0,0,0.0,373712.0,373712.0,320.0,1088.0,0.22727272727272727,147456.0,50176.0,4.192,191.8400000000001,104640.0,63728.0,102672.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1568.0
ampere_sgemm_32x32_sliced1x4_nn,50,56623104.0,114794496.0,0,0,0.0,114794496.0,114794496.0,331776.0,86400.0,0.7933884297520661,10616832.0,442368.0,12.544,204.3840000000001,663552.0,884736.0,56623104.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,13824.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",51,0.0,184320.0,0,0,0.0,184320.0,184320.0,0.0,8064.0,0.0,451584.0,147456.0,2.944,207.3280000000001,147456.0,36864.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,14112.0,4608.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",52,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.72,210.0480000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",53,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.688,212.73600000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",54,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.624,215.36000000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",55,393216.0,13062144.0,0,0,0.0,13062144.0,13062144.0,102144.0,192.0,0.99812382739212,147456.0,49152.0,17.472,232.83200000000008,9879552.0,2396160.0,393216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_32x32_sliced1x4_nn,56,18874368.0,38436864.0,0,0,0.0,38436864.0,38436864.0,116736.0,29184.0,0.8,3538944.0,196608.0,8.128,240.9600000000001,294912.0,393216.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,110592.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",57,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,3072.0,0.0,199680.0,49152.0,2.752,243.7120000000001,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6240.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",58,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.176,245.8880000000001,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",59,102672.0,373712.0,0,0,0.0,373712.0,373712.0,320.0,1088.0,0.22727272727272727,147456.0,50176.0,4.256,250.1440000000001,104640.0,63728.0,102672.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1568.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),60,75497472.0,151486464.0,0,0,0.0,151486464.0,151486464.0,253344.0,7680.0,0.9705774181684442,10616832.0,983040.0,13.984,264.1280000000001,0.0,491520.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,30720.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",61,0.0,344064.0,0,0,0.0,344064.0,344064.0,0.0,13824.0,0.0,995328.0,196608.0,3.584,267.7120000000001,294912.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,31104.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",62,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.336,270.0480000000001,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",63,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.24,272.2880000000001,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",64,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.208,274.49600000000015,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",65,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,2.528,277.02400000000017,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",66,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.272,279.29600000000016,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",67,285744.0,718944.0,0,0,0.0,718944.0,718944.0,0.0,768.0,0.0,196608.0,196608.0,2.304,281.60000000000014,49152.0,98304.0,285744.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",68,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.368,283.96800000000013,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",69,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.592,286.5600000000001,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_32x32_sliced1x4_nn,70,77070336.0,155344896.0,0,0,0.0,155344896.0,155344896.0,419328.0,114048.0,0.7861771058315334,14440896.0,344064.0,16.288,302.8480000000001,516096.0,688128.0,77070336.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,451278.0,10752.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",71,0.0,110592.0,0,0,0.0,110592.0,110592.0,0.0,4224.0,0.0,347136.0,49152.0,3.296,306.1440000000001,98304.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,10848.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",72,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.144,308.2880000000001,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",73,102672.0,373712.0,0,0,0.0,373712.0,373712.0,320.0,1088.0,0.22727272727272727,147456.0,50176.0,4.192,312.48000000000013,104640.0,63728.0,102672.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1568.0
ampere_sgemm_32x32_sliced1x4_nn,74,56623104.0,114794496.0,0,0,0.0,114794496.0,114794496.0,331776.0,86400.0,0.7933884297520661,10616832.0,442368.0,12.288,324.76800000000014,663552.0,884736.0,56623104.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,13824.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",75,0.0,184320.0,0,0,0.0,184320.0,184320.0,0.0,8064.0,0.0,451584.0,147456.0,2.976,327.74400000000014,147456.0,36864.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,14112.0,4608.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",76,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.688,330.43200000000013,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",77,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.72,333.15200000000016,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",78,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.688,335.84000000000015,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",79,393216.0,13062144.0,0,0,0.0,13062144.0,13062144.0,102144.0,192.0,0.99812382739212,147456.0,49152.0,17.536,353.37600000000015,9879552.0,2396160.0,393216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_32x32_sliced1x4_nn,80,18874368.0,38436864.0,0,0,0.0,38436864.0,38436864.0,116736.0,29184.0,0.8,3538944.0,196608.0,8.288,361.66400000000016,294912.0,393216.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,110592.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",81,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,3072.0,0.0,199680.0,49152.0,2.784,364.44800000000015,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6240.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",82,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.176,366.62400000000014,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",83,102672.0,373712.0,0,0,0.0,373712.0,373712.0,320.0,1088.0,0.22727272727272727,147456.0,50176.0,4.16,370.78400000000016,104640.0,63728.0,102672.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1568.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),84,75497472.0,151486464.0,0,0,0.0,151486464.0,151486464.0,253344.0,7680.0,0.9705774181684442,10616832.0,983040.0,13.888,384.67200000000014,0.0,491520.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,30720.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",85,0.0,344064.0,0,0,0.0,344064.0,344064.0,0.0,13824.0,0.0,995328.0,196608.0,3.712,388.3840000000001,294912.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,31104.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",86,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.176,390.5600000000001,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",87,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.144,392.7040000000001,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",88,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.144,394.8480000000001,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",89,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,2.592,397.4400000000001,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",90,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.176,399.6160000000001,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",91,285104.0,717664.0,0,0,0.0,717664.0,717664.0,0.0,768.0,0.0,196608.0,196608.0,2.304,401.9200000000001,49152.0,98304.0,285104.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",92,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.176,404.09600000000006,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",93,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.464,406.56000000000006,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_32x32_sliced1x4_nn,94,77070336.0,155344896.0,0,0,0.0,155344896.0,155344896.0,419328.0,114048.0,0.7861771058315334,14434400.0,344064.0,16.16,422.7200000000001,516096.0,688128.0,77070336.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,451075.0,10752.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",95,0.0,110592.0,0,0,0.0,110592.0,110592.0,0.0,4224.0,0.0,347136.0,49152.0,3.264,425.9840000000001,98304.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,10848.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",96,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,428.0960000000001,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",97,102672.0,373712.0,0,0,0.0,373712.0,373712.0,320.0,1088.0,0.22727272727272727,147456.0,50176.0,4.352,432.4480000000001,104640.0,63728.0,102672.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1568.0
ampere_sgemm_32x32_sliced1x4_nn,98,56623104.0,114794496.0,0,0,0.0,114794496.0,114794496.0,331776.0,86400.0,0.7933884297520661,10616832.0,442368.0,12.64,445.0880000000001,663552.0,884736.0,56623104.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,13824.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",99,0.0,184320.0,0,0,0.0,184320.0,184320.0,0.0,8064.0,0.0,451584.0,147456.0,2.944,448.0320000000001,147456.0,36864.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,14112.0,4608.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",100,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.88,450.9120000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",101,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.72,453.6320000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",102,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.656,456.2880000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",103,393216.0,13062144.0,0,0,0.0,13062144.0,13062144.0,102144.0,192.0,0.99812382739212,147456.0,49152.0,17.312,473.60000000000014,9879552.0,2396160.0,393216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_32x32_sliced1x4_nn,104,18874368.0,38436864.0,0,0,0.0,38436864.0,38436864.0,116736.0,29184.0,0.8,3538944.0,196608.0,8.608,482.20800000000014,294912.0,393216.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,110592.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",105,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,3072.0,0.0,199680.0,49152.0,2.72,484.92800000000017,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6240.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",106,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.176,487.10400000000016,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",107,102672.0,373712.0,0,0,0.0,373712.0,373712.0,320.0,1088.0,0.22727272727272727,147456.0,50176.0,4.288,491.39200000000017,104640.0,63728.0,102672.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1568.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),108,75497472.0,151486464.0,0,0,0.0,151486464.0,151486464.0,253344.0,7680.0,0.9705774181684442,10616832.0,983040.0,13.952,505.34400000000016,0.0,491520.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,30720.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",109,0.0,344064.0,0,0,0.0,344064.0,344064.0,0.0,13824.0,0.0,995328.0,196608.0,3.712,509.05600000000015,294912.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,31104.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",110,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.144,511.20000000000016,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",111,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.144,513.3440000000002,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",112,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.176,515.5200000000002,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",113,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,2.528,518.0480000000002,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",114,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.272,520.3200000000003,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",115,286032.0,719520.0,0,0,0.0,719520.0,719520.0,0.0,768.0,0.0,196608.0,196608.0,2.272,522.5920000000003,49152.0,98304.0,286032.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",116,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.208,524.8000000000003,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",117,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.592,527.3920000000003,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_32x32_sliced1x4_nn,118,77070336.0,155344896.0,0,0,0.0,155344896.0,155344896.0,419328.0,114048.0,0.7861771058315334,14437664.0,344064.0,16.768,544.1600000000003,516096.0,688128.0,77070336.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,451177.0,10752.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",119,0.0,110592.0,0,0,0.0,110592.0,110592.0,0.0,4224.0,0.0,347136.0,49152.0,3.296,547.4560000000004,98304.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,10848.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",120,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,549.5680000000003,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",121,102672.0,373712.0,0,0,0.0,373712.0,373712.0,320.0,1088.0,0.22727272727272727,147456.0,50176.0,4.224,553.7920000000004,104640.0,63728.0,102672.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1568.0
ampere_sgemm_32x32_sliced1x4_nn,122,56623104.0,114794496.0,0,0,0.0,114794496.0,114794496.0,331776.0,86400.0,0.7933884297520661,10616832.0,442368.0,12.224,566.0160000000004,663552.0,884736.0,56623104.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,13824.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",123,0.0,184320.0,0,0,0.0,184320.0,184320.0,0.0,8064.0,0.0,451584.0,147456.0,2.944,568.9600000000004,147456.0,36864.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,14112.0,4608.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",124,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.656,571.6160000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",125,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.752,574.3680000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",126,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.784,577.1520000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",127,393216.0,13062144.0,0,0,0.0,13062144.0,13062144.0,102144.0,192.0,0.99812382739212,147456.0,49152.0,17.568,594.7200000000003,9879552.0,2396160.0,393216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_32x32_sliced1x4_nn,128,18874368.0,38436864.0,0,0,0.0,38436864.0,38436864.0,116736.0,29184.0,0.8,3538944.0,196608.0,8.256,602.9760000000002,294912.0,393216.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,110592.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",129,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,3072.0,0.0,199680.0,49152.0,2.752,605.7280000000002,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6240.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",130,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.208,607.9360000000001,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",131,102672.0,373712.0,0,0,0.0,373712.0,373712.0,320.0,1088.0,0.22727272727272727,147456.0,50176.0,4.224,612.1600000000002,104640.0,63728.0,102672.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1568.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),132,75497472.0,151486464.0,0,0,0.0,151486464.0,151486464.0,253344.0,7680.0,0.9705774181684442,10616832.0,983040.0,13.824,625.9840000000002,0.0,491520.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,30720.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",133,0.0,344064.0,0,0,0.0,344064.0,344064.0,0.0,13824.0,0.0,995328.0,196608.0,3.648,629.6320000000002,294912.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,31104.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",134,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.208,631.8400000000001,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",135,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.176,634.0160000000002,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",136,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.176,636.1920000000002,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",137,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,2.528,638.7200000000003,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",138,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.24,640.9600000000003,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",139,285184.0,717824.0,0,0,0.0,717824.0,717824.0,0.0,768.0,0.0,196608.0,196608.0,2.304,643.2640000000002,49152.0,98304.0,285184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",140,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.208,645.4720000000002,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",141,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.56,648.0320000000002,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_32x32_sliced1x4_nn,142,77070336.0,155344896.0,0,0,0.0,155344896.0,155344896.0,419328.0,114048.0,0.7861771058315334,14432864.0,344064.0,16.32,664.3520000000002,516096.0,688128.0,77070336.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,451027.0,10752.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",143,0.0,110592.0,0,0,0.0,110592.0,110592.0,0.0,4224.0,0.0,347136.0,49152.0,3.232,667.5840000000002,98304.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,10848.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",144,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,669.6960000000001,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",145,102672.0,373712.0,0,0,0.0,373712.0,373712.0,320.0,1088.0,0.22727272727272727,147456.0,50176.0,4.256,673.9520000000001,104640.0,63728.0,102672.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1568.0
ampere_sgemm_32x32_sliced1x4_nn,146,56623104.0,114794496.0,0,0,0.0,114794496.0,114794496.0,331776.0,86400.0,0.7933884297520661,10616832.0,442368.0,12.8,686.7520000000001,663552.0,884736.0,56623104.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,13824.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",147,0.0,184320.0,0,0,0.0,184320.0,184320.0,0.0,8064.0,0.0,451584.0,147456.0,2.944,689.696,147456.0,36864.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,14112.0,4608.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",148,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.688,692.384,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",149,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.688,695.072,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",150,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.656,697.728,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",151,393216.0,13062144.0,0,0,0.0,13062144.0,13062144.0,102144.0,192.0,0.99812382739212,147456.0,49152.0,17.28,715.0079999999999,9879552.0,2396160.0,393216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_32x32_sliced1x4_nn,152,18874368.0,38436864.0,0,0,0.0,38436864.0,38436864.0,116736.0,29184.0,0.8,3538944.0,196608.0,8.448,723.4559999999999,294912.0,393216.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,110592.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",153,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,3072.0,0.0,199680.0,49152.0,2.784,726.2399999999999,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6240.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",154,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.176,728.4159999999999,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",155,102672.0,373712.0,0,0,0.0,373712.0,373712.0,320.0,1088.0,0.22727272727272727,147456.0,50176.0,4.192,732.608,104640.0,63728.0,102672.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1568.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),156,75497472.0,151486464.0,0,0,0.0,151486464.0,151486464.0,253344.0,7680.0,0.9705774181684442,10616832.0,983040.0,13.952,746.56,0.0,491520.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,30720.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",157,0.0,344064.0,0,0,0.0,344064.0,344064.0,0.0,13824.0,0.0,995328.0,196608.0,3.584,750.1439999999999,294912.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,31104.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",158,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.176,752.3199999999999,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",159,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.272,754.592,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",160,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.208,756.8,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",161,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,2.4,759.1999999999999,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",162,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.24,761.4399999999999,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",163,285344.0,718144.0,0,0,0.0,718144.0,718144.0,0.0,768.0,0.0,196608.0,196608.0,2.496,763.9359999999999,49152.0,98304.0,285344.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",164,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.176,766.112,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",165,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.688,768.8,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_32x32_sliced1x4_nn,166,77070336.0,155344896.0,0,0,0.0,155344896.0,155344896.0,419328.0,114048.0,0.7861771058315334,14441280.0,344064.0,16.736,785.536,516096.0,688128.0,77070336.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,451290.0,10752.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",167,0.0,110592.0,0,0,0.0,110592.0,110592.0,0.0,4224.0,0.0,347136.0,49152.0,3.264,788.8,98304.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,10848.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",168,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,790.9119999999999,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",169,102672.0,373712.0,0,0,0.0,373712.0,373712.0,320.0,1088.0,0.22727272727272727,147456.0,50176.0,4.256,795.1679999999999,104640.0,63728.0,102672.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1568.0
ampere_sgemm_32x32_sliced1x4_nn,170,56623104.0,114794496.0,0,0,0.0,114794496.0,114794496.0,331776.0,86400.0,0.7933884297520661,10616832.0,442368.0,12.48,807.6479999999999,663552.0,884736.0,56623104.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,13824.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",171,0.0,184320.0,0,0,0.0,184320.0,184320.0,0.0,8064.0,0.0,451584.0,147456.0,2.944,810.5919999999999,147456.0,36864.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,14112.0,4608.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",172,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.688,813.2799999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",173,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.784,816.0639999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",174,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.656,818.7199999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",175,393216.0,13062144.0,0,0,0.0,13062144.0,13062144.0,102144.0,192.0,0.99812382739212,147456.0,49152.0,17.312,836.0319999999998,9879552.0,2396160.0,393216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_32x32_sliced1x4_nn,176,18874368.0,38436864.0,0,0,0.0,38436864.0,38436864.0,116736.0,29184.0,0.8,3538944.0,196608.0,8.384,844.4159999999998,294912.0,393216.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,110592.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",177,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,3072.0,0.0,199680.0,49152.0,2.784,847.1999999999998,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6240.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",178,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.176,849.3759999999999,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",179,102672.0,373712.0,0,0,0.0,373712.0,373712.0,320.0,1088.0,0.22727272727272727,147456.0,50176.0,4.256,853.6319999999998,104640.0,63728.0,102672.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1568.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),180,75497472.0,151486464.0,0,0,0.0,151486464.0,151486464.0,253344.0,7680.0,0.9705774181684442,10616832.0,983040.0,13.856,867.4879999999998,0.0,491520.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,30720.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",181,0.0,344064.0,0,0,0.0,344064.0,344064.0,0.0,13824.0,0.0,995328.0,196608.0,3.68,871.1679999999998,294912.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,31104.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",182,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.176,873.3439999999998,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",183,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.176,875.5199999999999,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",184,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.208,877.7279999999998,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",185,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,2.528,880.2559999999999,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",186,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.272,882.5279999999999,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",187,285584.0,718624.0,0,0,0.0,718624.0,718624.0,0.0,768.0,0.0,196608.0,196608.0,2.56,885.0879999999999,49152.0,98304.0,285584.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",188,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.208,887.2959999999998,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",189,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.752,890.0479999999998,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_32x32_sliced1x4_nn,190,77070336.0,155344896.0,0,0,0.0,155344896.0,155344896.0,419328.0,114048.0,0.7861771058315334,14434048.0,344064.0,16.032,906.0799999999998,516096.0,688128.0,77070336.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,451064.0,10752.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",191,0.0,110592.0,0,0,0.0,110592.0,110592.0,0.0,4224.0,0.0,347136.0,49152.0,3.36,909.4399999999998,98304.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,10848.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",192,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,911.5519999999998,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",193,102672.0,373712.0,0,0,0.0,373712.0,373712.0,320.0,1088.0,0.22727272727272727,147456.0,50176.0,4.192,915.7439999999998,104640.0,63728.0,102672.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1568.0
ampere_sgemm_32x32_sliced1x4_nn,194,56623104.0,114794496.0,0,0,0.0,114794496.0,114794496.0,331776.0,86400.0,0.7933884297520661,10616832.0,442368.0,12.512,928.2559999999999,663552.0,884736.0,56623104.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,13824.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",195,0.0,184320.0,0,0,0.0,184320.0,184320.0,0.0,8064.0,0.0,451584.0,147456.0,2.976,931.2319999999999,147456.0,36864.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,14112.0,4608.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",196,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.688,933.9199999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",197,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.752,936.6719999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",198,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.656,939.3279999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",199,393216.0,13062144.0,0,0,0.0,13062144.0,13062144.0,102144.0,192.0,0.99812382739212,147456.0,49152.0,17.792,957.1199999999998,9879552.0,2396160.0,393216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_32x32_sliced1x4_nn,200,18874368.0,38436864.0,0,0,0.0,38436864.0,38436864.0,116736.0,29184.0,0.8,3538944.0,196608.0,8.16,965.2799999999997,294912.0,393216.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,110592.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",201,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,3072.0,0.0,199680.0,49152.0,2.816,968.0959999999998,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6240.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",202,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.176,970.2719999999998,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",203,102672.0,373712.0,0,0,0.0,373712.0,373712.0,320.0,1088.0,0.22727272727272727,147456.0,50176.0,4.256,974.5279999999998,104640.0,63728.0,102672.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1568.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),204,75497472.0,151486464.0,0,0,0.0,151486464.0,151486464.0,253344.0,7680.0,0.9705774181684442,10616832.0,983040.0,13.856,988.3839999999998,0.0,491520.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,30720.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",205,0.0,344064.0,0,0,0.0,344064.0,344064.0,0.0,13824.0,0.0,995328.0,196608.0,3.52,991.9039999999998,294912.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,31104.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",206,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.304,994.2079999999997,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",207,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.144,996.3519999999997,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",208,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.368,998.7199999999998,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",209,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,2.496,1001.2159999999998,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",210,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.432,1003.6479999999998,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",211,285696.0,718848.0,0,0,0.0,718848.0,718848.0,0.0,768.0,0.0,196608.0,196608.0,2.304,1005.9519999999998,49152.0,98304.0,285696.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",212,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.464,1008.4159999999998,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",213,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.592,1011.0079999999998,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_32x32_sliced1x4_nn,214,77070336.0,155344896.0,0,0,0.0,155344896.0,155344896.0,419328.0,114048.0,0.7861771058315334,14433280.0,344064.0,16.224,1027.2319999999997,516096.0,688128.0,77070336.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,451040.0,10752.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",215,0.0,110592.0,0,0,0.0,110592.0,110592.0,0.0,4224.0,0.0,347136.0,49152.0,3.296,1030.5279999999998,98304.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,10848.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",216,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,1032.6399999999999,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",217,102672.0,373712.0,0,0,0.0,373712.0,373712.0,320.0,1088.0,0.22727272727272727,147456.0,50176.0,4.192,1036.8319999999999,104640.0,63728.0,102672.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1568.0
ampere_sgemm_64x32_sliced1x4_tn,218,1236271104.0,2483810304.0,0,0,0.0,2483810304.0,2483810304.0,5810112.0,1533128.0,0.7912191348777924,177944320.0,3192000.0,188.8,1225.6319999999998,4829184.0,6438912.0,1236271104.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5560760.0,99750.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",219,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,1.728,1227.36,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,4.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",220,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,256.0,512.0,2.592,1229.952,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8.0,16.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",221,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,1232.0,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",222,0.0,804112.0,0,0,0.0,804112.0,804112.0,0.0,12578.0,0.0,3216448.0,3216448.0,5.728,1237.728,0.0,804112.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,100514.0,100514.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",223,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,64.0,1.696,1239.424,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,2.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",224,0.0,0.0,0,0,0.0,0.0,0.0,10240.0,35376.0,0.22448263767099264,3236160.0,192192.0,6.272,1245.696,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,101130.0,6006.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",225,0.0,0.0,0,0,0.0,0.0,0.0,47360.0,213152.0,0.18179584817589978,8405792.0,512.0,6.144,1251.84,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,262681.0,16.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",226,0.0,0.0,0,0,0.0,0.0,0.0,10240.0,35376.0,0.22448263767099264,3236160.0,187904.0,6.272,1258.1119999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,101130.0,5872.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",227,0.0,0.0,0,0,0.0,0.0,0.0,47360.0,216992.0,0.17915506597264252,8405792.0,768.0,6.304,1264.416,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,262681.0,24.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",228,0.0,0.0,0,0,0.0,0.0,0.0,10240.0,35376.0,0.22448263767099264,3236160.0,189184.0,6.272,1270.6879999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,101130.0,5912.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",229,0.0,0.0,0,0,0.0,0.0,0.0,47360.0,216352.0,0.17958985560004853,8405760.0,608.0,6.112,1276.8,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,262680.0,19.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",230,0.0,0.0,0,0,0.0,0.0,0.0,10240.0,35376.0,0.22448263767099264,3236160.0,187520.0,6.144,1282.944,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,101130.0,5860.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",231,0.0,0.0,0,0,0.0,0.0,0.0,47360.0,215072.0,0.18046579685404218,8405664.0,1024.0,6.016,1288.96,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,262677.0,32.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",232,0.0,0.0,0,0,0.0,0.0,0.0,0.0,60.0,0.0,20544.0,2560.0,3.328,1292.288,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,642.0,80.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",233,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.728,1294.016,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",234,0.0,0.0,0,0,0.0,0.0,0.0,497.0,48.0,0.9119266055045872,2560.0,0.0,3.744,1297.76,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,80.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",235,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.728,1299.488,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",236,0.0,0.0,0,0,0.0,0.0,0.0,497.0,48.0,0.9119266055045872,2560.0,0.0,3.712,1303.2,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,80.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",237,0.0,0.0,0,0,0.0,0.0,0.0,208128.0,46928.0,0.8160090333103318,3274240.0,24224.0,8.288,1311.488,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,102320.0,757.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",238,0.0,0.0,0,0,0.0,0.0,0.0,7328.0,128.0,0.9828326180257511,10240.0,2080.0,6.432,1317.92,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,320.0,65.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",239,0.0,0.0,0,0,0.0,0.0,0.0,0.0,75387.0,0.0,3238976.0,330784.0,6.592,1324.5120000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,101218.0,10337.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",240,0.0,0.0,0,0,0.0,0.0,0.0,0.0,18867.0,0.0,4020576.0,1792.0,6.688,1331.2000000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,125643.0,56.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",241,0.0,0.0,0,0,0.0,0.0,0.0,0.0,25129.0,0.0,0.0,6432896.0,5.344,1336.5440000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,201028.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",242,0.0,0.0,0,0,0.0,0.0,0.0,98304.0,25129.0,0.7964158693380214,3216448.0,0.0,7.296,1343.8400000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,100514.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",243,0.0,0.0,0,0,0.0,0.0,0.0,156.0,64.0,0.7090909090909091,8192.0,0.0,2.272,1346.1120000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",244,0.0,0.0,0,0,0.0,0.0,0.0,314125.0,117589.0,0.7276229170237704,12502720.0,8106080.0,21.184,1367.2960000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,390710.0,253315.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",245,0.0,0.0,0,0,0.0,0.0,0.0,89194.0,139138.0,0.39063293800255766,12563776.0,9917632.0,17.728,1385.0240000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,392618.0,309926.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",246,0.0,0.0,0,0,0.0,0.0,0.0,90025.0,138392.0,0.3941256561464339,12533568.0,9917632.0,17.952,1402.9760000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,391674.0,309926.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",247,0.0,0.0,0,0,0.0,0.0,0.0,90025.0,138691.0,0.39361041641161965,12563008.0,9916480.0,18.112,1421.0880000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,392594.0,309890.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",248,0.0,0.0,0,0,0.0,0.0,0.0,14336.0,25129.0,0.36325858355504875,6432896.0,0.0,9.792,1430.8800000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,201028.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",249,0.0,0.0,0,0,0.0,0.0,0.0,39.0,16.0,0.7090909090909091,2048.0,0.0,2.176,1433.0560000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",250,0.0,0.0,0,0,0.0,0.0,0.0,80036.0,118878.0,0.40236484108710296,10216192.0,5867904.0,16.224,1449.2800000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319256.0,183372.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",251,0.0,0.0,0,0,0.0,0.0,0.0,0.0,100516.0,0.0,9709888.0,9649344.0,12.736,1462.0160000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,303434.0,301542.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",252,11257568.0,26620176.0,0,0,0.0,26620176.0,26620176.0,2112.0,26816.0,0.07300884955752213,8715584.0,2912832.0,24.256,1486.2720000000004,3300928.0,804112.0,11257568.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,272362.0,91026.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",253,0.0,4096800.0,0,0,0.0,4096800.0,4096800.0,449136.0,50272.0,0.8993368147887099,3217888.0,2297088.0,72.736,1559.0080000000005,4096800.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,100559.0,71784.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",254,0.0,0.0,0,0,0.0,0.0,0.0,0.0,12578.0,0.0,3216448.0,803936.0,5.696,1564.7040000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,100514.0,25123.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",255,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,512.0,1.952,1566.6560000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,16.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",256,0.0,0.0,0,0,0.0,0.0,0.0,0.0,75387.0,0.0,7237024.0,351136.0,11.904,1578.5600000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,226157.0,10973.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",257,0.0,0.0,0,0,0.0,0.0,0.0,0.0,18867.0,0.0,4020576.0,0.0,6.88,1585.4400000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,125643.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",258,11257568.0,26620176.0,0,0,0.0,26620176.0,26620176.0,2112.0,26816.0,0.07300884955752213,8738688.0,2918208.0,24.576,1610.0160000000005,3300928.0,804112.0,11257568.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,273084.0,91194.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",259,0.0,0.0,0,0,0.0,0.0,0.0,7883.0,6387.0,0.5524176594253679,3216864.0,3200.0,8.544,1618.5600000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,100527.0,100.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",260,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.176,1620.7360000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",261,0.0,0.0,0,0,0.0,0.0,0.0,7883.0,6387.0,0.5524176594253679,3216864.0,3200.0,8.32,1629.0560000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,100527.0,100.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",262,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,1631.2000000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",263,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.08,1633.2800000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",264,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.944,1636.2240000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",265,0.0,877328.0,0,0,0.0,877328.0,877328.0,736.0,6328.0,0.10419026047565119,3216896.0,512.0,11.616,1647.8400000000004,877328.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,100528.0,16.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",266,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,2.016,1649.8560000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",267,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,1653.2480000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",268,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,1655.3280000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",269,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.944,1658.2720000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",270,2555904.0,6720032.0,0,0,0.0,6720032.0,6720032.0,0.0,25129.0,0.0,0.0,3216448.0,5.184,1663.4560000000004,0.0,1608224.0,2555904.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,100514.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",271,4020560.0,8041120.0,0,0,0.0,8041120.0,8041120.0,0.0,18867.0,0.0,6432896.0,29696.0,10.048,1673.5040000000004,0.0,0.0,4020560.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,201028.0,928.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",272,0.0,0.0,0,0,0.0,0.0,0.0,1472.0,6328.0,0.18871794871794872,3217472.0,512.0,15.936,1689.4400000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,100546.0,16.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",273,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,256.0,128.0,2.176,1691.6160000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",274,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,128.0,2.048,1693.6640000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,4.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",275,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,160.0,128.0,2.336,1696.0000000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",276,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,256.0,128.0,2.144,1698.1440000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8.0,4.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",277,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,256.0,512.0,2.624,1700.7680000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8.0,16.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",278,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,1702.4640000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",279,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,1704.1920000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",280,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.048,1706.2400000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",281,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,1707.9680000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",282,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,288.0,32.0,2.304,1710.2720000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,9.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",283,0.0,0.0,0,0,0.0,0.0,0.0,0.0,5.0,0.0,32.0,32.0,4.8,1715.0720000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",284,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.08,1717.1520000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",285,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,1719.2320000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",286,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,160.0,128.0,2.944,1722.1760000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5.0,4.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",287,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,32.0,3.04,1725.2160000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",288,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,1727.2640000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",289,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.176,1729.44,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",290,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,288.0,128.0,3.776,1733.2160000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,9.0,4.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",291,0.0,0.0,0,0,0.0,0.0,0.0,176.0,16.0,0.9166666666666666,256.0,96.0,3.2,1736.4160000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8.0,3.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",292,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,256.0,256.0,2.048,1738.4640000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8.0,8.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",293,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,256.0,32.0,2.368,1740.832,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",294,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,288.0,0.0,2.304,1743.1360000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,9.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",295,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,256.0,128.0,2.24,1745.3760000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8.0,4.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",296,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1152.0,0.0,46848.0,49152.0,11.328,1756.7040000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1464.0,1536.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",297,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1152.0,0.0,3840.0,49152.0,6.496,1763.2000000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,120.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",298,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.144,1765.3440000000003,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",299,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,256.0,32.0,2.112,1767.4560000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",300,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.616,1771.0720000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",301,102672.0,373712.0,0,0,0.0,373712.0,373712.0,320.0,1088.0,0.22727272727272727,147456.0,50176.0,4.256,1775.3280000000004,104640.0,63728.0,102672.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1568.0
ampere_sgemm_32x32_sliced1x4_nn,302,56623104.0,114794496.0,0,0,0.0,114794496.0,114794496.0,331776.0,86400.0,0.7933884297520661,10616832.0,442368.0,12.32,1787.6480000000004,663552.0,884736.0,56623104.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,13824.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",303,0.0,184320.0,0,0,0.0,184320.0,184320.0,0.0,8064.0,0.0,451584.0,147456.0,3.296,1790.9440000000004,147456.0,36864.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,14112.0,4608.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",304,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,4.16,1795.1040000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",305,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,4.128,1799.2320000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",306,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.688,1801.9200000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",307,393216.0,13074432.0,0,0,0.0,13074432.0,13074432.0,102144.0,192.0,0.99812382739212,245760.0,49152.0,18.976,1820.8960000000006,9891840.0,2396160.0,393216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_32x32_sliced1x4_nn,308,18874368.0,38436864.0,0,0,0.0,38436864.0,38436864.0,116736.0,29184.0,0.8,3538944.0,196608.0,8.384,1829.2800000000007,294912.0,393216.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,110592.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",309,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,3072.0,0.0,199680.0,49152.0,2.752,1832.0320000000006,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6240.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",310,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,1834.1440000000007,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",311,102672.0,373712.0,0,0,0.0,373712.0,373712.0,320.0,1088.0,0.22727272727272727,147456.0,50176.0,4.192,1838.3360000000007,104640.0,63728.0,102672.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1568.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),312,75497472.0,151486464.0,0,0,0.0,151486464.0,151486464.0,253344.0,7680.0,0.9705774181684442,10616832.0,983040.0,14.496,1852.8320000000008,0.0,491520.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,30720.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",313,0.0,344064.0,0,0,0.0,344064.0,344064.0,0.0,13824.0,0.0,995328.0,196608.0,3.52,1856.3520000000008,294912.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,31104.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",314,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.368,1858.7200000000007,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",315,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.336,1861.0560000000007,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",316,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.368,1863.4240000000007,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",317,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,2.432,1865.8560000000007,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",318,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.4,1868.2560000000008,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",319,285859.0,719174.0,0,0,0.0,719174.0,719174.0,0.0,768.0,0.0,196608.0,196608.0,2.304,1870.5600000000009,49152.0,98304.0,285859.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",320,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.336,1872.8960000000009,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",321,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.56,1875.4560000000008,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_32x32_sliced1x4_nn,322,77070336.0,155344896.0,0,0,0.0,155344896.0,155344896.0,419328.0,114048.0,0.7861771058315334,14434496.0,344064.0,15.584,1891.0400000000009,516096.0,688128.0,77070336.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,451078.0,10752.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",323,0.0,110592.0,0,0,0.0,110592.0,110592.0,0.0,4224.0,0.0,347136.0,49152.0,3.296,1894.336000000001,98304.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,10848.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",324,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.208,1896.544000000001,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",325,102672.0,373712.0,0,0,0.0,373712.0,373712.0,320.0,1088.0,0.22727272727272727,147456.0,50176.0,4.16,1900.704000000001,104640.0,63728.0,102672.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1568.0
ampere_sgemm_32x32_sliced1x4_nn,326,56623104.0,114794496.0,0,0,0.0,114794496.0,114794496.0,331776.0,86400.0,0.7933884297520661,10616832.0,442368.0,12.544,1913.2480000000012,663552.0,884736.0,56623104.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,13824.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",327,0.0,184320.0,0,0,0.0,184320.0,184320.0,0.0,8064.0,0.0,451584.0,147456.0,2.912,1916.1600000000012,147456.0,36864.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,14112.0,4608.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",328,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,4.064,1920.2240000000013,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",329,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,4.096,1924.3200000000013,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",330,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.688,1927.0080000000014,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",331,393216.0,13074432.0,0,0,0.0,13074432.0,13074432.0,102144.0,192.0,0.99812382739212,245760.0,49152.0,17.312,1944.3200000000013,9891840.0,2396160.0,393216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_32x32_sliced1x4_nn,332,18874368.0,38436864.0,0,0,0.0,38436864.0,38436864.0,116736.0,29184.0,0.8,3538944.0,196608.0,8.64,1952.9600000000014,294912.0,393216.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,110592.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",333,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,3072.0,0.0,199680.0,49152.0,2.752,1955.7120000000014,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6240.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",334,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,1957.8240000000014,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",335,102672.0,373712.0,0,0,0.0,373712.0,373712.0,320.0,1088.0,0.22727272727272727,147456.0,50176.0,4.416,1962.2400000000014,104640.0,63728.0,102672.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1568.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),336,75497472.0,151486464.0,0,0,0.0,151486464.0,151486464.0,253344.0,7680.0,0.9705774181684442,10616832.0,983040.0,13.792,1976.0320000000013,0.0,491520.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,30720.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",337,0.0,344064.0,0,0,0.0,344064.0,344064.0,0.0,13824.0,0.0,995328.0,196608.0,3.712,1979.7440000000013,294912.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,31104.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",338,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.24,1981.9840000000013,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",339,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.176,1984.1600000000012,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",340,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.496,1986.6560000000013,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",341,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,2.688,1989.3440000000014,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",342,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.4,1991.7440000000015,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",343,285871.0,719198.0,0,0,0.0,719198.0,719198.0,0.0,768.0,0.0,196608.0,196608.0,2.304,1994.0480000000016,49152.0,98304.0,285871.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",344,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.4,1996.4480000000017,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",345,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.656,1999.1040000000016,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_32x32_sliced1x4_nn,346,77070336.0,155344896.0,0,0,0.0,155344896.0,155344896.0,419328.0,114048.0,0.7861771058315334,14437312.0,344064.0,15.872,2014.9760000000017,516096.0,688128.0,77070336.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,451166.0,10752.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",347,0.0,110592.0,0,0,0.0,110592.0,110592.0,0.0,4224.0,0.0,347136.0,49152.0,3.264,2018.2400000000016,98304.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,10848.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",348,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.176,2020.4160000000015,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",349,102672.0,373712.0,0,0,0.0,373712.0,373712.0,320.0,1088.0,0.22727272727272727,147456.0,50176.0,4.224,2024.6400000000015,104640.0,63728.0,102672.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1568.0
ampere_sgemm_32x32_sliced1x4_nn,350,56623104.0,114794496.0,0,0,0.0,114794496.0,114794496.0,331776.0,86400.0,0.7933884297520661,10616832.0,442368.0,12.8,2037.4400000000014,663552.0,884736.0,56623104.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,13824.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",351,0.0,184320.0,0,0,0.0,184320.0,184320.0,0.0,8064.0,0.0,451584.0,147456.0,2.944,2040.3840000000014,147456.0,36864.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,14112.0,4608.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",352,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,4.064,2044.4480000000015,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",353,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,4.096,2048.5440000000012,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",354,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.688,2051.2320000000013,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",355,393216.0,13074432.0,0,0,0.0,13074432.0,13074432.0,102144.0,192.0,0.99812382739212,245760.0,49152.0,17.312,2068.5440000000012,9891840.0,2396160.0,393216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_32x32_sliced1x4_nn,356,18874368.0,38436864.0,0,0,0.0,38436864.0,38436864.0,116736.0,29184.0,0.8,3538944.0,196608.0,7.936,2076.4800000000014,294912.0,393216.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,110592.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",357,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,3072.0,0.0,199680.0,49152.0,2.72,2079.200000000001,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6240.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",358,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.08,2081.280000000001,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",359,102672.0,373712.0,0,0,0.0,373712.0,373712.0,320.0,1088.0,0.22727272727272727,147456.0,50176.0,4.224,2085.5040000000013,104640.0,63728.0,102672.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1568.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),360,75497472.0,151486464.0,0,0,0.0,151486464.0,151486464.0,253344.0,7680.0,0.9705774181684442,10616832.0,983040.0,14.368,2099.872000000001,0.0,491520.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,30720.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",361,0.0,344064.0,0,0,0.0,344064.0,344064.0,0.0,13824.0,0.0,995328.0,196608.0,3.744,2103.6160000000013,294912.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,31104.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",362,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.208,2105.8240000000014,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",363,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.208,2108.0320000000015,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",364,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.496,2110.5280000000016,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",365,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,2.592,2113.1200000000017,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",366,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.496,2115.616000000002,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",367,285509.0,718474.0,0,0,0.0,718474.0,718474.0,0.0,768.0,0.0,196608.0,196608.0,2.304,2117.920000000002,49152.0,98304.0,285509.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",368,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.368,2120.288000000002,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",369,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.56,2122.848000000002,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_32x32_sliced1x4_nn,370,77070336.0,155344896.0,0,0,0.0,155344896.0,155344896.0,419328.0,114048.0,0.7861771058315334,14435072.0,344064.0,16.16,2139.0080000000016,516096.0,688128.0,77070336.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,451096.0,10752.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",371,0.0,110592.0,0,0,0.0,110592.0,110592.0,0.0,4224.0,0.0,347136.0,49152.0,3.264,2142.2720000000018,98304.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,10848.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",372,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.144,2144.4160000000015,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",373,102672.0,373712.0,0,0,0.0,373712.0,373712.0,320.0,1088.0,0.22727272727272727,147456.0,50176.0,4.192,2148.6080000000015,104640.0,63728.0,102672.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1568.0
ampere_sgemm_32x32_sliced1x4_nn,374,56623104.0,114794496.0,0,0,0.0,114794496.0,114794496.0,331776.0,86400.0,0.7933884297520661,10616832.0,442368.0,12.448,2161.0560000000014,663552.0,884736.0,56623104.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,13824.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",375,0.0,184320.0,0,0,0.0,184320.0,184320.0,0.0,8064.0,0.0,451584.0,147456.0,2.912,2163.968000000001,147456.0,36864.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,14112.0,4608.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",376,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,4.096,2168.064000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",377,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,4.128,2172.1920000000014,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",378,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.72,2174.912000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",379,393216.0,13074432.0,0,0,0.0,13074432.0,13074432.0,102144.0,192.0,0.99812382739212,245760.0,49152.0,17.504,2192.416000000001,9891840.0,2396160.0,393216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_32x32_sliced1x4_nn,380,18874368.0,38436864.0,0,0,0.0,38436864.0,38436864.0,116736.0,29184.0,0.8,3538944.0,196608.0,8.16,2200.576000000001,294912.0,393216.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,110592.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",381,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,3072.0,0.0,199680.0,49152.0,2.72,2203.2960000000007,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6240.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",382,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.048,2205.3440000000005,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",383,102672.0,373712.0,0,0,0.0,373712.0,373712.0,320.0,1088.0,0.22727272727272727,147456.0,50176.0,4.224,2209.5680000000007,104640.0,63728.0,102672.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1568.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),384,75497472.0,151486464.0,0,0,0.0,151486464.0,151486464.0,253344.0,7680.0,0.9705774181684442,10616832.0,983040.0,13.92,2223.4880000000007,0.0,491520.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,30720.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",385,0.0,344064.0,0,0,0.0,344064.0,344064.0,0.0,13824.0,0.0,995328.0,196608.0,3.808,2227.2960000000007,294912.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,31104.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",386,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.304,2229.600000000001,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",387,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.272,2231.8720000000008,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",388,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.208,2234.080000000001,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",389,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,2.592,2236.672000000001,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",390,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.176,2238.848000000001,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",391,286003.0,719462.0,0,0,0.0,719462.0,719462.0,0.0,768.0,0.0,196608.0,196608.0,2.272,2241.120000000001,49152.0,98304.0,286003.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",392,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.176,2243.2960000000007,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",393,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.56,2245.8560000000007,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_32x32_sliced1x4_nn,394,77070336.0,155344896.0,0,0,0.0,155344896.0,155344896.0,419328.0,114048.0,0.7861771058315334,14438368.0,344064.0,15.808,2261.6640000000007,516096.0,688128.0,77070336.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,451199.0,10752.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",395,0.0,110592.0,0,0,0.0,110592.0,110592.0,0.0,4224.0,0.0,347136.0,49152.0,3.296,2264.9600000000005,98304.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,10848.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",396,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.144,2267.1040000000003,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",397,102672.0,373712.0,0,0,0.0,373712.0,373712.0,320.0,1088.0,0.22727272727272727,147456.0,50176.0,4.224,2271.3280000000004,104640.0,63728.0,102672.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1568.0
ampere_sgemm_32x32_sliced1x4_nn,398,56623104.0,114794496.0,0,0,0.0,114794496.0,114794496.0,331776.0,86400.0,0.7933884297520661,10616832.0,442368.0,12.416,2283.7440000000006,663552.0,884736.0,56623104.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,13824.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",399,0.0,184320.0,0,0,0.0,184320.0,184320.0,0.0,8064.0,0.0,451584.0,147456.0,3.104,2286.8480000000004,147456.0,36864.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,14112.0,4608.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",400,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,4.032,2290.8800000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",401,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,4.064,2294.9440000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",402,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.72,2297.664,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",403,393216.0,13074432.0,0,0,0.0,13074432.0,13074432.0,102144.0,192.0,0.99812382739212,245760.0,49152.0,17.728,2315.3920000000003,9891840.0,2396160.0,393216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_32x32_sliced1x4_nn,404,18874368.0,38436864.0,0,0,0.0,38436864.0,38436864.0,116736.0,29184.0,0.8,3538944.0,196608.0,8.512,2323.9040000000005,294912.0,393216.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,110592.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",405,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,3072.0,0.0,199680.0,49152.0,2.848,2326.7520000000004,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6240.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",406,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.176,2328.9280000000003,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",407,102672.0,373712.0,0,0,0.0,373712.0,373712.0,320.0,1088.0,0.22727272727272727,147456.0,50176.0,4.16,2333.088,104640.0,63728.0,102672.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1568.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),408,75497472.0,151486464.0,0,0,0.0,151486464.0,151486464.0,253344.0,7680.0,0.9705774181684442,10616832.0,983040.0,13.664,2346.7520000000004,0.0,491520.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,30720.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",409,0.0,344064.0,0,0,0.0,344064.0,344064.0,0.0,13824.0,0.0,995328.0,196608.0,3.584,2350.3360000000002,294912.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,31104.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",410,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.24,2352.576,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",411,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.208,2354.784,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",412,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.432,2357.216,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",413,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,2.432,2359.6479999999997,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",414,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.176,2361.8239999999996,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",415,285152.0,717760.0,0,0,0.0,717760.0,717760.0,0.0,768.0,0.0,196608.0,196608.0,2.432,2364.2559999999994,49152.0,98304.0,285152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",416,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.4,2366.6559999999995,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",417,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.656,2369.3119999999994,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_32x32_sliced1x4_nn,418,77070336.0,155344896.0,0,0,0.0,155344896.0,155344896.0,419328.0,114048.0,0.7861771058315334,14436128.0,344064.0,16.064,2385.3759999999993,516096.0,688128.0,77070336.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,451129.0,10752.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",419,0.0,110592.0,0,0,0.0,110592.0,110592.0,0.0,4224.0,0.0,347136.0,49152.0,3.36,2388.7359999999994,98304.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,10848.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",420,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.144,2390.879999999999,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",421,102672.0,373712.0,0,0,0.0,373712.0,373712.0,320.0,1088.0,0.22727272727272727,147456.0,50176.0,4.224,2395.1039999999994,104640.0,63728.0,102672.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1568.0
ampere_sgemm_32x32_sliced1x4_nn,422,56623104.0,114794496.0,0,0,0.0,114794496.0,114794496.0,331776.0,86400.0,0.7933884297520661,10616832.0,442368.0,12.992,2408.0959999999995,663552.0,884736.0,56623104.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,13824.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",423,0.0,184320.0,0,0,0.0,184320.0,184320.0,0.0,8064.0,0.0,451584.0,147456.0,3.008,2411.1039999999994,147456.0,36864.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,14112.0,4608.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",424,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,4.128,2415.2319999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",425,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,4.064,2419.2959999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",426,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.688,2421.9839999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",427,393216.0,13074432.0,0,0,0.0,13074432.0,13074432.0,102144.0,192.0,0.99812382739212,245760.0,49152.0,17.472,2439.4559999999997,9891840.0,2396160.0,393216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_32x32_sliced1x4_nn,428,18874368.0,38436864.0,0,0,0.0,38436864.0,38436864.0,116736.0,29184.0,0.8,3538944.0,196608.0,7.968,2447.4239999999995,294912.0,393216.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,110592.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",429,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,3072.0,0.0,199680.0,49152.0,2.784,2450.2079999999996,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6240.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",430,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.08,2452.2879999999996,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",431,102672.0,373712.0,0,0,0.0,373712.0,373712.0,320.0,1088.0,0.22727272727272727,147456.0,50176.0,4.192,2456.4799999999996,104640.0,63728.0,102672.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1568.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),432,75497472.0,151486464.0,0,0,0.0,151486464.0,151486464.0,253344.0,7680.0,0.9705774181684442,10616832.0,983040.0,13.856,2470.336,0.0,491520.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,30720.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",433,0.0,344064.0,0,0,0.0,344064.0,344064.0,0.0,13824.0,0.0,995328.0,196608.0,3.616,2473.9519999999998,294912.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,31104.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",434,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.176,2476.1279999999997,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",435,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.176,2478.3039999999996,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",436,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.24,2480.5439999999994,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",437,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,2.624,2483.167999999999,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",438,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.176,2485.343999999999,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",439,285664.0,718784.0,0,0,0.0,718784.0,718784.0,0.0,768.0,0.0,196608.0,196608.0,2.272,2487.615999999999,49152.0,98304.0,285664.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",440,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.432,2490.047999999999,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",441,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.72,2492.7679999999987,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_32x32_sliced1x4_nn,442,77070336.0,155344896.0,0,0,0.0,155344896.0,155344896.0,419328.0,114048.0,0.7861771058315334,14439616.0,344064.0,15.808,2508.5759999999987,516096.0,688128.0,77070336.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,451238.0,10752.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",443,0.0,110592.0,0,0,0.0,110592.0,110592.0,0.0,4224.0,0.0,347136.0,49152.0,3.264,2511.839999999999,98304.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,10848.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",444,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.24,2514.0799999999986,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",445,102672.0,373712.0,0,0,0.0,373712.0,373712.0,320.0,1088.0,0.22727272727272727,147456.0,50176.0,4.192,2518.2719999999986,104640.0,63728.0,102672.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1568.0
ampere_sgemm_32x32_sliced1x4_nn,446,56623104.0,114794496.0,0,0,0.0,114794496.0,114794496.0,331776.0,86400.0,0.7933884297520661,10616832.0,442368.0,12.832,2531.1039999999985,663552.0,884736.0,56623104.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,13824.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",447,0.0,184320.0,0,0,0.0,184320.0,184320.0,0.0,8064.0,0.0,451584.0,147456.0,2.976,2534.0799999999986,147456.0,36864.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,14112.0,4608.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",448,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,4.064,2538.1439999999984,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",449,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,4.096,2542.2399999999984,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",450,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.72,2544.959999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",451,393216.0,13074432.0,0,0,0.0,13074432.0,13074432.0,102144.0,192.0,0.99812382739212,245760.0,49152.0,17.632,2562.5919999999983,9891840.0,2396160.0,393216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_32x32_sliced1x4_nn,452,18874368.0,38436864.0,0,0,0.0,38436864.0,38436864.0,116736.0,29184.0,0.8,3538944.0,196608.0,8.128,2570.7199999999984,294912.0,393216.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,110592.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",453,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,3072.0,0.0,199680.0,49152.0,2.784,2573.5039999999985,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6240.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",454,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.048,2575.5519999999983,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",455,102672.0,373712.0,0,0,0.0,373712.0,373712.0,320.0,1088.0,0.22727272727272727,147456.0,50176.0,4.224,2579.7759999999985,104640.0,63728.0,102672.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1568.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),456,75497472.0,151486464.0,0,0,0.0,151486464.0,151486464.0,253344.0,7680.0,0.9705774181684442,10616832.0,983040.0,14.048,2593.8239999999983,0.0,491520.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,30720.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",457,0.0,344064.0,0,0,0.0,344064.0,344064.0,0.0,13824.0,0.0,995328.0,196608.0,3.712,2597.5359999999982,294912.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,31104.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",458,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.432,2599.967999999998,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",459,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.368,2602.335999999998,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",460,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.176,2604.511999999998,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",461,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,2.464,2606.975999999998,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",462,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.144,2609.1199999999976,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",463,285701.0,718858.0,0,0,0.0,718858.0,718858.0,0.0,768.0,0.0,196608.0,196608.0,2.304,2611.4239999999977,49152.0,98304.0,285701.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",464,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.208,2613.631999999998,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",465,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.432,2616.0639999999976,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_32x32_sliced1x4_nn,466,77070336.0,155344896.0,0,0,0.0,155344896.0,155344896.0,419328.0,114048.0,0.7861771058315334,14432160.0,344064.0,16.128,2632.1919999999977,516096.0,688128.0,77070336.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,451005.0,10752.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",467,0.0,110592.0,0,0,0.0,110592.0,110592.0,0.0,4224.0,0.0,347136.0,49152.0,3.264,2635.455999999998,98304.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,10848.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",468,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.176,2637.631999999998,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",469,102672.0,373712.0,0,0,0.0,373712.0,373712.0,320.0,1088.0,0.22727272727272727,147456.0,50176.0,4.16,2641.7919999999976,104640.0,63728.0,102672.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1568.0
ampere_sgemm_32x32_sliced1x4_nn,470,56623104.0,114794496.0,0,0,0.0,114794496.0,114794496.0,331776.0,86400.0,0.7933884297520661,10616832.0,442368.0,12.64,2654.4319999999975,663552.0,884736.0,56623104.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,13824.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",471,0.0,184320.0,0,0,0.0,184320.0,184320.0,0.0,8064.0,0.0,451584.0,147456.0,2.944,2657.3759999999975,147456.0,36864.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,14112.0,4608.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",472,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,4.096,2661.4719999999975,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",473,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,4.128,2665.5999999999976,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",474,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.784,2668.3839999999977,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",475,393216.0,13074432.0,0,0,0.0,13074432.0,13074432.0,102144.0,192.0,0.99812382739212,245760.0,49152.0,17.6,2685.9839999999976,9891840.0,2396160.0,393216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_32x32_sliced1x4_nn,476,18874368.0,38436864.0,0,0,0.0,38436864.0,38436864.0,116736.0,29184.0,0.8,3538944.0,196608.0,8.48,2694.4639999999977,294912.0,393216.0,18874368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,110592.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",477,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,3072.0,0.0,199680.0,49152.0,2.688,2697.1519999999978,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6240.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",478,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.08,2699.2319999999977,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",479,102672.0,373712.0,0,0,0.0,373712.0,373712.0,320.0,1088.0,0.22727272727272727,147456.0,50176.0,4.352,2703.5839999999976,104640.0,63728.0,102672.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1568.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),480,75497472.0,151486464.0,0,0,0.0,151486464.0,151486464.0,253344.0,7680.0,0.9705774181684442,10616832.0,983040.0,13.888,2717.4719999999975,0.0,491520.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,30720.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",481,0.0,344064.0,0,0,0.0,344064.0,344064.0,0.0,13824.0,0.0,995328.0,196608.0,3.648,2721.1199999999976,294912.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,31104.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",482,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.208,2723.3279999999977,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",483,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.176,2725.5039999999976,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",484,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.304,2727.8079999999977,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",485,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,2.624,2730.4319999999975,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",486,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.176,2732.6079999999974,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",487,285664.0,718784.0,0,0,0.0,718784.0,718784.0,0.0,768.0,0.0,196608.0,196608.0,2.368,2734.9759999999974,49152.0,98304.0,285664.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",488,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.208,2737.1839999999975,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",489,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.688,2739.8719999999976,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_32x32_sliced1x4_nn,490,77070336.0,155344896.0,0,0,0.0,155344896.0,155344896.0,419328.0,114048.0,0.7861771058315334,14437952.0,344064.0,16.096,2755.9679999999976,516096.0,688128.0,77070336.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,451186.0,10752.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",491,0.0,110592.0,0,0,0.0,110592.0,110592.0,0.0,4224.0,0.0,347136.0,49152.0,3.264,2759.2319999999977,98304.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,10848.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",492,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,2761.343999999998,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",493,102672.0,373712.0,0,0,0.0,373712.0,373712.0,320.0,1088.0,0.22727272727272727,147456.0,50176.0,4.192,2765.535999999998,104640.0,63728.0,102672.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1568.0
ampere_sgemm_64x32_sliced1x4_tn,494,1236271104.0,2483810304.0,0,0,0.0,2483810304.0,2483810304.0,5810112.0,1533128.0,0.7912191348777924,177938048.0,3201088.0,189.408,2954.9439999999977,4829184.0,6438912.0,1236271104.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5560564.0,100034.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",495,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,1.696,2956.6399999999976,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,4.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",496,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,384.0,640.0,2.624,2959.2639999999974,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12.0,20.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",497,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,2961.3439999999973,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",498,0.0,804112.0,0,0,0.0,804112.0,804112.0,0.0,12578.0,0.0,3216448.0,3216448.0,5.728,2967.0719999999974,0.0,804112.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,100514.0,100514.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",499,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,64.0,1.696,2968.7679999999973,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,2.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",500,0.0,0.0,0,0,0.0,0.0,0.0,10240.0,35376.0,0.22448263767099264,3236160.0,190336.0,6.144,2974.911999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,101130.0,5948.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",501,0.0,0.0,0,0,0.0,0.0,0.0,47360.0,213152.0,0.18179584817589978,8405984.0,704.0,6.432,2981.343999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,262687.0,22.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",502,0.0,0.0,0,0,0.0,0.0,0.0,10240.0,35376.0,0.22448263767099264,3236160.0,187520.0,6.208,2987.551999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,101130.0,5860.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",503,0.0,0.0,0,0,0.0,0.0,0.0,47360.0,216992.0,0.17915506597264252,8405792.0,512.0,6.368,2993.919999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,262681.0,16.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",504,0.0,0.0,0,0,0.0,0.0,0.0,10240.0,35376.0,0.22448263767099264,3236160.0,187392.0,6.368,3000.287999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,101130.0,5856.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",505,0.0,0.0,0,0,0.0,0.0,0.0,47360.0,214352.0,0.18096227914654275,8405792.0,448.0,6.304,3006.591999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,262681.0,14.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",506,0.0,0.0,0,0,0.0,0.0,0.0,10240.0,35376.0,0.22448263767099264,3236160.0,186496.0,6.112,3012.703999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,101130.0,5828.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",507,0.0,0.0,0,0,0.0,0.0,0.0,47360.0,214712.0,0.1807136969992979,8405760.0,1120.0,6.4,3019.103999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,262680.0,35.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",508,0.0,0.0,0,0,0.0,0.0,0.0,0.0,60.0,0.0,20544.0,2560.0,3.52,3022.623999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,642.0,80.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",509,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.696,3024.319999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",510,0.0,0.0,0,0,0.0,0.0,0.0,497.0,48.0,0.9119266055045872,2560.0,0.0,3.712,3028.031999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,80.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",511,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.728,3029.759999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",512,0.0,0.0,0,0,0.0,0.0,0.0,497.0,48.0,0.9119266055045872,2560.0,0.0,3.648,3033.407999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,80.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",513,0.0,0.0,0,0,0.0,0.0,0.0,225264.0,46944.0,0.8275436430964557,3274240.0,23616.0,8.128,3041.5359999999973,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,102320.0,738.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",514,0.0,0.0,0,0,0.0,0.0,0.0,7328.0,128.0,0.9828326180257511,10240.0,2080.0,6.496,3048.0319999999974,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,320.0,65.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",515,0.0,0.0,0,0,0.0,0.0,0.0,0.0,75387.0,0.0,3238912.0,332576.0,6.816,3054.8479999999972,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,101216.0,10393.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",516,0.0,0.0,0,0,0.0,0.0,0.0,0.0,18867.0,0.0,4020576.0,3072.0,6.752,3061.599999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,125643.0,96.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",517,0.0,0.0,0,0,0.0,0.0,0.0,0.0,25129.0,0.0,0.0,6432896.0,5.536,3067.1359999999972,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,201028.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",518,0.0,0.0,0,0,0.0,0.0,0.0,98304.0,25129.0,0.7964158693380214,3216448.0,0.0,7.2,3074.335999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,100514.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",519,0.0,0.0,0,0,0.0,0.0,0.0,156.0,64.0,0.7090909090909091,8192.0,0.0,2.144,3076.479999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",520,0.0,0.0,0,0,0.0,0.0,0.0,317725.0,120169.0,0.7255751391889361,12524864.0,8083296.0,20.832,3097.3119999999967,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,391402.0,252603.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",521,0.0,0.0,0,0,0.0,0.0,0.0,89194.0,144214.0,0.3821377159309021,12568768.0,9917632.0,17.312,3114.6239999999966,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,392774.0,309926.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",522,0.0,0.0,0,0,0.0,0.0,0.0,90025.0,144609.0,0.3836826717355541,12527552.0,9917632.0,17.952,3132.575999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,391486.0,309926.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",523,0.0,0.0,0,0,0.0,0.0,0.0,90025.0,142164.0,0.3877229326109333,12569408.0,9916544.0,17.664,3150.239999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,392794.0,309892.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",524,0.0,0.0,0,0,0.0,0.0,0.0,14336.0,25129.0,0.36325858355504875,6432896.0,0.0,9.76,3159.9999999999973,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,201028.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",525,0.0,0.0,0,0,0.0,0.0,0.0,39.0,16.0,0.7090909090909091,2048.0,0.0,2.176,3162.175999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",526,0.0,0.0,0,0,0.0,0.0,0.0,80036.0,126243.0,0.3879987783535891,10312320.0,5880000.0,16.352,3178.527999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,322260.0,183750.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",527,0.0,0.0,0,0,0.0,0.0,0.0,0.0,100516.0,0.0,9709888.0,9649344.0,12.832,3191.359999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,303434.0,301542.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",528,11257568.0,26620176.0,0,0,0.0,26620176.0,26620176.0,2112.0,26816.0,0.07300884955752213,8749952.0,2918304.0,24.32,3215.679999999997,3300928.0,804112.0,11257568.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,273436.0,91197.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",529,0.0,4096800.0,0,0,0.0,4096800.0,4096800.0,449136.0,50272.0,0.8993368147887099,3218688.0,2285920.0,72.608,3288.2879999999973,4096800.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,100584.0,71435.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",530,0.0,0.0,0,0,0.0,0.0,0.0,0.0,12578.0,0.0,3216448.0,803936.0,5.696,3293.983999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,100514.0,25123.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",531,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,512.0,1.92,3295.9039999999973,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,16.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",532,0.0,0.0,0,0,0.0,0.0,0.0,0.0,75387.0,0.0,7237024.0,371360.0,11.552,3307.4559999999974,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,226157.0,11605.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",533,0.0,0.0,0,0,0.0,0.0,0.0,0.0,18867.0,0.0,4020576.0,2304.0,6.656,3314.1119999999974,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,125643.0,72.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",534,11257568.0,26620176.0,0,0,0.0,26620176.0,26620176.0,2112.0,26816.0,0.07300884955752213,8701952.0,2910432.0,24.352,3338.463999999997,3300928.0,804112.0,11257568.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,271936.0,90951.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",535,0.0,0.0,0,0,0.0,0.0,0.0,7883.0,6387.0,0.5524176594253679,3216864.0,3200.0,8.256,3346.719999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,100527.0,100.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",536,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,3348.863999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",537,0.0,0.0,0,0,0.0,0.0,0.0,7883.0,6387.0,0.5524176594253679,3216864.0,3200.0,8.512,3357.375999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,100527.0,100.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",538,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.24,3359.615999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",539,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.08,3361.6959999999967,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",540,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.944,3364.6399999999967,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",541,0.0,877328.0,0,0,0.0,877328.0,877328.0,736.0,6328.0,0.10419026047565119,3216928.0,512.0,11.52,3376.1599999999967,877328.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,100529.0,16.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",542,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,1.984,3378.1439999999966,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",543,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,3381.4399999999964,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",544,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,3383.4559999999965,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",545,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.976,3386.4319999999966,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",546,2555904.0,6720032.0,0,0,0.0,6720032.0,6720032.0,0.0,25129.0,0.0,0.0,3216448.0,5.216,3391.6479999999965,0.0,1608224.0,2555904.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,100514.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",547,4020560.0,8041120.0,0,0,0.0,8041120.0,8041120.0,0.0,18867.0,0.0,6432896.0,20480.0,9.952,3401.5999999999967,0.0,0.0,4020560.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,201028.0,640.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",548,0.0,0.0,0,0,0.0,0.0,0.0,1472.0,6328.0,0.18871794871794872,3217888.0,512.0,15.68,3417.2799999999966,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,100559.0,16.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",549,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,256.0,128.0,2.112,3419.3919999999966,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",550,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,128.0,2.112,3421.5039999999967,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,4.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",551,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,160.0,128.0,2.24,3423.7439999999965,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",552,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,256.0,128.0,2.112,3425.8559999999966,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8.0,4.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",553,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,384.0,640.0,2.624,3428.4799999999964,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12.0,20.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",554,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,3430.2079999999964,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",555,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,3431.9039999999964,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",556,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.048,3433.951999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",557,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,3435.679999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",558,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,416.0,32.0,2.304,3437.9839999999963,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,13.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",559,0.0,0.0,0,0,0.0,0.0,0.0,0.0,5.0,0.0,32.0,32.0,4.704,3442.6879999999965,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",560,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.08,3444.7679999999964,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",561,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.112,3446.8799999999965,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",562,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,160.0,128.0,2.816,3449.6959999999963,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5.0,4.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",563,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,32.0,3.264,3452.9599999999964,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",564,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,3455.0399999999963,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
