Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.824,1.824,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,3.52,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,5.216,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.016,7.232,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.24,9.472000000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",6,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.304,11.776000000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",7,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,15.168000000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",8,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.168,18.336000000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",9,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,20.480000000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",10,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.664,22.144000000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",11,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.632,23.776000000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.664,25.44000000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,0.0,0.0,0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,2.4,27.840000000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,29.85600000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",15,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.112,31.96800000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",16,0.0,0.0,0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,32.0,32.0,2.496,34.46400000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",17,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,36.448000000000015,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",18,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,38.432000000000016,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",19,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,2.016,40.448000000000015,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",20,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1152.0,0.0,13056.0,49152.0,3.84,44.28800000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,408.0,1536.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",21,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1152.0,0.0,13056.0,49152.0,3.712,48.000000000000014,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,408.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",22,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.08,50.08000000000001,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",23,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,52.064000000000014,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",24,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,55.39200000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",25,71748.0,240884.0,0,0,0.0,240884.0,240884.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,7.264,62.65600000000002,72240.0,25148.0,71748.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1544.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),26,905969664.0,1812824064.0,0,0,0.0,1812824064.0,1812824064.0,2712096.0,3456.0,0.9987273305758829,116785152.0,442368.0,126.688,189.34400000000002,0.0,884736.0,905969664.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3649536.0,13824.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",27,0.0,184320.0,0,0,0.0,184320.0,184320.0,0.0,11520.0,0.0,479232.0,147456.0,3.584,192.92800000000003,147456.0,36864.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,14976.0,4608.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",28,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.688,195.616,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",29,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.624,198.24,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",30,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.656,200.89600000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",31,393216.0,13062144.0,0,0,0.0,13062144.0,13062144.0,102144.0,192.0,0.99812382739212,147456.0,49152.0,18.336,219.23200000000003,9879552.0,2396160.0,393216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_128x32_sliced1x4_nn,32,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,306432.0,0.7831816329303084,38956256.0,245760.0,45.664,264.896,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1217383.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",33,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,2.72,267.61600000000004,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",34,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.144,269.76000000000005,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",35,71748.0,240884.0,0,0,0.0,240884.0,240884.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,7.2,276.96000000000004,72240.0,25148.0,71748.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1544.0
ampere_sgemm_32x32_sliced1x4_nn,36,1208352768.0,2419458048.0,0,0,0.0,2419458048.0,2419458048.0,5996544.0,1330176.0,0.8184486373165618,158283520.0,196608.0,166.56,443.52000000000004,1179648.0,1572864.0,1208352768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4946360.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",37,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.24,445.76000000000005,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",38,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.176,447.93600000000004,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",39,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.144,450.08000000000004,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",40,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,2.592,452.672,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",41,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.144,454.81600000000003,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",42,269360.0,686176.0,0,0,0.0,686176.0,686176.0,0.0,768.0,0.0,196608.0,196608.0,2.208,457.02400000000006,49152.0,98304.0,269360.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",43,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.112,459.1360000000001,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",44,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.432,461.5680000000001,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_128x32_sliced1x4_nn,45,1211105280.0,2425651200.0,0,0,0.0,2425651200.0,2425651200.0,3952320.0,1218528.0,0.764346582997605,155781952.0,245760.0,164.576,626.1440000000001,1474560.0,1966080.0,1211105280.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4868186.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",46,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,2.688,628.8320000000001,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",47,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,630.9440000000001,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",48,71748.0,240884.0,0,0,0.0,240884.0,240884.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,7.072,638.0160000000001,72240.0,25148.0,71748.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1544.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),49,905969664.0,1812824064.0,0,0,0.0,1812824064.0,1812824064.0,2712096.0,3456.0,0.9987273305758829,116785152.0,442368.0,126.4,764.416,0.0,884736.0,905969664.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3649536.0,13824.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",50,0.0,184320.0,0,0,0.0,184320.0,184320.0,0.0,11520.0,0.0,479232.0,147456.0,3.648,768.0640000000001,147456.0,36864.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,14976.0,4608.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",51,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.656,770.72,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",52,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.656,773.376,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",53,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.624,776.0,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",54,393216.0,13062144.0,0,0,0.0,13062144.0,13062144.0,102144.0,192.0,0.99812382739212,147456.0,49152.0,17.408,793.408,9879552.0,2396160.0,393216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_128x32_sliced1x4_nn,55,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,306432.0,0.7831816329303084,38956256.0,245760.0,45.856,839.264,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1217383.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",56,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,2.688,841.952,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",57,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.144,844.096,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",58,71748.0,240884.0,0,0,0.0,240884.0,240884.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,7.104,851.2,72240.0,25148.0,71748.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1544.0
ampere_sgemm_32x32_sliced1x4_nn,59,1208352768.0,2419458048.0,0,0,0.0,2419458048.0,2419458048.0,5996544.0,1330176.0,0.8184486373165618,158880512.0,196608.0,165.728,1016.9280000000001,1179648.0,1572864.0,1208352768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4965016.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",60,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.208,1019.1360000000001,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",61,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.112,1021.248,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",62,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.112,1023.36,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",63,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,2.496,1025.856,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",64,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.112,1027.968,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",65,269940.0,687336.0,0,0,0.0,687336.0,687336.0,0.0,768.0,0.0,196608.0,196608.0,2.24,1030.208,49152.0,98304.0,269940.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",66,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.112,1032.3200000000002,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",67,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.592,1034.9120000000003,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_128x32_sliced1x4_nn,68,1211105280.0,2425651200.0,0,0,0.0,2425651200.0,2425651200.0,3952320.0,1218528.0,0.764346582997605,155780448.0,245760.0,163.904,1198.8160000000003,1474560.0,1966080.0,1211105280.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4868139.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",69,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,2.72,1201.5360000000003,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",70,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.08,1203.6160000000002,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",71,71748.0,240884.0,0,0,0.0,240884.0,240884.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,7.168,1210.784,72240.0,25148.0,71748.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1544.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),72,905969664.0,1812824064.0,0,0,0.0,1812824064.0,1812824064.0,2712096.0,3456.0,0.9987273305758829,116785152.0,442368.0,125.44,1336.2240000000002,0.0,884736.0,905969664.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3649536.0,13824.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",73,0.0,184320.0,0,0,0.0,184320.0,184320.0,0.0,11520.0,0.0,479232.0,147456.0,3.552,1339.776,147456.0,36864.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,14976.0,4608.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",74,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.72,1342.496,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",75,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.592,1345.0880000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",76,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.688,1347.7760000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",77,393216.0,13062144.0,0,0,0.0,13062144.0,13062144.0,102144.0,192.0,0.99812382739212,147456.0,49152.0,17.472,1365.2480000000003,9879552.0,2396160.0,393216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_128x32_sliced1x4_nn,78,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,306432.0,0.7831816329303084,38956096.0,245760.0,45.792,1411.0400000000002,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1217378.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",79,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,2.752,1413.7920000000001,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",80,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.08,1415.872,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",81,71748.0,240884.0,0,0,0.0,240884.0,240884.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,7.2,1423.0720000000001,72240.0,25148.0,71748.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1544.0
ampere_sgemm_32x32_sliced1x4_nn,82,1208352768.0,2419458048.0,0,0,0.0,2419458048.0,2419458048.0,5996544.0,1330176.0,0.8184486373165618,158520576.0,196608.0,166.912,1589.9840000000002,1179648.0,1572864.0,1208352768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4953768.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",83,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.176,1592.16,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",84,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.336,1594.496,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",85,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.144,1596.64,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",86,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,2.368,1599.008,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",87,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.208,1601.2160000000001,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",88,270324.0,688104.0,0,0,0.0,688104.0,688104.0,0.0,768.0,0.0,196608.0,196608.0,2.24,1603.4560000000001,49152.0,98304.0,270324.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",89,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.208,1605.6640000000002,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",90,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.592,1608.2560000000003,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_128x32_sliced1x4_nn,91,1211105280.0,2425651200.0,0,0,0.0,2425651200.0,2425651200.0,3952320.0,1218528.0,0.764346582997605,155780320.0,245760.0,163.84,1772.0960000000002,1474560.0,1966080.0,1211105280.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4868135.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",92,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,2.72,1774.8160000000003,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",93,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.08,1776.8960000000002,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",94,71748.0,240884.0,0,0,0.0,240884.0,240884.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,6.976,1783.8720000000003,72240.0,25148.0,71748.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1544.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),95,905969664.0,1812824064.0,0,0,0.0,1812824064.0,1812824064.0,2712096.0,3456.0,0.9987273305758829,116785152.0,442368.0,125.44,1909.3120000000004,0.0,884736.0,905969664.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3649536.0,13824.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",96,0.0,184320.0,0,0,0.0,184320.0,184320.0,0.0,11520.0,0.0,479232.0,147456.0,3.552,1912.8640000000003,147456.0,36864.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,14976.0,4608.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",97,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.624,1915.4880000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",98,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.624,1918.1120000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",99,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.592,1920.7040000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",100,393216.0,13062144.0,0,0,0.0,13062144.0,13062144.0,102144.0,192.0,0.99812382739212,147456.0,49152.0,17.536,1938.2400000000005,9879552.0,2396160.0,393216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_128x32_sliced1x4_nn,101,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,306432.0,0.7831816329303084,38955488.0,245760.0,45.952,1984.1920000000005,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1217359.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",102,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,2.848,1987.0400000000004,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",103,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.08,1989.1200000000003,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",104,71748.0,240884.0,0,0,0.0,240884.0,240884.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,7.168,1996.2880000000002,72240.0,25148.0,71748.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1544.0
ampere_sgemm_32x32_sliced1x4_nn,105,1208352768.0,2419458048.0,0,0,0.0,2419458048.0,2419458048.0,5996544.0,1330176.0,0.8184486373165618,158179968.0,196608.0,168.64,2164.9280000000003,1179648.0,1572864.0,1208352768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4943124.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",106,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.336,2167.264,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",107,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.144,2169.408,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",108,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.176,2171.584,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",109,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,2.496,2174.08,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",110,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.144,2176.2239999999997,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",111,270132.0,687720.0,0,0,0.0,687720.0,687720.0,0.0,768.0,0.0,196608.0,196608.0,2.272,2178.4959999999996,49152.0,98304.0,270132.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",112,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.144,2180.6399999999994,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",113,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.56,2183.1999999999994,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_128x32_sliced1x4_nn,114,1211105280.0,2425651200.0,0,0,0.0,2425651200.0,2425651200.0,3952320.0,1218528.0,0.764346582997605,155782496.0,245760.0,164.064,2347.263999999999,1474560.0,1966080.0,1211105280.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4868203.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",115,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,2.72,2349.983999999999,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",116,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.24,2352.223999999999,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",117,71748.0,240884.0,0,0,0.0,240884.0,240884.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,7.168,2359.391999999999,72240.0,25148.0,71748.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1544.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),118,905969664.0,1812824064.0,0,0,0.0,1812824064.0,1812824064.0,2712096.0,3456.0,0.9987273305758829,116785152.0,442368.0,125.92,2485.311999999999,0.0,884736.0,905969664.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3649536.0,13824.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",119,0.0,184320.0,0,0,0.0,184320.0,184320.0,0.0,11520.0,0.0,479232.0,147456.0,3.616,2488.927999999999,147456.0,36864.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,14976.0,4608.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",120,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.688,2491.615999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",121,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.688,2494.303999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",122,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.624,2496.927999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",123,393216.0,13062144.0,0,0,0.0,13062144.0,13062144.0,102144.0,192.0,0.99812382739212,147456.0,49152.0,17.952,2514.879999999999,9879552.0,2396160.0,393216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_128x32_sliced1x4_nn,124,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,306432.0,0.7831816329303084,38955744.0,245760.0,45.888,2560.767999999999,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1217367.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",125,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,2.688,2563.455999999999,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",126,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,2565.5679999999993,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",127,71748.0,240884.0,0,0,0.0,240884.0,240884.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,7.072,2572.6399999999994,72240.0,25148.0,71748.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1544.0
ampere_sgemm_32x32_sliced1x4_nn,128,1208352768.0,2419458048.0,0,0,0.0,2419458048.0,2419458048.0,5996544.0,1330176.0,0.8184486373165618,158439040.0,196608.0,166.432,2739.071999999999,1179648.0,1572864.0,1208352768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4951220.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",129,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.272,2741.343999999999,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",130,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.112,2743.455999999999,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",131,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.112,2745.5679999999993,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",132,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,2.528,2748.095999999999,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",133,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.24,2750.335999999999,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",134,269960.0,687376.0,0,0,0.0,687376.0,687376.0,0.0,768.0,0.0,196608.0,196608.0,2.24,2752.5759999999987,49152.0,98304.0,269960.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",135,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.112,2754.6879999999987,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",136,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.528,2757.2159999999985,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_128x32_sliced1x4_nn,137,1211105280.0,2425651200.0,0,0,0.0,2425651200.0,2425651200.0,3952320.0,1218528.0,0.764346582997605,155780896.0,245760.0,164.192,2921.4079999999985,1474560.0,1966080.0,1211105280.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4868153.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",138,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,2.848,2924.2559999999985,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",139,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.08,2926.3359999999984,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",140,71748.0,240884.0,0,0,0.0,240884.0,240884.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,7.072,2933.4079999999985,72240.0,25148.0,71748.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1544.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),141,905969664.0,1812824064.0,0,0,0.0,1812824064.0,1812824064.0,2712096.0,3456.0,0.9987273305758829,116785152.0,442368.0,125.824,3059.2319999999986,0.0,884736.0,905969664.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3649536.0,13824.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",142,0.0,184320.0,0,0,0.0,184320.0,184320.0,0.0,11520.0,0.0,479232.0,147456.0,3.552,3062.7839999999987,147456.0,36864.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,14976.0,4608.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",143,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.656,3065.4399999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",144,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.688,3068.127999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",145,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.656,3070.7839999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",146,393216.0,13062144.0,0,0,0.0,13062144.0,13062144.0,102144.0,192.0,0.99812382739212,147456.0,49152.0,17.696,3088.4799999999987,9879552.0,2396160.0,393216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_128x32_sliced1x4_nn,147,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,306432.0,0.7831816329303084,38955296.0,245760.0,45.792,3134.2719999999986,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1217353.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",148,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,2.976,3137.2479999999987,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",149,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.08,3139.3279999999986,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",150,71748.0,240884.0,0,0,0.0,240884.0,240884.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,7.136,3146.4639999999986,72240.0,25148.0,71748.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1544.0
ampere_sgemm_32x32_sliced1x4_nn,151,1208352768.0,2419458048.0,0,0,0.0,2419458048.0,2419458048.0,5996544.0,1330176.0,0.8184486373165618,158291584.0,196608.0,165.76,3312.2239999999983,1179648.0,1572864.0,1208352768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4946612.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",152,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.144,3314.367999999998,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",153,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.24,3316.607999999998,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",154,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.176,3318.783999999998,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",155,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,2.56,3321.343999999998,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",156,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.368,3323.7119999999977,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",157,269948.0,687352.0,0,0,0.0,687352.0,687352.0,0.0,768.0,0.0,196608.0,196608.0,2.272,3325.9839999999976,49152.0,98304.0,269948.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",158,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.144,3328.1279999999974,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",159,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.464,3330.5919999999974,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_128x32_sliced1x4_nn,160,1211105280.0,2425651200.0,0,0,0.0,2425651200.0,2425651200.0,3952320.0,1218528.0,0.764346582997605,155780800.0,245760.0,164.096,3494.6879999999974,1474560.0,1966080.0,1211105280.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4868150.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",161,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,2.72,3497.407999999997,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",162,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,3499.5199999999973,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",163,71748.0,240884.0,0,0,0.0,240884.0,240884.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,7.168,3506.6879999999974,72240.0,25148.0,71748.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1544.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),164,905969664.0,1812824064.0,0,0,0.0,1812824064.0,1812824064.0,2712096.0,3456.0,0.9987273305758829,116785152.0,442368.0,126.464,3633.1519999999973,0.0,884736.0,905969664.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3649536.0,13824.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",165,0.0,184320.0,0,0,0.0,184320.0,184320.0,0.0,11520.0,0.0,479232.0,147456.0,3.584,3636.735999999997,147456.0,36864.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,14976.0,4608.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",166,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.784,3639.5199999999973,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",167,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.656,3642.175999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",168,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.72,3644.895999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",169,393216.0,13062144.0,0,0,0.0,13062144.0,13062144.0,102144.0,192.0,0.99812382739212,147456.0,49152.0,17.568,3662.463999999997,9879552.0,2396160.0,393216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_128x32_sliced1x4_nn,170,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,306432.0,0.7831816329303084,38955552.0,245760.0,45.792,3708.255999999997,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1217361.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",171,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,2.816,3711.071999999997,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",172,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.176,3713.247999999997,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",173,71748.0,240884.0,0,0,0.0,240884.0,240884.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,7.104,3720.3519999999967,72240.0,25148.0,71748.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1544.0
ampere_sgemm_32x32_sliced1x4_nn,174,1208352768.0,2419458048.0,0,0,0.0,2419458048.0,2419458048.0,5996544.0,1330176.0,0.8184486373165618,158534784.0,196608.0,167.232,3887.5839999999966,1179648.0,1572864.0,1208352768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4954212.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",175,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.176,3889.7599999999966,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",176,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.112,3891.8719999999967,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",177,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.144,3894.0159999999964,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",178,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,2.432,3896.4479999999962,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",179,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.144,3898.591999999996,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",180,269816.0,687088.0,0,0,0.0,687088.0,687088.0,0.0,768.0,0.0,196608.0,196608.0,2.304,3900.895999999996,49152.0,98304.0,269816.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",181,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.176,3903.071999999996,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",182,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.592,3905.663999999996,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_128x32_sliced1x4_nn,183,1211105280.0,2425651200.0,0,0,0.0,2425651200.0,2425651200.0,3952320.0,1218528.0,0.764346582997605,155781760.0,245760.0,163.872,4069.535999999996,1474560.0,1966080.0,1211105280.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4868180.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",184,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,2.752,4072.287999999996,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",185,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,4074.399999999996,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",186,71748.0,240884.0,0,0,0.0,240884.0,240884.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,7.136,4081.535999999996,72240.0,25148.0,71748.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1544.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),187,905969664.0,1812824064.0,0,0,0.0,1812824064.0,1812824064.0,2712096.0,3456.0,0.9987273305758829,116785152.0,442368.0,126.496,4208.031999999996,0.0,884736.0,905969664.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3649536.0,13824.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",188,0.0,184320.0,0,0,0.0,184320.0,184320.0,0.0,11520.0,0.0,479232.0,147456.0,3.648,4211.679999999996,147456.0,36864.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,14976.0,4608.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",189,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.688,4214.367999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",190,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.656,4217.023999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",191,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.624,4219.647999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",192,393216.0,13062144.0,0,0,0.0,13062144.0,13062144.0,102144.0,192.0,0.99812382739212,147456.0,49152.0,17.664,4237.311999999995,9879552.0,2396160.0,393216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_128x32_sliced1x4_nn,193,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,306432.0,0.7831816329303084,38955712.0,245760.0,45.824,4283.135999999995,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1217366.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",194,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,2.72,4285.855999999995,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",195,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,4287.967999999995,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",196,71748.0,240884.0,0,0,0.0,240884.0,240884.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,7.168,4295.135999999995,72240.0,25148.0,71748.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1544.0
ampere_sgemm_32x32_sliced1x4_nn,197,1208352768.0,2419458048.0,0,0,0.0,2419458048.0,2419458048.0,5996544.0,1330176.0,0.8184486373165618,158554752.0,196608.0,166.592,4461.727999999995,1179648.0,1572864.0,1208352768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4954836.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",198,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.176,4463.903999999995,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",199,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.144,4466.047999999995,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",200,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.24,4468.287999999995,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",201,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,2.624,4470.911999999995,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",202,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.144,4473.055999999995,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",203,269644.0,686744.0,0,0,0.0,686744.0,686744.0,0.0,768.0,0.0,196608.0,196608.0,2.304,4475.359999999995,49152.0,98304.0,269644.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",204,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.208,4477.567999999995,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",205,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.528,4480.095999999995,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_128x32_sliced1x4_nn,206,1211105280.0,2425651200.0,0,0,0.0,2425651200.0,2425651200.0,3952320.0,1218528.0,0.764346582997605,155779808.0,245760.0,164.416,4644.511999999995,1474560.0,1966080.0,1211105280.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4868119.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",207,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,2.72,4647.231999999995,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",208,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.08,4649.311999999995,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",209,71748.0,240884.0,0,0,0.0,240884.0,240884.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,7.168,4656.479999999995,72240.0,25148.0,71748.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1544.0
ampere_sgemm_64x32_sliced1x4_tn,210,4945084416.0,9923973120.0,0,0,0.0,9923973120.0,9923973120.0,22863168.0,5145348.0,0.8162934444652477,645333888.0,2159232.0,730.08,5386.559999999995,14487552.0,19316736.0,4945084416.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,20166684.0,67476.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",211,0.0,804112.0,0,0,0.0,804112.0,804112.0,0.0,25136.0,0.0,2599488.0,823968.0,7.488,5394.047999999995,603084.0,201028.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,81234.0,25749.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",212,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,5395.743999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",213,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,64.0,128.0,2.624,5398.367999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",214,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.952,5400.319999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",215,0.0,201028.0,0,0,0.0,201028.0,201028.0,0.0,3158.0,0.0,804128.0,804128.0,2.848,5403.167999999995,0.0,201028.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25129.0,25129.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",216,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.664,5404.831999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",217,0.0,0.0,0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813024.0,57216.0,3.936,5408.767999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25407.0,1788.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",218,0.0,0.0,0,0,0.0,0.0,0.0,14800.0,82608.0,0.15193823915900131,5134592.0,0.0,5.536,5414.303999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160456.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",219,0.0,0.0,0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813024.0,58048.0,3.68,5417.983999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25407.0,1814.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",220,0.0,0.0,0,0,0.0,0.0,0.0,14800.0,83008.0,0.1513168656960576,5134592.0,0.0,5.568,5423.551999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160456.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",221,0.0,0.0,0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813024.0,56000.0,3.808,5427.359999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25407.0,1750.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",222,0.0,0.0,0,0,0.0,0.0,0.0,14800.0,82408.0,0.15225084355197102,5134592.0,0.0,5.504,5432.863999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160456.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",223,0.0,0.0,0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813024.0,57024.0,3.616,5436.479999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25407.0,1782.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",224,0.0,0.0,0,0,0.0,0.0,0.0,14800.0,83408.0,0.15070055392636036,5134592.0,128.0,5.536,5442.015999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160456.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",225,0.0,0.0,0,0,0.0,0.0,0.0,0.0,21.0,0.0,6432.0,800.0,2.4,5444.415999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,201.0,25.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",226,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.664,5446.0799999999945,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",227,0.0,0.0,0,0,0.0,0.0,0.0,497.0,22.0,0.9576107899807321,800.0,0.0,3.488,5449.567999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",228,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.664,5451.2319999999945,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",229,0.0,0.0,0,0,0.0,0.0,0.0,497.0,22.0,0.9576107899807321,800.0,0.0,3.616,5454.8479999999945,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",230,0.0,0.0,0,0,0.0,0.0,0.0,71040.0,13020.0,0.8451106352605282,831456.0,8672.0,6.144,5460.991999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25983.0,271.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",231,0.0,0.0,0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,544.0,6.432,5467.4239999999945,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,80.0,17.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",232,0.0,0.0,0,0,0.0,0.0,0.0,0.0,18849.0,0.0,814496.0,90848.0,3.68,5471.103999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25453.0,2839.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",233,0.0,0.0,0,0,0.0,0.0,0.0,0.0,4737.0,0.0,1005184.0,0.0,3.424,5474.527999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,31412.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",234,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6283.0,0.0,0.0,1608224.0,2.592,5477.119999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,50257.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",235,0.0,0.0,0,0,0.0,0.0,0.0,98304.0,6283.0,0.9399256121697726,804128.0,0.0,4.224,5481.343999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25129.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",236,0.0,0.0,0,0,0.0,0.0,0.0,156.0,64.0,0.7090909090909091,8192.0,0.0,2.112,5483.455999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",237,0.0,0.0,0,0,0.0,0.0,0.0,80583.0,30443.0,0.7258029650712445,3104576.0,2035936.0,10.4,5493.855999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,97018.0,63623.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",238,0.0,0.0,0,0,0.0,0.0,0.0,23142.0,38165.0,0.37747728644363615,3116224.0,2479936.0,8.576,5502.431999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,97382.0,77498.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",239,0.0,0.0,0,0,0.0,0.0,0.0,23883.0,40096.0,0.373294362212601,3125184.0,1887200.0,9.024,5511.455999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,97662.0,58975.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",240,0.0,0.0,0,0,0.0,0.0,0.0,22983.0,38020.0,0.37675196301821223,3073600.0,2479936.0,8.896,5520.351999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96050.0,77498.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",241,0.0,0.0,0,0,0.0,0.0,0.0,14336.0,6283.0,0.6952810514573937,1608224.0,0.0,4.512,5524.863999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,50257.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",242,0.0,0.0,0,0,0.0,0.0,0.0,39.0,16.0,0.7090909090909091,2048.0,0.0,2.144,5527.007999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",243,0.0,0.0,0,0,0.0,0.0,0.0,20059.0,18415.0,0.5213650777148204,2109984.0,1388832.0,8.064,5535.071999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,65937.0,43401.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",244,0.0,0.0,0,0,0.0,0.0,0.0,0.0,25132.0,0.0,2428160.0,2412352.0,5.28,5540.351999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75880.0,75386.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",245,2814392.0,6655044.0,0,0,0.0,6655044.0,6655044.0,528.0,6704.0,0.07300884955752213,2279424.0,753088.0,23.648,5563.9999999999945,825232.0,201028.0,2814392.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,71232.0,23534.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",246,0.0,1024200.0,0,0,0.0,1024200.0,1024200.0,112284.0,12568.0,0.8993368147887099,804512.0,623296.0,72.192,5636.191999999995,1024200.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25141.0,19478.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",247,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3158.0,0.0,804128.0,200800.0,2.944,5639.135999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25129.0,6275.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",248,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,1.888,5641.023999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",249,0.0,0.0,0,0,0.0,0.0,0.0,0.0,18849.0,0.0,1809280.0,87744.0,7.808,5648.831999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,56540.0,2742.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",250,0.0,0.0,0,0,0.0,0.0,0.0,0.0,4737.0,0.0,1005184.0,0.0,3.232,5652.063999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,31412.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",251,2814392.0,6655044.0,0,0,0.0,6655044.0,6655044.0,528.0,6704.0,0.07300884955752213,2280576.0,753984.0,24.0,5676.063999999995,825232.0,201028.0,2814392.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,71268.0,23562.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",252,0.0,0.0,0,0,0.0,0.0,0.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,6.24,5682.303999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",253,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.112,5684.415999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",254,0.0,0.0,0,0,0.0,0.0,0.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,6.4,5690.815999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",255,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,5692.895999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",256,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.048,5694.943999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",257,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.136,5698.0799999999945,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",258,0.0,220484.0,0,0,0.0,220484.0,220484.0,320.0,1582.0,0.16824395373291273,804256.0,128.0,11.04,5709.119999999994,220484.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25133.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",259,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,5711.135999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",260,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,5714.399999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",261,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,5716.415999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",262,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.008,5719.423999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",263,1769472.0,3941000.0,0,0,0.0,3941000.0,3941000.0,0.0,6283.0,0.0,0.0,804128.0,3.936,5723.359999999993,0.0,402056.0,1769472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,25129.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",264,1005140.0,2010280.0,0,0,0.0,2010280.0,2010280.0,0.0,4737.0,0.0,1608256.0,0.0,4.8,5728.1599999999935,0.0,0.0,1005140.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,50258.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",265,0.0,0.0,0,0,0.0,0.0,0.0,640.0,1582.0,0.28802880288028804,804896.0,128.0,15.744,5743.903999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25153.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",266,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,1.984,5745.887999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",267,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,5747.903999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",268,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.208,5750.111999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",269,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.048,5752.159999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",270,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,64.0,128.0,2.56,5754.719999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",271,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.664,5756.383999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",272,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.664,5758.0479999999925,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",273,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.176,5760.223999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",274,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.664,5761.887999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",275,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,32.0,2.272,5764.159999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",276,0.0,0.0,0,0,0.0,0.0,0.0,0.0,5.0,0.0,32.0,32.0,4.864,5769.023999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",277,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.176,5771.1999999999925,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",278,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,5773.247999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",279,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.816,5776.063999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",280,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,5779.327999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",281,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,5781.375999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",282,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.304,5783.679999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",283,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,32.0,3.36,5787.039999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",284,0.0,0.0,0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,64.0,32.0,2.464,5789.503999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",285,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,1.984,5791.487999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",286,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,1.952,5793.439999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",287,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,0.0,2.112,5795.551999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",288,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,2.208,5797.759999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",289,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1152.0,0.0,49920.0,49152.0,4.16,5801.919999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1560.0,1536.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",290,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1152.0,0.0,13056.0,49152.0,3.36,5805.279999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,408.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",291,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.08,5807.3599999999915,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",292,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,2.016,5809.375999999991,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",293,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,5812.7039999999915,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",294,71748.0,240884.0,0,0,0.0,240884.0,240884.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,7.168,5819.871999999991,72240.0,25148.0,71748.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1544.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),295,905969664.0,1812824064.0,0,0,0.0,1812824064.0,1812824064.0,2712096.0,3456.0,0.9987273305758829,116785152.0,442368.0,125.44,5945.311999999991,0.0,884736.0,905969664.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3649536.0,13824.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",296,0.0,184320.0,0,0,0.0,184320.0,184320.0,0.0,11520.0,0.0,479232.0,147456.0,3.584,5948.895999999991,147456.0,36864.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,14976.0,4608.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",297,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,4.0,5952.895999999991,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",298,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,4.0,5956.895999999991,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",299,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.624,5959.51999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",300,393216.0,13074432.0,0,0,0.0,13074432.0,13074432.0,102144.0,192.0,0.99812382739212,245760.0,49152.0,17.568,5977.087999999991,9891840.0,2396160.0,393216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_128x32_sliced1x4_nn,301,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,306432.0,0.7831816329303084,38956544.0,245760.0,45.632,6022.71999999999,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1217392.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",302,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,2.752,6025.471999999991,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",303,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.176,6027.647999999991,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",304,71748.0,240884.0,0,0,0.0,240884.0,240884.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,7.136,6034.7839999999915,72240.0,25148.0,71748.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1544.0
ampere_sgemm_32x32_sliced1x4_nn,305,1208352768.0,2419458048.0,0,0,0.0,2419458048.0,2419458048.0,5996544.0,1330176.0,0.8184486373165618,158124416.0,196608.0,165.152,6199.9359999999915,1179648.0,1572864.0,1208352768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4941388.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",306,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.112,6202.047999999992,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",307,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.208,6204.255999999991,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",308,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.112,6206.367999999991,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",309,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,2.464,6208.831999999991,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",310,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.112,6210.943999999991,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",311,269974.0,687404.0,0,0,0.0,687404.0,687404.0,0.0,768.0,0.0,196608.0,196608.0,2.272,6213.215999999991,49152.0,98304.0,269974.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",312,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.144,6215.3599999999915,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",313,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.368,6217.727999999992,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_128x32_sliced1x4_nn,314,1211105280.0,2425651200.0,0,0,0.0,2425651200.0,2425651200.0,3952320.0,1218528.0,0.764346582997605,155780576.0,245760.0,164.0,6381.727999999992,1474560.0,1966080.0,1211105280.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4868143.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",315,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,2.688,6384.415999999992,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",316,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.08,6386.495999999992,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",317,71748.0,240884.0,0,0,0.0,240884.0,240884.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,7.104,6393.599999999992,72240.0,25148.0,71748.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1544.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),318,905969664.0,1812824064.0,0,0,0.0,1812824064.0,1812824064.0,2712096.0,3456.0,0.9987273305758829,116785152.0,442368.0,127.104,6520.703999999992,0.0,884736.0,905969664.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3649536.0,13824.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",319,0.0,184320.0,0,0,0.0,184320.0,184320.0,0.0,11520.0,0.0,479232.0,147456.0,3.584,6524.287999999992,147456.0,36864.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,14976.0,4608.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",320,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,4.0,6528.287999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",321,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,4.0,6532.287999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",322,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.688,6534.975999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",323,393216.0,13074432.0,0,0,0.0,13074432.0,13074432.0,102144.0,192.0,0.99812382739212,245760.0,49152.0,17.536,6552.511999999992,9891840.0,2396160.0,393216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_128x32_sliced1x4_nn,324,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,306432.0,0.7831816329303084,38956896.0,245760.0,45.6,6598.111999999993,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1217403.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",325,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,2.688,6600.799999999993,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",326,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.08,6602.879999999993,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",327,71748.0,240884.0,0,0,0.0,240884.0,240884.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,7.104,6609.983999999993,72240.0,25148.0,71748.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1544.0
ampere_sgemm_32x32_sliced1x4_nn,328,1208352768.0,2419458048.0,0,0,0.0,2419458048.0,2419458048.0,5996544.0,1330176.0,0.8184486373165618,158559872.0,196608.0,165.216,6775.199999999993,1179648.0,1572864.0,1208352768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4954996.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",329,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.304,6777.5039999999935,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",330,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.4,6779.903999999993,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",331,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.112,6782.015999999993,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",332,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,2.624,6784.639999999993,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",333,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.144,6786.783999999993,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",334,269754.0,686964.0,0,0,0.0,686964.0,686964.0,0.0,768.0,0.0,196608.0,196608.0,2.368,6789.151999999994,49152.0,98304.0,269754.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",335,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.368,6791.519999999994,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",336,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.368,6793.8879999999945,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_128x32_sliced1x4_nn,337,1211105280.0,2425651200.0,0,0,0.0,2425651200.0,2425651200.0,3952320.0,1218528.0,0.764346582997605,155781888.0,245760.0,163.584,6957.471999999994,1474560.0,1966080.0,1211105280.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4868184.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",338,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,2.752,6960.223999999995,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",339,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.08,6962.303999999995,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",340,71748.0,240884.0,0,0,0.0,240884.0,240884.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,7.168,6969.471999999994,72240.0,25148.0,71748.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1544.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),341,905969664.0,1812824064.0,0,0,0.0,1812824064.0,1812824064.0,2712096.0,3456.0,0.9987273305758829,116785152.0,442368.0,125.792,7095.263999999995,0.0,884736.0,905969664.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3649536.0,13824.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",342,0.0,184320.0,0,0,0.0,184320.0,184320.0,0.0,11520.0,0.0,479232.0,147456.0,3.648,7098.911999999995,147456.0,36864.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,14976.0,4608.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",343,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,4.064,7102.975999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",344,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,4.0,7106.975999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",345,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.656,7109.631999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",346,393216.0,13074432.0,0,0,0.0,13074432.0,13074432.0,102144.0,192.0,0.99812382739212,245760.0,49152.0,17.76,7127.391999999995,9891840.0,2396160.0,393216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_128x32_sliced1x4_nn,347,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,306432.0,0.7831816329303084,38955680.0,245760.0,45.6,7172.991999999996,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1217365.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",348,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,2.912,7175.903999999996,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",349,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.08,7177.983999999996,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",350,71748.0,240884.0,0,0,0.0,240884.0,240884.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,7.04,7185.023999999996,72240.0,25148.0,71748.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1544.0
ampere_sgemm_32x32_sliced1x4_nn,351,1208352768.0,2419458048.0,0,0,0.0,2419458048.0,2419458048.0,5996544.0,1330176.0,0.8184486373165618,158687744.0,196608.0,166.016,7351.039999999995,1179648.0,1572864.0,1208352768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4958992.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",352,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.4,7353.439999999995,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",353,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.336,7355.775999999995,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",354,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.112,7357.887999999995,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",355,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,2.592,7360.479999999995,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",356,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.144,7362.623999999995,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",357,270234.0,687924.0,0,0,0.0,687924.0,687924.0,0.0,768.0,0.0,196608.0,196608.0,2.272,7364.895999999995,49152.0,98304.0,270234.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",358,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.144,7367.039999999995,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",359,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.432,7369.471999999995,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_128x32_sliced1x4_nn,360,1211105280.0,2425651200.0,0,0,0.0,2425651200.0,2425651200.0,3952320.0,1218528.0,0.764346582997605,155781568.0,245760.0,164.064,7533.5359999999955,1474560.0,1966080.0,1211105280.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4868174.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",361,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,2.688,7536.223999999996,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",362,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.208,7538.431999999995,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",363,71748.0,240884.0,0,0,0.0,240884.0,240884.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,7.04,7545.471999999995,72240.0,25148.0,71748.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1544.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),364,905969664.0,1812824064.0,0,0,0.0,1812824064.0,1812824064.0,2712096.0,3456.0,0.9987273305758829,116785152.0,442368.0,126.368,7671.839999999996,0.0,884736.0,905969664.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3649536.0,13824.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",365,0.0,184320.0,0,0,0.0,184320.0,184320.0,0.0,11520.0,0.0,479232.0,147456.0,3.552,7675.391999999995,147456.0,36864.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,14976.0,4608.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",366,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,4.0,7679.391999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",367,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,4.064,7683.455999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",368,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.624,7686.079999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",369,393216.0,13074432.0,0,0,0.0,13074432.0,13074432.0,102144.0,192.0,0.99812382739212,245760.0,49152.0,17.44,7703.519999999995,9891840.0,2396160.0,393216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_128x32_sliced1x4_nn,370,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,306432.0,0.7831816329303084,38955840.0,245760.0,45.728,7749.247999999995,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1217370.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",371,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,2.688,7751.935999999995,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",372,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,7754.047999999995,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",373,71748.0,240884.0,0,0,0.0,240884.0,240884.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,7.168,7761.215999999995,72240.0,25148.0,71748.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1544.0
ampere_sgemm_32x32_sliced1x4_nn,374,1208352768.0,2419458048.0,0,0,0.0,2419458048.0,2419458048.0,5996544.0,1330176.0,0.8184486373165618,158059008.0,196608.0,165.376,7926.591999999995,1179648.0,1572864.0,1208352768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4939344.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",375,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.24,7928.831999999995,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",376,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.176,7931.007999999995,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",377,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.176,7933.183999999996,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",378,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,2.624,7935.807999999995,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",379,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.144,7937.951999999996,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",380,269888.0,687232.0,0,0,0.0,687232.0,687232.0,0.0,768.0,0.0,196608.0,196608.0,2.4,7940.351999999995,49152.0,98304.0,269888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",381,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.176,7942.527999999996,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",382,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.656,7945.183999999996,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_128x32_sliced1x4_nn,383,1211105280.0,2425651200.0,0,0,0.0,2425651200.0,2425651200.0,3952320.0,1218528.0,0.764346582997605,155782112.0,245760.0,163.808,8108.991999999996,1474560.0,1966080.0,1211105280.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4868191.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",384,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,2.688,8111.679999999996,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",385,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.08,8113.759999999996,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",386,71748.0,240884.0,0,0,0.0,240884.0,240884.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,7.04,8120.799999999996,72240.0,25148.0,71748.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1544.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),387,905969664.0,1812824064.0,0,0,0.0,1812824064.0,1812824064.0,2712096.0,3456.0,0.9987273305758829,116785152.0,442368.0,125.952,8246.751999999995,0.0,884736.0,905969664.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3649536.0,13824.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",388,0.0,184320.0,0,0,0.0,184320.0,184320.0,0.0,11520.0,0.0,479232.0,147456.0,3.68,8250.431999999995,147456.0,36864.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,14976.0,4608.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",389,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,4.0,8254.431999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",390,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,4.064,8258.495999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",391,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.688,8261.183999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",392,393216.0,13074432.0,0,0,0.0,13074432.0,13074432.0,102144.0,192.0,0.99812382739212,245760.0,49152.0,17.536,8278.719999999996,9891840.0,2396160.0,393216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_128x32_sliced1x4_nn,393,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,306432.0,0.7831816329303084,38956096.0,245760.0,45.536,8324.255999999996,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1217378.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",394,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,2.816,8327.071999999996,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",395,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,8329.183999999996,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",396,71748.0,240884.0,0,0,0.0,240884.0,240884.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,7.04,8336.223999999997,72240.0,25148.0,71748.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1544.0
ampere_sgemm_32x32_sliced1x4_nn,397,1208352768.0,2419458048.0,0,0,0.0,2419458048.0,2419458048.0,5996544.0,1330176.0,0.8184486373165618,158358784.0,196608.0,165.184,8501.407999999996,1179648.0,1572864.0,1208352768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4948712.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",398,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.144,8503.551999999996,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",399,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.208,8505.759999999997,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",400,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.144,8507.903999999997,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",401,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,2.592,8510.495999999997,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",402,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.368,8512.863999999998,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",403,269978.0,687412.0,0,0,0.0,687412.0,687412.0,0.0,768.0,0.0,196608.0,196608.0,2.24,8515.103999999998,49152.0,98304.0,269978.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",404,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.176,8517.279999999997,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",405,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.336,8519.615999999996,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_128x32_sliced1x4_nn,406,1211105280.0,2425651200.0,0,0,0.0,2425651200.0,2425651200.0,3952320.0,1218528.0,0.764346582997605,155781600.0,245760.0,163.744,8683.359999999997,1474560.0,1966080.0,1211105280.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4868175.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",407,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,2.784,8686.143999999997,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",408,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.272,8688.415999999997,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",409,71748.0,240884.0,0,0,0.0,240884.0,240884.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,7.104,8695.519999999997,72240.0,25148.0,71748.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1544.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),410,905969664.0,1812824064.0,0,0,0.0,1812824064.0,1812824064.0,2712096.0,3456.0,0.9987273305758829,116785152.0,442368.0,125.184,8820.703999999996,0.0,884736.0,905969664.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3649536.0,13824.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",411,0.0,184320.0,0,0,0.0,184320.0,184320.0,0.0,11520.0,0.0,479232.0,147456.0,3.616,8824.319999999996,147456.0,36864.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,14976.0,4608.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",412,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,4.0,8828.319999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",413,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,4.0,8832.319999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",414,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.656,8834.975999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",415,393216.0,13074432.0,0,0,0.0,13074432.0,13074432.0,102144.0,192.0,0.99812382739212,245760.0,49152.0,17.6,8852.575999999997,9891840.0,2396160.0,393216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_128x32_sliced1x4_nn,416,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,306432.0,0.7831816329303084,38956896.0,245760.0,45.6,8898.175999999998,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1217403.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",417,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,2.688,8900.863999999998,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",418,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,8902.975999999997,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",419,71748.0,240884.0,0,0,0.0,240884.0,240884.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,7.104,8910.079999999996,72240.0,25148.0,71748.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1544.0
ampere_sgemm_32x32_sliced1x4_nn,420,1208352768.0,2419458048.0,0,0,0.0,2419458048.0,2419458048.0,5996544.0,1330176.0,0.8184486373165618,158404864.0,196608.0,165.888,9075.967999999997,1179648.0,1572864.0,1208352768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4950152.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",421,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.176,9078.143999999997,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",422,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.176,9080.319999999996,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",423,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.4,9082.719999999996,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",424,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,2.528,9085.247999999996,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",425,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.304,9087.551999999996,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",426,270126.0,687708.0,0,0,0.0,687708.0,687708.0,0.0,768.0,0.0,196608.0,196608.0,2.368,9089.919999999996,49152.0,98304.0,270126.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",427,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.272,9092.191999999997,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",428,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.592,9094.783999999998,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_128x32_sliced1x4_nn,429,1211105280.0,2425651200.0,0,0,0.0,2425651200.0,2425651200.0,3952320.0,1218528.0,0.764346582997605,155779584.0,245760.0,163.584,9258.367999999999,1474560.0,1966080.0,1211105280.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4868112.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",430,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,2.72,9261.087999999998,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",431,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.24,9263.327999999998,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",432,71748.0,240884.0,0,0,0.0,240884.0,240884.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,7.136,9270.463999999998,72240.0,25148.0,71748.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1544.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),433,905969664.0,1812824064.0,0,0,0.0,1812824064.0,1812824064.0,2712096.0,3456.0,0.9987273305758829,116785152.0,442368.0,126.048,9396.511999999999,0.0,884736.0,905969664.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3649536.0,13824.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",434,0.0,184320.0,0,0,0.0,184320.0,184320.0,0.0,11520.0,0.0,479232.0,147456.0,3.584,9400.096,147456.0,36864.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,14976.0,4608.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",435,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,4.064,9404.16,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",436,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,4.032,9408.192,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",437,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.624,9410.815999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",438,393216.0,13074432.0,0,0,0.0,13074432.0,13074432.0,102144.0,192.0,0.99812382739212,245760.0,49152.0,17.472,9428.287999999999,9891840.0,2396160.0,393216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_128x32_sliced1x4_nn,439,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,306432.0,0.7831816329303084,38956544.0,245760.0,45.632,9473.919999999998,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1217392.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",440,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,2.72,9476.639999999998,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",441,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,9478.751999999997,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",442,71748.0,240884.0,0,0,0.0,240884.0,240884.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,7.136,9485.887999999997,72240.0,25148.0,71748.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1544.0
ampere_sgemm_32x32_sliced1x4_nn,443,1208352768.0,2419458048.0,0,0,0.0,2419458048.0,2419458048.0,5996544.0,1330176.0,0.8184486373165618,158995584.0,196608.0,165.664,9651.551999999998,1179648.0,1572864.0,1208352768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4968612.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",444,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.144,9653.695999999998,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",445,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.304,9655.999999999998,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",446,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.208,9658.207999999999,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",447,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,2.656,9660.864,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",448,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.176,9663.039999999999,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",449,270017.0,687490.0,0,0,0.0,687490.0,687490.0,0.0,768.0,0.0,196608.0,196608.0,2.272,9665.312,49152.0,98304.0,270017.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",450,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.144,9667.456,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",451,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.432,9669.888,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_128x32_sliced1x4_nn,452,1211105280.0,2425651200.0,0,0,0.0,2425651200.0,2425651200.0,3952320.0,1218528.0,0.764346582997605,155780640.0,245760.0,163.552,9833.44,1474560.0,1966080.0,1211105280.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4868145.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",453,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,2.688,9836.128,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",454,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.08,9838.208,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",455,71748.0,240884.0,0,0,0.0,240884.0,240884.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,7.072,9845.28,72240.0,25148.0,71748.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1544.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),456,905969664.0,1812824064.0,0,0,0.0,1812824064.0,1812824064.0,2712096.0,3456.0,0.9987273305758829,116785152.0,442368.0,125.152,9970.432,0.0,884736.0,905969664.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3649536.0,13824.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",457,0.0,184320.0,0,0,0.0,184320.0,184320.0,0.0,11520.0,0.0,479232.0,147456.0,3.616,9974.048,147456.0,36864.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,14976.0,4608.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",458,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,3.968,9978.016000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",459,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,4.0,9982.016000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",460,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,2.624,9984.640000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",461,393216.0,13074432.0,0,0,0.0,13074432.0,13074432.0,102144.0,192.0,0.99812382739212,245760.0,49152.0,17.664,10002.304000000002,9891840.0,2396160.0,393216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_128x32_sliced1x4_nn,462,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,306432.0,0.7831816329303084,38956352.0,245760.0,45.408,10047.712000000001,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1217386.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",463,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,2.752,10050.464000000002,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",464,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.08,10052.544000000002,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",465,71748.0,240884.0,0,0,0.0,240884.0,240884.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,7.264,10059.808,72240.0,25148.0,71748.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1544.0
ampere_sgemm_32x32_sliced1x4_nn,466,1208352768.0,2419458048.0,0,0,0.0,2419458048.0,2419458048.0,5996544.0,1330176.0,0.8184486373165618,158413312.0,196608.0,165.728,10225.536,1179648.0,1572864.0,1208352768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4950416.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",467,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.304,10227.84,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",468,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.304,10230.144,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",469,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.176,10232.32,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",470,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,2.592,10234.912,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",471,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.208,10237.12,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",472,269812.0,687080.0,0,0,0.0,687080.0,687080.0,0.0,768.0,0.0,196608.0,196608.0,2.4,10239.52,49152.0,98304.0,269812.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",473,49152.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.368,10241.888,0.0,0.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",474,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.464,10244.352,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_128x32_sliced1x4_nn,475,1211105280.0,2425651200.0,0,0,0.0,2425651200.0,2425651200.0,3952320.0,1218528.0,0.764346582997605,155779712.0,245760.0,163.936,10408.288,1474560.0,1966080.0,1211105280.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4868116.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",476,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,2.688,10410.976,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",477,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,10413.088,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",478,71748.0,240884.0,0,0,0.0,240884.0,240884.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,7.264,10420.351999999999,72240.0,25148.0,71748.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1544.0
ampere_sgemm_64x32_sliced1x4_tn,479,4945084416.0,9923973120.0,0,0,0.0,9923973120.0,9923973120.0,22863168.0,5145348.0,0.8162934444652477,645526784.0,2160416.0,727.936,11148.287999999999,14487552.0,19316736.0,4945084416.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,20172712.0,67513.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",480,0.0,804112.0,0,0,0.0,804112.0,804112.0,0.0,25136.0,0.0,2596032.0,818400.0,7.584,11155.872,603084.0,201028.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,81126.0,25575.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",481,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,11157.568,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",482,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,96.0,160.0,2.528,11160.096,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",483,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,11162.08,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",484,0.0,201028.0,0,0,0.0,201028.0,201028.0,0.0,3158.0,0.0,804128.0,804128.0,3.04,11165.12,0.0,201028.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25129.0,25129.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",485,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.664,11166.784000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",486,0.0,0.0,0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813024.0,58880.0,3.808,11170.592000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25407.0,1840.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",487,0.0,0.0,0,0,0.0,0.0,0.0,14800.0,82608.0,0.15193823915900131,5134592.0,0.0,5.696,11176.288000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160456.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",488,0.0,0.0,0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813024.0,58240.0,3.872,11180.160000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25407.0,1820.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",489,0.0,0.0,0,0,0.0,0.0,0.0,14800.0,83008.0,0.1513168656960576,5134592.0,0.0,5.568,11185.728000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160456.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",490,0.0,0.0,0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813024.0,57088.0,3.648,11189.376,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25407.0,1784.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",491,0.0,0.0,0,0,0.0,0.0,0.0,14800.0,82708.0,0.15178241785289412,5134592.0,0.0,5.6,11194.976,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160456.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",492,0.0,0.0,0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813024.0,57088.0,3.872,11198.848,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25407.0,1784.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",493,0.0,0.0,0,0,0.0,0.0,0.0,14800.0,83358.0,0.15077731820126736,5134592.0,128.0,5.568,11204.416,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160456.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",494,0.0,0.0,0,0,0.0,0.0,0.0,0.0,21.0,0.0,6432.0,800.0,2.432,11206.848,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,201.0,25.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",495,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.632,11208.48,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",496,0.0,0.0,0,0,0.0,0.0,0.0,497.0,22.0,0.9576107899807321,800.0,0.0,3.552,11212.032,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",497,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.664,11213.696,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",498,0.0,0.0,0,0,0.0,0.0,0.0,497.0,22.0,0.9576107899807321,800.0,0.0,3.52,11217.216,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",499,0.0,0.0,0,0,0.0,0.0,0.0,64032.0,13014.0,0.8310879215014407,831456.0,8608.0,6.048,11223.264000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25983.0,269.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",500,0.0,0.0,0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,544.0,6.368,11229.632000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,80.0,17.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",501,0.0,0.0,0,0,0.0,0.0,0.0,0.0,18849.0,0.0,814496.0,86528.0,3.68,11233.312000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25453.0,2704.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",502,0.0,0.0,0,0,0.0,0.0,0.0,0.0,4737.0,0.0,1005184.0,0.0,3.392,11236.704000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,31412.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",503,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6283.0,0.0,0.0,1608224.0,2.624,11239.328000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,50257.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",504,0.0,0.0,0,0,0.0,0.0,0.0,98304.0,6283.0,0.9399256121697726,804128.0,0.0,4.224,11243.552000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25129.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",505,0.0,0.0,0,0,0.0,0.0,0.0,156.0,64.0,0.7090909090909091,8192.0,0.0,2.112,11245.664,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",506,0.0,0.0,0,0,0.0,0.0,0.0,78942.0,29990.0,0.7246906326882826,3051328.0,2051424.0,10.272,11255.936000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95354.0,64107.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",507,0.0,0.0,0,0,0.0,0.0,0.0,23142.0,40529.0,0.3634621727316989,3098176.0,2479936.0,8.48,11264.416000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96818.0,77498.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",508,0.0,0.0,0,0,0.0,0.0,0.0,23883.0,38209.0,0.3846389228886169,3106112.0,1885664.0,9.056,11273.472000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,97066.0,58927.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",509,0.0,0.0,0,0,0.0,0.0,0.0,22983.0,38812.0,0.3719232947649486,3106880.0,2479936.0,9.152,11282.624000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,97090.0,77498.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",510,0.0,0.0,0,0,0.0,0.0,0.0,14336.0,6283.0,0.6952810514573937,1608224.0,0.0,4.512,11287.136000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,50257.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",511,0.0,0.0,0,0,0.0,0.0,0.0,39.0,16.0,0.7090909090909091,2048.0,0.0,2.208,11289.344000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",512,0.0,0.0,0,0,0.0,0.0,0.0,20059.0,18499.0,0.5202292650033715,2097056.0,1391040.0,7.872,11297.216000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,65533.0,43470.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",513,0.0,0.0,0,0,0.0,0.0,0.0,0.0,25132.0,0.0,2427232.0,2412352.0,5.248,11302.464000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75851.0,75386.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",514,2814392.0,6655044.0,0,0,0.0,6655044.0,6655044.0,528.0,6704.0,0.07300884955752213,2278528.0,752640.0,23.808,11326.272000000003,825232.0,201028.0,2814392.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,71204.0,23520.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",515,0.0,1024200.0,0,0,0.0,1024200.0,1024200.0,112284.0,12568.0,0.8993368147887099,804640.0,628288.0,72.32,11398.592000000002,1024200.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25145.0,19634.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",516,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3158.0,0.0,804128.0,200864.0,2.88,11401.472000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25129.0,6277.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",517,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,1.856,11403.328000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",518,0.0,0.0,0,0,0.0,0.0,0.0,0.0,18849.0,0.0,1809280.0,85632.0,7.872,11411.2,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,56540.0,2676.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",519,0.0,0.0,0,0,0.0,0.0,0.0,0.0,4737.0,0.0,1005184.0,0.0,3.264,11414.464,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,31412.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",520,2814392.0,6655044.0,0,0,0.0,6655044.0,6655044.0,528.0,6704.0,0.07300884955752213,2278528.0,752320.0,23.648,11438.112,825232.0,201028.0,2814392.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,71204.0,23510.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",521,0.0,0.0,0,0,0.0,0.0,0.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,6.08,11444.192,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",522,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.112,11446.303999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",523,0.0,0.0,0,0,0.0,0.0,0.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,6.144,11452.447999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",524,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,11454.591999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",525,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.016,11456.607999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",526,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.912,11459.519999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",527,0.0,220484.0,0,0,0.0,220484.0,220484.0,320.0,1582.0,0.16824395373291273,804224.0,128.0,11.04,11470.56,220484.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25132.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",528,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.952,11472.511999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",529,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,11475.839999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",530,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,11477.823999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",531,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.944,11480.767999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",532,1769472.0,3941000.0,0,0,0.0,3941000.0,3941000.0,0.0,6283.0,0.0,0.0,804128.0,3.936,11484.703999999998,0.0,402056.0,1769472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,25129.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",533,1005140.0,2010280.0,0,0,0.0,2010280.0,2010280.0,0.0,4737.0,0.0,1608256.0,0.0,4.864,11489.567999999997,0.0,0.0,1005140.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,50258.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",534,0.0,0.0,0,0,0.0,0.0,0.0,640.0,1582.0,0.28802880288028804,804704.0,128.0,15.936,11505.503999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25147.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",535,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.112,11507.615999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",536,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,11509.631999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",537,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.208,11511.839999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",538,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.016,11513.855999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",539,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,96.0,160.0,2.528,11516.383999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",540,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,11518.079999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",541,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.664,11519.743999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",542,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,1.984,11521.727999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",543,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.664,11523.391999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",544,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,128.0,32.0,2.24,11525.631999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",545,0.0,0.0,0,0,0.0,0.0,0.0,0.0,5.0,0.0,32.0,32.0,4.8,11530.431999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",546,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.016,11532.447999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",547,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,11534.495999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",548,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.784,11537.279999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",549,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,11540.511999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",550,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,11542.527999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
