Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,64.0,1.856,1.856,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,2.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,64.0,1.696,3.552,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,2.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",3,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,32.0,2.528,6.08,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",4,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,64.0,3.616,9.696,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,2.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",5,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.2,12.896,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",6,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.176,15.072000000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",7,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,64.0,1.792,16.864,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,2.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",8,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,18.592000000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",9,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.696,20.288000000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",10,0.0,0.0,0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,2.432,22.720000000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",11,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,24.768,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",12,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,26.912,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",13,0.0,0.0,0,0,0.0,0.0,0.0,96.0,8.0,0.9230769230769231,64.0,32.0,2.592,29.503999999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.048,31.552,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",15,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,2.08,33.632,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",16,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,0.0,2.08,35.711999999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",17,0.0,0.0,0,0,0.0,0.0,0.0,0.0,576.0,0.0,3456.0,24576.0,4.832,40.544,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,108.0,768.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",18,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,2.688,43.232,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",19,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,46.464,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",20,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,2.432,48.896,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",21,0.0,1024.0,0,0,0.0,1024.0,1024.0,64.0,48.0,0.5714285714285714,2560.0,2048.0,2.496,51.392,0.0,1024.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,80.0,64.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",22,0.0,0.0,0,0,0.0,0.0,0.0,0.0,40.0,0.0,4096.0,4096.0,2.624,54.016000000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",23,8192.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,16.0,0.0,4096.0,4096.0,2.72,56.736000000000004,0.0,2048.0,8192.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",24,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.016,58.752,0.0,1024.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",25,7168.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,16.0,0.0,4096.0,4096.0,2.72,61.472,0.0,2048.0,7168.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",26,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.016,63.488,0.0,1024.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",27,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.016,65.504,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",28,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.16,69.664,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",29,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,2.336,72.0,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",30,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,74.048,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",31,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.688,76.736,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",32,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.72,79.456,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,33,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3066336.0,122880.0,8.192,87.648,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95823.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",34,0.0,43008.0,0,0,0.0,43008.0,43008.0,0.0,1920.0,0.0,125952.0,24576.0,2.816,90.464,36864.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3936.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,35,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3068672.0,122880.0,8.0,98.464,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95896.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",36,0.0,43008.0,0,0,0.0,43008.0,43008.0,0.0,1920.0,0.0,125952.0,24576.0,2.656,101.12,36864.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3936.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,37,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3071840.0,122880.0,8.064,109.184,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95995.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",38,0.0,43008.0,0,0,0.0,43008.0,43008.0,0.0,1920.0,0.0,125952.0,24576.0,2.784,111.968,36864.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3936.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",39,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.72,114.688,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",40,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.624,117.312,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",41,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,4.032,121.344,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",42,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.816,124.16,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",43,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.048,126.208,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",44,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.816,129.024,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",45,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.752,131.776,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",46,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,4.064,135.84,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",47,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.688,138.528,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",48,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.112,140.64,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",49,98304.0,8825856.0,0,0,0.0,8825856.0,8825856.0,49920.0,96.0,0.9980806142034548,73728.0,24576.0,20.16,160.79999999999998,7440384.0,1188864.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,50,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3067264.0,122880.0,7.712,168.51199999999997,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95852.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",51,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.688,171.19999999999996,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",52,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.08,173.27999999999997,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",53,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.048,175.32799999999997,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",54,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.128,179.45599999999996,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",55,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.984,181.43999999999997,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",56,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,183.42399999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",57,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.72,186.14399999999998,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",58,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.656,188.79999999999998,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,59,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.296,204.09599999999998,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",60,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.528,206.62399999999997,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",61,282624.0,589824.0,0,0,0.0,589824.0,589824.0,0.0,384.0,0.0,98304.0,98304.0,2.336,208.95999999999998,24576.0,0.0,282624.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,62,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.776,224.736,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",63,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.56,227.296,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",64,0.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.496,229.792,0.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,65,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,84480.0,0.8172757475083057,10616832.0,196608.0,15.904,245.696,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",66,0.0,55296.0,0,0,0.0,55296.0,55296.0,0.0,1728.0,0.0,196608.0,24576.0,2.336,248.032,49152.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",67,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.048,250.08,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",68,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,1.984,252.06400000000002,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",69,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.096,256.16,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",70,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.984,258.144,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",71,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,260.128,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",72,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.816,262.94399999999996,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",73,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.688,265.63199999999995,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,74,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3067616.0,122880.0,7.936,273.5679999999999,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95863.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",75,0.0,43008.0,0,0,0.0,43008.0,43008.0,0.0,1920.0,0.0,125952.0,24576.0,2.624,276.19199999999995,36864.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3936.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,76,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3074240.0,122880.0,7.68,283.87199999999996,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96070.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",77,0.0,43008.0,0,0,0.0,43008.0,43008.0,0.0,1920.0,0.0,125952.0,24576.0,2.688,286.55999999999995,36864.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3936.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,78,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3070304.0,122880.0,7.872,294.43199999999996,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95947.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",79,0.0,43008.0,0,0,0.0,43008.0,43008.0,0.0,1920.0,0.0,125952.0,24576.0,2.688,297.11999999999995,36864.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3936.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",80,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.72,299.84,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",81,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.784,302.62399999999997,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",82,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,4.0,306.62399999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",83,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.656,309.28,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",84,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.176,311.45599999999996,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",85,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.72,314.176,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",86,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.688,316.864,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",87,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,4.0,320.864,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",88,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.848,323.712,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",89,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.08,325.792,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",90,98304.0,8825856.0,0,0,0.0,8825856.0,8825856.0,49920.0,96.0,0.9980806142034548,73728.0,24576.0,20.256,346.048,7440384.0,1188864.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,91,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3067264.0,122880.0,7.712,353.76,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95852.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",92,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.528,356.288,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",93,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.112,358.40000000000003,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",94,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.08,360.48,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",95,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.288,364.76800000000003,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",96,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.984,366.752,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",97,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,368.76800000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",98,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.688,371.456,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",99,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.624,374.08000000000004,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,100,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.584,389.66400000000004,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",101,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.56,392.22400000000005,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",102,282624.0,589824.0,0,0,0.0,589824.0,589824.0,0.0,384.0,0.0,98304.0,98304.0,2.336,394.56000000000006,24576.0,0.0,282624.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,103,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.584,410.14400000000006,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",104,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.72,412.8640000000001,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",105,0.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.24,415.1040000000001,0.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,106,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,84480.0,0.8172757475083057,10616832.0,196608.0,15.808,430.9120000000001,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",107,0.0,55296.0,0,0,0.0,55296.0,55296.0,0.0,1728.0,0.0,196608.0,24576.0,2.304,433.21600000000007,49152.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",108,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.144,435.36000000000007,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",109,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.048,437.4080000000001,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",110,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.128,441.53600000000006,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",111,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.952,443.48800000000006,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",112,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,445.47200000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",113,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.752,448.22400000000005,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",114,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.624,450.84800000000007,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,115,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3066496.0,122880.0,8.096,458.9440000000001,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95828.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",116,0.0,43008.0,0,0,0.0,43008.0,43008.0,0.0,1920.0,0.0,125952.0,24576.0,2.624,461.5680000000001,36864.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3936.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,117,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3069376.0,122880.0,7.808,469.3760000000001,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95918.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",118,0.0,43008.0,0,0,0.0,43008.0,43008.0,0.0,1920.0,0.0,125952.0,24576.0,2.656,472.0320000000001,36864.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3936.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,119,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3069088.0,122880.0,7.84,479.87200000000007,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95909.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",120,0.0,43008.0,0,0,0.0,43008.0,43008.0,0.0,1920.0,0.0,125952.0,24576.0,2.688,482.56000000000006,36864.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3936.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",121,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.784,485.34400000000005,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",122,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.624,487.9680000000001,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",123,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,3.968,491.9360000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",124,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.688,494.6240000000001,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",125,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.112,496.7360000000001,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",126,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.784,499.5200000000001,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",127,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.688,502.2080000000001,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",128,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,4.096,506.3040000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",129,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.752,509.0560000000001,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",130,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.048,511.1040000000001,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",131,98304.0,8825856.0,0,0,0.0,8825856.0,8825856.0,49920.0,96.0,0.9980806142034548,73728.0,24576.0,20.128,531.2320000000001,7440384.0,1188864.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,132,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3065824.0,122880.0,7.68,538.912,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95807.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",133,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.56,541.472,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",134,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.144,543.616,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",135,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.048,545.664,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",136,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.096,549.76,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",137,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.952,551.712,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",138,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,553.728,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",139,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.592,556.3199999999999,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",140,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.656,558.9759999999999,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,141,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.36,574.3359999999999,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",142,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.592,576.9279999999999,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",143,282624.0,589824.0,0,0,0.0,589824.0,589824.0,0.0,384.0,0.0,98304.0,98304.0,2.336,579.2639999999999,24576.0,0.0,282624.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,144,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.712,594.9759999999999,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",145,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.592,597.5679999999999,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",146,0.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.336,599.9039999999999,0.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,147,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,84480.0,0.8172757475083057,10616832.0,196608.0,15.84,615.7439999999999,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",148,0.0,55296.0,0,0,0.0,55296.0,55296.0,0.0,1728.0,0.0,196608.0,24576.0,2.304,618.0479999999999,49152.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",149,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.24,620.2879999999999,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",150,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.048,622.3359999999999,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",151,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.096,626.4319999999999,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",152,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.952,628.3839999999999,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",153,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,630.3999999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",154,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.624,633.0239999999999,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",155,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.624,635.6479999999999,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,156,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3065760.0,122880.0,7.776,643.4239999999999,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95805.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",157,0.0,43008.0,0,0,0.0,43008.0,43008.0,0.0,1920.0,0.0,125952.0,24576.0,2.656,646.0799999999998,36864.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3936.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,158,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3071072.0,122880.0,7.776,653.8559999999998,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95971.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",159,0.0,43008.0,0,0,0.0,43008.0,43008.0,0.0,1920.0,0.0,125952.0,24576.0,2.656,656.5119999999997,36864.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3936.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,160,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3073088.0,122880.0,7.744,664.2559999999997,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96034.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",161,0.0,43008.0,0,0,0.0,43008.0,43008.0,0.0,1920.0,0.0,125952.0,24576.0,2.72,666.9759999999998,36864.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3936.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",162,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.752,669.7279999999997,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",163,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.592,672.3199999999997,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",164,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,4.0,676.3199999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",165,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.688,679.0079999999997,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",166,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.336,681.3439999999997,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",167,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.688,684.0319999999997,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",168,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.656,686.6879999999996,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",169,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,4.032,690.7199999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",170,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.72,693.4399999999997,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",171,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.144,695.5839999999997,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",172,98304.0,8825856.0,0,0,0.0,8825856.0,8825856.0,49920.0,96.0,0.9980806142034548,73728.0,24576.0,20.288,715.8719999999997,7440384.0,1188864.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,173,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3068288.0,122880.0,7.744,723.6159999999998,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95884.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",174,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.528,726.1439999999998,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",175,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.112,728.2559999999997,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",176,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.016,730.2719999999997,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",177,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.096,734.3679999999997,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",178,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.92,736.2879999999997,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",179,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.952,738.2399999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",180,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.656,740.8959999999996,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",181,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.688,743.5839999999996,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,182,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.264,758.8479999999996,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",183,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.752,761.5999999999996,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",184,282624.0,589824.0,0,0,0.0,589824.0,589824.0,0.0,384.0,0.0,98304.0,98304.0,2.304,763.9039999999995,24576.0,0.0,282624.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,185,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.712,779.6159999999995,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",186,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.496,782.1119999999995,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",187,0.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.208,784.3199999999995,0.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,188,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,84480.0,0.8172757475083057,10616832.0,196608.0,15.552,799.8719999999995,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",189,0.0,55296.0,0,0,0.0,55296.0,55296.0,0.0,1728.0,0.0,196608.0,24576.0,2.432,802.3039999999995,49152.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",190,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.144,804.4479999999995,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",191,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.08,806.5279999999996,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",192,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.096,810.6239999999996,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",193,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.984,812.6079999999996,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",194,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,814.5919999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",195,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.624,817.2159999999997,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",196,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.688,819.9039999999997,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,197,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3067904.0,122880.0,7.616,827.5199999999996,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95872.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",198,0.0,43008.0,0,0,0.0,43008.0,43008.0,0.0,1920.0,0.0,125952.0,24576.0,2.816,830.3359999999997,36864.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3936.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,199,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3069152.0,122880.0,7.712,838.0479999999997,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95911.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",200,0.0,43008.0,0,0,0.0,43008.0,43008.0,0.0,1920.0,0.0,125952.0,24576.0,2.624,840.6719999999997,36864.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3936.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,201,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3069728.0,122880.0,7.712,848.3839999999997,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95929.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",202,0.0,43008.0,0,0,0.0,43008.0,43008.0,0.0,1920.0,0.0,125952.0,24576.0,2.752,851.1359999999996,36864.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3936.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",203,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.656,853.7919999999996,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",204,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.656,856.4479999999995,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",205,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,4.0,860.4479999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",206,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.72,863.1679999999996,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",207,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.112,865.2799999999995,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",208,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.784,868.0639999999995,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",209,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.688,870.7519999999995,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",210,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,3.968,874.7199999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",211,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.688,877.4079999999994,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",212,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.112,879.5199999999994,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",213,98304.0,8825856.0,0,0,0.0,8825856.0,8825856.0,49920.0,96.0,0.9980806142034548,73728.0,24576.0,20.128,899.6479999999995,7440384.0,1188864.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,214,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3066912.0,122880.0,7.776,907.4239999999994,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95841.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",215,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.56,909.9839999999994,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",216,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.08,912.0639999999994,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",217,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.112,914.1759999999994,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",218,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.128,918.3039999999994,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",219,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.888,920.1919999999994,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",220,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,922.2079999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",221,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.784,924.9919999999994,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",222,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.752,927.7439999999993,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,223,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.36,943.1039999999994,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",224,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.656,945.7599999999993,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",225,282624.0,589824.0,0,0,0.0,589824.0,589824.0,0.0,384.0,0.0,98304.0,98304.0,2.368,948.1279999999994,24576.0,0.0,282624.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,226,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.584,963.7119999999993,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",227,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.688,966.3999999999993,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",228,0.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.24,968.6399999999993,0.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,229,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,84480.0,0.8172757475083057,10616832.0,196608.0,15.68,984.3199999999993,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",230,0.0,55296.0,0,0,0.0,55296.0,55296.0,0.0,1728.0,0.0,196608.0,24576.0,2.336,986.6559999999993,49152.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",231,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.272,988.9279999999993,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",232,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,1.984,990.9119999999994,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",233,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.192,995.1039999999994,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",234,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.952,997.0559999999994,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",235,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,999.0399999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",236,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.688,1001.7279999999994,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",237,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.688,1004.4159999999994,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,238,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3069056.0,122880.0,7.744,1012.1599999999994,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95908.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",239,0.0,43008.0,0,0,0.0,43008.0,43008.0,0.0,1920.0,0.0,125952.0,24576.0,2.656,1014.8159999999993,36864.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3936.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,240,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3071520.0,122880.0,7.936,1022.7519999999994,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95985.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",241,0.0,43008.0,0,0,0.0,43008.0,43008.0,0.0,1920.0,0.0,125952.0,24576.0,2.816,1025.5679999999993,36864.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3936.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,242,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3070592.0,122880.0,7.68,1033.2479999999994,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95956.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",243,0.0,43008.0,0,0,0.0,43008.0,43008.0,0.0,1920.0,0.0,125952.0,24576.0,2.656,1035.9039999999993,36864.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3936.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",244,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.72,1038.6239999999993,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",245,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.72,1041.3439999999994,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",246,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,4.064,1045.4079999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",247,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.688,1048.0959999999995,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",248,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.08,1050.1759999999995,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",249,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.72,1052.8959999999995,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",250,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.656,1055.5519999999995,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",251,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,3.936,1059.4879999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",252,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.688,1062.1759999999995,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",253,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.144,1064.3199999999995,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",254,98304.0,8825856.0,0,0,0.0,8825856.0,8825856.0,49920.0,96.0,0.9980806142034548,73728.0,24576.0,20.256,1084.5759999999996,7440384.0,1188864.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,255,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3066464.0,122880.0,7.872,1092.4479999999996,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95827.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",256,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.528,1094.9759999999997,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",257,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.144,1097.1199999999997,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",258,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.016,1099.1359999999997,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",259,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.128,1103.2639999999997,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",260,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.92,1105.1839999999997,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",261,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,1107.1999999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",262,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.72,1109.9199999999998,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",263,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.656,1112.5759999999998,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,264,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.264,1127.8399999999997,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",265,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.592,1130.4319999999998,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",266,282624.0,589824.0,0,0,0.0,589824.0,589824.0,0.0,384.0,0.0,98304.0,98304.0,2.272,1132.7039999999997,24576.0,0.0,282624.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,267,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.904,1148.6079999999997,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",268,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.528,1151.1359999999997,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",269,0.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.208,1153.3439999999998,0.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,270,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,84480.0,0.8172757475083057,10616832.0,196608.0,15.52,1168.8639999999998,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",271,0.0,55296.0,0,0,0.0,55296.0,55296.0,0.0,1728.0,0.0,196608.0,24576.0,2.368,1171.2319999999997,49152.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",272,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.08,1173.3119999999997,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",273,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.08,1175.3919999999996,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",274,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.064,1179.4559999999997,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",275,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.92,1181.3759999999997,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",276,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,1183.4239999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",277,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.688,1186.1119999999999,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",278,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.72,1188.8319999999999,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,279,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3068736.0,122880.0,8.192,1197.024,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95898.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",280,0.0,43008.0,0,0,0.0,43008.0,43008.0,0.0,1920.0,0.0,125952.0,24576.0,2.624,1199.648,36864.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3936.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,281,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3069888.0,122880.0,7.936,1207.5839999999998,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95934.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",282,0.0,43008.0,0,0,0.0,43008.0,43008.0,0.0,1920.0,0.0,125952.0,24576.0,2.752,1210.3359999999998,36864.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3936.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,283,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3070688.0,122880.0,8.0,1218.3359999999998,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95959.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",284,0.0,43008.0,0,0,0.0,43008.0,43008.0,0.0,1920.0,0.0,125952.0,24576.0,2.624,1220.9599999999998,36864.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3936.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",285,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.784,1223.744,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",286,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.656,1226.3999999999999,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",287,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,4.0,1230.3999999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",288,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.688,1233.088,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",289,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.112,1235.2,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",290,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.688,1237.8880000000001,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",291,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.624,1240.5120000000002,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",292,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,3.968,1244.4800000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",293,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.816,1247.2960000000003,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",294,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.112,1249.4080000000004,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",295,98304.0,8825856.0,0,0,0.0,8825856.0,8825856.0,49920.0,96.0,0.9980806142034548,73728.0,24576.0,20.096,1269.5040000000004,7440384.0,1188864.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,296,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3068224.0,122880.0,7.872,1277.3760000000004,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95882.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",297,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.752,1280.1280000000004,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",298,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.08,1282.2080000000003,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",299,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,1.984,1284.1920000000002,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",300,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.128,1288.3200000000002,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",301,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.952,1290.2720000000002,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",302,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,1292.3200000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",303,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.72,1295.0400000000002,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",304,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.624,1297.6640000000002,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,305,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.36,1313.0240000000001,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",306,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.528,1315.5520000000001,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",307,282624.0,589824.0,0,0,0.0,589824.0,589824.0,0.0,384.0,0.0,98304.0,98304.0,2.496,1318.0480000000002,24576.0,0.0,282624.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,308,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.232,1333.2800000000002,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",309,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.752,1336.0320000000002,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",310,0.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.24,1338.2720000000002,0.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,311,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,84480.0,0.8172757475083057,10616832.0,196608.0,15.648,1353.92,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",312,0.0,55296.0,0,0,0.0,55296.0,55296.0,0.0,1728.0,0.0,196608.0,24576.0,2.464,1356.384,49152.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",313,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.144,1358.528,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",314,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.016,1360.544,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",315,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.096,1364.64,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",316,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.92,1366.5600000000002,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",317,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,1368.5760000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",318,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.688,1371.2640000000004,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",319,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.752,1374.0160000000003,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,320,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3069376.0,122880.0,7.904,1381.9200000000003,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95918.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",321,0.0,43008.0,0,0,0.0,43008.0,43008.0,0.0,1920.0,0.0,125952.0,24576.0,2.72,1384.6400000000003,36864.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3936.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,322,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3070400.0,122880.0,7.616,1392.2560000000003,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95950.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",323,0.0,43008.0,0,0,0.0,43008.0,43008.0,0.0,1920.0,0.0,125952.0,24576.0,2.656,1394.9120000000003,36864.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3936.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,324,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3071968.0,122880.0,7.52,1402.4320000000002,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95999.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",325,0.0,43008.0,0,0,0.0,43008.0,43008.0,0.0,1920.0,0.0,125952.0,24576.0,2.688,1405.1200000000003,36864.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3936.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",326,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.752,1407.8720000000003,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",327,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.72,1410.5920000000003,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",328,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,4.0,1414.5920000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",329,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.752,1417.3440000000003,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",330,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.08,1419.4240000000002,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",331,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.816,1422.2400000000002,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",332,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.688,1424.9280000000003,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",333,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,4.032,1428.9600000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",334,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.688,1431.6480000000004,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",335,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.08,1433.7280000000003,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",336,98304.0,8825856.0,0,0,0.0,8825856.0,8825856.0,49920.0,96.0,0.9980806142034548,73728.0,24576.0,20.288,1454.0160000000003,7440384.0,1188864.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,337,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3067392.0,122880.0,8.032,1462.0480000000002,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95856.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",338,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.496,1464.5440000000003,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",339,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.048,1466.5920000000003,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",340,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.016,1468.6080000000004,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",341,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.128,1472.7360000000003,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",342,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.984,1474.7200000000003,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",343,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,1476.7360000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",344,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.656,1479.3920000000003,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",345,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.656,1482.0480000000002,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,346,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.36,1497.4080000000001,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",347,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.688,1500.0960000000002,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",348,282624.0,589824.0,0,0,0.0,589824.0,589824.0,0.0,384.0,0.0,98304.0,98304.0,2.336,1502.4320000000002,24576.0,0.0,282624.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,349,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.904,1518.3360000000002,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",350,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.592,1520.9280000000003,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",351,0.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.208,1523.1360000000004,0.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,352,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,84480.0,0.8172757475083057,10616832.0,196608.0,15.488,1538.6240000000005,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",353,0.0,55296.0,0,0,0.0,55296.0,55296.0,0.0,1728.0,0.0,196608.0,24576.0,2.528,1541.1520000000005,49152.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",354,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.24,1543.3920000000005,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",355,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.016,1545.4080000000006,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",356,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.096,1549.5040000000006,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",357,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.952,1551.4560000000006,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",358,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,1553.5040000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",359,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.688,1556.1920000000007,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",360,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.688,1558.8800000000008,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,361,3733979136.0,7501991936.0,0,0,0.0,7501991936.0,7501991936.0,17548608.0,4140256.0,0.809106830122592,505404800.0,4861952.0,520.224,2079.1040000000007,14585856.0,19447808.0,3733979136.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,15793900.0,151936.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",362,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,64.0,1.696,2080.8000000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,2.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",363,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,128.0,256.0,2.592,2083.3920000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,8.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",364,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2085.408000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",365,0.0,1215488.0,0,0,0.0,1215488.0,1215488.0,0.0,18992.0,0.0,4861952.0,4861952.0,8.096,2093.504000000001,0.0,1215488.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,151936.0,151936.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",366,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,2095.232000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",367,0.0,0.0,0,0,0.0,0.0,0.0,10880.0,48864.0,0.1821103374397429,4866048.0,196096.0,7.936,2103.168000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,152064.0,6128.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",368,0.0,0.0,0,0,0.0,0.0,0.0,50320.0,471256.0,0.09647683175606239,18076800.0,960.0,9.824,2112.992000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,564900.0,30.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",369,0.0,0.0,0,0,0.0,0.0,0.0,10880.0,48864.0,0.1821103374397429,4866048.0,194816.0,7.744,2120.7360000000012,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,152064.0,6088.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",370,0.0,0.0,0,0,0.0,0.0,0.0,50320.0,475336.0,0.0957280046265999,18176640.0,768.0,9.952,2130.6880000000015,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,568020.0,24.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",371,0.0,0.0,0,0,0.0,0.0,0.0,10880.0,48864.0,0.1821103374397429,4866048.0,198528.0,7.872,2138.5600000000013,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,152064.0,6204.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",372,0.0,0.0,0,0,0.0,0.0,0.0,50320.0,472616.0,0.096225924396102,18104512.0,864.0,9.696,2148.256000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,565766.0,27.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",373,0.0,0.0,0,0,0.0,0.0,0.0,10880.0,48864.0,0.1821103374397429,4866048.0,196736.0,7.904,2156.160000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,152064.0,6148.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",374,0.0,0.0,0,0,0.0,0.0,0.0,50320.0,470576.0,0.09660277675390097,18057888.0,1056.0,9.856,2166.0160000000014,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,564309.0,33.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",375,0.0,0.0,0,0,0.0,0.0,0.0,0.0,66.0,0.0,21792.0,2720.0,3.232,2169.2480000000014,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,681.0,85.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",376,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.728,2170.9760000000015,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",377,0.0,0.0,0,0,0.0,0.0,0.0,497.0,52.0,0.9052823315118397,2720.0,0.0,3.68,2174.6560000000013,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,85.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",378,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.632,2176.2880000000014,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",379,0.0,0.0,0,0,0.0,0.0,0.0,497.0,52.0,0.9052823315118397,2720.0,0.0,3.68,2179.968000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,85.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",380,0.0,0.0,0,0,0.0,0.0,0.0,451584.0,60400.0,0.882027563361355,4906784.0,14944.0,10.624,2190.592000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,153337.0,467.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",381,0.0,0.0,0,0,0.0,0.0,0.0,3664.0,64.0,0.9828326180257511,5120.0,992.0,6.592,2197.184000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160.0,31.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",382,0.0,0.0,0,0,0.0,0.0,0.0,0.0,113952.0,0.0,4888512.0,487840.0,7.872,2205.056000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,152766.0,15245.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",383,0.0,0.0,0,0,0.0,0.0,0.0,0.0,28488.0,0.0,6077440.0,16128.0,9.344,2214.400000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,189920.0,504.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",384,0.0,0.0,0,0,0.0,0.0,0.0,0.0,37984.0,0.0,0.0,9723904.0,6.944,2221.344000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,303872.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",385,0.0,0.0,0,0,0.0,0.0,0.0,98304.0,37984.0,0.7212960788917586,4861952.0,0.0,8.608,2229.952000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,151936.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",386,0.0,0.0,0,0,0.0,0.0,0.0,156.0,64.0,0.7090909090909091,8192.0,0.0,2.208,2232.160000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",387,0.0,0.0,0,0,0.0,0.0,0.0,349356.0,191558.0,0.6458623736860203,18245376.0,12061472.0,25.952,2258.1120000000014,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,570168.0,376921.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",388,0.0,0.0,0,0,0.0,0.0,0.0,134352.0,214523.0,0.38510068075958437,18572160.0,14991360.0,23.776,2281.8880000000013,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,580380.0,468480.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",389,0.0,0.0,0,0,0.0,0.0,0.0,135156.0,210004.0,0.3915749217754085,18624384.0,14991360.0,23.68,2305.568000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,582012.0,468480.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",390,0.0,0.0,0,0,0.0,0.0,0.0,135156.0,212753.0,0.38848089586644785,18642432.0,12847680.0,24.224,2329.7920000000013,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,582576.0,401490.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",391,0.0,0.0,0,0,0.0,0.0,0.0,14336.0,37984.0,0.27400611620795107,9723904.0,0.0,12.992,2342.7840000000015,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,303872.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",392,0.0,0.0,0,0,0.0,0.0,0.0,39.0,16.0,0.7090909090909091,2048.0,0.0,2.208,2344.9920000000016,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",393,0.0,0.0,0,0,0.0,0.0,0.0,111421.0,226543.0,0.3296830431643607,16926208.0,9010752.0,22.464,2367.4560000000015,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,528944.0,281586.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",394,0.0,0.0,0,0,0.0,0.0,0.0,0.0,151936.0,0.0,14655232.0,14585856.0,18.08,2385.5360000000014,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,457976.0,455808.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",395,17016832.0,40153344.0,0,0,0.0,40153344.0,40153344.0,1056.0,38272.0,0.026851098454027666,14585856.0,4861952.0,63.136,2448.6720000000014,4904192.0,1215488.0,17016832.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,455808.0,151936.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",396,0.0,6104232.0,0,0,0.0,6104232.0,6104232.0,669744.0,75968.0,0.8981268908103933,4861952.0,4861952.0,211.712,2660.3840000000014,6104232.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,151936.0,151936.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",397,0.0,0.0,0,0,0.0,0.0,0.0,0.0,18992.0,0.0,4861952.0,1215488.0,7.264,2667.6480000000015,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,151936.0,37984.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",398,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,256.0,1.92,2669.5680000000016,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,8.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",399,0.0,0.0,0,0,0.0,0.0,0.0,0.0,113952.0,0.0,10939392.0,523136.0,15.136,2684.7040000000015,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,341856.0,16348.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",400,0.0,0.0,0,0,0.0,0.0,0.0,0.0,28488.0,0.0,6077440.0,2816.0,9.376,2694.0800000000017,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,189920.0,88.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",401,17016832.0,40153344.0,0,0,0.0,40153344.0,40153344.0,1056.0,38272.0,0.026851098454027666,14585856.0,4861952.0,62.592,2756.672000000002,4904192.0,1215488.0,17016832.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,455808.0,151936.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",402,0.0,0.0,0,0,0.0,0.0,0.0,11833.0,9651.0,0.5507819772854217,4862560.0,4800.0,10.272,2766.944000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,151955.0,150.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",403,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.176,2769.1200000000017,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",404,0.0,0.0,0,0,0.0,0.0,0.0,11833.0,9651.0,0.5507819772854217,4862560.0,4800.0,10.24,2779.3600000000015,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,151955.0,150.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",405,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,2781.5040000000013,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",406,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.016,2783.5200000000013,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",407,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.976,2786.4960000000015,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",408,0.0,1971352.0,0,0,0.0,1971352.0,1971352.0,14744.0,9664.0,0.6040642412323828,4862784.0,4992.0,10.368,2796.8640000000014,1971352.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,151962.0,156.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",409,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,2798.8480000000013,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",410,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,2802.1760000000013,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",411,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,2804.224000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",412,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.944,2807.168000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",413,2555904.0,7542784.0,0,0,0.0,7542784.0,7542784.0,0.0,37984.0,0.0,0.0,4861952.0,5.376,2812.5440000000012,0.0,2430976.0,2555904.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,151936.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",414,6077440.0,12154880.0,0,0,0.0,12154880.0,12154880.0,0.0,28488.0,0.0,9723904.0,98304.0,13.408,2825.952000000001,0.0,0.0,6077440.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,303872.0,3072.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",415,0.0,0.0,0,0,0.0,0.0,0.0,26904.0,9824.0,0.7325201481158788,4864512.0,5920.0,12.096,2838.048000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,152016.0,185.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",416,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,128.0,256.0,2.592,2840.6400000000012,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,8.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",417,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,2842.336000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",418,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,2844.064000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",419,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.08,2846.144000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",420,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,2848.192000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",421,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,64.0,2.848,2851.040000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,2.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",422,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.072,2854.112000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",423,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2856.128000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",424,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.112,2858.240000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",425,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,160.0,64.0,3.232,2861.472000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5.0,2.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",426,0.0,0.0,0,0,0.0,0.0,0.0,96.0,8.0,0.9230769230769231,128.0,32.0,2.56,2864.032000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",427,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,128.0,2.016,2866.048000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",428,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,32.0,2.08,2868.128000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",429,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,160.0,0.0,2.112,2870.240000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",430,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,64.0,2.208,2872.4480000000012,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,2.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",431,0.0,0.0,0,0,0.0,0.0,0.0,0.0,576.0,0.0,24960.0,24576.0,8.16,2880.608000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,780.0,768.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",432,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,32.0,2.432,2883.040000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",433,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,2886.368000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",434,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,2.432,2888.8000000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",435,0.0,1024.0,0,0,0.0,1024.0,1024.0,64.0,48.0,0.5714285714285714,2560.0,2048.0,2.016,2890.8160000000007,0.0,1024.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,80.0,64.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",436,0.0,0.0,0,0,0.0,0.0,0.0,0.0,40.0,0.0,4096.0,4096.0,2.624,2893.4400000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",437,8192.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,16.0,0.0,4096.0,4096.0,2.88,2896.3200000000006,0.0,2048.0,8192.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",438,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,1.984,2898.3040000000005,0.0,1024.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",439,7200.0,16448.0,0,0,0.0,16448.0,16448.0,0.0,16.0,0.0,4096.0,4096.0,2.784,2901.0880000000006,0.0,2048.0,7200.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",440,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.016,2903.1040000000007,0.0,1024.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",441,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.08,2905.1840000000007,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",442,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.224,2909.408000000001,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",443,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.984,2911.3920000000007,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",444,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,2913.4400000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",445,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.688,2916.1280000000006,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",446,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.656,2918.7840000000006,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,447,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3066528.0,122880.0,7.744,2926.5280000000007,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95829.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",448,0.0,43008.0,0,0,0.0,43008.0,43008.0,0.0,1920.0,0.0,125952.0,24576.0,2.656,2929.1840000000007,36864.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3936.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,449,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3068896.0,122880.0,7.712,2936.8960000000006,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95903.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",450,0.0,43008.0,0,0,0.0,43008.0,43008.0,0.0,1920.0,0.0,125952.0,24576.0,2.752,2939.6480000000006,36864.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3936.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,451,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3068960.0,122880.0,7.712,2947.3600000000006,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95905.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",452,0.0,43008.0,0,0,0.0,43008.0,43008.0,0.0,1920.0,0.0,125952.0,24576.0,2.656,2950.0160000000005,36864.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3936.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",453,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.784,2952.8000000000006,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",454,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,3.04,2955.8400000000006,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",455,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,4.032,2959.8720000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",456,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.72,2962.5920000000006,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",457,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.112,2964.7040000000006,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",458,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.816,2967.5200000000004,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",459,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.688,2970.2080000000005,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",460,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,4.0,2974.2080000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",461,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.784,2976.9920000000006,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",462,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.048,2979.0400000000004,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",463,0.0,0.0,0,0,0.0,0.0,0.0,0.0,480.0,0.0,49152.0,49152.0,2.656,2981.6960000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",464,0.0,0.0,0,0,0.0,0.0,0.0,0.0,480.0,0.0,49152.0,49152.0,2.656,2984.3520000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",465,77344.0,8773908.0,0,0,0.0,8773908.0,8773908.0,50522.0,96.0,0.998103441463511,122880.0,24576.0,20.32,3004.6720000000005,7432321.0,1186899.0,77344.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,466,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3067904.0,122880.0,7.68,3012.3520000000003,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95872.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",467,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.656,3015.0080000000003,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",468,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.112,3017.1200000000003,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",469,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.016,3019.1360000000004,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",470,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.096,3023.2320000000004,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",471,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.984,3025.2160000000003,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",472,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,3027.2320000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",473,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.752,3029.9840000000004,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",474,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.72,3032.704,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,475,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.36,3048.0640000000003,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",476,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.688,3050.7520000000004,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",477,282624.0,589824.0,0,0,0.0,589824.0,589824.0,0.0,384.0,0.0,98304.0,98304.0,2.336,3053.088,24576.0,0.0,282624.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,478,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.392,3068.48,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",479,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.56,3071.04,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",480,0.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.24,3073.2799999999997,0.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,481,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,84480.0,0.8172757475083057,10616832.0,196608.0,15.68,3088.9599999999996,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",482,0.0,55296.0,0,0,0.0,55296.0,55296.0,0.0,1728.0,0.0,196608.0,24576.0,2.368,3091.3279999999995,49152.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",483,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.144,3093.4719999999993,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",484,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.016,3095.4879999999994,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",485,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.128,3099.6159999999995,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",486,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.888,3101.5039999999995,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",487,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,3103.551999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",488,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.72,3106.271999999999,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",489,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.688,3108.959999999999,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,490,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3067456.0,122880.0,7.776,3116.735999999999,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95858.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",491,0.0,43008.0,0,0,0.0,43008.0,43008.0,0.0,1920.0,0.0,125952.0,24576.0,2.624,3119.3599999999988,36864.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3936.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,492,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3068960.0,122880.0,7.776,3127.1359999999986,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95905.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",493,0.0,43008.0,0,0,0.0,43008.0,43008.0,0.0,1920.0,0.0,125952.0,24576.0,2.624,3129.7599999999984,36864.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3936.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,494,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3070816.0,122880.0,7.744,3137.5039999999985,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95963.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",495,0.0,43008.0,0,0,0.0,43008.0,43008.0,0.0,1920.0,0.0,125952.0,24576.0,2.656,3140.1599999999985,36864.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3936.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",496,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.784,3142.9439999999986,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",497,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.688,3145.6319999999987,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",498,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,4.096,3149.7279999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",499,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.656,3152.3839999999987,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",500,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.08,3154.4639999999986,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",501,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.688,3157.1519999999987,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",502,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.688,3159.839999999999,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",503,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,4.064,3163.9039999999986,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",504,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.688,3166.5919999999987,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",505,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.144,3168.7359999999985,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",506,0.0,0.0,0,0,0.0,0.0,0.0,0.0,480.0,0.0,49152.0,49152.0,2.624,3171.3599999999983,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",507,0.0,0.0,0,0,0.0,0.0,0.0,0.0,480.0,0.0,49152.0,49152.0,2.624,3173.983999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",508,91200.0,8810280.0,0,0,0.0,8810280.0,8810280.0,50235.0,96.0,0.9980926268105144,122880.0,24576.0,20.224,3194.2079999999983,7439682.0,1188198.0,91200.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,509,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3068640.0,122880.0,7.744,3201.9519999999984,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95895.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",510,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.528,3204.479999999998,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",511,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.08,3206.559999999998,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",512,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.016,3208.575999999998,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",513,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.16,3212.735999999998,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",514,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.984,3214.719999999998,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",515,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,3216.703999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",516,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.688,3219.391999999998,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",517,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.688,3222.079999999998,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,518,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.232,3237.311999999998,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",519,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.656,3239.967999999998,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",520,282624.0,589824.0,0,0,0.0,589824.0,589824.0,0.0,384.0,0.0,98304.0,98304.0,2.336,3242.303999999998,24576.0,0.0,282624.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,521,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.616,3257.919999999998,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",522,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.592,3260.511999999998,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",523,0.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.208,3262.719999999998,0.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,524,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,84480.0,0.8172757475083057,10616832.0,196608.0,15.808,3278.527999999998,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",525,0.0,55296.0,0,0,0.0,55296.0,55296.0,0.0,1728.0,0.0,196608.0,24576.0,2.304,3280.831999999998,49152.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",526,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.048,3282.879999999998,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",527,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.016,3284.895999999998,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",528,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.128,3289.023999999998,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",529,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.984,3291.007999999998,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",530,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,3293.0559999999978,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",531,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.656,3295.7119999999977,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",532,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.752,3298.4639999999977,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,533,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3066592.0,122880.0,7.808,3306.2719999999977,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95831.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",534,0.0,43008.0,0,0,0.0,43008.0,43008.0,0.0,1920.0,0.0,125952.0,24576.0,2.592,3308.8639999999978,36864.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3936.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,535,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3069120.0,122880.0,7.872,3316.7359999999976,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95910.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",536,0.0,43008.0,0,0,0.0,43008.0,43008.0,0.0,1920.0,0.0,125952.0,24576.0,2.72,3319.4559999999974,36864.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3936.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,537,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3070336.0,122880.0,7.744,3327.1999999999975,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95948.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",538,0.0,43008.0,0,0,0.0,43008.0,43008.0,0.0,1920.0,0.0,125952.0,24576.0,2.784,3329.9839999999976,36864.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3936.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",539,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.72,3332.7039999999974,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",540,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.656,3335.3599999999974,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",541,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,4.032,3339.3919999999976,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",542,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.688,3342.0799999999977,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",543,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.144,3344.2239999999974,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",544,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.848,3347.0719999999974,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",545,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.688,3349.7599999999975,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",546,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,4.064,3353.8239999999973,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",547,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.72,3356.543999999997,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",548,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.272,3358.815999999997,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",549,0.0,0.0,0,0,0.0,0.0,0.0,0.0,480.0,0.0,49152.0,49152.0,2.592,3361.407999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",550,0.0,0.0,0,0,0.0,0.0,0.0,0.0,480.0,0.0,49152.0,49152.0,2.592,3363.9999999999973,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",551,96288.0,8823636.0,0,0,0.0,8823636.0,8823636.0,49974.0,96.0,0.9980826842420611,122880.0,24576.0,20.352,3384.351999999997,7442385.0,1188675.0,96288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,552,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3067712.0,122880.0,7.744,3392.0959999999973,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95866.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",553,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.72,3394.815999999997,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",554,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.112,3396.927999999997,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",555,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,1.984,3398.911999999997,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",556,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.096,3403.007999999997,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",557,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.952,3404.9599999999973,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",558,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,3406.9439999999972,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",559,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.656,3409.599999999997,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",560,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.784,3412.3839999999973,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,561,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.52,3427.9039999999973,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",562,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.56,3430.463999999997,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",563,282624.0,589824.0,0,0,0.0,589824.0,589824.0,0.0,384.0,0.0,98304.0,98304.0,2.368,3432.831999999997,24576.0,0.0,282624.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,564,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.36,3448.1919999999973,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",565,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.56,3450.751999999997,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",566,0.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.368,3453.119999999997,0.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,567,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,84480.0,0.8172757475083057,10616832.0,196608.0,15.52,3468.639999999997,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",568,0.0,55296.0,0,0,0.0,55296.0,55296.0,0.0,1728.0,0.0,196608.0,24576.0,2.368,3471.007999999997,49152.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",569,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.144,3473.151999999997,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",570,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.016,3475.167999999997,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",571,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.224,3479.391999999997,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",572,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.952,3481.3439999999973,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",573,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,3483.3599999999974,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",574,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.592,3485.9519999999975,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",575,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.656,3488.6079999999974,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,576,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3065248.0,122880.0,7.936,3496.5439999999976,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95789.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",577,0.0,43008.0,0,0,0.0,43008.0,43008.0,0.0,1920.0,0.0,125952.0,24576.0,2.688,3499.2319999999977,36864.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3936.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,578,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3069632.0,122880.0,7.904,3507.1359999999977,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95926.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",579,0.0,43008.0,0,0,0.0,43008.0,43008.0,0.0,1920.0,0.0,125952.0,24576.0,2.624,3509.7599999999975,36864.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3936.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,580,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3068768.0,122880.0,7.744,3517.5039999999976,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95899.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",581,0.0,43008.0,0,0,0.0,43008.0,43008.0,0.0,1920.0,0.0,125952.0,24576.0,2.624,3520.1279999999974,36864.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3936.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",582,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.656,3522.7839999999974,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",583,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.656,3525.4399999999973,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",584,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,4.0,3529.4399999999973,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",585,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.72,3532.159999999997,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",586,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.112,3534.271999999997,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",587,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.688,3536.9599999999973,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",588,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.688,3539.6479999999974,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",589,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,4.0,3543.6479999999974,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",590,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.688,3546.3359999999975,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",591,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.08,3548.4159999999974,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",592,0.0,0.0,0,0,0.0,0.0,0.0,0.0,480.0,0.0,49152.0,49152.0,2.624,3551.0399999999972,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",593,0.0,0.0,0,0,0.0,0.0,0.0,0.0,480.0,0.0,49152.0,49152.0,2.688,3553.7279999999973,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",594,98304.0,8828928.0,0,0,0.0,8828928.0,8828928.0,49920.0,96.0,0.9980806142034548,122880.0,24576.0,20.096,3573.8239999999973,7443456.0,1188864.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,595,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3068480.0,122880.0,7.712,3581.5359999999973,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95890.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",596,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.72,3584.255999999997,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",597,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.08,3586.335999999997,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",598,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.016,3588.351999999997,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",599,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.224,3592.5759999999973,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",600,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.952,3594.5279999999975,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",601,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.112,3596.6399999999976,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",602,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.688,3599.3279999999977,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",603,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.688,3602.015999999998,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,604,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.296,3617.3119999999976,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",605,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.496,3619.8079999999977,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",606,282624.0,589824.0,0,0,0.0,589824.0,589824.0,0.0,384.0,0.0,98304.0,98304.0,2.272,3622.0799999999977,24576.0,0.0,282624.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,607,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.392,3637.4719999999975,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",608,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.72,3640.1919999999973,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",609,0.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.272,3642.463999999997,0.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,610,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,84480.0,0.8172757475083057,10616832.0,196608.0,15.52,3657.983999999997,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",611,0.0,55296.0,0,0,0.0,55296.0,55296.0,0.0,1728.0,0.0,196608.0,24576.0,2.304,3660.2879999999973,49152.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",612,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.112,3662.3999999999974,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",613,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.048,3664.447999999997,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",614,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.224,3668.6719999999973,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",615,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.952,3670.6239999999975,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",616,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,3672.6719999999973,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",617,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.72,3675.391999999997,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",618,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.688,3678.079999999997,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,619,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3066560.0,122880.0,7.936,3686.0159999999973,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95830.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",620,0.0,43008.0,0,0,0.0,43008.0,43008.0,0.0,1920.0,0.0,125952.0,24576.0,2.656,3688.6719999999973,36864.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3936.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,621,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3069824.0,122880.0,7.744,3696.4159999999974,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95932.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",622,0.0,43008.0,0,0,0.0,43008.0,43008.0,0.0,1920.0,0.0,125952.0,24576.0,2.656,3699.0719999999974,36864.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3936.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,623,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3069120.0,122880.0,7.712,3706.7839999999974,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95910.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",624,0.0,43008.0,0,0,0.0,43008.0,43008.0,0.0,1920.0,0.0,125952.0,24576.0,2.848,3709.6319999999973,36864.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3936.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",625,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.912,3712.543999999997,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",626,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.656,3715.199999999997,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",627,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,4.0,3719.199999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",628,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.752,3721.951999999997,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",629,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.08,3724.031999999997,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",630,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.656,3726.687999999997,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",631,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.624,3729.3119999999967,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",632,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,4.032,3733.343999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",633,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.752,3736.095999999997,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",634,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.08,3738.1759999999967,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",635,0.0,0.0,0,0,0.0,0.0,0.0,0.0,480.0,0.0,49152.0,49152.0,2.656,3740.8319999999967,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",636,0.0,0.0,0,0,0.0,0.0,0.0,0.0,480.0,0.0,49152.0,49152.0,2.88,3743.711999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",637,98304.0,8828928.0,0,0,0.0,8828928.0,8828928.0,49920.0,96.0,0.9980806142034548,122880.0,24576.0,20.288,3763.999999999997,7443456.0,1188864.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,638,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3067712.0,122880.0,7.616,3771.615999999997,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95866.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",639,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.528,3774.1439999999966,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",640,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.112,3776.2559999999967,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",641,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.112,3778.3679999999968,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",642,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.192,3782.5599999999968,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",643,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.952,3784.511999999997,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",644,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,3786.5599999999968,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",645,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.656,3789.2159999999967,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",646,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.688,3791.903999999997,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,647,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.328,3807.231999999997,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",648,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.56,3809.7919999999967,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",649,282624.0,589824.0,0,0,0.0,589824.0,589824.0,0.0,384.0,0.0,98304.0,98304.0,2.368,3812.1599999999967,24576.0,0.0,282624.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,650,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.648,3827.807999999997,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",651,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.72,3830.5279999999966,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",652,0.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.208,3832.7359999999967,0.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,653,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,84480.0,0.8172757475083057,10616832.0,196608.0,15.424,3848.1599999999967,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",654,0.0,55296.0,0,0,0.0,55296.0,55296.0,0.0,1728.0,0.0,196608.0,24576.0,2.496,3850.6559999999968,49152.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",655,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.08,3852.7359999999967,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",656,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.048,3854.7839999999965,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",657,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.096,3858.8799999999965,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",658,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.952,3860.8319999999967,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",659,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,3862.847999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",660,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.656,3865.5039999999967,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",661,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.752,3868.2559999999967,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,662,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3068512.0,122880.0,7.776,3876.0319999999965,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95891.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",663,0.0,43008.0,0,0,0.0,43008.0,43008.0,0.0,1920.0,0.0,125952.0,24576.0,2.624,3878.6559999999963,36864.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3936.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,664,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3068736.0,122880.0,7.744,3886.3999999999965,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95898.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",665,0.0,43008.0,0,0,0.0,43008.0,43008.0,0.0,1920.0,0.0,125952.0,24576.0,2.688,3889.0879999999966,36864.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3936.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,666,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3067712.0,122880.0,7.744,3896.8319999999967,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95866.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",667,0.0,43008.0,0,0,0.0,43008.0,43008.0,0.0,1920.0,0.0,125952.0,24576.0,2.688,3899.519999999997,36864.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3936.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",668,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.752,3902.2719999999968,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",669,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.624,3904.8959999999965,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",670,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,3.968,3908.8639999999964,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",671,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.72,3911.583999999996,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",672,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.144,3913.727999999996,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",673,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.72,3916.447999999996,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",674,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.656,3919.1039999999957,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",675,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,4.0,3923.1039999999957,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",676,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.72,3925.8239999999955,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",677,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.048,3927.8719999999953,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",678,0.0,0.0,0,0,0.0,0.0,0.0,0.0,480.0,0.0,49152.0,49152.0,2.592,3930.4639999999954,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",679,0.0,0.0,0,0,0.0,0.0,0.0,0.0,480.0,0.0,49152.0,49152.0,2.72,3933.183999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",680,98304.0,8828928.0,0,0,0.0,8828928.0,8828928.0,49920.0,96.0,0.9980806142034548,122880.0,24576.0,20.224,3953.4079999999954,7443456.0,1188864.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,681,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3066560.0,122880.0,7.808,3961.2159999999953,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95830.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",682,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.56,3963.7759999999953,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",683,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.112,3965.8879999999954,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",684,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.048,3967.935999999995,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",685,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.064,3971.999999999995,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",686,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.92,3973.919999999995,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",687,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,3975.935999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",688,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.688,3978.6239999999952,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",689,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.816,3981.439999999995,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,690,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.296,3996.735999999995,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",691,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.688,3999.423999999995,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",692,282624.0,589824.0,0,0,0.0,589824.0,589824.0,0.0,384.0,0.0,98304.0,98304.0,2.336,4001.7599999999948,24576.0,0.0,282624.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,693,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.296,4017.0559999999946,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",694,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.528,4019.5839999999944,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",695,0.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.24,4021.823999999994,0.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,696,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,84480.0,0.8172757475083057,10616832.0,196608.0,15.552,4037.3759999999943,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",697,0.0,55296.0,0,0,0.0,55296.0,55296.0,0.0,1728.0,0.0,196608.0,24576.0,2.528,4039.903999999994,49152.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",698,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.08,4041.983999999994,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",699,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.016,4043.999999999994,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",700,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.16,4048.159999999994,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",701,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.952,4050.111999999994,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",702,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,4052.1279999999942,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",703,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.656,4054.783999999994,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",704,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.752,4057.535999999994,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,705,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3067840.0,122880.0,8.0,4065.535999999994,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95870.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",706,0.0,43008.0,0,0,0.0,43008.0,43008.0,0.0,1920.0,0.0,125952.0,24576.0,2.72,4068.255999999994,36864.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3936.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,707,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3068032.0,122880.0,7.776,4076.031999999994,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95876.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",708,0.0,43008.0,0,0,0.0,43008.0,43008.0,0.0,1920.0,0.0,125952.0,24576.0,2.656,4078.6879999999937,36864.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3936.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,709,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3067936.0,122880.0,8.032,4086.719999999994,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95873.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",710,0.0,43008.0,0,0,0.0,43008.0,43008.0,0.0,1920.0,0.0,125952.0,24576.0,2.592,4089.311999999994,36864.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3936.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",711,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.72,4092.031999999994,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",712,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.72,4094.7519999999936,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",713,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,4.032,4098.783999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",714,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.72,4101.5039999999935,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",715,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.08,4103.5839999999935,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",716,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.752,4106.335999999994,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",717,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.656,4108.991999999994,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",718,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,4.0,4112.991999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",719,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.688,4115.679999999994,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",720,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.08,4117.759999999994,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",721,0.0,0.0,0,0,0.0,0.0,0.0,0.0,480.0,0.0,49152.0,49152.0,2.688,4120.447999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",722,0.0,0.0,0,0,0.0,0.0,0.0,0.0,480.0,0.0,49152.0,49152.0,2.656,4123.103999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",723,98304.0,8828928.0,0,0,0.0,8828928.0,8828928.0,49920.0,96.0,0.9980806142034548,122880.0,24576.0,20.288,4143.3919999999935,7443456.0,1188864.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,724,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3068224.0,122880.0,7.808,4151.199999999993,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95882.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",725,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.496,4153.695999999994,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",726,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.08,4155.7759999999935,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",727,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.08,4157.855999999993,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",728,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.16,4162.015999999993,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",729,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.984,4163.999999999994,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",730,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,4166.047999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",731,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.656,4168.703999999993,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",732,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.656,4171.359999999993,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,733,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.232,4186.591999999993,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",734,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.528,4189.1199999999935,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",735,282624.0,589824.0,0,0,0.0,589824.0,589824.0,0.0,384.0,0.0,98304.0,98304.0,2.4,4191.519999999993,24576.0,0.0,282624.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,736,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.392,4206.911999999993,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",737,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.784,4209.695999999993,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",738,0.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.208,4211.903999999992,0.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,739,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,84480.0,0.8172757475083057,10616832.0,196608.0,15.776,4227.679999999992,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",740,0.0,55296.0,0,0,0.0,55296.0,55296.0,0.0,1728.0,0.0,196608.0,24576.0,2.56,4230.2399999999925,49152.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",741,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.08,4232.319999999992,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",742,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,1.984,4234.303999999993,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",743,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.096,4238.399999999992,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",744,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.952,4240.351999999993,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",745,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,4242.4319999999925,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",746,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.656,4245.0879999999925,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",747,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.624,4247.711999999992,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,748,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3066144.0,122880.0,7.872,4255.583999999993,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95817.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",749,0.0,43008.0,0,0,0.0,43008.0,43008.0,0.0,1920.0,0.0,125952.0,24576.0,2.592,4258.175999999992,36864.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3936.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,750,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3069792.0,122880.0,7.712,4265.887999999993,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95931.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",751,0.0,43008.0,0,0,0.0,43008.0,43008.0,0.0,1920.0,0.0,125952.0,24576.0,2.656,4268.543999999993,36864.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3936.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,752,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3071104.0,122880.0,7.648,4276.191999999993,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95972.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",753,0.0,43008.0,0,0,0.0,43008.0,43008.0,0.0,1920.0,0.0,125952.0,24576.0,2.816,4279.0079999999925,36864.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3936.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",754,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.72,4281.727999999993,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",755,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.656,4284.383999999993,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",756,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,4.0,4288.383999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",757,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.72,4291.103999999993,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",758,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.048,4293.151999999993,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",759,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.784,4295.935999999992,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",760,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.688,4298.6239999999925,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",761,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,4.032,4302.655999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",762,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.752,4305.407999999993,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",763,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.144,4307.551999999993,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",764,0.0,0.0,0,0,0.0,0.0,0.0,0.0,480.0,0.0,49152.0,49152.0,2.816,4310.367999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",765,0.0,0.0,0,0,0.0,0.0,0.0,0.0,480.0,0.0,49152.0,49152.0,2.624,4312.991999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",766,98304.0,8828928.0,0,0,0.0,8828928.0,8828928.0,49920.0,96.0,0.9980806142034548,122880.0,24576.0,20.128,4333.119999999993,7443456.0,1188864.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,767,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3068160.0,122880.0,7.712,4340.831999999993,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95880.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",768,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.56,4343.3919999999935,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",769,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.112,4345.5039999999935,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",770,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.048,4347.551999999993,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",771,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.096,4351.647999999993,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",772,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.984,4353.631999999993,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",773,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,4355.615999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",774,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.624,4358.239999999993,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",775,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.72,4360.959999999994,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,776,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.328,4376.287999999994,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",777,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.56,4378.8479999999945,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",778,282624.0,589824.0,0,0,0.0,589824.0,589824.0,0.0,384.0,0.0,98304.0,98304.0,2.368,4381.215999999995,24576.0,0.0,282624.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,779,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.296,4396.511999999995,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",780,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.592,4399.103999999995,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",781,0.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.176,4401.279999999995,0.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,782,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,84480.0,0.8172757475083057,10616832.0,196608.0,15.68,4416.9599999999955,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",783,0.0,55296.0,0,0,0.0,55296.0,55296.0,0.0,1728.0,0.0,196608.0,24576.0,2.496,4419.455999999996,49152.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",784,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.112,4421.567999999996,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",785,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.08,4423.647999999996,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",786,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.096,4427.743999999995,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",787,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.92,4429.663999999995,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",788,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,4431.711999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",789,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.656,4434.367999999995,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",790,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.72,4437.087999999995,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,791,3733979136.0,7501991936.0,0,0,0.0,7501991936.0,7501991936.0,17548608.0,4140256.0,0.809106830122592,505185664.0,4861952.0,523.872,4960.9599999999955,14585856.0,19447808.0,3733979136.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,15787052.0,151936.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",792,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,64.0,1.696,4962.655999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,2.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",793,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,192.0,320.0,2.72,4965.375999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6.0,10.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",794,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,4967.423999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",795,0.0,1215488.0,0,0,0.0,1215488.0,1215488.0,0.0,18992.0,0.0,4861952.0,4861952.0,8.192,4975.615999999995,0.0,1215488.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,151936.0,151936.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",796,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.664,4977.279999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",797,0.0,0.0,0,0,0.0,0.0,0.0,10880.0,48864.0,0.1821103374397429,4866048.0,198080.0,7.84,4985.119999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,152064.0,6190.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",798,0.0,0.0,0,0,0.0,0.0,0.0,50320.0,471256.0,0.09647683175606239,18078880.0,768.0,10.24,4995.359999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,564965.0,24.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",799,0.0,0.0,0,0,0.0,0.0,0.0,10880.0,48864.0,0.1821103374397429,4866048.0,196672.0,7.776,5003.135999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,152064.0,6146.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",800,0.0,0.0,0,0,0.0,0.0,0.0,50320.0,475336.0,0.0957280046265999,18181696.0,864.0,9.856,5012.991999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,568178.0,27.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",801,0.0,0.0,0,0,0.0,0.0,0.0,10880.0,48864.0,0.1821103374397429,4866048.0,197184.0,7.904,5020.895999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,152064.0,6162.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",802,0.0,0.0,0,0,0.0,0.0,0.0,50320.0,472701.0,0.09621028601146034,18120000.0,832.0,9.856,5030.751999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,566250.0,26.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",803,0.0,0.0,0,0,0.0,0.0,0.0,10880.0,48864.0,0.1821103374397429,4866048.0,197504.0,7.808,5038.559999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,152064.0,6172.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",804,0.0,0.0,0,0,0.0,0.0,0.0,50320.0,473721.0,0.09602302109949412,18155104.0,1216.0,9.92,5048.479999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,567347.0,38.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",805,0.0,0.0,0,0,0.0,0.0,0.0,0.0,66.0,0.0,21792.0,2720.0,3.136,5051.615999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,681.0,85.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",806,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.696,5053.311999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",807,0.0,0.0,0,0,0.0,0.0,0.0,497.0,52.0,0.9052823315118397,2720.0,0.0,3.776,5057.087999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,85.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",808,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.728,5058.815999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",809,0.0,0.0,0,0,0.0,0.0,0.0,497.0,52.0,0.9052823315118397,2720.0,0.0,3.712,5062.527999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,85.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",810,0.0,0.0,0,0,0.0,0.0,0.0,344496.0,60410.0,0.8508048781692541,4906784.0,15776.0,10.208,5072.735999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,153337.0,493.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",811,0.0,0.0,0,0,0.0,0.0,0.0,3664.0,64.0,0.9828326180257511,5120.0,992.0,6.528,5079.263999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160.0,31.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",812,0.0,0.0,0,0,0.0,0.0,0.0,0.0,113952.0,0.0,4888160.0,491680.0,7.968,5087.231999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,152755.0,15365.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",813,0.0,0.0,0,0,0.0,0.0,0.0,0.0,28488.0,0.0,6077440.0,32128.0,9.568,5096.799999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,189920.0,1004.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",814,0.0,0.0,0,0,0.0,0.0,0.0,0.0,37984.0,0.0,0.0,9723904.0,7.296,5104.095999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,303872.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",815,0.0,0.0,0,0,0.0,0.0,0.0,98304.0,37984.0,0.7212960788917586,4861952.0,0.0,8.64,5112.735999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,151936.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",816,0.0,0.0,0,0,0.0,0.0,0.0,156.0,64.0,0.7090909090909091,8192.0,0.0,2.176,5114.911999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",817,0.0,0.0,0,0,0.0,0.0,0.0,354852.0,192829.0,0.6479173095287221,18287104.0,12071680.0,26.24,5141.151999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,571472.0,377240.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",818,0.0,0.0,0,0,0.0,0.0,0.0,135252.0,214582.0,0.3866176529439677,18686720.0,10095680.0,23.872,5165.023999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,583960.0,315490.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",819,0.0,0.0,0,0,0.0,0.0,0.0,135156.0,213999.0,0.3870945568587017,18604928.0,14991360.0,24.128,5189.151999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,581404.0,468480.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",820,0.0,0.0,0,0,0.0,0.0,0.0,135156.0,213958.0,0.38714001730093894,18513536.0,12855744.0,23.968,5213.119999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,578548.0,401742.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",821,0.0,0.0,0,0,0.0,0.0,0.0,14336.0,37984.0,0.27400611620795107,9723904.0,0.0,12.832,5225.951999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,303872.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",822,0.0,0.0,0,0,0.0,0.0,0.0,39.0,16.0,0.7090909090909091,2048.0,0.0,2.176,5228.127999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",823,0.0,0.0,0,0,0.0,0.0,0.0,111421.0,194594.0,0.3641030668431286,16573568.0,9000832.0,21.888,5250.015999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,517924.0,281276.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",824,0.0,0.0,0,0,0.0,0.0,0.0,0.0,151936.0,0.0,14655904.0,14585856.0,18.144,5268.159999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,457997.0,455808.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",825,17016832.0,40153344.0,0,0,0.0,40153344.0,40153344.0,1056.0,38272.0,0.026851098454027666,14585856.0,4861952.0,62.624,5330.783999999997,4904192.0,1215488.0,17016832.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,455808.0,151936.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",826,0.0,6104232.0,0,0,0.0,6104232.0,6104232.0,669744.0,75968.0,0.8981268908103933,4861952.0,4861952.0,211.52,5542.303999999997,6104232.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,151936.0,151936.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",827,0.0,0.0,0,0,0.0,0.0,0.0,0.0,18992.0,0.0,4861952.0,1215488.0,7.296,5549.599999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,151936.0,37984.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",828,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,256.0,1.92,5551.519999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,8.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",829,0.0,0.0,0,0,0.0,0.0,0.0,0.0,113952.0,0.0,10939392.0,540256.0,14.976,5566.495999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,341856.0,16883.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",830,0.0,0.0,0,0,0.0,0.0,0.0,0.0,28488.0,0.0,6077440.0,3968.0,9.312,5575.807999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,189920.0,124.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",831,17016832.0,40153344.0,0,0,0.0,40153344.0,40153344.0,1056.0,38272.0,0.026851098454027666,14585856.0,4861952.0,62.624,5638.431999999997,4904192.0,1215488.0,17016832.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,455808.0,151936.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",832,0.0,0.0,0,0,0.0,0.0,0.0,11833.0,9651.0,0.5507819772854217,4862560.0,4800.0,10.336,5648.767999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,151955.0,150.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",833,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,5650.9119999999975,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",834,0.0,0.0,0,0,0.0,0.0,0.0,11833.0,9651.0,0.5507819772854217,4862560.0,4800.0,10.368,5661.279999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,151955.0,150.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",835,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,5663.423999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",836,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.048,5665.471999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",837,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.976,5668.447999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",838,0.0,1971352.0,0,0,0.0,1971352.0,1971352.0,14744.0,9664.0,0.6040642412323828,4862784.0,4928.0,10.272,5678.7199999999975,1971352.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,151962.0,154.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",839,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,5680.735999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",840,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.2,5683.935999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",841,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,5685.983999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",842,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.88,5688.863999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",843,2555904.0,7542784.0,0,0,0.0,7542784.0,7542784.0,0.0,37984.0,0.0,0.0,4861952.0,5.376,5694.239999999997,0.0,2430976.0,2555904.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,151936.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",844,6077440.0,12154880.0,0,0,0.0,12154880.0,12154880.0,0.0,28488.0,0.0,9723904.0,135680.0,13.472,5707.711999999997,0.0,0.0,6077440.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,303872.0,4240.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",845,0.0,0.0,0,0,0.0,0.0,0.0,26904.0,9824.0,0.7325201481158788,4864512.0,5632.0,12.096,5719.807999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,152016.0,176.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",846,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,192.0,320.0,2.624,5722.431999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6.0,10.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",847,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,5724.127999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",848,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,5725.855999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",849,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.048,5727.903999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",850,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,5729.9199999999955,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",851,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,64.0,2.88,5732.799999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,2.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",852,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.264,5736.063999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",853,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,5738.143999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
