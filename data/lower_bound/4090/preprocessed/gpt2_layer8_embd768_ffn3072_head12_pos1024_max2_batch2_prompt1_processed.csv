Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.824,1.824,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,3.52,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,5.248,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.048,7.296,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.4,9.696,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",6,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.336,12.032,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",7,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,15.424,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",8,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.136,18.56,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",9,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.208,20.768,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",10,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,22.464000000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",11,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,24.192000000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.728,25.920000000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,0.0,0.0,0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,2.4,28.320000000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,30.336000000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",15,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.176,32.51200000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",16,0.0,0.0,0,0,0.0,0.0,0.0,36.0,2.0,0.9473684210526315,32.0,32.0,2.496,35.00800000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",17,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,36.99200000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",18,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,39.04000000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",19,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,2.112,41.152000000000015,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",20,0.0,0.0,0,0,0.0,0.0,0.0,0.0,144.0,0.0,3264.0,6144.0,3.424,44.576000000000015,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,102.0,192.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",21,0.0,0.0,0,0,0.0,0.0,0.0,0.0,144.0,0.0,3264.0,6144.0,3.424,48.000000000000014,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,102.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",22,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,50.08000000000001,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",23,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,52.064000000000014,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",24,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,55.424000000000014,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",25,12834.0,46714.0,0,0,0.0,46714.0,46714.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,4.16,59.58400000000002,13080.0,7966.0,12834.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",26,3538944.0,7188480.0,0,0,0.0,7188480.0,7188480.0,32544.0,57456.0,0.3616,7308288.0,18432.0,14.304,73.88800000000002,55296.0,55296.0,3538944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,228384.0,576.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",27,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,2.624,76.51200000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",28,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,2.624,79.13600000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",29,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,2.656,81.79200000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",30,49152.0,1632768.0,0,0,0.0,1632768.0,1632768.0,12768.0,24.0,0.99812382739212,18432.0,6144.0,11.904,93.69600000000001,1234944.0,299520.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",31,1179648.0,2396160.0,0,0,0.0,2396160.0,2396160.0,10848.0,19152.0,0.3616,2436096.0,6144.0,12.928,106.62400000000001,18432.0,18432.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76128.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",32,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,108.70400000000001,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",33,12834.0,46714.0,0,0,0.0,46714.0,46714.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,4.16,112.864,13080.0,7966.0,12834.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",34,4718592.0,9584640.0,0,0,0.0,9584640.0,9584640.0,43392.0,76608.0,0.3616,9744384.0,24576.0,16.544,129.40800000000002,73728.0,73728.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304512.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",35,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.048,131.45600000000002,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",36,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.016,133.472,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",37,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.048,135.52,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",38,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.048,137.568,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",39,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,1.984,139.55200000000002,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",40,35766.0,89964.0,0,0,0.0,89964.0,89964.0,0.0,96.0,0.0,24576.0,24576.0,2.144,141.69600000000003,6144.0,12288.0,35766.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",41,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.016,143.71200000000002,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",42,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.112,145.824,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_32x32_sliced1x4_nn,43,77070336.0,155344896.0,0,0,0.0,155344896.0,155344896.0,419328.0,78768.0,0.8418618097716103,10045824.0,43008.0,15.872,161.69600000000003,516096.0,688128.0,77070336.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313932.0,1344.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",44,0.0,13824.0,0,0,0.0,13824.0,13824.0,0.0,864.0,0.0,46080.0,6144.0,2.976,164.67200000000003,12288.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1440.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",45,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.112,166.78400000000002,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",46,12834.0,46714.0,0,0,0.0,46714.0,46714.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,4.192,170.97600000000003,13080.0,7966.0,12834.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",47,3538944.0,7188480.0,0,0,0.0,7188480.0,7188480.0,32544.0,57456.0,0.3616,7308288.0,18432.0,14.304,185.28000000000003,55296.0,55296.0,3538944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,228384.0,576.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",48,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,2.624,187.90400000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",49,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,2.656,190.56000000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",50,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,2.72,193.28000000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",51,49152.0,1632768.0,0,0,0.0,1632768.0,1632768.0,12768.0,24.0,0.99812382739212,18432.0,6144.0,11.392,204.67200000000003,1234944.0,299520.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",52,1179648.0,2396160.0,0,0,0.0,2396160.0,2396160.0,10848.0,19152.0,0.3616,2436096.0,6144.0,13.344,218.01600000000002,18432.0,18432.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76128.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",53,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.144,220.16000000000003,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",54,12834.0,46714.0,0,0,0.0,46714.0,46714.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,4.288,224.44800000000004,13080.0,7966.0,12834.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",55,4718592.0,9584640.0,0,0,0.0,9584640.0,9584640.0,43392.0,76608.0,0.3616,9744384.0,24576.0,15.712,240.16000000000003,73728.0,73728.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304512.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",56,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.08,242.24000000000004,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",57,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.048,244.28800000000004,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",58,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.08,246.36800000000005,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",59,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.08,248.44800000000006,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",60,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.016,250.46400000000006,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",61,35718.0,89868.0,0,0,0.0,89868.0,89868.0,0.0,96.0,0.0,24576.0,24576.0,2.144,252.60800000000006,6144.0,12288.0,35718.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",62,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.048,254.65600000000006,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",63,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.08,256.73600000000005,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_32x32_sliced1x4_nn,64,77070336.0,155344896.0,0,0,0.0,155344896.0,155344896.0,419328.0,78768.0,0.8418618097716103,10046304.0,43008.0,15.584,272.32000000000005,516096.0,688128.0,77070336.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313947.0,1344.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",65,0.0,13824.0,0,0,0.0,13824.0,13824.0,0.0,864.0,0.0,46080.0,6144.0,2.912,275.232,12288.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1440.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",66,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.176,277.408,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",67,12834.0,46714.0,0,0,0.0,46714.0,46714.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,4.256,281.664,13080.0,7966.0,12834.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",68,3538944.0,7188480.0,0,0,0.0,7188480.0,7188480.0,32544.0,57456.0,0.3616,7308288.0,18432.0,14.24,295.904,55296.0,55296.0,3538944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,228384.0,576.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",69,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,2.72,298.624,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",70,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,2.656,301.28000000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",71,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,2.592,303.872,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",72,49152.0,1632768.0,0,0,0.0,1632768.0,1632768.0,12768.0,24.0,0.99812382739212,18432.0,6144.0,11.328,315.2,1234944.0,299520.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",73,1179648.0,2396160.0,0,0,0.0,2396160.0,2396160.0,10848.0,19152.0,0.3616,2436096.0,6144.0,12.768,327.96799999999996,18432.0,18432.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76128.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",74,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.144,330.11199999999997,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",75,12834.0,46714.0,0,0,0.0,46714.0,46714.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,4.32,334.43199999999996,13080.0,7966.0,12834.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",76,4718592.0,9584640.0,0,0,0.0,9584640.0,9584640.0,43392.0,76608.0,0.3616,9744384.0,24576.0,15.52,349.95199999999994,73728.0,73728.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304512.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",77,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.048,351.99999999999994,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",78,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.048,354.04799999999994,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",79,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.016,356.06399999999996,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",80,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.08,358.14399999999995,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",81,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.016,360.15999999999997,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",82,35638.0,89708.0,0,0,0.0,89708.0,89708.0,0.0,96.0,0.0,24576.0,24576.0,2.208,362.368,6144.0,12288.0,35638.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",83,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.016,364.384,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",84,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.208,366.59200000000004,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_32x32_sliced1x4_nn,85,77070336.0,155344896.0,0,0,0.0,155344896.0,155344896.0,419328.0,78768.0,0.8418618097716103,10045696.0,43008.0,15.712,382.30400000000003,516096.0,688128.0,77070336.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313928.0,1344.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",86,0.0,13824.0,0,0,0.0,13824.0,13824.0,0.0,864.0,0.0,46080.0,6144.0,2.848,385.15200000000004,12288.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1440.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",87,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,387.232,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",88,12834.0,46714.0,0,0,0.0,46714.0,46714.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,4.256,391.48800000000006,13080.0,7966.0,12834.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",89,3538944.0,7188480.0,0,0,0.0,7188480.0,7188480.0,32544.0,57456.0,0.3616,7308288.0,18432.0,14.592,406.08000000000004,55296.0,55296.0,3538944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,228384.0,576.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",90,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,2.688,408.76800000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",91,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,2.688,411.456,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",92,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,2.656,414.112,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",93,49152.0,1632768.0,0,0,0.0,1632768.0,1632768.0,12768.0,24.0,0.99812382739212,18432.0,6144.0,11.36,425.47200000000004,1234944.0,299520.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",94,1179648.0,2396160.0,0,0,0.0,2396160.0,2396160.0,10848.0,19152.0,0.3616,2436096.0,6144.0,12.736,438.208,18432.0,18432.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76128.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",95,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.048,440.25600000000003,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",96,12834.0,46714.0,0,0,0.0,46714.0,46714.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,4.288,444.54400000000004,13080.0,7966.0,12834.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",97,4718592.0,9584640.0,0,0,0.0,9584640.0,9584640.0,43392.0,76608.0,0.3616,9744384.0,24576.0,15.84,460.384,73728.0,73728.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304512.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",98,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.08,462.464,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",99,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.048,464.512,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",100,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.016,466.528,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",101,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.08,468.608,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",102,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.016,470.624,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",103,35754.0,89940.0,0,0,0.0,89940.0,89940.0,0.0,96.0,0.0,24576.0,24576.0,2.048,472.672,6144.0,12288.0,35754.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",104,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.016,474.68800000000005,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",105,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.112,476.80000000000007,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_32x32_sliced1x4_nn,106,77070336.0,155344896.0,0,0,0.0,155344896.0,155344896.0,419328.0,78768.0,0.8418618097716103,10045632.0,43008.0,15.68,492.4800000000001,516096.0,688128.0,77070336.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313926.0,1344.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",107,0.0,13824.0,0,0,0.0,13824.0,13824.0,0.0,864.0,0.0,46080.0,6144.0,3.072,495.5520000000001,12288.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1440.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",108,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.112,497.6640000000001,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",109,12834.0,46714.0,0,0,0.0,46714.0,46714.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,4.256,501.9200000000001,13080.0,7966.0,12834.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",110,3538944.0,7188480.0,0,0,0.0,7188480.0,7188480.0,32544.0,57456.0,0.3616,7308288.0,18432.0,15.008,516.9280000000001,55296.0,55296.0,3538944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,228384.0,576.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",111,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,2.688,519.6160000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",112,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,2.656,522.272,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",113,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,2.624,524.8960000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",114,49152.0,1632768.0,0,0,0.0,1632768.0,1632768.0,12768.0,24.0,0.99812382739212,18432.0,6144.0,11.264,536.1600000000001,1234944.0,299520.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",115,1179648.0,2396160.0,0,0,0.0,2396160.0,2396160.0,10848.0,19152.0,0.3616,2436096.0,6144.0,12.704,548.864,18432.0,18432.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76128.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",116,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,550.9440000000001,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",117,12834.0,46714.0,0,0,0.0,46714.0,46714.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,4.256,555.2,13080.0,7966.0,12834.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",118,4718592.0,9584640.0,0,0,0.0,9584640.0,9584640.0,43392.0,76608.0,0.3616,9744384.0,24576.0,15.904,571.104,73728.0,73728.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304512.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",119,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.016,573.12,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",120,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.048,575.168,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",121,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.144,577.312,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",122,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.144,579.456,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",123,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.048,581.504,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",124,35648.0,89728.0,0,0,0.0,89728.0,89728.0,0.0,96.0,0.0,24576.0,24576.0,2.112,583.616,6144.0,12288.0,35648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",125,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.048,585.664,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",126,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.08,587.744,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_32x32_sliced1x4_nn,127,77070336.0,155344896.0,0,0,0.0,155344896.0,155344896.0,419328.0,78768.0,0.8418618097716103,10047360.0,43008.0,15.936,603.6800000000001,516096.0,688128.0,77070336.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313980.0,1344.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",128,0.0,13824.0,0,0,0.0,13824.0,13824.0,0.0,864.0,0.0,46080.0,6144.0,2.848,606.528,12288.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1440.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",129,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.112,608.64,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",130,12834.0,46714.0,0,0,0.0,46714.0,46714.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,4.256,612.896,13080.0,7966.0,12834.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",131,3538944.0,7188480.0,0,0,0.0,7188480.0,7188480.0,32544.0,57456.0,0.3616,7308288.0,18432.0,14.56,627.4559999999999,55296.0,55296.0,3538944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,228384.0,576.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",132,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,2.656,630.1119999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",133,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,2.656,632.7679999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",134,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,2.624,635.3919999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",135,49152.0,1632768.0,0,0,0.0,1632768.0,1632768.0,12768.0,24.0,0.99812382739212,18432.0,6144.0,11.36,646.7519999999998,1234944.0,299520.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",136,1179648.0,2396160.0,0,0,0.0,2396160.0,2396160.0,10848.0,19152.0,0.3616,2436096.0,6144.0,12.64,659.3919999999998,18432.0,18432.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76128.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",137,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.112,661.5039999999998,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",138,12834.0,46714.0,0,0,0.0,46714.0,46714.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,4.32,665.8239999999998,13080.0,7966.0,12834.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",139,4718592.0,9584640.0,0,0,0.0,9584640.0,9584640.0,43392.0,76608.0,0.3616,9744384.0,24576.0,15.488,681.3119999999999,73728.0,73728.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304512.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",140,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.016,683.3279999999999,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",141,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.048,685.3759999999999,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",142,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.112,687.4879999999998,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",143,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.016,689.5039999999998,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",144,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.048,691.5519999999998,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",145,35668.0,89768.0,0,0,0.0,89768.0,89768.0,0.0,96.0,0.0,24576.0,24576.0,2.144,693.6959999999998,6144.0,12288.0,35668.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",146,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.08,695.7759999999998,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",147,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.112,697.8879999999998,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_32x32_sliced1x4_nn,148,77070336.0,155344896.0,0,0,0.0,155344896.0,155344896.0,419328.0,78768.0,0.8418618097716103,10045696.0,43008.0,15.84,713.7279999999998,516096.0,688128.0,77070336.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313928.0,1344.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",149,0.0,13824.0,0,0,0.0,13824.0,13824.0,0.0,864.0,0.0,46080.0,6144.0,2.976,716.7039999999998,12288.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1440.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",150,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,718.7839999999999,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",151,12834.0,46714.0,0,0,0.0,46714.0,46714.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,4.256,723.0399999999998,13080.0,7966.0,12834.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",152,3538944.0,7188480.0,0,0,0.0,7188480.0,7188480.0,32544.0,57456.0,0.3616,7308288.0,18432.0,14.592,737.6319999999998,55296.0,55296.0,3538944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,228384.0,576.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",153,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,2.656,740.2879999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",154,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,2.688,742.9759999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",155,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,2.624,745.5999999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",156,49152.0,1632768.0,0,0,0.0,1632768.0,1632768.0,12768.0,24.0,0.99812382739212,18432.0,6144.0,11.296,756.8959999999998,1234944.0,299520.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",157,1179648.0,2396160.0,0,0,0.0,2396160.0,2396160.0,10848.0,19152.0,0.3616,2436096.0,6144.0,13.056,769.9519999999999,18432.0,18432.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76128.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",158,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,772.0319999999999,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",159,12834.0,46714.0,0,0,0.0,46714.0,46714.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,4.192,776.2239999999999,13080.0,7966.0,12834.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",160,4718592.0,9584640.0,0,0,0.0,9584640.0,9584640.0,43392.0,76608.0,0.3616,9744384.0,24576.0,15.616,791.8399999999999,73728.0,73728.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304512.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",161,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.112,793.9519999999999,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",162,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.08,796.0319999999999,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",163,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.048,798.0799999999999,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",164,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.08,800.16,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",165,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.016,802.1759999999999,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",166,35698.0,89828.0,0,0,0.0,89828.0,89828.0,0.0,96.0,0.0,24576.0,24576.0,2.144,804.3199999999999,6144.0,12288.0,35698.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",167,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.048,806.3679999999999,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",168,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.08,808.448,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_32x32_sliced1x4_nn,169,77070336.0,155344896.0,0,0,0.0,155344896.0,155344896.0,419328.0,78768.0,0.8418618097716103,10046400.0,43008.0,15.712,824.16,516096.0,688128.0,77070336.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313950.0,1344.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",170,0.0,13824.0,0,0,0.0,13824.0,13824.0,0.0,864.0,0.0,46080.0,6144.0,2.912,827.072,12288.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1440.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",171,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,829.152,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",172,12834.0,46714.0,0,0,0.0,46714.0,46714.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,4.256,833.408,13080.0,7966.0,12834.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",173,3538944.0,7188480.0,0,0,0.0,7188480.0,7188480.0,32544.0,57456.0,0.3616,7308288.0,18432.0,14.016,847.424,55296.0,55296.0,3538944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,228384.0,576.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",174,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,2.624,850.048,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",175,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,2.624,852.672,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",176,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,2.624,855.296,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",177,49152.0,1632768.0,0,0,0.0,1632768.0,1632768.0,12768.0,24.0,0.99812382739212,18432.0,6144.0,11.328,866.624,1234944.0,299520.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",178,1179648.0,2396160.0,0,0,0.0,2396160.0,2396160.0,10848.0,19152.0,0.3616,2436096.0,6144.0,13.056,879.6800000000001,18432.0,18432.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76128.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",179,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.112,881.792,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",180,12834.0,46714.0,0,0,0.0,46714.0,46714.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,4.288,886.08,13080.0,7966.0,12834.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",181,4718592.0,9584640.0,0,0,0.0,9584640.0,9584640.0,43392.0,76608.0,0.3616,9744384.0,24576.0,15.808,901.888,73728.0,73728.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304512.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",182,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.08,903.9680000000001,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",183,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.016,905.984,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",184,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.016,908.0,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",185,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.08,910.08,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",186,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.112,912.192,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",187,35712.0,89856.0,0,0,0.0,89856.0,89856.0,0.0,96.0,0.0,24576.0,24576.0,2.144,914.336,6144.0,12288.0,35712.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",188,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.016,916.352,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",189,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.112,918.4639999999999,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_32x32_sliced1x4_nn,190,77070336.0,155344896.0,0,0,0.0,155344896.0,155344896.0,419328.0,78768.0,0.8418618097716103,10045824.0,43008.0,15.552,934.016,516096.0,688128.0,77070336.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313932.0,1344.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",191,0.0,13824.0,0,0,0.0,13824.0,13824.0,0.0,864.0,0.0,46080.0,6144.0,2.88,936.896,12288.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1440.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",192,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,938.976,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",193,12834.0,46714.0,0,0,0.0,46714.0,46714.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,4.256,943.232,13080.0,7966.0,12834.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,196.0
ampere_sgemm_64x32_sliced1x4_tn,194,1236271104.0,2483810304.0,0,0,0.0,2483810304.0,2483810304.0,5810112.0,1247038.0,0.8232943893781484,156727552.0,384864.0,186.976,1130.208,4829184.0,6438912.0,1236271104.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4897736.0,12027.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",195,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,1131.9360000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",196,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,64.0,64.0,2.656,1134.592,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",197,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,1136.672,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",198,0.0,100514.0,0,0,0.0,100514.0,100514.0,0.0,1580.0,0.0,402080.0,402080.0,2.432,1139.104,0.0,100514.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12565.0,12565.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",199,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,1140.8,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",200,0.0,0.0,0,0,0.0,0.0,0.0,1600.0,4742.0,0.2522863450015768,406880.0,29504.0,3.52,1144.32,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12715.0,922.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",201,0.0,0.0,0,0,0.0,0.0,0.0,7400.0,41304.0,0.15193823915900131,2569600.0,0.0,5.376,1149.696,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,80300.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",202,0.0,0.0,0,0,0.0,0.0,0.0,1600.0,4742.0,0.2522863450015768,406880.0,29824.0,3.648,1153.3439999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12715.0,932.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",203,0.0,0.0,0,0,0.0,0.0,0.0,7400.0,41904.0,0.15008924225214992,2569600.0,0.0,5.312,1158.6559999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,80300.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",204,0.0,0.0,0,0,0.0,0.0,0.0,1600.0,4742.0,0.2522863450015768,406880.0,28992.0,3.68,1162.3359999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12715.0,906.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",205,0.0,0.0,0,0,0.0,0.0,0.0,7400.0,41804.0,0.15039427688805787,2569600.0,0.0,5.28,1167.6159999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,80300.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",206,0.0,0.0,0,0,0.0,0.0,0.0,1600.0,4742.0,0.2522863450015768,406880.0,28928.0,3.552,1171.1679999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12715.0,904.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",207,0.0,0.0,0,0,0.0,0.0,0.0,7400.0,41604.0,0.1510080809729818,2569600.0,64.0,5.376,1176.5439999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,80300.0,2.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",208,0.0,0.0,0,0,0.0,0.0,0.0,0.0,12.0,0.0,3232.0,416.0,2.368,1178.9119999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,101.0,13.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",209,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.728,1180.6399999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",210,0.0,0.0,0,0,0.0,0.0,0.0,497.0,16.0,0.9688109161793372,416.0,0.0,3.456,1184.0959999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,13.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",211,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.696,1185.7919999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",212,0.0,0.0,0,0,0.0,0.0,0.0,497.0,16.0,0.9688109161793372,416.0,0.0,3.456,1189.2479999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,13.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",213,0.0,0.0,0,0,0.0,0.0,0.0,26016.0,6506.0,0.7999508025336696,416224.0,4448.0,5.6,1194.8479999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,13007.0,139.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",214,0.0,0.0,0,0,0.0,0.0,0.0,916.0,16.0,0.9828326180257511,1280.0,192.0,6.432,1201.2799999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,40.0,6.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",215,0.0,0.0,0,0,0.0,0.0,0.0,0.0,9426.0,0.0,408416.0,45216.0,3.68,1204.9599999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12763.0,1413.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",216,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2370.0,0.0,502624.0,0.0,2.912,1207.8719999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,15707.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",217,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3142.0,0.0,0.0,804128.0,2.176,1210.0479999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,25129.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",218,0.0,0.0,0,0,0.0,0.0,0.0,98304.0,3142.0,0.9690278571851034,402080.0,0.0,4.032,1214.0799999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12565.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",219,0.0,0.0,0,0,0.0,0.0,0.0,156.0,64.0,0.7090909090909091,8192.0,0.0,2.112,1216.1919999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",220,0.0,0.0,0,0,0.0,0.0,0.0,38943.0,14531.0,0.7282604630287617,1467840.0,1007328.0,9.088,1225.2799999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,45870.0,31479.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",221,0.0,0.0,0,0,0.0,0.0,0.0,12021.0,15108.0,0.44310516421541524,1461440.0,1240000.0,7.008,1232.2879999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,45670.0,38750.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",222,0.0,0.0,0,0,0.0,0.0,0.0,12843.0,15063.0,0.4602236078262739,1451712.0,1240000.0,7.872,1240.1599999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,45366.0,38750.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",223,0.0,0.0,0,0,0.0,0.0,0.0,12843.0,15026.0,0.46083461911084,1464384.0,1109056.0,7.968,1248.1279999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,45762.0,34658.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",224,0.0,0.0,0,0,0.0,0.0,0.0,14336.0,3142.0,0.8202311477285731,804128.0,0.0,3.872,1251.9999999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25129.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",225,0.0,0.0,0,0,0.0,0.0,0.0,39.0,16.0,0.7090909090909091,2048.0,0.0,2.176,1254.1759999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",226,0.0,0.0,0,0,0.0,0.0,0.0,10079.0,8096.0,0.5545529573590097,994976.0,737376.0,6.304,1260.4799999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,31093.0,23043.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",227,0.0,0.0,0,0,0.0,0.0,0.0,0.0,12568.0,0.0,1214784.0,1206208.0,3.552,1264.0319999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,37962.0,37694.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",228,1407196.0,3327522.0,0,0,0.0,3327522.0,3327522.0,264.0,3352.0,0.07300884955752213,1142208.0,376448.0,24.224,1288.2559999999994,412616.0,100514.0,1407196.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,35694.0,11764.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",229,0.0,512100.0,0,0,0.0,512100.0,512100.0,56142.0,6284.0,0.8993368147887099,402240.0,342208.0,71.968,1360.2239999999995,512100.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12570.0,10694.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",230,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1580.0,0.0,402080.0,100416.0,2.496,1362.7199999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12565.0,3138.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",231,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,64.0,1.888,1364.6079999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,2.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",232,0.0,0.0,0,0,0.0,0.0,0.0,0.0,9426.0,0.0,904672.0,39552.0,7.712,1372.3199999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,28271.0,1236.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",233,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2370.0,0.0,502624.0,0.0,2.88,1375.1999999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,15707.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",234,1407196.0,3327522.0,0,0,0.0,3327522.0,3327522.0,264.0,3352.0,0.07300884955752213,1136576.0,376448.0,23.712,1398.9119999999996,412616.0,100514.0,1407196.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,35518.0,11764.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",235,0.0,0.0,0,0,0.0,0.0,0.0,62.0,788.0,0.07294117647058823,402080.0,32.0,17.984,1416.8959999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12565.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",236,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,1418.9759999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",237,0.0,0.0,0,0,0.0,0.0,0.0,62.0,788.0,0.07294117647058823,402080.0,32.0,18.048,1437.0239999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12565.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",238,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.176,1439.1999999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",239,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.08,1441.2799999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",240,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.944,1444.2239999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",241,0.0,110114.0,0,0,0.0,110114.0,110114.0,152.0,791.0,0.16118769883351008,402112.0,64.0,11.232,1455.4559999999992,110114.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12566.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",242,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,1457.4719999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",243,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,1460.7359999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",244,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,1462.7519999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",245,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.976,1465.7279999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",246,905472.0,2011972.0,0,0,0.0,2011972.0,2011972.0,0.0,3142.0,0.0,0.0,402080.0,3.2,1468.9279999999994,0.0,201028.0,905472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,12565.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",247,502570.0,1005140.0,0,0,0.0,1005140.0,1005140.0,0.0,2370.0,0.0,804160.0,0.0,4.064,1472.9919999999995,0.0,0.0,502570.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25130.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",248,0.0,0.0,0,0,0.0,0.0,0.0,304.0,791.0,0.2776255707762557,402144.0,64.0,15.488,1488.4799999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12567.0,2.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",249,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,1.984,1490.4639999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",250,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,1492.5119999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",251,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.24,1494.7519999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",252,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.144,1496.8959999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",253,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,64.0,64.0,2.592,1499.4879999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",254,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,1501.2159999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",255,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.76,1502.9759999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",256,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.08,1505.0559999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",257,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,1506.7519999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",258,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.272,1509.0239999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<256, 2, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",259,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,32.0,32.0,3.776,1512.7999999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",260,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.08,1514.8799999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",261,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,1516.9599999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",262,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.816,1519.7759999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",263,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.2,1522.9759999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",264,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,1525.0239999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",265,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.176,1527.1999999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",266,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.36,1530.5599999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",267,0.0,0.0,0,0,0.0,0.0,0.0,36.0,2.0,0.9473684210526315,32.0,32.0,2.496,1533.0559999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",268,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,1535.0719999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",269,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,1537.1519999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",270,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,2.08,1539.2319999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",271,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.272,1541.5039999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",272,0.0,0.0,0,0,0.0,0.0,0.0,0.0,144.0,0.0,6336.0,6144.0,3.296,1544.7999999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",273,0.0,0.0,0,0,0.0,0.0,0.0,0.0,144.0,0.0,3264.0,6144.0,3.104,1547.9039999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,102.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",274,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.048,1549.9519999999993,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",275,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,1551.9999999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",276,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.136,1555.1359999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",277,12834.0,46714.0,0,0,0.0,46714.0,46714.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,4.288,1559.4239999999993,13080.0,7966.0,12834.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",278,3538944.0,7188480.0,0,0,0.0,7188480.0,7188480.0,32544.0,57456.0,0.3616,7308288.0,18432.0,14.336,1573.7599999999993,55296.0,55296.0,3538944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,228384.0,576.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",279,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,3.968,1577.7279999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",280,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.096,1581.8239999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",281,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,2.624,1584.4479999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",282,49152.0,1634304.0,0,0,0.0,1634304.0,1634304.0,12768.0,24.0,0.99812382739212,30720.0,6144.0,11.392,1595.8399999999995,1236480.0,299520.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,960.0,192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",283,1179648.0,2396160.0,0,0,0.0,2396160.0,2396160.0,10848.0,19152.0,0.3616,2436096.0,6144.0,13.056,1608.8959999999995,18432.0,18432.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76128.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",284,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.112,1611.0079999999996,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",285,12834.0,46714.0,0,0,0.0,46714.0,46714.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,4.224,1615.2319999999995,13080.0,7966.0,12834.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",286,4718592.0,9584640.0,0,0,0.0,9584640.0,9584640.0,43392.0,76608.0,0.3616,9744384.0,24576.0,15.904,1631.1359999999995,73728.0,73728.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304512.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",287,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.048,1633.1839999999995,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",288,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.048,1635.2319999999995,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",289,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.08,1637.3119999999994,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",290,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.048,1639.3599999999994,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",291,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.016,1641.3759999999995,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",292,35747.0,89926.0,0,0,0.0,89926.0,89926.0,0.0,96.0,0.0,24576.0,24576.0,2.144,1643.5199999999995,6144.0,12288.0,35747.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",293,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.112,1645.6319999999996,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",294,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.112,1647.7439999999997,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_32x32_sliced1x4_nn,295,77070336.0,155344896.0,0,0,0.0,155344896.0,155344896.0,419328.0,78768.0,0.8418618097716103,10045920.0,43008.0,15.904,1663.6479999999997,516096.0,688128.0,77070336.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313935.0,1344.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",296,0.0,13824.0,0,0,0.0,13824.0,13824.0,0.0,864.0,0.0,46080.0,6144.0,2.976,1666.6239999999998,12288.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1440.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",297,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.24,1668.8639999999998,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",298,12834.0,46714.0,0,0,0.0,46714.0,46714.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,4.224,1673.0879999999997,13080.0,7966.0,12834.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",299,3538944.0,7188480.0,0,0,0.0,7188480.0,7188480.0,32544.0,57456.0,0.3616,7308288.0,18432.0,14.336,1687.4239999999998,55296.0,55296.0,3538944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,228384.0,576.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",300,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.0,1691.4239999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",301,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.064,1695.4879999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",302,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,2.752,1698.2399999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",303,49152.0,1634304.0,0,0,0.0,1634304.0,1634304.0,12768.0,24.0,0.99812382739212,30720.0,6144.0,11.136,1709.3759999999997,1236480.0,299520.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,960.0,192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",304,1179648.0,2396160.0,0,0,0.0,2396160.0,2396160.0,10848.0,19152.0,0.3616,2436096.0,6144.0,12.672,1722.0479999999998,18432.0,18432.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76128.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",305,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,1724.1279999999997,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",306,12834.0,46714.0,0,0,0.0,46714.0,46714.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,4.224,1728.3519999999996,13080.0,7966.0,12834.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",307,4718592.0,9584640.0,0,0,0.0,9584640.0,9584640.0,43392.0,76608.0,0.3616,9744384.0,24576.0,15.872,1744.2239999999997,73728.0,73728.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304512.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",308,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.016,1746.2399999999998,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",309,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.08,1748.3199999999997,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",310,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.144,1750.4639999999997,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",311,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.08,1752.5439999999996,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",312,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.048,1754.5919999999996,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",313,35702.0,89836.0,0,0,0.0,89836.0,89836.0,0.0,96.0,0.0,24576.0,24576.0,2.112,1756.7039999999997,6144.0,12288.0,35702.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",314,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.112,1758.8159999999998,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",315,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.112,1760.9279999999999,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_32x32_sliced1x4_nn,316,77070336.0,155344896.0,0,0,0.0,155344896.0,155344896.0,419328.0,78768.0,0.8418618097716103,10046784.0,43008.0,15.392,1776.32,516096.0,688128.0,77070336.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313962.0,1344.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",317,0.0,13824.0,0,0,0.0,13824.0,13824.0,0.0,864.0,0.0,46080.0,6144.0,2.944,1779.264,12288.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1440.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",318,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,1781.3439999999998,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",319,12834.0,46714.0,0,0,0.0,46714.0,46714.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,4.256,1785.6,13080.0,7966.0,12834.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",320,3538944.0,7188480.0,0,0,0.0,7188480.0,7188480.0,32544.0,57456.0,0.3616,7308288.0,18432.0,14.848,1800.4479999999999,55296.0,55296.0,3538944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,228384.0,576.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",321,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,3.968,1804.416,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",322,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.096,1808.512,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",323,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,2.688,1811.2,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",324,49152.0,1634304.0,0,0,0.0,1634304.0,1634304.0,12768.0,24.0,0.99812382739212,30720.0,6144.0,11.232,1822.432,1236480.0,299520.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,960.0,192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",325,1179648.0,2396160.0,0,0,0.0,2396160.0,2396160.0,10848.0,19152.0,0.3616,2436096.0,6144.0,12.832,1835.2640000000001,18432.0,18432.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76128.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",326,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.112,1837.3760000000002,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",327,12834.0,46714.0,0,0,0.0,46714.0,46714.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,4.192,1841.5680000000002,13080.0,7966.0,12834.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",328,4718592.0,9584640.0,0,0,0.0,9584640.0,9584640.0,43392.0,76608.0,0.3616,9744384.0,24576.0,15.648,1857.2160000000001,73728.0,73728.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304512.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",329,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,1.984,1859.2,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",330,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,1.984,1861.184,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",331,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.016,1863.2,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",332,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.112,1865.3120000000001,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",333,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.08,1867.392,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",334,35646.0,89724.0,0,0,0.0,89724.0,89724.0,0.0,96.0,0.0,24576.0,24576.0,2.144,1869.536,6144.0,12288.0,35646.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",335,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.016,1871.5520000000001,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",336,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.112,1873.6640000000002,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_32x32_sliced1x4_nn,337,77070336.0,155344896.0,0,0,0.0,155344896.0,155344896.0,419328.0,78768.0,0.8418618097716103,10046176.0,43008.0,15.68,1889.3440000000003,516096.0,688128.0,77070336.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313943.0,1344.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",338,0.0,13824.0,0,0,0.0,13824.0,13824.0,0.0,864.0,0.0,46080.0,6144.0,2.848,1892.1920000000002,12288.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1440.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",339,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,1894.2720000000002,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",340,12834.0,46714.0,0,0,0.0,46714.0,46714.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,4.288,1898.5600000000002,13080.0,7966.0,12834.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",341,3538944.0,7188480.0,0,0,0.0,7188480.0,7188480.0,32544.0,57456.0,0.3616,7308288.0,18432.0,14.4,1912.9600000000003,55296.0,55296.0,3538944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,228384.0,576.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",342,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.032,1916.9920000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",343,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.032,1921.0240000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",344,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,2.688,1923.7120000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",345,49152.0,1634304.0,0,0,0.0,1634304.0,1634304.0,12768.0,24.0,0.99812382739212,30720.0,6144.0,11.296,1935.0080000000003,1236480.0,299520.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,960.0,192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",346,1179648.0,2396160.0,0,0,0.0,2396160.0,2396160.0,10848.0,19152.0,0.3616,2436096.0,6144.0,13.024,1948.0320000000002,18432.0,18432.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76128.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",347,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.144,1950.1760000000002,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",348,12834.0,46714.0,0,0,0.0,46714.0,46714.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,4.288,1954.4640000000002,13080.0,7966.0,12834.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",349,4718592.0,9584640.0,0,0,0.0,9584640.0,9584640.0,43392.0,76608.0,0.3616,9744384.0,24576.0,16.032,1970.496,73728.0,73728.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304512.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",350,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.016,1972.5120000000002,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",351,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.016,1974.5280000000002,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",352,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.048,1976.5760000000002,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",353,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.08,1978.6560000000002,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",354,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.016,1980.6720000000003,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",355,35720.0,89872.0,0,0,0.0,89872.0,89872.0,0.0,96.0,0.0,24576.0,24576.0,2.144,1982.8160000000003,6144.0,12288.0,35720.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",356,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.048,1984.8640000000003,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",357,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.144,1987.0080000000003,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_32x32_sliced1x4_nn,358,77070336.0,155344896.0,0,0,0.0,155344896.0,155344896.0,419328.0,78768.0,0.8418618097716103,10045376.0,43008.0,15.552,2002.5600000000002,516096.0,688128.0,77070336.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313918.0,1344.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",359,0.0,13824.0,0,0,0.0,13824.0,13824.0,0.0,864.0,0.0,46080.0,6144.0,2.976,2005.5360000000003,12288.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1440.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",360,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.176,2007.7120000000002,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",361,12834.0,46714.0,0,0,0.0,46714.0,46714.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,4.256,2011.9680000000003,13080.0,7966.0,12834.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",362,3538944.0,7188480.0,0,0,0.0,7188480.0,7188480.0,32544.0,57456.0,0.3616,7308288.0,18432.0,14.976,2026.9440000000004,55296.0,55296.0,3538944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,228384.0,576.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",363,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.064,2031.0080000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",364,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.064,2035.0720000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",365,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,2.784,2037.8560000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",366,49152.0,1634304.0,0,0,0.0,1634304.0,1634304.0,12768.0,24.0,0.99812382739212,30720.0,6144.0,11.52,2049.3760000000007,1236480.0,299520.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,960.0,192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",367,1179648.0,2396160.0,0,0,0.0,2396160.0,2396160.0,10848.0,19152.0,0.3616,2436096.0,6144.0,12.96,2062.3360000000007,18432.0,18432.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76128.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",368,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.112,2064.448000000001,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",369,12834.0,46714.0,0,0,0.0,46714.0,46714.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,4.416,2068.864000000001,13080.0,7966.0,12834.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",370,4718592.0,9584640.0,0,0,0.0,9584640.0,9584640.0,43392.0,76608.0,0.3616,9744384.0,24576.0,15.552,2084.416000000001,73728.0,73728.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304512.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",371,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.048,2086.464000000001,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",372,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.24,2088.7040000000006,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",373,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.08,2090.7840000000006,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",374,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.112,2092.8960000000006,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",375,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.016,2094.9120000000007,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",376,35660.0,89752.0,0,0,0.0,89752.0,89752.0,0.0,96.0,0.0,24576.0,24576.0,2.144,2097.0560000000005,6144.0,12288.0,35660.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",377,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.016,2099.0720000000006,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",378,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.048,2101.1200000000003,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_32x32_sliced1x4_nn,379,77070336.0,155344896.0,0,0,0.0,155344896.0,155344896.0,419328.0,78768.0,0.8418618097716103,10045120.0,43008.0,15.648,2116.7680000000005,516096.0,688128.0,77070336.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313910.0,1344.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",380,0.0,13824.0,0,0,0.0,13824.0,13824.0,0.0,864.0,0.0,46080.0,6144.0,2.912,2119.6800000000003,12288.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1440.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",381,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.208,2121.8880000000004,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",382,12834.0,46714.0,0,0,0.0,46714.0,46714.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,4.224,2126.1120000000005,13080.0,7966.0,12834.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",383,3538944.0,7188480.0,0,0,0.0,7188480.0,7188480.0,32544.0,57456.0,0.3616,7308288.0,18432.0,14.432,2140.5440000000003,55296.0,55296.0,3538944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,228384.0,576.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",384,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.0,2144.5440000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",385,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.064,2148.608,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",386,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,2.592,2151.2000000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",387,49152.0,1634304.0,0,0,0.0,1634304.0,1634304.0,12768.0,24.0,0.99812382739212,30720.0,6144.0,11.232,2162.4320000000002,1236480.0,299520.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,960.0,192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",388,1179648.0,2396160.0,0,0,0.0,2396160.0,2396160.0,10848.0,19152.0,0.3616,2436096.0,6144.0,13.152,2175.5840000000003,18432.0,18432.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76128.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",389,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.144,2177.728,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",390,12834.0,46714.0,0,0,0.0,46714.0,46714.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,4.224,2181.952,13080.0,7966.0,12834.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",391,4718592.0,9584640.0,0,0,0.0,9584640.0,9584640.0,43392.0,76608.0,0.3616,9744384.0,24576.0,15.936,2197.8880000000004,73728.0,73728.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304512.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",392,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.048,2199.936,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",393,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.016,2201.952,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",394,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,1.984,2203.936,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",395,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.24,2206.176,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",396,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.112,2208.288,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",397,35723.0,89878.0,0,0,0.0,89878.0,89878.0,0.0,96.0,0.0,24576.0,24576.0,2.176,2210.464,6144.0,12288.0,35723.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",398,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.016,2212.48,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",399,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.048,2214.528,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_32x32_sliced1x4_nn,400,77070336.0,155344896.0,0,0,0.0,155344896.0,155344896.0,419328.0,78768.0,0.8418618097716103,10045920.0,43008.0,15.392,2229.9199999999996,516096.0,688128.0,77070336.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313935.0,1344.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",401,0.0,13824.0,0,0,0.0,13824.0,13824.0,0.0,864.0,0.0,46080.0,6144.0,2.848,2232.7679999999996,12288.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1440.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",402,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.048,2234.8159999999993,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",403,12834.0,46714.0,0,0,0.0,46714.0,46714.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,4.288,2239.1039999999994,13080.0,7966.0,12834.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",404,3538944.0,7188480.0,0,0,0.0,7188480.0,7188480.0,32544.0,57456.0,0.3616,7308288.0,18432.0,14.464,2253.5679999999993,55296.0,55296.0,3538944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,228384.0,576.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",405,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.064,2257.631999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",406,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.0,2261.631999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",407,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,2.656,2264.287999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",408,49152.0,1634304.0,0,0,0.0,1634304.0,1634304.0,12768.0,24.0,0.99812382739212,30720.0,6144.0,11.36,2275.6479999999992,1236480.0,299520.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,960.0,192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",409,1179648.0,2396160.0,0,0,0.0,2396160.0,2396160.0,10848.0,19152.0,0.3616,2436096.0,6144.0,13.024,2288.671999999999,18432.0,18432.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76128.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",410,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.048,2290.719999999999,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",411,12834.0,46714.0,0,0,0.0,46714.0,46714.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,4.32,2295.039999999999,13080.0,7966.0,12834.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",412,4718592.0,9584640.0,0,0,0.0,9584640.0,9584640.0,43392.0,76608.0,0.3616,9744384.0,24576.0,15.744,2310.783999999999,73728.0,73728.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304512.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",413,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.112,2312.8959999999993,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",414,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.048,2314.943999999999,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",415,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.048,2316.991999999999,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",416,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.112,2319.103999999999,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",417,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.016,2321.119999999999,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",418,35717.0,89866.0,0,0,0.0,89866.0,89866.0,0.0,96.0,0.0,24576.0,24576.0,2.112,2323.231999999999,6144.0,12288.0,35717.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",419,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.016,2325.247999999999,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",420,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.08,2327.327999999999,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_32x32_sliced1x4_nn,421,77070336.0,155344896.0,0,0,0.0,155344896.0,155344896.0,419328.0,78768.0,0.8418618097716103,10045888.0,43008.0,16.0,2343.327999999999,516096.0,688128.0,77070336.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313934.0,1344.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",422,0.0,13824.0,0,0,0.0,13824.0,13824.0,0.0,864.0,0.0,46080.0,6144.0,2.912,2346.239999999999,12288.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1440.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",423,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,2348.319999999999,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",424,12834.0,46714.0,0,0,0.0,46714.0,46714.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,4.224,2352.543999999999,13080.0,7966.0,12834.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",425,3538944.0,7188480.0,0,0,0.0,7188480.0,7188480.0,32544.0,57456.0,0.3616,7308288.0,18432.0,14.176,2366.719999999999,55296.0,55296.0,3538944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,228384.0,576.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",426,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,3.968,2370.6879999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",427,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.0,2374.6879999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",428,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,2.624,2377.3119999999985,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",429,49152.0,1634304.0,0,0,0.0,1634304.0,1634304.0,12768.0,24.0,0.99812382739212,30720.0,6144.0,11.392,2388.7039999999984,1236480.0,299520.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,960.0,192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",430,1179648.0,2396160.0,0,0,0.0,2396160.0,2396160.0,10848.0,19152.0,0.3616,2436096.0,6144.0,12.864,2401.5679999999984,18432.0,18432.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76128.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",431,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.144,2403.711999999998,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",432,12834.0,46714.0,0,0,0.0,46714.0,46714.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,4.224,2407.9359999999983,13080.0,7966.0,12834.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",433,4718592.0,9584640.0,0,0,0.0,9584640.0,9584640.0,43392.0,76608.0,0.3616,9744384.0,24576.0,15.424,2423.3599999999983,73728.0,73728.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304512.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",434,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.08,2425.4399999999982,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",435,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,1.984,2427.423999999998,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",436,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.016,2429.4399999999982,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",437,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.144,2431.583999999998,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",438,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.08,2433.663999999998,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",439,35700.0,89832.0,0,0,0.0,89832.0,89832.0,0.0,96.0,0.0,24576.0,24576.0,2.176,2435.839999999998,6144.0,12288.0,35700.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",440,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.048,2437.8879999999976,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",441,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.08,2439.9679999999976,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_32x32_sliced1x4_nn,442,77070336.0,155344896.0,0,0,0.0,155344896.0,155344896.0,419328.0,78768.0,0.8418618097716103,10045664.0,43008.0,15.84,2455.8079999999977,516096.0,688128.0,77070336.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313927.0,1344.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",443,0.0,13824.0,0,0,0.0,13824.0,13824.0,0.0,864.0,0.0,46080.0,6144.0,2.88,2458.687999999998,12288.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1440.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",444,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.144,2460.8319999999976,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",445,12834.0,46714.0,0,0,0.0,46714.0,46714.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,4.32,2465.1519999999978,13080.0,7966.0,12834.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,196.0
ampere_sgemm_64x32_sliced1x4_tn,446,1236271104.0,2483810304.0,0,0,0.0,2483810304.0,2483810304.0,5810112.0,1247038.0,0.8232943893781484,156735232.0,383776.0,187.424,2652.5759999999977,4829184.0,6438912.0,1236271104.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4897976.0,11993.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",447,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,2654.2719999999977,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",448,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,64.0,64.0,2.592,2656.8639999999978,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",449,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2658.879999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",450,0.0,100514.0,0,0,0.0,100514.0,100514.0,0.0,1580.0,0.0,402080.0,402080.0,2.624,2661.5039999999976,0.0,100514.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12565.0,12565.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",451,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,2663.1999999999975,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",452,0.0,0.0,0,0,0.0,0.0,0.0,1600.0,4742.0,0.2522863450015768,406880.0,29184.0,3.552,2666.7519999999977,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12715.0,912.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",453,0.0,0.0,0,0,0.0,0.0,0.0,7400.0,41304.0,0.15193823915900131,2569600.0,0.0,5.28,2672.031999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,80300.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",454,0.0,0.0,0,0,0.0,0.0,0.0,1600.0,4742.0,0.2522863450015768,406880.0,29312.0,3.392,2675.4239999999977,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12715.0,916.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",455,0.0,0.0,0,0,0.0,0.0,0.0,7400.0,41904.0,0.15008924225214992,2569600.0,0.0,5.664,2681.087999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,80300.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",456,0.0,0.0,0,0,0.0,0.0,0.0,1600.0,4742.0,0.2522863450015768,406880.0,29056.0,3.648,2684.735999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12715.0,908.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",457,0.0,0.0,0,0,0.0,0.0,0.0,7400.0,41554.0,0.15116231564325694,2569600.0,0.0,5.344,2690.079999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,80300.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",458,0.0,0.0,0,0,0.0,0.0,0.0,1600.0,4742.0,0.2522863450015768,406880.0,29568.0,3.392,2693.471999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12715.0,924.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",459,0.0,0.0,0,0,0.0,0.0,0.0,7400.0,41754.0,0.1505472596329902,2569600.0,64.0,5.6,2699.071999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,80300.0,2.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",460,0.0,0.0,0,0,0.0,0.0,0.0,0.0,12.0,0.0,3232.0,416.0,2.432,2701.5039999999976,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,101.0,13.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",461,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.696,2703.1999999999975,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",462,0.0,0.0,0,0,0.0,0.0,0.0,497.0,16.0,0.9688109161793372,416.0,0.0,3.584,2706.7839999999974,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,13.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",463,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.696,2708.4799999999973,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",464,0.0,0.0,0,0,0.0,0.0,0.0,497.0,16.0,0.9688109161793372,416.0,0.0,3.616,2712.0959999999973,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,13.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",465,0.0,0.0,0,0,0.0,0.0,0.0,24576.0,6510.0,0.7905809689249179,416224.0,4448.0,5.76,2717.8559999999975,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,13007.0,139.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",466,0.0,0.0,0,0,0.0,0.0,0.0,916.0,16.0,0.9828326180257511,1280.0,192.0,6.432,2724.2879999999973,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,40.0,6.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",467,0.0,0.0,0,0,0.0,0.0,0.0,0.0,9426.0,0.0,408416.0,45568.0,3.552,2727.8399999999974,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12763.0,1424.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",468,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2370.0,0.0,502624.0,0.0,3.008,2730.8479999999972,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,15707.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",469,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3142.0,0.0,0.0,804128.0,2.176,2733.023999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,25129.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",470,0.0,0.0,0,0,0.0,0.0,0.0,98304.0,3142.0,0.9690278571851034,402080.0,0.0,3.936,2736.9599999999973,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12565.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",471,0.0,0.0,0,0,0.0,0.0,0.0,156.0,64.0,0.7090909090909091,8192.0,0.0,2.272,2739.2319999999972,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",472,0.0,0.0,0,0,0.0,0.0,0.0,38943.0,14572.0,0.7277025133140241,1459264.0,1016736.0,9.184,2748.4159999999974,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,45602.0,31773.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",473,0.0,0.0,0,0,0.0,0.0,0.0,12921.0,15131.0,0.46060886924283473,1464640.0,1117856.0,7.456,2755.8719999999976,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,45770.0,34933.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",474,0.0,0.0,0,0,0.0,0.0,0.0,12843.0,15062.0,0.46024010034044077,1461184.0,1240000.0,8.032,2763.9039999999977,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,45662.0,38750.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",475,0.0,0.0,0,0,0.0,0.0,0.0,12843.0,15034.0,0.4607023711303225,1457600.0,1109120.0,8.096,2771.9999999999977,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,45550.0,34660.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",476,0.0,0.0,0,0,0.0,0.0,0.0,14336.0,3142.0,0.8202311477285731,804128.0,0.0,3.808,2775.8079999999977,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25129.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",477,0.0,0.0,0,0,0.0,0.0,0.0,39.0,16.0,0.7090909090909091,2048.0,0.0,2.24,2778.0479999999975,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",478,0.0,0.0,0,0,0.0,0.0,0.0,10079.0,8124.0,0.5536999395704005,985248.0,735904.0,6.208,2784.2559999999976,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,30789.0,22997.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",479,0.0,0.0,0,0,0.0,0.0,0.0,0.0,12568.0,0.0,1214880.0,1206208.0,3.712,2787.9679999999976,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,37965.0,37694.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",480,1407196.0,3327522.0,0,0,0.0,3327522.0,3327522.0,264.0,3352.0,0.07300884955752213,1136320.0,377088.0,23.68,2811.6479999999974,412616.0,100514.0,1407196.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,35510.0,11784.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",481,0.0,512100.0,0,0,0.0,512100.0,512100.0,56142.0,6284.0,0.8993368147887099,402240.0,341248.0,71.968,2883.6159999999973,512100.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12570.0,10664.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",482,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1580.0,0.0,402080.0,100416.0,2.464,2886.079999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12565.0,3138.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",483,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,64.0,1.92,2887.9999999999973,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,2.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",484,0.0,0.0,0,0,0.0,0.0,0.0,0.0,9426.0,0.0,904672.0,40000.0,7.52,2895.5199999999973,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,28271.0,1250.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",485,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2370.0,0.0,502624.0,0.0,2.72,2898.239999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,15707.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",486,1407196.0,3327522.0,0,0,0.0,3327522.0,3327522.0,264.0,3352.0,0.07300884955752213,1135680.0,376128.0,23.776,2922.015999999997,412616.0,100514.0,1407196.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,35490.0,11754.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",487,0.0,0.0,0,0,0.0,0.0,0.0,62.0,788.0,0.07294117647058823,402080.0,32.0,18.304,2940.319999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12565.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",488,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.176,2942.495999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",489,0.0,0.0,0,0,0.0,0.0,0.0,62.0,788.0,0.07294117647058823,402080.0,32.0,18.144,2960.6399999999967,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12565.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",490,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.208,2962.847999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",491,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.08,2964.9279999999967,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",492,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.944,2967.8719999999967,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",493,0.0,110114.0,0,0,0.0,110114.0,110114.0,152.0,791.0,0.16118769883351008,402112.0,64.0,10.784,2978.6559999999968,110114.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12566.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",494,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2980.671999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",495,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,2984.031999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",496,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,2986.0799999999967,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",497,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.008,2989.0879999999966,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",498,905472.0,2011972.0,0,0,0.0,2011972.0,2011972.0,0.0,3142.0,0.0,0.0,402080.0,3.232,2992.3199999999965,0.0,201028.0,905472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,12565.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",499,502570.0,1005140.0,0,0,0.0,1005140.0,1005140.0,0.0,2370.0,0.0,804160.0,0.0,4.064,2996.3839999999964,0.0,0.0,502570.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25130.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",500,0.0,0.0,0,0,0.0,0.0,0.0,304.0,791.0,0.2776255707762557,402368.0,64.0,16.128,3012.5119999999965,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12574.0,2.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",501,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.048,3014.5599999999963,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",502,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.112,3016.6719999999964,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",503,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.208,3018.8799999999965,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",504,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.048,3020.9279999999962,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",505,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,64.0,64.0,2.592,3023.5199999999963,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",506,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,3025.2479999999964,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",507,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,3026.9439999999963,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",508,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.016,3028.9599999999964,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",509,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,3030.6879999999965,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",510,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,32.0,2.272,3032.9599999999964,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,1.0
"void native::reduce_kernel<256, 2, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",511,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,32.0,32.0,3.616,3036.5759999999964,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",512,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.08,3038.6559999999963,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",513,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,3040.7359999999962,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",514,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.784,3043.5199999999963,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",515,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,3046.7519999999963,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",516,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,3048.799999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
