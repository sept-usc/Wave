Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.888,1.888,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,3.6159999999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.76,5.3759999999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.048,7.4239999999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.336,9.76,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",6,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,11.488,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",7,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,13.216,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",8,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.696,14.911999999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",9,0.0,0.0,0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,2.4,17.311999999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",10,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,19.327999999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",11,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.176,21.503999999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.728,23.232,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,0.0,0.0,0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,2.56,25.791999999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,27.808,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",15,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,29.856,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",16,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,2.048,31.904000000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(detail::TensorInfo<T1, T3>, detail::TensorInfo<const T1, T3>, detail::TensorInfo<const T2, T3>, int, int, T3, long)",17,0.0,0.0,0,0,0.0,0.0,0.0,0.0,72.0,0.0,3264.0,3072.0,4.032,35.93600000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,102.0,96.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(detail::TensorInfo<T1, T3>, detail::TensorInfo<const T1, T3>, detail::TensorInfo<const T2, T3>, int, int, T3, long)",18,0.0,0.0,0,0,0.0,0.0,0.0,0.0,72.0,0.0,3264.0,3072.0,3.232,39.168000000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,102.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",19,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,41.34400000000001,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",20,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.432,43.77600000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",21,6417.0,23357.0,0,0,0.0,23357.0,23357.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,4.352,48.128000000000014,6540.0,3983.0,6417.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",22,1774080.0,3621888.0,0,0,0.0,3621888.0,3621888.0,17280.0,111744.0,0.13392857142857142,11141280.0,21472.0,11.168,59.296000000000014,73728.0,0.0,1774080.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,348165.0,671.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",23,0.0,6912.0,0,0,0.0,6912.0,6912.0,0.0,6912.0,0.0,18432.0,8512.0,2.464,61.76000000000001,4608.0,2304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,266.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",24,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2880.0,0.0,18432.0,128.0,2.496,64.25600000000001,2304.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,4.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",25,24576.0,816384.0,0,0,0.0,816384.0,816384.0,6384.0,12.0,0.99812382739212,9216.0,3072.0,12.032,76.28800000000001,617472.0,149760.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",26,593664.0,1248768.0,0,0,0.0,1248768.0,1248768.0,7440.0,36984.0,0.16747703943814155,2435328.0,15360.0,5.632,81.92000000000002,61440.0,0.0,593664.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76104.0,480.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",27,0.0,4608.0,0,0,0.0,4608.0,4608.0,0.0,4608.0,0.0,15360.0,2752.0,2.464,84.38400000000001,3840.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,480.0,86.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",28,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.496,86.88000000000001,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",29,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.112,88.992,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",30,6417.0,23357.0,0,0,0.0,23357.0,23357.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,4.224,93.21600000000001,6540.0,3983.0,6417.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,98.0
"void gemvNSP_kernel<float, float, float, float, 1, 16, 4, 1024, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T10)",31,2362368.0,4798464.0,0,0,0.0,4798464.0,4798464.0,9024.0,147648.0,0.05759803921568627,9744384.0,12288.0,13.632,106.84800000000001,73728.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304512.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",32,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.112,108.96000000000001,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",33,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,2.08,111.04,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",34,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.016,113.05600000000001,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",35,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.08,115.13600000000001,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",36,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.048,117.18400000000001,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",37,17883.0,44982.0,0,0,0.0,44982.0,44982.0,0.0,48.0,0.0,12288.0,12288.0,2.144,119.32800000000002,3072.0,6144.0,17883.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",38,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,1.984,121.31200000000001,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",39,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.048,123.36000000000001,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 8, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",40,2360064.0,4732416.0,0,0,0.0,4732416.0,4732416.0,1584.0,147552.0,0.010621177985194722,10030656.0,3072.0,13.504,136.864,12288.0,0.0,2360064.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313458.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",41,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,139.04,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",42,6417.0,23357.0,0,0,0.0,23357.0,23357.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,4.32,143.35999999999999,6540.0,3983.0,6417.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",43,1774080.0,3621888.0,0,0,0.0,3621888.0,3621888.0,17280.0,111744.0,0.13392857142857142,11207680.0,22240.0,11.424,154.784,73728.0,0.0,1774080.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,350240.0,695.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",44,0.0,6912.0,0,0,0.0,6912.0,6912.0,0.0,6912.0,0.0,18432.0,8032.0,2.496,157.28,4608.0,2304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,251.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",45,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2880.0,0.0,18432.0,224.0,2.4,159.68,2304.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,7.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",46,24576.0,816384.0,0,0,0.0,816384.0,816384.0,6384.0,12.0,0.99812382739212,9216.0,3072.0,11.392,171.072,617472.0,149760.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",47,593664.0,1248768.0,0,0,0.0,1248768.0,1248768.0,7440.0,36984.0,0.16747703943814155,2435328.0,15360.0,5.952,177.024,61440.0,0.0,593664.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76104.0,480.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",48,0.0,4608.0,0,0,0.0,4608.0,4608.0,0.0,4608.0,0.0,15360.0,2816.0,2.592,179.616,3840.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,480.0,88.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",49,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.4,182.01600000000002,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",50,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,184.192,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",51,6417.0,23357.0,0,0,0.0,23357.0,23357.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,4.288,188.48000000000002,6540.0,3983.0,6417.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,98.0
"void gemvNSP_kernel<float, float, float, float, 1, 16, 4, 1024, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T10)",52,2362368.0,4798464.0,0,0,0.0,4798464.0,4798464.0,9024.0,147648.0,0.05759803921568627,9744384.0,12288.0,13.28,201.76000000000002,73728.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304512.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",53,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.016,203.776,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",54,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,1.984,205.76000000000002,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",55,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.016,207.776,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",56,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.08,209.85600000000002,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",57,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.048,211.90400000000002,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",58,17859.0,44934.0,0,0,0.0,44934.0,44934.0,0.0,48.0,0.0,12288.0,12288.0,2.144,214.04800000000003,3072.0,6144.0,17859.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",59,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,1.984,216.03200000000004,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",60,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.24,218.27200000000005,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 8, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",61,2360064.0,4732416.0,0,0,0.0,4732416.0,4732416.0,1584.0,147552.0,0.010621177985194722,10030368.0,3072.0,13.92,232.19200000000004,12288.0,0.0,2360064.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313449.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",62,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.144,234.33600000000004,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",63,6417.0,23357.0,0,0,0.0,23357.0,23357.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,4.288,238.62400000000005,6540.0,3983.0,6417.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",64,1774080.0,3621888.0,0,0,0.0,3621888.0,3621888.0,17280.0,111744.0,0.13392857142857142,11087520.0,21184.0,11.328,249.95200000000006,73728.0,0.0,1774080.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,346485.0,662.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",65,0.0,6912.0,0,0,0.0,6912.0,6912.0,0.0,6912.0,0.0,18432.0,8128.0,2.656,252.60800000000006,4608.0,2304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,254.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",66,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2880.0,0.0,18432.0,64.0,2.432,255.04000000000005,2304.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,2.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",67,24576.0,816384.0,0,0,0.0,816384.0,816384.0,6384.0,12.0,0.99812382739212,9216.0,3072.0,11.328,266.36800000000005,617472.0,149760.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",68,593664.0,1248768.0,0,0,0.0,1248768.0,1248768.0,7440.0,36984.0,0.16747703943814155,2435328.0,15360.0,5.856,272.22400000000005,61440.0,0.0,593664.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76104.0,480.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",69,0.0,4608.0,0,0,0.0,4608.0,4608.0,0.0,4608.0,0.0,15360.0,2944.0,2.528,274.75200000000007,3840.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,480.0,92.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",70,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.336,277.0880000000001,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",71,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.144,279.2320000000001,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",72,6417.0,23357.0,0,0,0.0,23357.0,23357.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,4.288,283.5200000000001,6540.0,3983.0,6417.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,98.0
"void gemvNSP_kernel<float, float, float, float, 1, 16, 4, 1024, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T10)",73,2362368.0,4798464.0,0,0,0.0,4798464.0,4798464.0,9024.0,147648.0,0.05759803921568627,9744384.0,12288.0,13.28,296.80000000000007,73728.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304512.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",74,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.016,298.8160000000001,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",75,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,2.016,300.8320000000001,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",76,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.048,302.8800000000001,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",77,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.048,304.9280000000001,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",78,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,1.984,306.9120000000001,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",79,17819.0,44854.0,0,0,0.0,44854.0,44854.0,0.0,48.0,0.0,12288.0,12288.0,2.112,309.0240000000001,3072.0,6144.0,17819.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",80,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,2.016,311.04000000000013,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",81,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.112,313.15200000000016,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 8, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",82,2360064.0,4732416.0,0,0,0.0,4732416.0,4732416.0,1584.0,147552.0,0.010621177985194722,10030272.0,3072.0,13.696,326.8480000000002,12288.0,0.0,2360064.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313446.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",83,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.144,328.9920000000002,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",84,6417.0,23357.0,0,0,0.0,23357.0,23357.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,4.288,333.2800000000002,6540.0,3983.0,6417.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",85,1774080.0,3621888.0,0,0,0.0,3621888.0,3621888.0,17280.0,111744.0,0.13392857142857142,11272992.0,22400.0,11.296,344.5760000000002,73728.0,0.0,1774080.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,352281.0,700.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",86,0.0,6912.0,0,0,0.0,6912.0,6912.0,0.0,6912.0,0.0,18432.0,7808.0,2.464,347.0400000000002,4608.0,2304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,244.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",87,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2880.0,0.0,18432.0,288.0,2.432,349.4720000000002,2304.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,9.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",88,24576.0,816384.0,0,0,0.0,816384.0,816384.0,6384.0,12.0,0.99812382739212,9216.0,3072.0,11.488,360.9600000000002,617472.0,149760.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",89,593664.0,1248768.0,0,0,0.0,1248768.0,1248768.0,7440.0,36984.0,0.16747703943814155,2435328.0,15360.0,5.664,366.6240000000002,61440.0,0.0,593664.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76104.0,480.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",90,0.0,4608.0,0,0,0.0,4608.0,4608.0,0.0,4608.0,0.0,15360.0,2368.0,2.528,369.1520000000002,3840.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,480.0,74.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",91,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.304,371.4560000000002,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",92,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,373.6320000000002,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",93,6417.0,23357.0,0,0,0.0,23357.0,23357.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,4.416,378.0480000000002,6540.0,3983.0,6417.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,98.0
"void gemvNSP_kernel<float, float, float, float, 1, 16, 4, 1024, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T10)",94,2362368.0,4798464.0,0,0,0.0,4798464.0,4798464.0,9024.0,147648.0,0.05759803921568627,9744384.0,12288.0,13.152,391.20000000000016,73728.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304512.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",95,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,1.984,393.18400000000014,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",96,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,2.016,395.20000000000016,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",97,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.048,397.24800000000016,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",98,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.112,399.3600000000002,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",99,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,1.984,401.34400000000016,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",100,17877.0,44970.0,0,0,0.0,44970.0,44970.0,0.0,48.0,0.0,12288.0,12288.0,2.144,403.48800000000017,3072.0,6144.0,17877.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",101,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,2.016,405.5040000000002,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",102,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.048,407.5520000000002,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 8, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",103,2360064.0,4732416.0,0,0,0.0,4732416.0,4732416.0,1584.0,147552.0,0.010621177985194722,10030592.0,3072.0,13.664,421.2160000000002,12288.0,0.0,2360064.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313456.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",104,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,423.39200000000017,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",105,6417.0,23357.0,0,0,0.0,23357.0,23357.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,4.288,427.6800000000002,6540.0,3983.0,6417.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",106,1774080.0,3621888.0,0,0,0.0,3621888.0,3621888.0,17280.0,111744.0,0.13392857142857142,11185440.0,21536.0,11.168,438.8480000000002,73728.0,0.0,1774080.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,349545.0,673.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",107,0.0,6912.0,0,0,0.0,6912.0,6912.0,0.0,6912.0,0.0,18432.0,7616.0,2.464,441.3120000000002,4608.0,2304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,238.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",108,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2880.0,0.0,18432.0,96.0,2.432,443.7440000000002,2304.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,3.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",109,24576.0,816384.0,0,0,0.0,816384.0,816384.0,6384.0,12.0,0.99812382739212,9216.0,3072.0,11.328,455.0720000000002,617472.0,149760.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",110,593664.0,1248768.0,0,0,0.0,1248768.0,1248768.0,7440.0,36984.0,0.16747703943814155,2435328.0,15360.0,5.6,460.6720000000002,61440.0,0.0,593664.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76104.0,480.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",111,0.0,4608.0,0,0,0.0,4608.0,4608.0,0.0,4608.0,0.0,15360.0,2400.0,2.464,463.1360000000002,3840.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,480.0,75.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",112,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.336,465.4720000000002,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",113,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.208,467.68000000000023,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",114,6417.0,23357.0,0,0,0.0,23357.0,23357.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,4.352,472.0320000000002,6540.0,3983.0,6417.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,98.0
"void gemvNSP_kernel<float, float, float, float, 1, 16, 4, 1024, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T10)",115,2362368.0,4798464.0,0,0,0.0,4798464.0,4798464.0,9024.0,147648.0,0.05759803921568627,9744384.0,12288.0,13.184,485.21600000000024,73728.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304512.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",116,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.016,487.23200000000026,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",117,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,2.016,489.2480000000003,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",118,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,1.952,491.2000000000003,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",119,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.08,493.28000000000026,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",120,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.016,495.2960000000003,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",121,17824.0,44864.0,0,0,0.0,44864.0,44864.0,0.0,48.0,0.0,12288.0,12288.0,2.144,497.4400000000003,3072.0,6144.0,17824.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",122,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,2.048,499.4880000000003,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",123,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.048,501.5360000000003,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 8, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",124,2360064.0,4732416.0,0,0,0.0,4732416.0,4732416.0,1584.0,147552.0,0.010621177985194722,10030464.0,3072.0,13.664,515.2000000000003,12288.0,0.0,2360064.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313452.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",125,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.208,517.4080000000002,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",126,6417.0,23357.0,0,0,0.0,23357.0,23357.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,4.256,521.6640000000002,6540.0,3983.0,6417.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",127,1774080.0,3621888.0,0,0,0.0,3621888.0,3621888.0,17280.0,111744.0,0.13392857142857142,11242752.0,21760.0,11.232,532.8960000000002,73728.0,0.0,1774080.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,351336.0,680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",128,0.0,6912.0,0,0,0.0,6912.0,6912.0,0.0,6912.0,0.0,18432.0,8192.0,2.688,535.5840000000002,4608.0,2304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,256.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",129,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2880.0,0.0,18432.0,64.0,2.56,538.1440000000001,2304.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,2.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",130,24576.0,816384.0,0,0,0.0,816384.0,816384.0,6384.0,12.0,0.99812382739212,9216.0,3072.0,11.36,549.5040000000001,617472.0,149760.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",131,593664.0,1248768.0,0,0,0.0,1248768.0,1248768.0,7440.0,36984.0,0.16747703943814155,2435328.0,15360.0,6.144,555.6480000000001,61440.0,0.0,593664.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76104.0,480.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",132,0.0,4608.0,0,0,0.0,4608.0,4608.0,0.0,4608.0,0.0,15360.0,2464.0,2.624,558.2720000000002,3840.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,480.0,77.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",133,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.336,560.6080000000002,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",134,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.144,562.7520000000002,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",135,6417.0,23357.0,0,0,0.0,23357.0,23357.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,4.288,567.0400000000002,6540.0,3983.0,6417.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,98.0
"void gemvNSP_kernel<float, float, float, float, 1, 16, 4, 1024, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T10)",136,2362368.0,4798464.0,0,0,0.0,4798464.0,4798464.0,9024.0,147648.0,0.05759803921568627,9744384.0,12288.0,13.024,580.0640000000002,73728.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304512.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",137,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.08,582.1440000000002,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",138,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,2.08,584.2240000000003,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",139,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,1.984,586.2080000000003,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",140,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.08,588.2880000000004,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",141,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.016,590.3040000000003,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",142,17834.0,44884.0,0,0,0.0,44884.0,44884.0,0.0,48.0,0.0,12288.0,12288.0,2.08,592.3840000000004,3072.0,6144.0,17834.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",143,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,1.984,594.3680000000004,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",144,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.112,596.4800000000004,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 8, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",145,2360064.0,4732416.0,0,0,0.0,4732416.0,4732416.0,1584.0,147552.0,0.010621177985194722,10030688.0,3072.0,13.6,610.0800000000004,12288.0,0.0,2360064.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313459.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",146,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,612.2560000000004,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",147,6417.0,23357.0,0,0,0.0,23357.0,23357.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,4.288,616.5440000000004,6540.0,3983.0,6417.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",148,1774080.0,3621888.0,0,0,0.0,3621888.0,3621888.0,17280.0,111744.0,0.13392857142857142,11194656.0,21568.0,11.36,627.9040000000005,73728.0,0.0,1774080.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,349833.0,674.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",149,0.0,6912.0,0,0,0.0,6912.0,6912.0,0.0,6912.0,0.0,18432.0,7904.0,2.464,630.3680000000005,4608.0,2304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,247.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",150,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2880.0,0.0,18432.0,0.0,2.368,632.7360000000006,2304.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,0.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",151,24576.0,816384.0,0,0,0.0,816384.0,816384.0,6384.0,12.0,0.99812382739212,9216.0,3072.0,11.36,644.0960000000006,617472.0,149760.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",152,593664.0,1248768.0,0,0,0.0,1248768.0,1248768.0,7440.0,36984.0,0.16747703943814155,2435328.0,15360.0,5.728,649.8240000000005,61440.0,0.0,593664.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76104.0,480.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",153,0.0,4608.0,0,0,0.0,4608.0,4608.0,0.0,4608.0,0.0,15360.0,2816.0,2.528,652.3520000000005,3840.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,480.0,88.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",154,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.4,654.7520000000005,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",155,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,656.9280000000006,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",156,6417.0,23357.0,0,0,0.0,23357.0,23357.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,4.224,661.1520000000006,6540.0,3983.0,6417.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,98.0
"void gemvNSP_kernel<float, float, float, float, 1, 16, 4, 1024, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T10)",157,2362368.0,4798464.0,0,0,0.0,4798464.0,4798464.0,9024.0,147648.0,0.05759803921568627,9744384.0,12288.0,13.024,674.1760000000006,73728.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304512.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",158,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,1.984,676.1600000000007,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",159,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,2.016,678.1760000000006,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",160,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.048,680.2240000000006,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",161,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.112,682.3360000000006,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",162,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.016,684.3520000000005,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",163,17849.0,44914.0,0,0,0.0,44914.0,44914.0,0.0,48.0,0.0,12288.0,12288.0,2.112,686.4640000000005,3072.0,6144.0,17849.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",164,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,2.016,688.4800000000005,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",165,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.048,690.5280000000005,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 8, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",166,2360064.0,4732416.0,0,0,0.0,4732416.0,4732416.0,1584.0,147552.0,0.010621177985194722,10030464.0,3072.0,13.696,704.2240000000005,12288.0,0.0,2360064.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313452.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",167,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.144,706.3680000000005,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",168,6417.0,23357.0,0,0,0.0,23357.0,23357.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,4.288,710.6560000000005,6540.0,3983.0,6417.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",169,1774080.0,3621888.0,0,0,0.0,3621888.0,3621888.0,17280.0,111744.0,0.13392857142857142,11119200.0,22080.0,11.456,722.1120000000005,73728.0,0.0,1774080.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,347475.0,690.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",170,0.0,6912.0,0,0,0.0,6912.0,6912.0,0.0,6912.0,0.0,18432.0,8384.0,2.56,724.6720000000005,4608.0,2304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,262.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",171,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2880.0,0.0,18432.0,192.0,2.496,727.1680000000005,2304.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,6.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",172,24576.0,816384.0,0,0,0.0,816384.0,816384.0,6384.0,12.0,0.99812382739212,9216.0,3072.0,11.296,738.4640000000005,617472.0,149760.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",173,593664.0,1248768.0,0,0,0.0,1248768.0,1248768.0,7440.0,36984.0,0.16747703943814155,2435328.0,15360.0,5.728,744.1920000000005,61440.0,0.0,593664.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76104.0,480.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",174,0.0,4608.0,0,0,0.0,4608.0,4608.0,0.0,4608.0,0.0,15360.0,2656.0,2.496,746.6880000000004,3840.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,480.0,83.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",175,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.368,749.0560000000005,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",176,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,751.2320000000005,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",177,6417.0,23357.0,0,0,0.0,23357.0,23357.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,4.32,755.5520000000006,6540.0,3983.0,6417.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,98.0
"void gemvNSP_kernel<float, float, float, float, 1, 16, 4, 1024, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T10)",178,2362368.0,4798464.0,0,0,0.0,4798464.0,4798464.0,9024.0,147648.0,0.05759803921568627,9744384.0,12288.0,13.28,768.8320000000006,73728.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304512.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",179,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.016,770.8480000000005,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",180,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,2.016,772.8640000000005,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",181,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,1.984,774.8480000000005,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",182,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.048,776.8960000000005,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",183,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,1.984,778.8800000000006,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",184,17856.0,44928.0,0,0,0.0,44928.0,44928.0,0.0,48.0,0.0,12288.0,12288.0,2.176,781.0560000000006,3072.0,6144.0,17856.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",185,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,2.048,783.1040000000006,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",186,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.08,785.1840000000007,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 8, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",187,2360064.0,4732416.0,0,0,0.0,4732416.0,4732416.0,1584.0,147552.0,0.010621177985194722,10030240.0,3072.0,13.504,798.6880000000007,12288.0,0.0,2360064.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313445.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",188,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,800.8640000000007,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",189,6417.0,23357.0,0,0,0.0,23357.0,23357.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,4.256,805.1200000000007,6540.0,3983.0,6417.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",190,38647633.0,77697343.0,0,0,0.0,77697343.0,77697343.0,138216.0,2425045.0,0.05392193771917881,155476832.0,262624.0,166.912,972.0320000000007,402077.0,0.0,38647633.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4858651.0,8207.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",191,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,973.7280000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",192,0.0,0.0,0,0,0.0,0.0,0.0,0.0,4.0,0.0,64.0,64.0,2.624,976.3520000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",193,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,978.4320000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",194,0.0,50257.0,0,0,0.0,50257.0,50257.0,0.0,790.0,0.0,201056.0,201056.0,2.24,980.6720000000008,0.0,50257.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6283.0,6283.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",195,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,982.3680000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",196,0.0,0.0,0,0,0.0,0.0,0.0,800.0,2371.0,0.2522863450015768,202656.0,13952.0,3.424,985.7920000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6333.0,436.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",197,0.0,0.0,0,0,0.0,0.0,0.0,3700.0,20652.0,0.15193823915900131,1284800.0,0.0,5.28,991.0720000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,40150.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",198,0.0,0.0,0,0,0.0,0.0,0.0,800.0,2371.0,0.2522863450015768,202656.0,14464.0,3.456,994.5280000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6333.0,452.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",199,0.0,0.0,0,0,0.0,0.0,0.0,3700.0,20952.0,0.15008924225214992,1284800.0,0.0,5.312,999.8400000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,40150.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",200,0.0,0.0,0,0,0.0,0.0,0.0,800.0,2371.0,0.2522863450015768,202656.0,13568.0,3.456,1003.2960000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6333.0,424.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",201,0.0,0.0,0,0,0.0,0.0,0.0,3700.0,20902.0,0.15039427688805787,1284800.0,0.0,5.408,1008.7040000000009,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,40150.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",202,0.0,0.0,0,0,0.0,0.0,0.0,800.0,2371.0,0.2522863450015768,202656.0,13632.0,3.36,1012.0640000000009,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6333.0,426.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",203,0.0,0.0,0,0,0.0,0.0,0.0,3700.0,20802.0,0.1510080809729818,1284800.0,32.0,5.376,1017.4400000000009,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,40150.0,1.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",204,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,1632.0,224.0,2.304,1019.7440000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,51.0,7.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",205,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.632,1021.3760000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",206,0.0,0.0,0,0,0.0,0.0,0.0,497.0,12.0,0.9764243614931237,224.0,0.0,3.488,1024.8640000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",207,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.696,1026.5600000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",208,0.0,0.0,0,0,0.0,0.0,0.0,497.0,12.0,0.9764243614931237,224.0,0.0,3.456,1030.0160000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 1>(detail::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, detail::TensorInfo<T1, T2>, T2, detail::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",209,0.0,0.0,0,0,0.0,0.0,0.0,13008.0,3253.0,0.7999508025336696,207360.0,2240.0,5.696,1035.7120000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6480.0,70.0
"void native::radixSortKVInPlace<(int)-2, (int)-1, 32, 4, float, long, unsigned int>(detail::TensorInfo<T5, T7>, T7, T7, T7, detail::TensorInfo<T6, T7>, T7, bool)",210,0.0,0.0,0,0,0.0,0.0,0.0,458.0,8.0,0.9828326180257511,640.0,0.0,6.016,1041.7280000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,20.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",211,0.0,0.0,0,0,0.0,0.0,0.0,0.0,4713.0,0.0,204224.0,20256.0,3.584,1045.3120000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6382.0,633.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",212,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1185.0,0.0,251328.0,0.0,2.272,1047.5840000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7854.0,0.0
"native::<unnamed>::fill_reverse_indices_kernel(long *, int, detail::IntDivider<unsigned int>)",213,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1571.0,0.0,0.0,402080.0,2.048,1049.6320000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,12565.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",214,0.0,0.0,0,0,0.0,0.0,0.0,98304.0,1571.0,0.984270337922403,201056.0,0.0,3.968,1053.6000000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6283.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",215,0.0,0.0,0,0,0.0,0.0,0.0,156.0,64.0,0.7090909090909091,8192.0,0.0,2.176,1055.7760000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",216,0.0,0.0,0,0,0.0,0.0,0.0,19229.0,7225.0,0.7268844031148408,707200.0,503744.0,8.288,1064.0640000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,22100.0,15742.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",217,0.0,0.0,0,0,0.0,0.0,0.0,6629.0,7316.0,0.47536751523843673,704000.0,620544.0,6.976,1071.0400000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,22000.0,19392.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",218,0.0,0.0,0,0,0.0,0.0,0.0,7346.0,7253.0,0.5031851496677855,699776.0,620544.0,7.296,1078.3360000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,21868.0,19392.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",219,0.0,0.0,0,0,0.0,0.0,0.0,7346.0,7262.0,0.5028751369112815,696064.0,541344.0,7.104,1085.4400000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,21752.0,16917.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",220,703598.0,1663761.0,0,0,0.0,1663761.0,1663761.0,132.0,1676.0,0.07300884955752213,603168.0,201056.0,23.68,1109.1200000000008,206308.0,50257.0,703598.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,18849.0,6283.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<float, 1>>(T1, int)",221,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,480.0,1.696,1110.8160000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,15.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<float, std::plus<float>>::Policy900, const float *, float *, at_cuda_detail::ScanTileState<float, 1>, std::plus<float>, at_cuda_detail::NullType, unsigned int, float, 0>(T2, T3, T4, int, T5, T6, T7)",222,0.0,134117.0,0,0,0.0,134117.0,134117.0,7017.0,3299.0,0.6802055060100815,215648.0,202720.0,3.776,1114.5920000000008,134117.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6739.0,6335.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",223,0.0,0.0,0,0,0.0,0.0,0.0,0.0,790.0,0.0,201056.0,50208.0,2.272,1116.8640000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6283.0,1569.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",224,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,1118.5920000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",225,0.0,0.0,0,0,0.0,0.0,0.0,0.0,4713.0,0.0,452352.0,18400.0,7.456,1126.0480000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,14136.0,575.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",226,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1185.0,0.0,251328.0,0.0,2.336,1128.3840000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7854.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",227,703598.0,1663761.0,0,0,0.0,1663761.0,1663761.0,132.0,1676.0,0.07300884955752213,603168.0,201056.0,23.68,1152.0640000000008,206308.0,50257.0,703598.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,18849.0,6283.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",228,0.0,0.0,0,0,0.0,0.0,0.0,62.0,395.0,0.13566739606126915,201056.0,32.0,10.656,1162.7200000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6283.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",229,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.112,1164.8320000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",230,0.0,0.0,0,0,0.0,0.0,0.0,62.0,395.0,0.13566739606126915,201056.0,32.0,10.848,1175.6800000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6283.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",231,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.176,1177.8560000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",232,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.08,1179.9360000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",233,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.944,1182.8800000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",234,0.0,54833.0,0,0,0.0,54833.0,54833.0,62.0,395.0,0.13566739606126915,201056.0,32.0,10.528,1193.4080000000006,54833.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6283.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",235,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,1195.3920000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",236,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,1197.4720000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",237,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.976,1200.4480000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",238,453888.0,1008290.0,0,0,0.0,1008290.0,1008290.0,0.0,1571.0,0.0,0.0,201056.0,2.56,1203.0080000000005,0.0,100514.0,453888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,6283.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",239,251285.0,502570.0,0,0,0.0,502570.0,502570.0,0.0,1185.0,0.0,402112.0,0.0,3.616,1206.6240000000005,0.0,0.0,251285.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12566.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",240,0.0,0.0,0,0,0.0,0.0,0.0,124.0,395.0,0.23892100192678228,201056.0,32.0,16.224,1222.8480000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6283.0,1.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",241,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.048,1224.8960000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",242,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,1226.9440000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",243,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,1.984,1228.9280000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",244,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.048,1230.9760000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",245,0.0,0.0,0,0,0.0,0.0,0.0,0.0,4.0,0.0,64.0,64.0,2.624,1233.6000000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",246,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,1235.3280000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",247,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.76,1237.0880000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",248,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.176,1239.2640000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",249,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,1240.9920000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithoutCast, memory::StoreWithoutCast>(int, T1, T2, T4, T5, T6, T7)",250,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,1.984,1242.9760000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",251,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.208,1245.1840000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",252,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.112,1247.2960000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",253,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.784,1250.0800000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",254,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.2,1253.2800000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",255,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,1255.3600000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",256,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,1257.5040000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",257,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.264,1260.7680000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",258,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.696,1262.4640000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",259,0.0,0.0,0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,2.56,1265.0240000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",260,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,1267.0720000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",261,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,1269.1200000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",262,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,2.112,1271.2320000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(detail::TensorInfo<T1, T3>, detail::TensorInfo<const T1, T3>, detail::TensorInfo<const T2, T3>, int, int, T3, long)",263,0.0,0.0,0,0,0.0,0.0,0.0,0.0,72.0,0.0,3264.0,3072.0,2.88,1274.1120000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,102.0,96.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(detail::TensorInfo<T1, T3>, detail::TensorInfo<const T1, T3>, detail::TensorInfo<const T2, T3>, int, int, T3, long)",264,0.0,0.0,0,0,0.0,0.0,0.0,0.0,72.0,0.0,3264.0,3072.0,2.944,1277.0560000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,102.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",265,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,1279.2320000000004,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",266,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.176,1281.4080000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",267,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,1284.6720000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",268,6417.0,23357.0,0,0,0.0,23357.0,23357.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,4.256,1288.9280000000003,6540.0,3983.0,6417.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",269,1774080.0,3621888.0,0,0,0.0,3621888.0,3621888.0,17280.0,111744.0,0.13392857142857142,11187136.0,21728.0,11.36,1300.2880000000002,73728.0,0.0,1774080.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,349598.0,679.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",270,0.0,6912.0,0,0,0.0,6912.0,6912.0,0.0,6912.0,0.0,18432.0,8672.0,2.432,1302.7200000000003,4608.0,2304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,271.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",271,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2880.0,0.0,18432.0,128.0,2.4,1305.1200000000003,2304.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,4.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",272,0.0,0.0,0,0,0.0,0.0,0.0,0.0,60.0,0.0,6144.0,6144.0,2.592,1307.7120000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",273,0.0,0.0,0,0,0.0,0.0,0.0,0.0,60.0,0.0,6144.0,6144.0,2.592,1310.3040000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",274,24576.0,817152.0,0,0,0.0,817152.0,817152.0,6384.0,12.0,0.99812382739212,15360.0,3072.0,11.52,1321.8240000000005,618240.0,149760.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",275,593664.0,1248768.0,0,0,0.0,1248768.0,1248768.0,7440.0,36984.0,0.16747703943814155,2435328.0,15360.0,5.824,1327.6480000000006,61440.0,0.0,593664.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76104.0,480.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",276,0.0,4608.0,0,0,0.0,4608.0,4608.0,0.0,4608.0,0.0,15360.0,2752.0,2.464,1330.1120000000005,3840.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,480.0,86.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",277,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.464,1332.5760000000005,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",278,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.112,1334.6880000000006,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",279,6417.0,23357.0,0,0,0.0,23357.0,23357.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,4.256,1338.9440000000006,6540.0,3983.0,6417.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,98.0
"void gemvNSP_kernel<float, float, float, float, 1, 16, 4, 1024, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T10)",280,2362368.0,4798464.0,0,0,0.0,4798464.0,4798464.0,9024.0,147648.0,0.05759803921568627,9744384.0,12288.0,13.312,1352.2560000000005,73728.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304512.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",281,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.016,1354.2720000000006,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",282,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,2.048,1356.3200000000006,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",283,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.016,1358.3360000000007,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",284,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.048,1360.3840000000007,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",285,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.016,1362.4000000000008,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",286,17875.0,44966.0,0,0,0.0,44966.0,44966.0,0.0,48.0,0.0,12288.0,12288.0,2.112,1364.5120000000009,3072.0,6144.0,17875.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",287,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,1.984,1366.4960000000008,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",288,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.048,1368.5440000000008,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 8, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",289,2360064.0,4732416.0,0,0,0.0,4732416.0,4732416.0,1584.0,147552.0,0.010621177985194722,10030368.0,3072.0,13.536,1382.0800000000008,12288.0,0.0,2360064.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313449.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",290,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.208,1384.288000000001,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",291,6417.0,23357.0,0,0,0.0,23357.0,23357.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,4.224,1388.5120000000009,6540.0,3983.0,6417.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",292,1774080.0,3621888.0,0,0,0.0,3621888.0,3621888.0,17280.0,111744.0,0.13392857142857142,11193568.0,22528.0,11.456,1399.9680000000008,73728.0,0.0,1774080.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,349799.0,704.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",293,0.0,6912.0,0,0,0.0,6912.0,6912.0,0.0,6912.0,0.0,18432.0,8640.0,2.496,1402.4640000000009,4608.0,2304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,270.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",294,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2880.0,0.0,18432.0,128.0,2.4,1404.864000000001,2304.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,4.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",295,0.0,0.0,0,0,0.0,0.0,0.0,0.0,60.0,0.0,6144.0,6144.0,2.624,1407.488000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",296,0.0,0.0,0,0,0.0,0.0,0.0,0.0,60.0,0.0,6144.0,6144.0,2.528,1410.016000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",297,24576.0,817152.0,0,0,0.0,817152.0,817152.0,6384.0,12.0,0.99812382739212,15360.0,3072.0,11.328,1421.344000000001,618240.0,149760.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",298,593664.0,1248768.0,0,0,0.0,1248768.0,1248768.0,7440.0,36984.0,0.16747703943814155,2435328.0,15360.0,5.76,1427.104000000001,61440.0,0.0,593664.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76104.0,480.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",299,0.0,4608.0,0,0,0.0,4608.0,4608.0,0.0,4608.0,0.0,15360.0,2880.0,2.528,1429.632000000001,3840.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,480.0,90.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",300,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.368,1432.000000000001,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",301,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.208,1434.208000000001,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",302,6417.0,23357.0,0,0,0.0,23357.0,23357.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,4.32,1438.528000000001,6540.0,3983.0,6417.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,98.0
"void gemvNSP_kernel<float, float, float, float, 1, 16, 4, 1024, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T10)",303,2362368.0,4798464.0,0,0,0.0,4798464.0,4798464.0,9024.0,147648.0,0.05759803921568627,9744384.0,12288.0,13.536,1452.064000000001,73728.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304512.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",304,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.016,1454.080000000001,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",305,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,2.016,1456.0960000000011,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",306,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.048,1458.1440000000011,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",307,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.08,1460.224000000001,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",308,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,1.984,1462.208000000001,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",309,17859.0,44934.0,0,0,0.0,44934.0,44934.0,0.0,48.0,0.0,12288.0,12288.0,2.144,1464.352000000001,3072.0,6144.0,17859.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",310,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,1.984,1466.336000000001,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",311,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.048,1468.384000000001,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 8, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",312,2360064.0,4732416.0,0,0,0.0,4732416.0,4732416.0,1584.0,147552.0,0.010621177985194722,10030752.0,3072.0,13.728,1482.112000000001,12288.0,0.0,2360064.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313461.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",313,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.208,1484.320000000001,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",314,6417.0,23357.0,0,0,0.0,23357.0,23357.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,4.32,1488.640000000001,6540.0,3983.0,6417.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",315,1774080.0,3621888.0,0,0,0.0,3621888.0,3621888.0,17280.0,111744.0,0.13392857142857142,11158560.0,22272.0,11.36,1500.000000000001,73728.0,0.0,1774080.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,348705.0,696.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",316,0.0,6912.0,0,0,0.0,6912.0,6912.0,0.0,6912.0,0.0,18432.0,8000.0,2.4,1502.400000000001,4608.0,2304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,250.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",317,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2880.0,0.0,18432.0,32.0,2.4,1504.800000000001,2304.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",318,0.0,0.0,0,0,0.0,0.0,0.0,0.0,60.0,0.0,6144.0,6144.0,2.528,1507.328000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",319,0.0,0.0,0,0,0.0,0.0,0.0,0.0,60.0,0.0,6144.0,6144.0,2.528,1509.8560000000011,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",320,24576.0,817152.0,0,0,0.0,817152.0,817152.0,6384.0,12.0,0.99812382739212,15360.0,3072.0,11.488,1521.3440000000012,618240.0,149760.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",321,593664.0,1248768.0,0,0,0.0,1248768.0,1248768.0,7440.0,36984.0,0.16747703943814155,2435328.0,15360.0,5.696,1527.040000000001,61440.0,0.0,593664.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76104.0,480.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",322,0.0,4608.0,0,0,0.0,4608.0,4608.0,0.0,4608.0,0.0,15360.0,2816.0,2.528,1529.5680000000011,3840.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,480.0,88.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",323,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.4,1531.9680000000012,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",324,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.144,1534.1120000000012,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",325,6417.0,23357.0,0,0,0.0,23357.0,23357.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,4.256,1538.3680000000013,6540.0,3983.0,6417.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,98.0
"void gemvNSP_kernel<float, float, float, float, 1, 16, 4, 1024, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T10)",326,2362368.0,4798464.0,0,0,0.0,4798464.0,4798464.0,9024.0,147648.0,0.05759803921568627,9744384.0,12288.0,13.056,1551.4240000000013,73728.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304512.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",327,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,1.984,1553.4080000000013,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",328,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,2.016,1555.4240000000013,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",329,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.048,1557.4720000000013,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",330,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.08,1559.5520000000013,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",331,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.016,1561.5680000000013,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",332,17813.0,44842.0,0,0,0.0,44842.0,44842.0,0.0,48.0,0.0,12288.0,12288.0,2.112,1563.6800000000014,3072.0,6144.0,17813.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",333,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,2.016,1565.6960000000015,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",334,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.144,1567.8400000000015,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 8, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",335,2360064.0,4732416.0,0,0,0.0,4732416.0,4732416.0,1584.0,147552.0,0.010621177985194722,10030560.0,3072.0,13.44,1581.2800000000016,12288.0,0.0,2360064.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313455.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",336,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.144,1583.4240000000016,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",337,6417.0,23357.0,0,0,0.0,23357.0,23357.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,4.256,1587.6800000000017,6540.0,3983.0,6417.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",338,1774080.0,3621888.0,0,0,0.0,3621888.0,3621888.0,17280.0,111744.0,0.13392857142857142,11096864.0,22112.0,11.52,1599.2000000000016,73728.0,0.0,1774080.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,346777.0,691.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",339,0.0,6912.0,0,0,0.0,6912.0,6912.0,0.0,6912.0,0.0,18432.0,8448.0,2.496,1601.6960000000017,4608.0,2304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,264.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",340,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2880.0,0.0,18432.0,288.0,2.4,1604.0960000000018,2304.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,9.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",341,0.0,0.0,0,0,0.0,0.0,0.0,0.0,60.0,0.0,6144.0,6144.0,2.688,1606.784000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",342,0.0,0.0,0,0,0.0,0.0,0.0,0.0,60.0,0.0,6144.0,6144.0,2.56,1609.3440000000019,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",343,24576.0,817152.0,0,0,0.0,817152.0,817152.0,6384.0,12.0,0.99812382739212,15360.0,3072.0,11.2,1620.544000000002,618240.0,149760.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",344,593664.0,1248768.0,0,0,0.0,1248768.0,1248768.0,7440.0,36984.0,0.16747703943814155,2435328.0,15360.0,5.632,1626.176000000002,61440.0,0.0,593664.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76104.0,480.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",345,0.0,4608.0,0,0,0.0,4608.0,4608.0,0.0,4608.0,0.0,15360.0,2784.0,2.528,1628.704000000002,3840.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,480.0,87.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",346,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.4,1631.104000000002,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",347,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,1633.280000000002,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",348,6417.0,23357.0,0,0,0.0,23357.0,23357.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,4.256,1637.536000000002,6540.0,3983.0,6417.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,98.0
"void gemvNSP_kernel<float, float, float, float, 1, 16, 4, 1024, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T10)",349,2362368.0,4798464.0,0,0,0.0,4798464.0,4798464.0,9024.0,147648.0,0.05759803921568627,9744384.0,12288.0,13.376,1650.912000000002,73728.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304512.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",350,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.016,1652.9280000000022,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",351,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,2.016,1654.9440000000022,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",352,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,1.984,1656.9280000000022,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",353,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.08,1659.008000000002,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",354,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.016,1661.0240000000022,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",355,17861.0,44938.0,0,0,0.0,44938.0,44938.0,0.0,48.0,0.0,12288.0,12288.0,2.144,1663.1680000000022,3072.0,6144.0,17861.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",356,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,1.984,1665.152000000002,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",357,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.08,1667.232000000002,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 8, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",358,2360064.0,4732416.0,0,0,0.0,4732416.0,4732416.0,1584.0,147552.0,0.010621177985194722,10030336.0,3072.0,13.6,1680.832000000002,12288.0,0.0,2360064.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313448.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",359,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.272,1683.1040000000019,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",360,6417.0,23357.0,0,0,0.0,23357.0,23357.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,4.352,1687.456000000002,6540.0,3983.0,6417.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",361,1774080.0,3621888.0,0,0,0.0,3621888.0,3621888.0,17280.0,111744.0,0.13392857142857142,11227264.0,21824.0,11.36,1698.8160000000018,73728.0,0.0,1774080.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,350852.0,682.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",362,0.0,6912.0,0,0,0.0,6912.0,6912.0,0.0,6912.0,0.0,18432.0,8256.0,2.496,1701.312000000002,4608.0,2304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,258.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",363,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2880.0,0.0,18432.0,128.0,2.432,1703.744000000002,2304.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,4.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",364,0.0,0.0,0,0,0.0,0.0,0.0,0.0,60.0,0.0,6144.0,6144.0,2.56,1706.304000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",365,0.0,0.0,0,0,0.0,0.0,0.0,0.0,60.0,0.0,6144.0,6144.0,2.56,1708.8640000000019,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",366,24576.0,817152.0,0,0,0.0,817152.0,817152.0,6384.0,12.0,0.99812382739212,15360.0,3072.0,11.424,1720.2880000000018,618240.0,149760.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",367,593664.0,1248768.0,0,0,0.0,1248768.0,1248768.0,7440.0,36984.0,0.16747703943814155,2435328.0,15360.0,5.888,1726.1760000000017,61440.0,0.0,593664.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76104.0,480.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",368,0.0,4608.0,0,0,0.0,4608.0,4608.0,0.0,4608.0,0.0,15360.0,2784.0,2.464,1728.6400000000017,3840.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,480.0,87.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",369,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.368,1731.0080000000016,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",370,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.208,1733.2160000000017,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",371,6417.0,23357.0,0,0,0.0,23357.0,23357.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,4.224,1737.4400000000016,6540.0,3983.0,6417.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,98.0
"void gemvNSP_kernel<float, float, float, float, 1, 16, 4, 1024, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T10)",372,2362368.0,4798464.0,0,0,0.0,4798464.0,4798464.0,9024.0,147648.0,0.05759803921568627,9744384.0,12288.0,13.28,1750.7200000000016,73728.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304512.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",373,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.048,1752.7680000000016,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",374,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,1.984,1754.7520000000015,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",375,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,1.984,1756.7360000000015,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",376,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.112,1758.8480000000015,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",377,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.016,1760.8640000000016,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",378,17813.0,44842.0,0,0,0.0,44842.0,44842.0,0.0,48.0,0.0,12288.0,12288.0,2.144,1763.0080000000016,3072.0,6144.0,17813.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",379,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,2.016,1765.0240000000017,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",380,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.08,1767.1040000000016,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 8, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",381,2360064.0,4732416.0,0,0,0.0,4732416.0,4732416.0,1584.0,147552.0,0.010621177985194722,10030528.0,3072.0,13.504,1780.6080000000015,12288.0,0.0,2360064.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313454.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",382,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,1782.7840000000015,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",383,6417.0,23357.0,0,0,0.0,23357.0,23357.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,4.256,1787.0400000000016,6540.0,3983.0,6417.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",384,1774080.0,3621888.0,0,0,0.0,3621888.0,3621888.0,17280.0,111744.0,0.13392857142857142,11220672.0,22112.0,11.456,1798.4960000000015,73728.0,0.0,1774080.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,350646.0,691.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",385,0.0,6912.0,0,0,0.0,6912.0,6912.0,0.0,6912.0,0.0,18432.0,8000.0,2.56,1801.0560000000014,4608.0,2304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,250.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",386,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2880.0,0.0,18432.0,224.0,2.464,1803.5200000000013,2304.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,7.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",387,0.0,0.0,0,0,0.0,0.0,0.0,0.0,60.0,0.0,6144.0,6144.0,2.656,1806.1760000000013,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",388,0.0,0.0,0,0,0.0,0.0,0.0,0.0,60.0,0.0,6144.0,6144.0,2.528,1808.7040000000013,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",389,24576.0,817152.0,0,0,0.0,817152.0,817152.0,6384.0,12.0,0.99812382739212,15360.0,3072.0,11.296,1820.0000000000014,618240.0,149760.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",390,593664.0,1248768.0,0,0,0.0,1248768.0,1248768.0,7440.0,36984.0,0.16747703943814155,2435328.0,15360.0,5.76,1825.7600000000014,61440.0,0.0,593664.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76104.0,480.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",391,0.0,4608.0,0,0,0.0,4608.0,4608.0,0.0,4608.0,0.0,15360.0,2496.0,2.496,1828.2560000000014,3840.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,480.0,78.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",392,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.368,1830.6240000000014,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",393,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.144,1832.7680000000014,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",394,6417.0,23357.0,0,0,0.0,23357.0,23357.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,4.352,1837.1200000000015,6540.0,3983.0,6417.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,98.0
"void gemvNSP_kernel<float, float, float, float, 1, 16, 4, 1024, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T10)",395,2362368.0,4798464.0,0,0,0.0,4798464.0,4798464.0,9024.0,147648.0,0.05759803921568627,9744384.0,12288.0,13.408,1850.5280000000014,73728.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304512.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",396,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,1.984,1852.5120000000013,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",397,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,2.048,1854.5600000000013,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",398,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,1.984,1856.5440000000012,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",399,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.016,1858.5600000000013,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",400,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.016,1860.5760000000014,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",401,17864.0,44944.0,0,0,0.0,44944.0,44944.0,0.0,48.0,0.0,12288.0,12288.0,2.112,1862.6880000000015,3072.0,6144.0,17864.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",402,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,2.016,1864.7040000000015,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",403,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.08,1866.7840000000015,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 8, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",404,2360064.0,4732416.0,0,0,0.0,4732416.0,4732416.0,1584.0,147552.0,0.010621177985194722,10030656.0,3072.0,13.76,1880.5440000000015,12288.0,0.0,2360064.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313458.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",405,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,1882.7200000000014,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",406,6417.0,23357.0,0,0,0.0,23357.0,23357.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,4.256,1886.9760000000015,6540.0,3983.0,6417.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",407,1774080.0,3621888.0,0,0,0.0,3621888.0,3621888.0,17280.0,111744.0,0.13392857142857142,11117984.0,22240.0,11.168,1898.1440000000014,73728.0,0.0,1774080.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,347437.0,695.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",408,0.0,6912.0,0,0,0.0,6912.0,6912.0,0.0,6912.0,0.0,18432.0,8224.0,2.4,1900.5440000000015,4608.0,2304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,257.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",409,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2880.0,0.0,18432.0,32.0,2.432,1902.9760000000015,2304.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",410,0.0,0.0,0,0,0.0,0.0,0.0,0.0,60.0,0.0,6144.0,6144.0,2.624,1905.6000000000015,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",411,0.0,0.0,0,0,0.0,0.0,0.0,0.0,60.0,0.0,6144.0,6144.0,2.56,1908.1600000000014,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",412,24576.0,817152.0,0,0,0.0,817152.0,817152.0,6384.0,12.0,0.99812382739212,15360.0,3072.0,11.36,1919.5200000000013,618240.0,149760.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",413,593664.0,1248768.0,0,0,0.0,1248768.0,1248768.0,7440.0,36984.0,0.16747703943814155,2435328.0,15360.0,5.856,1925.3760000000013,61440.0,0.0,593664.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76104.0,480.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",414,0.0,4608.0,0,0,0.0,4608.0,4608.0,0.0,4608.0,0.0,15360.0,2528.0,2.464,1927.8400000000013,3840.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,480.0,79.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",415,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.336,1930.1760000000013,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",416,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,1932.3520000000012,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",417,6417.0,23357.0,0,0,0.0,23357.0,23357.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,4.224,1936.5760000000012,6540.0,3983.0,6417.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,98.0
"void gemvNSP_kernel<float, float, float, float, 1, 16, 4, 1024, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T10)",418,2362368.0,4798464.0,0,0,0.0,4798464.0,4798464.0,9024.0,147648.0,0.05759803921568627,9744384.0,12288.0,13.28,1949.8560000000011,73728.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304512.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",419,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.048,1951.9040000000011,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",420,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,1.984,1953.888000000001,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",421,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.016,1955.9040000000011,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",422,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.08,1957.984000000001,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",423,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,1.952,1959.936000000001,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",424,17872.0,44960.0,0,0,0.0,44960.0,44960.0,0.0,48.0,0.0,12288.0,12288.0,2.144,1962.080000000001,3072.0,6144.0,17872.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",425,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,2.016,1964.0960000000011,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",426,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.144,1966.2400000000011,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 8, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",427,2360064.0,4732416.0,0,0,0.0,4732416.0,4732416.0,1584.0,147552.0,0.010621177985194722,10030688.0,3072.0,13.376,1979.6160000000011,12288.0,0.0,2360064.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313459.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",428,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.144,1981.7600000000011,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",429,6417.0,23357.0,0,0,0.0,23357.0,23357.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,4.288,1986.0480000000011,6540.0,3983.0,6417.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",430,1774080.0,3621888.0,0,0,0.0,3621888.0,3621888.0,17280.0,111744.0,0.13392857142857142,11256064.0,21920.0,11.232,1997.280000000001,73728.0,0.0,1774080.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,351752.0,685.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",431,0.0,6912.0,0,0,0.0,6912.0,6912.0,0.0,6912.0,0.0,18432.0,8032.0,2.432,1999.7120000000011,4608.0,2304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,251.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",432,0.0,2304.0,0,0,0.0,2304.0,2304.0,0.0,2880.0,0.0,18432.0,192.0,2.496,2002.2080000000012,2304.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,6.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",433,0.0,0.0,0,0,0.0,0.0,0.0,0.0,60.0,0.0,6144.0,6144.0,2.56,2004.7680000000012,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",434,0.0,0.0,0,0,0.0,0.0,0.0,0.0,60.0,0.0,6144.0,6144.0,2.72,2007.4880000000012,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",435,24576.0,817152.0,0,0,0.0,817152.0,817152.0,6384.0,12.0,0.99812382739212,15360.0,3072.0,11.328,2018.8160000000012,618240.0,149760.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",436,593664.0,1248768.0,0,0,0.0,1248768.0,1248768.0,7440.0,36984.0,0.16747703943814155,2435328.0,15360.0,5.696,2024.512000000001,61440.0,0.0,593664.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76104.0,480.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",437,0.0,4608.0,0,0,0.0,4608.0,4608.0,0.0,4608.0,0.0,15360.0,2848.0,2.592,2027.1040000000012,3840.0,768.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,480.0,89.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",438,0.0,768.0,0,0,0.0,768.0,768.0,0.0,960.0,0.0,6144.0,0.0,2.336,2029.4400000000012,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",439,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.112,2031.5520000000013,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",440,6417.0,23357.0,0,0,0.0,23357.0,23357.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,4.384,2035.9360000000013,6540.0,3983.0,6417.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,98.0
"void gemvNSP_kernel<float, float, float, float, 1, 16, 4, 1024, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T10)",441,2362368.0,4798464.0,0,0,0.0,4798464.0,4798464.0,9024.0,147648.0,0.05759803921568627,9744384.0,12288.0,13.28,2049.2160000000013,73728.0,0.0,2362368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304512.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",442,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.144,2051.360000000001,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",443,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,2.048,2053.408000000001,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",444,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.016,2055.424000000001,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",445,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.112,2057.536000000001,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",446,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.016,2059.552000000001,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",447,17846.0,44908.0,0,0,0.0,44908.0,44908.0,0.0,48.0,0.0,12288.0,12288.0,2.112,2061.664000000001,3072.0,6144.0,17846.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",448,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,2.016,2063.680000000001,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",449,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.08,2065.760000000001,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 8, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",450,2360064.0,4732416.0,0,0,0.0,4732416.0,4732416.0,1584.0,147552.0,0.010621177985194722,10030496.0,3072.0,13.632,2079.392000000001,12288.0,0.0,2360064.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313453.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",451,768.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,6144.0,3072.0,2.176,2081.568000000001,0.0,0.0,768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",452,6417.0,23357.0,0,0,0.0,23357.0,23357.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,4.256,2085.824000000001,6540.0,3983.0,6417.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",453,38647633.0,77697343.0,0,0,0.0,77697343.0,77697343.0,138216.0,2425045.0,0.05392193771917881,155492608.0,263936.0,166.624,2252.448000000001,402077.0,0.0,38647633.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4859144.0,8248.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",454,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,2254.1440000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",455,0.0,0.0,0,0,0.0,0.0,0.0,0.0,5.0,0.0,64.0,64.0,2.56,2256.7040000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",456,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,2258.7520000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",457,0.0,50257.0,0,0,0.0,50257.0,50257.0,0.0,790.0,0.0,201056.0,201056.0,2.272,2261.0240000000003,0.0,50257.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6283.0,6283.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",458,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,2262.7200000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",459,0.0,0.0,0,0,0.0,0.0,0.0,800.0,2371.0,0.2522863450015768,202656.0,13760.0,3.456,2266.1760000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6333.0,430.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",460,0.0,0.0,0,0,0.0,0.0,0.0,3700.0,20652.0,0.15193823915900131,1284800.0,0.0,5.408,2271.5840000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,40150.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",461,0.0,0.0,0,0,0.0,0.0,0.0,800.0,2371.0,0.2522863450015768,202656.0,14592.0,3.52,2275.1040000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6333.0,456.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",462,0.0,0.0,0,0,0.0,0.0,0.0,3700.0,20952.0,0.15008924225214992,1284800.0,0.0,5.248,2280.3520000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,40150.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",463,0.0,0.0,0,0,0.0,0.0,0.0,800.0,2371.0,0.2522863450015768,202656.0,13760.0,3.36,2283.7120000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6333.0,430.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",464,0.0,0.0,0,0,0.0,0.0,0.0,3700.0,20952.0,0.15008924225214992,1284800.0,0.0,5.152,2288.8640000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,40150.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",465,0.0,0.0,0,0,0.0,0.0,0.0,800.0,2371.0,0.2522863450015768,202656.0,14208.0,3.392,2292.2560000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6333.0,444.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",466,0.0,0.0,0,0,0.0,0.0,0.0,3700.0,20852.0,0.15070055392636036,1284800.0,32.0,5.376,2297.6320000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,40150.0,1.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",467,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,1632.0,224.0,2.336,2299.9680000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,51.0,7.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",468,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.696,2301.664,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",469,0.0,0.0,0,0,0.0,0.0,0.0,497.0,12.0,0.9764243614931237,224.0,0.0,3.424,2305.088,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",470,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.632,2306.7200000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",471,0.0,0.0,0,0,0.0,0.0,0.0,497.0,12.0,0.9764243614931237,224.0,0.0,3.456,2310.1760000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 1>(detail::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, detail::TensorInfo<T1, T2>, T2, detail::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",472,0.0,0.0,0,0,0.0,0.0,0.0,11616.0,3255.0,0.7811176114585435,207360.0,2272.0,5.6,2315.7760000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6480.0,71.0
"void native::radixSortKVInPlace<(int)-2, (int)-1, 32, 4, float, long, unsigned int>(detail::TensorInfo<T5, T7>, T7, T7, T7, detail::TensorInfo<T6, T7>, T7, bool)",473,0.0,0.0,0,0,0.0,0.0,0.0,458.0,8.0,0.9828326180257511,640.0,0.0,6.016,2321.7920000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,20.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",474,0.0,0.0,0,0,0.0,0.0,0.0,0.0,4713.0,0.0,204224.0,19616.0,3.552,2325.3440000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6382.0,613.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",475,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1185.0,0.0,251328.0,0.0,2.528,2327.8720000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7854.0,0.0
"native::<unnamed>::fill_reverse_indices_kernel(long *, int, detail::IntDivider<unsigned int>)",476,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1571.0,0.0,0.0,402080.0,2.016,2329.8880000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,12565.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",477,0.0,0.0,0,0,0.0,0.0,0.0,98304.0,1571.0,0.984270337922403,201056.0,0.0,3.968,2333.856,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6283.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",478,0.0,0.0,0,0,0.0,0.0,0.0,156.0,64.0,0.7090909090909091,8192.0,0.0,2.208,2336.0640000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",479,0.0,0.0,0,0,0.0,0.0,0.0,19229.0,7277.0,0.7254583867803516,710016.0,514240.0,8.416,2344.4800000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,22188.0,16070.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",480,0.0,0.0,0,0,0.0,0.0,0.0,7529.0,7292.0,0.5079954119155252,698752.0,499424.0,7.424,2351.9040000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,21836.0,15607.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",481,0.0,0.0,0,0,0.0,0.0,0.0,7346.0,7231.0,0.5039445702133498,702592.0,620544.0,7.296,2359.2000000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,21956.0,19392.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",482,0.0,0.0,0,0,0.0,0.0,0.0,7346.0,7256.0,0.5030817696205999,695296.0,539680.0,7.136,2366.3360000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,21728.0,16865.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",483,703598.0,1663761.0,0,0,0.0,1663761.0,1663761.0,132.0,1676.0,0.07300884955752213,603168.0,201056.0,24.064,2390.4,206308.0,50257.0,703598.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,18849.0,6283.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<float, 1>>(T1, int)",484,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,480.0,1.696,2392.096,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,15.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<float, std::plus<float>>::Policy900, const float *, float *, at_cuda_detail::ScanTileState<float, 1>, std::plus<float>, at_cuda_detail::NullType, unsigned int, float, 0>(T2, T3, T4, int, T5, T6, T7)",485,0.0,134117.0,0,0,0.0,134117.0,134117.0,7017.0,3286.0,0.6810637678346113,215648.0,202720.0,3.872,2395.968,134117.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6739.0,6335.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",486,0.0,0.0,0,0,0.0,0.0,0.0,0.0,790.0,0.0,201056.0,50208.0,2.304,2398.272,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6283.0,1569.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",487,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.664,2399.936,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",488,0.0,0.0,0,0,0.0,0.0,0.0,0.0,4713.0,0.0,452352.0,19584.0,7.36,2407.2960000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,14136.0,612.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",489,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1185.0,0.0,251328.0,0.0,2.528,2409.824,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7854.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",490,703598.0,1663761.0,0,0,0.0,1663761.0,1663761.0,132.0,1676.0,0.07300884955752213,603168.0,201056.0,23.744,2433.568,206308.0,50257.0,703598.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,18849.0,6283.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",491,0.0,0.0,0,0,0.0,0.0,0.0,62.0,395.0,0.13566739606126915,201056.0,32.0,10.624,2444.192,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6283.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",492,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.112,2446.304,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",493,0.0,0.0,0,0,0.0,0.0,0.0,62.0,395.0,0.13566739606126915,201056.0,32.0,10.72,2457.024,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6283.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",494,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,2459.1679999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",495,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.048,2461.2159999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",496,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.072,2464.2879999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",497,0.0,54833.0,0,0,0.0,54833.0,54833.0,62.0,395.0,0.13566739606126915,201056.0,32.0,10.656,2474.9439999999995,54833.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6283.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",498,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2476.9599999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",499,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2478.9759999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",500,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.944,2481.9199999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",501,453888.0,1008290.0,0,0,0.0,1008290.0,1008290.0,0.0,1571.0,0.0,0.0,201056.0,2.528,2484.4479999999994,0.0,100514.0,453888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,6283.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",502,251285.0,502570.0,0,0,0.0,502570.0,502570.0,0.0,1185.0,0.0,402112.0,0.0,3.488,2487.9359999999992,0.0,0.0,251285.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12566.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",503,0.0,0.0,0,0,0.0,0.0,0.0,124.0,395.0,0.23892100192678228,201056.0,32.0,15.904,2503.8399999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6283.0,1.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",504,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.048,2505.887999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",505,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,2507.935999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",506,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.016,2509.951999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",507,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.016,2511.967999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",508,0.0,0.0,0,0,0.0,0.0,0.0,0.0,5.0,0.0,64.0,64.0,2.56,2514.527999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",509,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.664,2516.191999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",510,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,2517.887999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",511,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.08,2519.967999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",512,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,2521.663999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",513,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.016,2523.679999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",514,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.048,2525.7279999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",515,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2527.743999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",516,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.752,2530.4959999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",517,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.136,2533.6319999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",518,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,2535.7119999999986,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
