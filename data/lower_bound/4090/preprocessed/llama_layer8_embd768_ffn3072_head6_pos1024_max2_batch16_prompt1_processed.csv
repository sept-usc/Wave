Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,1.856,1.856,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,4.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,1.696,3.552,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,5.28,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.016,7.296,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.304,9.6,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",6,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,160.0,32.0,2.304,11.904,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",7,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,128.0,3.392,15.296,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,4.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",8,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,32.0,3.264,18.56,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",9,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,21.087999999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",10,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,1.696,22.784,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,4.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",11,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,24.512,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.728,26.240000000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,0.0,0.0,0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,2.432,28.672,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,30.688000000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",15,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.208,32.896,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",16,0.0,0.0,0,0,0.0,0.0,0.0,176.0,16.0,0.9166666666666666,128.0,32.0,2.624,35.52,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",17,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,128.0,2.048,37.568000000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",18,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,32.0,2.08,39.648,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",19,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,160.0,0.0,2.144,41.792,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",20,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1152.0,0.0,3840.0,49152.0,6.752,48.544000000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,120.0,1536.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",21,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,32.0,2.528,51.072,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",22,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,54.496,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",23,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,64.0,2.432,56.928000000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,2.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",24,0.0,2048.0,0,0,0.0,2048.0,2048.0,128.0,96.0,0.5714285714285714,5120.0,4096.0,2.016,58.944,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",25,0.0,0.0,0,0,0.0,0.0,0.0,0.0,80.0,0.0,8192.0,8192.0,2.592,61.536,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",26,16384.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,32.0,0.0,8192.0,8192.0,2.816,64.352,0.0,4096.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",27,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.144,66.49600000000001,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",28,14336.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,32.0,0.0,8192.0,8192.0,2.784,69.28000000000002,0.0,4096.0,14336.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",29,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.048,71.32800000000002,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",30,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.016,73.34400000000002,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",31,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,4.928,78.27200000000002,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",32,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.92,80.19200000000002,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",33,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.112,82.30400000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",34,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.752,85.05600000000001,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",35,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.784,87.84000000000002,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,36,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3698304.0,245760.0,7.968,95.80800000000002,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115572.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",37,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.816,98.62400000000002,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,38,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3707392.0,245760.0,7.808,106.43200000000002,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115856.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",39,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.752,109.18400000000001,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,40,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3705024.0,245760.0,7.68,116.864,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115782.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",41,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.624,119.488,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",42,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.912,122.4,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",43,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.656,125.05600000000001,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",44,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.032,129.08800000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",45,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.72,131.80800000000002,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",46,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.144,133.95200000000003,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",47,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.72,136.67200000000003,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",48,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.72,139.39200000000002,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",49,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.096,143.48800000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",50,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.72,146.20800000000003,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",51,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.4,148.60800000000003,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",52,196608.0,17651712.0,0,0,0.0,17651712.0,17651712.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,20.512,169.12000000000003,14880768.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,53,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3700000.0,245760.0,7.936,177.05600000000004,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115625.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",54,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.624,179.68000000000004,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",55,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,181.79200000000003,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",56,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.048,183.84000000000003,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",57,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,4.896,188.73600000000002,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",58,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.984,190.72000000000003,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",59,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.048,192.76800000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",60,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.624,195.39200000000002,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",61,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.72,198.11200000000002,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,62,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.392,213.50400000000002,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",63,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.072,216.57600000000002,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",64,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,2.752,219.32800000000003,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,65,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.68,235.00800000000004,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",66,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.296,238.30400000000003,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",67,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.528,240.83200000000002,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,68,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,95232.0,0.7987012987012987,11796480.0,393216.0,16.0,256.832,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",69,0.0,110592.0,0,0,0.0,110592.0,110592.0,0.0,3456.0,0.0,393216.0,49152.0,2.56,259.392,98304.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",70,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,261.504,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",71,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.016,263.52000000000004,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",72,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,5.056,268.576,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",73,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.952,270.528,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",74,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.048,272.576,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",75,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.688,275.264,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",76,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.72,277.98400000000004,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,77,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3695456.0,245760.0,8.384,286.36800000000005,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115483.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",78,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.688,289.05600000000004,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,79,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3701600.0,245760.0,7.808,296.86400000000003,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115675.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",80,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.624,299.48800000000006,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,81,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3700800.0,245760.0,7.936,307.42400000000004,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115650.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",82,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.752,310.17600000000004,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",83,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.72,312.8960000000001,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",84,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.624,315.5200000000001,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",85,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.0,319.5200000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",86,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.688,322.2080000000001,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",87,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.336,324.5440000000001,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",88,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.752,327.2960000000001,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",89,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.656,329.9520000000001,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",90,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.096,334.0480000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",91,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.72,336.76800000000014,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",92,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.208,338.97600000000017,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",93,196608.0,17651712.0,0,0,0.0,17651712.0,17651712.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,20.352,359.32800000000015,14880768.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,94,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3699136.0,245760.0,7.84,367.1680000000001,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115598.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",95,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.592,369.7600000000001,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",96,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.144,371.9040000000001,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",97,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.048,373.9520000000001,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",98,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,5.056,379.0080000000001,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",99,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.952,380.9600000000001,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",100,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.016,382.9760000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",101,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.72,385.69600000000014,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",102,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.656,388.35200000000015,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,103,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.36,403.71200000000016,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",104,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.072,406.78400000000016,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",105,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,2.464,409.24800000000016,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,106,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.808,425.05600000000015,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",107,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.264,428.32000000000016,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",108,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.432,430.7520000000002,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,109,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,95232.0,0.7987012987012987,11796480.0,393216.0,15.68,446.4320000000002,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",110,0.0,110592.0,0,0,0.0,110592.0,110592.0,0.0,3456.0,0.0,393216.0,49152.0,2.528,448.9600000000002,98304.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",111,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.08,451.0400000000002,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",112,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.048,453.0880000000002,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",113,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,4.832,457.9200000000002,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",114,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.984,459.90400000000017,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",115,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.016,461.9200000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",116,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.688,464.6080000000002,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",117,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.688,467.29600000000016,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,118,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3697408.0,245760.0,7.84,475.13600000000014,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115544.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",119,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.624,477.76000000000016,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,120,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3702464.0,245760.0,7.84,485.60000000000014,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115702.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",121,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.656,488.25600000000014,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,122,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3704992.0,245760.0,7.936,496.1920000000001,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115781.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",123,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.816,499.0080000000001,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",124,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.848,501.8560000000001,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",125,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.656,504.5120000000001,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",126,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.032,508.5440000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",127,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.688,511.2320000000001,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",128,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,513.344,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",129,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.752,516.096,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",130,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.688,518.784,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",131,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.0,522.784,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",132,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.688,525.472,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",133,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.144,527.616,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",134,196608.0,17651712.0,0,0,0.0,17651712.0,17651712.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,20.448,548.064,14880768.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,135,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3699392.0,245760.0,7.808,555.872,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115606.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",136,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.656,558.5279999999999,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",137,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.176,560.704,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",138,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.112,562.8159999999999,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",139,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,4.832,567.6479999999999,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",140,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.952,569.5999999999999,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",141,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.048,571.6479999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",142,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.656,574.3039999999999,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",143,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.72,577.0239999999999,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,144,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.456,592.4799999999999,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",145,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.264,595.7439999999999,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",146,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,2.432,598.1759999999999,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,147,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.776,613.9519999999999,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",148,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.264,617.2159999999999,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",149,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.432,619.6479999999999,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,150,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,95232.0,0.7987012987012987,11796480.0,393216.0,15.936,635.584,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",151,0.0,110592.0,0,0,0.0,110592.0,110592.0,0.0,3456.0,0.0,393216.0,49152.0,2.496,638.0799999999999,98304.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",152,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,640.1919999999999,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",153,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.08,642.2719999999999,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",154,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,4.96,647.232,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",155,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.952,649.184,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",156,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,1.984,651.168,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",157,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.688,653.856,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",158,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.656,656.512,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,159,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3700832.0,245760.0,7.744,664.256,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115651.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",160,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.688,666.944,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,161,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3703008.0,245760.0,7.808,674.752,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115719.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",162,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.72,677.472,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,163,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3702976.0,245760.0,7.872,685.3439999999999,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115718.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",164,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.592,687.9359999999999,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",165,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.752,690.6879999999999,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",166,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.752,693.4399999999998,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",167,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,3.968,697.4079999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",168,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,3.04,700.4479999999998,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",169,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.176,702.6239999999998,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",170,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.816,705.4399999999998,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",171,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.656,708.0959999999998,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",172,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.096,712.1919999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",173,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.752,714.9439999999997,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",174,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,717.0559999999997,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",175,196608.0,17651712.0,0,0,0.0,17651712.0,17651712.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,20.224,737.2799999999997,14880768.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,176,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3700672.0,245760.0,7.904,745.1839999999997,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115646.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",177,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.624,747.8079999999998,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",178,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.176,749.9839999999998,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",179,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.048,752.0319999999998,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",180,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,5.088,757.1199999999998,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",181,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.952,759.0719999999998,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",182,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,1.984,761.0559999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",183,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.624,763.6799999999998,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",184,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.688,766.3679999999998,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,185,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.712,782.0799999999998,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",186,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.296,785.3759999999999,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",187,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,2.432,787.8079999999999,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,188,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.392,803.1999999999999,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",189,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.136,806.3359999999999,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",190,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.432,808.7679999999999,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,191,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,95232.0,0.7987012987012987,11796480.0,393216.0,16.32,825.088,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",192,0.0,110592.0,0,0,0.0,110592.0,110592.0,0.0,3456.0,0.0,393216.0,49152.0,2.528,827.616,98304.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",193,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.144,829.76,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",194,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.112,831.872,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",195,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,4.896,836.7679999999999,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",196,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.952,838.7199999999999,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",197,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.048,840.7679999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",198,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.656,843.4239999999999,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",199,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.624,846.0479999999999,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,200,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3698112.0,245760.0,7.904,853.9519999999999,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115566.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",201,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.688,856.6399999999999,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,202,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3704000.0,245760.0,7.776,864.4159999999998,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115750.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",203,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.848,867.2639999999998,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,204,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3705088.0,245760.0,7.776,875.0399999999997,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115784.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",205,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.848,877.8879999999997,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",206,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.784,880.6719999999997,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",207,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.624,883.2959999999997,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",208,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.032,887.3279999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",209,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.816,890.1439999999998,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",210,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.176,892.3199999999998,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",211,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.72,895.0399999999998,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",212,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.656,897.6959999999998,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",213,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.064,901.7599999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",214,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.688,904.4479999999998,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",215,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.08,906.5279999999998,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",216,196608.0,17651712.0,0,0,0.0,17651712.0,17651712.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,20.448,926.9759999999998,14880768.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,217,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3700672.0,245760.0,7.712,934.6879999999998,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115646.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",218,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.688,937.3759999999997,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",219,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.272,939.6479999999998,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",220,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.08,941.7279999999998,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",221,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,4.96,946.6879999999999,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",222,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.952,948.6399999999999,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",223,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,1.952,950.5919999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",224,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.816,953.4079999999999,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",225,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.72,956.1279999999999,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,226,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.424,971.5519999999999,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",227,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.2,974.752,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",228,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,2.4,977.1519999999999,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,229,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.648,992.8,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",230,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.136,995.9359999999999,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",231,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.56,998.4959999999999,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,232,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,95232.0,0.7987012987012987,11796480.0,393216.0,16.96,1015.4559999999999,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",233,0.0,110592.0,0,0,0.0,110592.0,110592.0,0.0,3456.0,0.0,393216.0,49152.0,2.56,1018.0159999999998,98304.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",234,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.336,1020.3519999999999,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",235,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.048,1022.3999999999999,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",236,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,5.024,1027.4239999999998,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",237,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.984,1029.4079999999997,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",238,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.112,1031.5199999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",239,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.688,1034.2079999999999,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",240,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.688,1036.896,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,241,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3696352.0,245760.0,7.744,1044.6399999999999,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115511.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",242,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.656,1047.2959999999998,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,243,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3703008.0,245760.0,7.872,1055.168,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115719.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",244,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.592,1057.76,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,245,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3701408.0,245760.0,7.712,1065.472,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115669.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",246,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.592,1068.064,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",247,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.72,1070.784,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",248,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.752,1073.536,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",249,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.032,1077.568,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",250,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.72,1080.288,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",251,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.144,1082.432,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",252,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.72,1085.152,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",253,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.656,1087.808,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",254,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.032,1091.84,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",255,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.784,1094.624,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",256,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.208,1096.832,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",257,196608.0,17651712.0,0,0,0.0,17651712.0,17651712.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,20.32,1117.152,14880768.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,258,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3701312.0,245760.0,7.968,1125.1200000000001,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115666.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",259,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.656,1127.776,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",260,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.304,1130.0800000000002,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",261,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.112,1132.1920000000002,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",262,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,5.056,1137.2480000000003,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",263,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.888,1139.1360000000002,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",264,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.016,1141.1520000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",265,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.88,1144.0320000000004,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",266,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.72,1146.7520000000004,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,267,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.392,1162.1440000000005,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",268,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.136,1165.2800000000004,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",269,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,2.464,1167.7440000000004,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,270,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.328,1183.0720000000003,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",271,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.04,1186.1120000000003,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",272,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.592,1188.7040000000004,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,273,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,95232.0,0.7987012987012987,11796480.0,393216.0,16.352,1205.0560000000005,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",274,0.0,110592.0,0,0,0.0,110592.0,110592.0,0.0,3456.0,0.0,393216.0,49152.0,2.56,1207.6160000000004,98304.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",275,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.272,1209.8880000000004,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",276,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.048,1211.9360000000004,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",277,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,4.896,1216.8320000000003,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",278,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.952,1218.7840000000003,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",279,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,1.952,1220.7360000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",280,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.656,1223.3920000000003,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",281,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.656,1226.0480000000002,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,282,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3698272.0,245760.0,7.808,1233.8560000000002,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115571.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",283,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.944,1236.8000000000002,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,284,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3703840.0,245760.0,7.776,1244.5760000000002,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115745.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",285,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.816,1247.3920000000003,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,286,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3704096.0,245760.0,7.712,1255.1040000000003,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115753.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",287,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.592,1257.6960000000004,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",288,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.688,1260.3840000000005,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",289,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.624,1263.0080000000005,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",290,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.064,1267.0720000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",291,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.72,1269.7920000000006,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",292,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,1271.9040000000007,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",293,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.752,1274.6560000000006,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",294,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.72,1277.3760000000007,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",295,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.0,1281.3760000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",296,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.72,1284.0960000000007,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",297,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.208,1286.3040000000008,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",298,196608.0,17651712.0,0,0,0.0,17651712.0,17651712.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,20.608,1306.9120000000007,14880768.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,299,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3701312.0,245760.0,7.968,1314.8800000000008,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115666.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",300,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.592,1317.472000000001,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",301,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.272,1319.7440000000008,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",302,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.048,1321.7920000000008,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",303,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,4.864,1326.6560000000009,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",304,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.952,1328.6080000000009,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",305,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.016,1330.624000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",306,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.784,1333.408000000001,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",307,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.72,1336.128000000001,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,308,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.392,1351.5200000000011,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",309,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.136,1354.656000000001,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",310,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,2.4,1357.0560000000012,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,311,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.328,1372.3840000000012,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",312,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.232,1375.6160000000011,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",313,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.624,1378.2400000000011,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,314,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,95232.0,0.7987012987012987,11796480.0,393216.0,15.808,1394.0480000000011,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",315,0.0,110592.0,0,0,0.0,110592.0,110592.0,0.0,3456.0,0.0,393216.0,49152.0,2.56,1396.608000000001,98304.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",316,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,1398.7200000000012,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",317,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.08,1400.800000000001,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",318,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,5.088,1405.888000000001,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",319,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.92,1407.8080000000011,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",320,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.016,1409.8240000000012,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",321,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.688,1412.5120000000013,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",322,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.688,1415.2000000000014,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,323,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3698176.0,245760.0,7.936,1423.1360000000013,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115568.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",324,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.592,1425.7280000000014,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,325,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3706080.0,245760.0,8.16,1433.8880000000015,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115815.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",326,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.816,1436.7040000000015,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,327,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3703104.0,245760.0,7.68,1444.3840000000016,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115722.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",328,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.592,1446.9760000000017,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",329,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.72,1449.6960000000017,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",330,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.72,1452.4160000000018,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",331,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.0,1456.4160000000018,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",332,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.784,1459.2000000000019,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",333,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,1461.312000000002,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",334,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.72,1464.032000000002,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",335,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.592,1466.624000000002,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",336,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.0,1470.624000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",337,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.752,1473.376000000002,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",338,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.368,1475.744000000002,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",339,196608.0,17651712.0,0,0,0.0,17651712.0,17651712.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,20.384,1496.128000000002,14880768.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,340,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3697952.0,245760.0,7.776,1503.904000000002,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115561.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",341,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.656,1506.560000000002,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",342,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.24,1508.800000000002,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",343,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.016,1510.816000000002,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",344,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,4.992,1515.808000000002,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",345,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.952,1517.760000000002,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",346,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.048,1519.808000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",347,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.656,1522.464000000002,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",348,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.72,1525.184000000002,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,349,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.456,1540.640000000002,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",350,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.232,1543.872000000002,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",351,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,2.368,1546.2400000000018,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,352,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.424,1561.6640000000018,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",353,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.104,1564.7680000000018,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",354,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.464,1567.2320000000018,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,355,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,95232.0,0.7987012987012987,11796480.0,393216.0,16.576,1583.8080000000018,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",356,0.0,110592.0,0,0,0.0,110592.0,110592.0,0.0,3456.0,0.0,393216.0,49152.0,2.72,1586.5280000000018,98304.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",357,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.144,1588.6720000000018,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",358,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.048,1590.7200000000018,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",359,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,5.216,1595.9360000000017,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",360,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.92,1597.8560000000018,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",361,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,1.984,1599.8400000000017,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",362,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.784,1602.6240000000018,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",363,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.688,1605.312000000002,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_128x32_tn,364,786432000.0,1573888000.0,0,0,0.0,1573888000.0,1573888000.0,4082000.0,880000.0,0.822652156388553,109384064.0,2048000.0,113.984,1719.2960000000019,0.0,1024000.0,786432000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3418252.0,64000.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",365,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,1.728,1721.024000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,4.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",366,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,256.0,512.0,2.56,1723.5840000000019,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8.0,16.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",367,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,1725.600000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",368,0.0,512000.0,0,0,0.0,512000.0,512000.0,0.0,8000.0,0.0,2048000.0,2048000.0,4.288,1729.888000000002,0.0,512000.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64000.0,64000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",369,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,64.0,1.728,1731.616000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,2.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",370,0.0,0.0,0,0,0.0,0.0,0.0,8192.0,24192.0,0.25296442687747034,2055520.0,151872.0,4.96,1736.576000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64235.0,4746.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",371,0.0,0.0,0,0,0.0,0.0,0.0,37888.0,137760.0,0.2157041355438149,5909408.0,896.0,5.088,1741.664000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,184669.0,28.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",372,0.0,0.0,0,0,0.0,0.0,0.0,8192.0,24192.0,0.25296442687747034,2055520.0,152960.0,4.8,1746.464000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64235.0,4780.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",373,0.0,0.0,0,0,0.0,0.0,0.0,37888.0,140832.0,0.21199641897940913,5909440.0,704.0,5.28,1751.744000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,184670.0,22.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",374,0.0,0.0,0,0,0.0,0.0,0.0,8192.0,24192.0,0.25296442687747034,2055520.0,149824.0,4.832,1756.576000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64235.0,4682.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",375,0.0,0.0,0,0,0.0,0.0,0.0,37888.0,137760.0,0.2157041355438149,5909408.0,832.0,5.152,1761.728000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,184669.0,26.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",376,0.0,0.0,0,0,0.0,0.0,0.0,8192.0,24192.0,0.25296442687747034,2055520.0,149696.0,4.832,1766.5600000000022,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64235.0,4678.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",377,0.0,0.0,0,0,0.0,0.0,0.0,37888.0,137248.0,0.216334734149461,5909376.0,736.0,5.088,1771.6480000000022,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,184668.0,23.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",378,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,16448.0,2048.0,3.136,1774.7840000000022,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,514.0,64.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",379,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.696,1776.480000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",380,0.0,0.0,0,0,0.0,0.0,0.0,497.0,40.0,0.925512104283054,2048.0,0.0,3.648,1780.128000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",381,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.696,1781.824000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",382,0.0,0.0,0,0,0.0,0.0,0.0,497.0,40.0,0.925512104283054,2048.0,0.0,3.648,1785.4720000000018,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",383,0.0,0.0,0,0,0.0,0.0,0.0,165888.0,33696.0,0.8311688311688312,2087616.0,22848.0,6.848,1792.3200000000018,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,65238.0,714.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",384,0.0,0.0,0,0,0.0,0.0,0.0,7328.0,128.0,0.9828326180257511,10240.0,2080.0,6.464,1798.7840000000017,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,320.0,65.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",385,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48000.0,0.0,2065184.0,205920.0,4.704,1803.4880000000016,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64537.0,6435.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",386,0.0,0.0,0,0,0.0,0.0,0.0,0.0,12000.0,0.0,2560000.0,0.0,4.928,1808.4160000000018,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,80000.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",387,0.0,0.0,0,0,0.0,0.0,0.0,0.0,16000.0,0.0,0.0,4096000.0,3.936,1812.3520000000017,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,128000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",388,0.0,0.0,0,0,0.0,0.0,0.0,98304.0,16000.0,0.8600223964165733,2048000.0,0.0,5.44,1817.7920000000017,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",389,0.0,0.0,0,0,0.0,0.0,0.0,156.0,64.0,0.7090909090909091,8192.0,0.0,2.176,1819.9680000000017,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",390,0.0,0.0,0,0,0.0,0.0,0.0,206483.0,79629.0,0.7216859132088134,8080128.0,5189824.0,17.792,1837.7600000000016,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,252504.0,162182.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",391,0.0,0.0,0,0,0.0,0.0,0.0,57179.0,94263.0,0.37756368774844495,8136960.0,6315008.0,13.408,1851.1680000000015,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,254280.0,197344.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",392,0.0,0.0,0,0,0.0,0.0,0.0,57983.0,93693.0,0.38228196946121995,8085120.0,6315008.0,14.592,1865.7600000000016,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,252660.0,197344.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",393,0.0,0.0,0,0,0.0,0.0,0.0,57983.0,94349.0,0.3806357167239976,8114432.0,6315008.0,14.464,1880.2240000000015,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,253576.0,197344.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",394,0.0,0.0,0,0,0.0,0.0,0.0,14336.0,16000.0,0.47257383966244726,4096000.0,0.0,7.104,1887.3280000000016,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",395,0.0,0.0,0,0,0.0,0.0,0.0,39.0,16.0,0.7090909090909091,2048.0,0.0,2.24,1889.5680000000016,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",396,0.0,0.0,0,0,0.0,0.0,0.0,54406.0,132852.0,0.2905403240449006,6010752.0,3677312.0,12.416,1901.9840000000015,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,187836.0,114916.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",397,0.0,0.0,0,0,0.0,0.0,0.0,0.0,64000.0,0.0,6187616.0,6144000.0,9.376,1911.3600000000015,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,193363.0,192000.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",398,7168000.0,16980480.0,0,0,0.0,16980480.0,16980480.0,2112.0,20992.0,0.09141274238227147,4097664.0,2048000.0,17.696,1929.0560000000014,2132480.0,512000.0,7168000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128052.0,64000.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",399,0.0,2621952.0,0,0,0.0,2621952.0,2621952.0,287360.0,32000.0,0.8997995991983968,2048000.0,2048000.0,47.008,1976.0640000000014,2621952.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64000.0,64000.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",400,0.0,0.0,0,0,0.0,0.0,0.0,0.0,8000.0,0.0,2048000.0,512000.0,4.448,1980.5120000000015,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64000.0,16000.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",401,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,512.0,1.952,1982.4640000000015,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,16.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",402,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48000.0,0.0,4608000.0,242688.0,9.056,1991.5200000000016,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144000.0,7584.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",403,0.0,0.0,0,0,0.0,0.0,0.0,0.0,12000.0,0.0,2560000.0,0.0,4.864,1996.3840000000016,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,80000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",404,7168000.0,16980480.0,0,0,0.0,16980480.0,16980480.0,2112.0,20992.0,0.09141274238227147,4139008.0,2048000.0,17.6,2013.9840000000015,2132480.0,512000.0,7168000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,129344.0,64000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",405,0.0,0.0,0,0,0.0,0.0,0.0,5039.0,4066.0,0.5534321801208127,2048256.0,2048.0,7.2,2021.1840000000016,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64008.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",406,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.176,2023.3600000000015,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",407,0.0,0.0,0,0,0.0,0.0,0.0,5039.0,4066.0,0.5534321801208127,2048256.0,2048.0,7.2,2030.5600000000015,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64008.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",408,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.176,2032.7360000000015,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",409,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.08,2034.8160000000014,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",410,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.008,2037.8240000000014,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",411,0.0,585216.0,0,0,0.0,585216.0,585216.0,736.0,4016.0,0.15488215488215487,2048000.0,512.0,8.544,2046.3680000000015,585216.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64000.0,16.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",412,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,1.984,2048.3520000000017,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",413,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,2051.6800000000017,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",414,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,2053.7280000000014,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",415,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.008,2056.7360000000012,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",416,1769472.0,4562944.0,0,0,0.0,4562944.0,4562944.0,0.0,16000.0,0.0,0.0,2048000.0,4.128,2060.8640000000014,0.0,1024000.0,1769472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,64000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",417,2560000.0,5120000.0,0,0,0.0,5120000.0,5120000.0,0.0,12000.0,0.0,4096000.0,28160.0,7.424,2068.2880000000014,0.0,0.0,2560000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128000.0,880.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",418,0.0,0.0,0,0,0.0,0.0,0.0,1472.0,4016.0,0.26822157434402333,2048000.0,512.0,11.68,2079.968000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64000.0,16.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",419,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,256.0,128.0,2.016,2081.9840000000013,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",420,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,128.0,2.016,2084.0000000000014,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,4.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",421,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,160.0,128.0,2.272,2086.2720000000013,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",422,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,256.0,128.0,2.08,2088.352000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8.0,4.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",423,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,256.0,512.0,2.656,2091.008000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8.0,16.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",424,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,2092.7360000000012,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",425,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,2094.432000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",426,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.112,2096.5440000000012,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",427,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,2098.240000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",428,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,288.0,32.0,2.24,2100.480000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,9.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",429,0.0,0.0,0,0,0.0,0.0,0.0,0.0,5.0,0.0,32.0,32.0,4.8,2105.280000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",430,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.144,2107.424000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",431,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,2109.504000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",432,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,160.0,128.0,2.784,2112.288000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5.0,4.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",433,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,32.0,3.232,2115.520000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",434,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,2117.5680000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",435,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.112,2119.6800000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",436,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,288.0,128.0,3.328,2123.0080000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,9.0,4.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",437,0.0,0.0,0,0,0.0,0.0,0.0,176.0,16.0,0.9166666666666666,256.0,96.0,2.752,2125.7600000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8.0,3.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",438,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,256.0,256.0,2.048,2127.8080000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8.0,8.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",439,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,256.0,32.0,2.016,2129.8240000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",440,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,288.0,0.0,2.112,2131.9360000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,9.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",441,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,256.0,128.0,2.304,2134.2400000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8.0,4.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",442,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1152.0,0.0,34560.0,49152.0,9.44,2143.6800000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1080.0,1536.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",443,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,256.0,32.0,2.624,2146.3040000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",444,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,2149.6960000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",445,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,64.0,2.784,2152.4800000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,2.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",446,0.0,2048.0,0,0,0.0,2048.0,2048.0,128.0,96.0,0.5714285714285714,5120.0,4096.0,2.08,2154.5600000000004,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",447,0.0,0.0,0,0,0.0,0.0,0.0,0.0,80.0,0.0,8192.0,8192.0,2.56,2157.1200000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",448,16384.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,32.0,0.0,8192.0,8192.0,2.688,2159.8080000000004,0.0,4096.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",449,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.08,2161.8880000000004,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",450,14400.0,32896.0,0,0,0.0,32896.0,32896.0,0.0,32.0,0.0,8192.0,8192.0,2.656,2164.5440000000003,0.0,4096.0,14400.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",451,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.016,2166.5600000000004,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",452,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.08,2168.6400000000003,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",453,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,4.992,2173.6320000000005,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",454,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.952,2175.5840000000007,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",455,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.016,2177.600000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",456,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.72,2180.3200000000006,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",457,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.752,2183.0720000000006,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,458,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3697056.0,245760.0,7.648,2190.7200000000007,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115533.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",459,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.816,2193.5360000000005,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,460,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3706432.0,245760.0,7.776,2201.3120000000004,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115826.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",461,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.848,2204.1600000000003,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,462,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3705152.0,245760.0,7.712,2211.8720000000003,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115786.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",463,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.624,2214.496,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",464,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.944,2217.44,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",465,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.624,2220.064,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",466,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,3.968,2224.0319999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",467,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.752,2226.7839999999997,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",468,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.144,2228.9279999999994,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",469,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.752,2231.6799999999994,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",470,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.656,2234.3359999999993,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",471,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.032,2238.3679999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",472,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.784,2241.1519999999996,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",473,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.144,2243.2959999999994,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",474,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,2.624,2245.919999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",475,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,2.624,2248.543999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",476,196608.0,17657856.0,0,0,0.0,17657856.0,17657856.0,99840.0,192.0,0.9980806142034548,245760.0,49152.0,20.608,2269.151999999999,14886912.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,477,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3698528.0,245760.0,7.712,2276.863999999999,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115579.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",478,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.72,2279.583999999999,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",479,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.24,2281.8239999999987,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",480,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.08,2283.9039999999986,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",481,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,5.056,2288.9599999999987,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",482,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.952,2290.911999999999,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",483,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.016,2292.927999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",484,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.688,2295.615999999999,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",485,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.848,2298.463999999999,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,486,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.488,2313.951999999999,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",487,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.264,2317.215999999999,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",488,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,2.624,2319.839999999999,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,489,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.616,2335.4559999999988,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",490,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.04,2338.4959999999987,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",491,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.528,2341.0239999999985,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,492,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,95232.0,0.7987012987012987,11796480.0,393216.0,16.128,2357.1519999999987,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",493,0.0,110592.0,0,0,0.0,110592.0,110592.0,0.0,3456.0,0.0,393216.0,49152.0,2.56,2359.7119999999986,98304.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",494,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.144,2361.8559999999984,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",495,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.048,2363.903999999998,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",496,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,4.96,2368.863999999998,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",497,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.952,2370.8159999999984,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",498,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,1.984,2372.7999999999984,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",499,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.752,2375.5519999999983,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",500,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.72,2378.271999999998,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,501,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3700832.0,245760.0,8.0,2386.271999999998,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115651.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",502,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.688,2388.959999999998,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,503,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3705504.0,245760.0,7.968,2396.927999999998,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115797.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",504,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.656,2399.583999999998,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,505,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3704384.0,245760.0,7.84,2407.423999999998,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115762.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",506,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.592,2410.0159999999983,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",507,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.72,2412.735999999998,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",508,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.656,2415.391999999998,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",509,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.064,2419.455999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",510,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.752,2422.207999999998,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",511,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,2424.319999999998,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",512,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.752,2427.071999999998,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",513,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.592,2429.663999999998,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",514,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,3.968,2433.631999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",515,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.752,2436.3839999999977,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",516,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.176,2438.5599999999977,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",517,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,2.784,2441.343999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",518,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,2.656,2443.9999999999977,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",519,196608.0,17657856.0,0,0,0.0,17657856.0,17657856.0,99840.0,192.0,0.9980806142034548,245760.0,49152.0,20.512,2464.511999999998,14886912.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,520,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3696160.0,245760.0,7.84,2472.351999999998,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115505.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",521,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.816,2475.167999999998,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",522,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,2477.279999999998,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",523,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.144,2479.4239999999977,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",524,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,4.832,2484.2559999999976,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",525,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.984,2486.2399999999975,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",526,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.176,2488.4159999999974,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",527,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.656,2491.0719999999974,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",528,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.88,2493.9519999999975,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,529,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.36,2509.3119999999976,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",530,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.232,2512.5439999999976,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",531,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,2.432,2514.9759999999974,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,532,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.456,2530.4319999999975,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",533,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.296,2533.7279999999973,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",534,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.432,2536.159999999997,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,535,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,95232.0,0.7987012987012987,11796480.0,393216.0,16.128,2552.2879999999973,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",536,0.0,110592.0,0,0,0.0,110592.0,110592.0,0.0,3456.0,0.0,393216.0,49152.0,2.56,2554.8479999999972,98304.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",537,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.272,2557.119999999997,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",538,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.112,2559.2319999999972,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",539,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,5.088,2564.3199999999974,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",540,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,2.016,2566.3359999999975,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",541,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.08,2568.4159999999974,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",542,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.784,2571.1999999999975,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",543,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.72,2573.9199999999973,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,544,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3697952.0,245760.0,7.84,2581.7599999999975,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115561.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",545,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.688,2584.4479999999976,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,546,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3702912.0,245760.0,7.712,2592.1599999999976,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115716.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",547,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.656,2594.8159999999975,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,548,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3702112.0,245760.0,7.744,2602.5599999999977,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115691.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",549,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.656,2605.2159999999976,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",550,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.784,2607.9999999999977,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",551,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.656,2610.6559999999977,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",552,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.064,2614.7199999999975,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",553,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.752,2617.4719999999975,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",554,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.176,2619.6479999999974,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",555,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.72,2622.367999999997,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",556,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.72,2625.087999999997,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",557,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.064,2629.151999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",558,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.72,2631.8719999999967,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",559,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,2633.9839999999967,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",560,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,2.688,2636.671999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",561,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,2.624,2639.2959999999966,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",562,196608.0,17657856.0,0,0,0.0,17657856.0,17657856.0,99840.0,192.0,0.9980806142034548,245760.0,49152.0,20.192,2659.4879999999966,14886912.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,563,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3699392.0,245760.0,7.968,2667.4559999999965,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115606.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",564,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.656,2670.1119999999964,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",565,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.208,2672.3199999999965,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",566,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.08,2674.3999999999965,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",567,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,5.056,2679.4559999999965,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",568,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,2.016,2681.4719999999966,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",569,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.144,2683.6159999999963,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",570,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.784,2686.3999999999965,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",571,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.784,2689.1839999999966,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,572,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.392,2704.5759999999964,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",573,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.072,2707.6479999999965,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",574,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,2.656,2710.3039999999964,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,575,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.328,2725.6319999999964,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",576,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.168,2728.7999999999965,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",577,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.432,2731.2319999999963,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,578,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,95232.0,0.7987012987012987,11796480.0,393216.0,16.288,2747.5199999999963,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",579,0.0,110592.0,0,0,0.0,110592.0,110592.0,0.0,3456.0,0.0,393216.0,49152.0,2.656,2750.1759999999963,98304.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",580,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.336,2752.511999999996,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",581,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.112,2754.623999999996,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",582,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,4.896,2759.5199999999963,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",583,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,2.08,2761.5999999999963,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",584,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.016,2763.6159999999963,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",585,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.656,2766.2719999999963,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",586,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.624,2768.895999999996,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,587,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3701440.0,245760.0,8.032,2776.9279999999962,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115670.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",588,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.656,2779.583999999996,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,589,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3703104.0,245760.0,7.712,2787.295999999996,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115722.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",590,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.848,2790.143999999996,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,591,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3701216.0,245760.0,7.776,2797.919999999996,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115663.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",592,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.752,2800.671999999996,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",593,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.72,2803.3919999999957,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",594,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.592,2805.983999999996,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",595,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.032,2810.015999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",596,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.688,2812.703999999996,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",597,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.144,2814.847999999996,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",598,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.72,2817.5679999999957,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",599,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.848,2820.4159999999956,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",600,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.0,2824.4159999999956,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",601,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.752,2827.1679999999956,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",602,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.048,2829.2159999999953,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",603,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,2.848,2832.0639999999953,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",604,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,2.784,2834.8479999999954,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",605,196608.0,17657856.0,0,0,0.0,17657856.0,17657856.0,99840.0,192.0,0.9980806142034548,245760.0,49152.0,20.704,2855.5519999999956,14886912.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,606,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3700928.0,245760.0,8.032,2863.5839999999957,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115654.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",607,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.592,2866.175999999996,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",608,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,2868.287999999996,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",609,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.016,2870.303999999996,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",610,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,4.864,2875.167999999996,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",611,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.984,2877.151999999996,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",612,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.016,2879.167999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",613,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.752,2881.919999999996,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",614,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.752,2884.671999999996,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,615,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.328,2899.999999999996,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",616,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.136,2903.135999999996,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",617,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,2.432,2905.5679999999957,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,618,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.52,2921.0879999999956,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",619,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.2,2924.2879999999955,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",620,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.432,2926.7199999999953,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,621,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,95232.0,0.7987012987012987,11796480.0,393216.0,16.32,2943.0399999999954,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",622,0.0,110592.0,0,0,0.0,110592.0,110592.0,0.0,3456.0,0.0,393216.0,49152.0,2.56,2945.5999999999954,98304.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",623,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.24,2947.839999999995,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",624,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.048,2949.887999999995,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",625,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,5.088,2954.975999999995,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",626,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.952,2956.9279999999953,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",627,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.016,2958.9439999999954,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",628,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.656,2961.5999999999954,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",629,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.752,2964.3519999999953,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,630,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3701024.0,245760.0,7.808,2972.1599999999953,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115657.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",631,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.624,2974.783999999995,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,632,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3706720.0,245760.0,7.776,2982.559999999995,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115835.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",633,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.656,2985.215999999995,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,634,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3704992.0,245760.0,7.84,2993.055999999995,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115781.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",635,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.848,2995.903999999995,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",636,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.784,2998.687999999995,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",637,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.72,3001.407999999995,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",638,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.0,3005.407999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",639,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.72,3008.1279999999947,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",640,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.176,3010.3039999999946,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",641,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.816,3013.1199999999944,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",642,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.592,3015.7119999999945,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",643,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.032,3019.7439999999947,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",644,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.752,3022.4959999999946,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",645,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.208,3024.7039999999947,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",646,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,2.72,3027.4239999999945,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",647,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,2.656,3030.0799999999945,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",648,196608.0,17657856.0,0,0,0.0,17657856.0,17657856.0,99840.0,192.0,0.9980806142034548,245760.0,49152.0,20.544,3050.6239999999943,14886912.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,649,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3700512.0,245760.0,7.872,3058.495999999994,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115641.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",650,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.752,3061.247999999994,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",651,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.112,3063.359999999994,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",652,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.08,3065.439999999994,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",653,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,5.12,3070.559999999994,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",654,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,2.016,3072.575999999994,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",655,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.016,3074.591999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",656,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.72,3077.311999999994,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",657,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.688,3079.999999999994,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,658,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.584,3095.583999999994,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",659,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.168,3098.751999999994,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",660,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,2.624,3101.375999999994,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,661,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.456,3116.831999999994,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",662,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.072,3119.903999999994,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",663,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.4,3122.303999999994,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,664,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,95232.0,0.7987012987012987,11796480.0,393216.0,15.968,3138.271999999994,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",665,0.0,110592.0,0,0,0.0,110592.0,110592.0,0.0,3456.0,0.0,393216.0,49152.0,2.496,3140.767999999994,98304.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",666,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.08,3142.847999999994,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",667,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.016,3144.863999999994,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",668,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,4.864,3149.727999999994,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",669,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,2.048,3151.775999999994,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",670,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.016,3153.791999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",671,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.848,3156.639999999994,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",672,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.816,3159.4559999999938,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,673,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3698624.0,245760.0,7.68,3167.1359999999936,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115582.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",674,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.72,3169.8559999999934,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,675,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3705312.0,245760.0,7.616,3177.4719999999934,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115791.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",676,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.656,3180.1279999999933,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,677,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3704992.0,245760.0,8.032,3188.1599999999935,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115781.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",678,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.72,3190.8799999999933,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",679,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.88,3193.7599999999934,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",680,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.72,3196.479999999993,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",681,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.0,3200.479999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",682,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.656,3203.135999999993,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",683,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.144,3205.279999999993,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",684,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.72,3207.9999999999927,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",685,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.72,3210.7199999999925,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",686,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.096,3214.8159999999925,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",687,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.752,3217.5679999999925,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",688,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.176,3219.7439999999924,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",689,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,2.624,3222.367999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",690,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,2.656,3225.023999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",691,196608.0,17657856.0,0,0,0.0,17657856.0,17657856.0,99840.0,192.0,0.9980806142034548,245760.0,49152.0,20.544,3245.567999999992,14886912.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,692,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3700416.0,245760.0,8.096,3253.663999999992,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115638.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",693,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.688,3256.351999999992,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",694,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.304,3258.655999999992,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",695,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.048,3260.703999999992,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",696,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,4.992,3265.695999999992,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",697,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.984,3267.679999999992,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",698,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,1.984,3269.663999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",699,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.688,3272.351999999992,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",700,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.688,3275.0399999999922,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,701,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.456,3290.4959999999924,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",702,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.136,3293.6319999999923,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",703,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,2.4,3296.0319999999924,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,704,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.424,3311.4559999999924,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",705,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.296,3314.751999999992,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",706,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.592,3317.3439999999923,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,707,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,95232.0,0.7987012987012987,11796480.0,393216.0,16.032,3333.3759999999925,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",708,0.0,110592.0,0,0,0.0,110592.0,110592.0,0.0,3456.0,0.0,393216.0,49152.0,2.528,3335.9039999999923,98304.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",709,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.176,3338.079999999992,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",710,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.048,3340.127999999992,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",711,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,4.992,3345.119999999992,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",712,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.984,3347.103999999992,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",713,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.016,3349.119999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",714,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.656,3351.775999999992,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",715,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.848,3354.623999999992,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,716,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3698336.0,245760.0,7.872,3362.495999999992,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115573.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",717,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.656,3365.151999999992,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,718,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3705248.0,245760.0,8.0,3373.151999999992,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115789.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",719,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.656,3375.807999999992,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,720,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3704960.0,245760.0,7.936,3383.743999999992,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115780.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",721,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.72,3386.4639999999918,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",722,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.72,3389.1839999999916,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",723,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.656,3391.8399999999915,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",724,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.0,3395.8399999999915,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",725,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.88,3398.7199999999916,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",726,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.176,3400.8959999999915,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",727,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.72,3403.6159999999913,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",728,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.688,3406.3039999999914,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",729,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.0,3410.3039999999914,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",730,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.688,3412.9919999999915,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",731,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.144,3415.1359999999913,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",732,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,2.656,3417.7919999999913,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",733,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,2.848,3420.6399999999912,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",734,196608.0,17657856.0,0,0,0.0,17657856.0,17657856.0,99840.0,192.0,0.9980806142034548,245760.0,49152.0,20.384,3441.0239999999912,14886912.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,735,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3699424.0,245760.0,7.776,3448.799999999991,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115607.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",736,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.72,3451.519999999991,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",737,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.144,3453.6639999999907,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",738,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.016,3455.6799999999907,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",739,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,4.96,3460.639999999991,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",740,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.984,3462.6239999999907,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",741,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.048,3464.6719999999905,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",742,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.752,3467.4239999999904,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",743,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.688,3470.1119999999905,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,744,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.488,3485.5999999999904,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",745,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.104,3488.70399999999,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",746,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,2.4,3491.1039999999903,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,747,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.296,3506.39999999999,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",748,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.04,3509.43999999999,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",749,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.624,3512.06399999999,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,750,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,95232.0,0.7987012987012987,11796480.0,393216.0,15.808,3527.87199999999,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",751,0.0,110592.0,0,0,0.0,110592.0,110592.0,0.0,3456.0,0.0,393216.0,49152.0,2.528,3530.3999999999896,98304.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",752,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.144,3532.5439999999894,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",753,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.112,3534.6559999999895,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",754,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,4.928,3539.5839999999894,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",755,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.952,3541.5359999999896,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",756,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.016,3543.5519999999897,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",757,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.784,3546.33599999999,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",758,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.784,3549.11999999999,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,759,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3697824.0,245760.0,7.744,3556.86399999999,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115557.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",760,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.72,3559.58399999999,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,761,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3707584.0,245760.0,8.096,3567.67999999999,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115862.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",762,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.656,3570.33599999999,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,763,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3705792.0,245760.0,7.904,3578.23999999999,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115806.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",764,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.72,3580.9599999999896,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",765,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.816,3583.7759999999894,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",766,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.656,3586.4319999999893,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",767,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.032,3590.4639999999895,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",768,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.752,3593.2159999999894,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",769,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.08,3595.2959999999894,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",770,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.72,3598.015999999989,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",771,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,2.656,3600.671999999989,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",772,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,4.096,3604.767999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",773,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,2.784,3607.551999999989,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",774,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.336,3609.887999999989,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",775,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,2.624,3612.511999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",776,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,2.688,3615.199999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",777,196608.0,17657856.0,0,0,0.0,17657856.0,17657856.0,99840.0,192.0,0.9980806142034548,245760.0,49152.0,20.576,3635.775999999989,14886912.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_32x32_sliced1x4_tn,778,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,30720.0,0.8048780487804879,3697920.0,245760.0,7.744,3643.519999999989,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,115560.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",779,0.0,73728.0,0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,245760.0,49152.0,2.592,3646.111999999989,61440.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",780,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.144,3648.255999999989,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",781,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.08,3650.335999999989,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",782,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,4.832,3655.1679999999888,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",783,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.952,3657.119999999989,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",784,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.016,3659.135999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",785,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.816,3661.951999999989,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",786,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.624,3664.5759999999887,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,787,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.36,3679.935999999989,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",788,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.104,3683.0399999999886,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",789,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,2.464,3685.5039999999885,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,790,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,98304.0,0.8117647058823529,11796480.0,786432.0,15.456,3700.9599999999887,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",791,0.0,245760.0,0,0,0.0,245760.0,245760.0,0.0,7680.0,0.0,786432.0,196608.0,3.136,3704.0959999999886,196608.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",792,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.528,3706.6239999999884,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_64x32_sliced1x4_tn,793,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,95232.0,0.7987012987012987,11796480.0,393216.0,15.84,3722.4639999999886,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,368640.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",794,0.0,110592.0,0,0,0.0,110592.0,110592.0,0.0,3456.0,0.0,393216.0,49152.0,2.56,3725.0239999999885,98304.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",795,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.08,3727.1039999999884,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",796,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.176,3729.2799999999884,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",797,0.0,16400.0,0,0,0.0,16400.0,16400.0,0.0,112.0,0.0,49152.0,32.0,5.088,3734.3679999999886,16384.0,16.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",798,16.0,32.0,0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,64.0,1.984,3736.3519999999885,0.0,0.0,16.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",799,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,1.984,3738.3359999999884,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",800,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,2.72,3741.055999999988,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",801,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,2.72,3743.775999999988,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_128x32_tn,802,786432000.0,1573888000.0,0,0,0.0,1573888000.0,1573888000.0,4082000.0,880000.0,0.822652156388553,109468224.0,2048000.0,112.064,3855.839999999988,0.0,1024000.0,786432000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3420882.0,64000.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",803,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,1.728,3857.567999999988,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,4.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",804,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,384.0,640.0,2.624,3860.1919999999877,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12.0,20.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",805,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,3862.2719999999877,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",806,0.0,512000.0,0,0,0.0,512000.0,512000.0,0.0,8000.0,0.0,2048000.0,2048000.0,4.16,3866.4319999999875,0.0,512000.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64000.0,64000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",807,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,64.0,1.728,3868.1599999999876,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,2.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",808,0.0,0.0,0,0,0.0,0.0,0.0,8192.0,24192.0,0.25296442687747034,2055520.0,153472.0,4.864,3873.0239999999876,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64235.0,4796.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",809,0.0,0.0,0,0,0.0,0.0,0.0,37888.0,137760.0,0.2157041355438149,5909376.0,704.0,5.12,3878.1439999999875,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,184668.0,22.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",810,0.0,0.0,0,0,0.0,0.0,0.0,8192.0,24192.0,0.25296442687747034,2055520.0,152384.0,4.896,3883.0399999999877,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64235.0,4762.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",811,0.0,0.0,0,0,0.0,0.0,0.0,37888.0,140832.0,0.21199641897940913,5909472.0,704.0,5.44,3888.4799999999877,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,184671.0,22.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",812,0.0,0.0,0,0,0.0,0.0,0.0,8192.0,24192.0,0.25296442687747034,2055520.0,150464.0,4.896,3893.375999999988,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64235.0,4702.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",813,0.0,0.0,0,0,0.0,0.0,0.0,37888.0,138336.0,0.214999092064645,5909440.0,864.0,5.184,3898.559999999988,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,184670.0,27.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",814,0.0,0.0,0,0,0.0,0.0,0.0,8192.0,24192.0,0.25296442687747034,2055520.0,149632.0,4.864,3903.423999999988,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64235.0,4676.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",815,0.0,0.0,0,0,0.0,0.0,0.0,37888.0,139680.0,0.21337177869886467,5909344.0,928.0,5.088,3908.5119999999883,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,184667.0,29.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",816,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48.0,0.0,16448.0,2048.0,3.232,3911.7439999999883,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,514.0,64.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",817,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.632,3913.3759999999884,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",818,0.0,0.0,0,0,0.0,0.0,0.0,497.0,40.0,0.925512104283054,2048.0,0.0,3.648,3917.0239999999885,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",819,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.728,3918.7519999999886,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",820,0.0,0.0,0,0,0.0,0.0,0.0,497.0,40.0,0.925512104283054,2048.0,0.0,3.68,3922.4319999999884,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",821,0.0,0.0,0,0,0.0,0.0,0.0,131904.0,33696.0,0.7965217391304348,2087616.0,23264.0,6.72,3929.151999999988,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,65238.0,727.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",822,0.0,0.0,0,0,0.0,0.0,0.0,7328.0,128.0,0.9828326180257511,10240.0,2080.0,6.496,3935.6479999999883,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,320.0,65.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",823,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48000.0,0.0,2065184.0,213184.0,4.864,3940.5119999999883,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64537.0,6662.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",824,0.0,0.0,0,0,0.0,0.0,0.0,0.0,12000.0,0.0,2560000.0,0.0,4.672,3945.1839999999884,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,80000.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",825,0.0,0.0,0,0,0.0,0.0,0.0,0.0,16000.0,0.0,0.0,4096000.0,3.936,3949.1199999999885,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,128000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",826,0.0,0.0,0,0,0.0,0.0,0.0,98304.0,16000.0,0.8600223964165733,2048000.0,0.0,5.568,3954.6879999999887,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",827,0.0,0.0,0,0,0.0,0.0,0.0,156.0,64.0,0.7090909090909091,8192.0,0.0,2.176,3956.8639999999887,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",828,0.0,0.0,0,0,0.0,0.0,0.0,204779.0,77539.0,0.7253487202374628,8105600.0,5204000.0,17.472,3974.335999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,253300.0,162625.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",829,0.0,0.0,0,0,0.0,0.0,0.0,58979.0,91086.0,0.3930230233565455,8110208.0,4154784.0,13.408,3987.743999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,253444.0,129837.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",830,0.0,0.0,0,0,0.0,0.0,0.0,57983.0,90591.0,0.39026343774819283,8117376.0,6315008.0,14.592,4002.335999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,253668.0,197344.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",831,0.0,0.0,0,0,0.0,0.0,0.0,57983.0,89850.0,0.3922195991422754,8135552.0,6315008.0,14.688,4017.023999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,254236.0,197344.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",832,0.0,0.0,0,0,0.0,0.0,0.0,14336.0,16000.0,0.47257383966244726,4096000.0,0.0,7.04,4024.063999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",833,0.0,0.0,0,0,0.0,0.0,0.0,39.0,16.0,0.7090909090909091,2048.0,0.0,2.176,4026.239999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",834,0.0,0.0,0,0,0.0,0.0,0.0,54406.0,131318.0,0.292940061596778,5955072.0,3686752.0,12.608,4038.847999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,186096.0,115211.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",835,0.0,0.0,0,0,0.0,0.0,0.0,0.0,64000.0,0.0,6188640.0,6144000.0,9.472,4048.3199999999892,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,193395.0,192000.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",836,7168000.0,16980480.0,0,0,0.0,16980480.0,16980480.0,2112.0,20992.0,0.09141274238227147,4124544.0,2048000.0,17.888,4066.207999999989,2132480.0,512000.0,7168000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128892.0,64000.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",837,0.0,2621952.0,0,0,0.0,2621952.0,2621952.0,287360.0,32000.0,0.8997995991983968,2048000.0,2048000.0,46.944,4113.151999999989,2621952.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64000.0,64000.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",838,0.0,0.0,0,0,0.0,0.0,0.0,0.0,8000.0,0.0,2048000.0,512000.0,4.384,4117.535999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64000.0,16000.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",839,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,512.0,1.952,4119.487999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,16.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",840,0.0,0.0,0,0,0.0,0.0,0.0,0.0,48000.0,0.0,4608000.0,244096.0,9.248,4128.735999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,144000.0,7628.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",841,0.0,0.0,0,0,0.0,0.0,0.0,0.0,12000.0,0.0,2560000.0,0.0,4.96,4133.695999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,80000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",842,7168000.0,16980480.0,0,0,0.0,16980480.0,16980480.0,2112.0,20992.0,0.09141274238227147,4112256.0,2048000.0,18.208,4151.903999999989,2132480.0,512000.0,7168000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128508.0,64000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",843,0.0,0.0,0,0,0.0,0.0,0.0,5039.0,4066.0,0.5534321801208127,2048256.0,2048.0,7.328,4159.231999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64008.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",844,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,4161.375999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",845,0.0,0.0,0,0,0.0,0.0,0.0,5039.0,4066.0,0.5534321801208127,2048256.0,2048.0,7.52,4168.89599999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64008.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",846,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,4171.03999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",847,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,1.984,4173.02399999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",848,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.944,4175.967999999991,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",849,0.0,585216.0,0,0,0.0,585216.0,585216.0,736.0,4016.0,0.15488215488215487,2048000.0,512.0,8.544,4184.511999999991,585216.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64000.0,16.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",850,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,2.048,4186.55999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",851,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.168,4189.72799999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",852,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,4191.74399999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",853,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.008,4194.7519999999895,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",854,1769472.0,4562944.0,0,0,0.0,4562944.0,4562944.0,0.0,16000.0,0.0,0.0,2048000.0,4.128,4198.879999999989,0.0,1024000.0,1769472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,64000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",855,2560000.0,5120000.0,0,0,0.0,5120000.0,5120000.0,0.0,12000.0,0.0,4096000.0,0.0,7.424,4206.303999999989,0.0,0.0,2560000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",856,0.0,0.0,0,0,0.0,0.0,0.0,1472.0,4016.0,0.26822157434402333,2048000.0,512.0,12.064,4218.3679999999895,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64000.0,16.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",857,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,256.0,128.0,2.112,4220.47999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",858,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,128.0,2.112,4222.59199999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,4.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",859,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,160.0,128.0,2.272,4224.86399999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",860,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,256.0,128.0,2.08,4226.9439999999895,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8.0,4.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",861,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,384.0,640.0,2.624,4229.567999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12.0,20.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",862,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.664,4231.231999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",863,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.664,4232.895999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",864,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.08,4234.975999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",865,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,4236.703999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",866,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,416.0,32.0,2.336,4239.039999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,13.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",867,0.0,0.0,0,0,0.0,0.0,0.0,0.0,5.0,0.0,32.0,32.0,4.768,4243.807999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",868,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.08,4245.887999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",869,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,4247.935999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",870,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,160.0,128.0,2.88,4250.815999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5.0,4.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",871,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,32.0,3.232,4254.047999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",872,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,4256.127999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
