Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.856,1.856,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,3.552,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",3,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.528,6.08,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",4,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.552,9.632,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",5,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.136,12.768,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",6,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,14.912,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",7,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.792,16.704,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",8,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,18.432000000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",9,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.696,20.128000000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",10,0.0,0.0,0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,2.432,22.560000000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",11,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,24.608000000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",12,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,26.752000000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",13,0.0,0.0,0,0,0.0,0.0,0.0,36.0,2.0,0.9473684210526315,32.0,32.0,2.528,29.28,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,31.328000000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",15,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.112,33.440000000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",16,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,2.24,35.68000000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",17,0.0,0.0,0,0,0.0,0.0,0.0,0.0,144.0,0.0,3264.0,6144.0,3.456,39.13600000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,102.0,192.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",18,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,41.69600000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",19,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,44.92800000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",20,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.464,47.39200000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",21,0.0,256.0,0,0,0.0,256.0,256.0,16.0,12.0,0.5714285714285714,640.0,512.0,2.496,49.88800000000001,0.0,256.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,20.0,16.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",22,0.0,0.0,0,0,0.0,0.0,0.0,0.0,10.0,0.0,1024.0,1024.0,2.624,52.512000000000015,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",23,2048.0,4608.0,0,0,0.0,4608.0,4608.0,0.0,16.0,0.0,1024.0,1024.0,2.752,55.26400000000002,0.0,512.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",24,0.0,256.0,0,0,0.0,256.0,256.0,0.0,16.0,0.0,1024.0,1024.0,1.984,57.24800000000002,0.0,256.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",25,1792.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,16.0,0.0,1024.0,1024.0,2.592,59.84000000000002,0.0,512.0,1792.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",26,0.0,256.0,0,0,0.0,256.0,256.0,0.0,16.0,0.0,1024.0,1024.0,1.984,61.82400000000002,0.0,256.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",27,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.048,63.87200000000002,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",28,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.808,67.68000000000002,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",29,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.984,69.66400000000002,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",30,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,71.74400000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",31,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.656,74.40000000000002,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",32,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.752,77.15200000000002,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",33,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,7.04,84.19200000000002,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",34,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,6.816,91.00800000000002,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",35,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,6.784,97.79200000000003,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92256.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",36,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.688,100.48000000000003,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",37,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.656,103.13600000000004,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",38,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.456,106.59200000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",39,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.72,109.31200000000004,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",40,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,111.39200000000004,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",41,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.72,114.11200000000004,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",42,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.688,116.80000000000004,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",43,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.392,120.19200000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",44,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.688,122.88000000000004,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",45,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.112,124.99200000000003,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",46,24576.0,2206464.0,0,0,0.0,2206464.0,2206464.0,12480.0,24.0,0.9980806142034548,18432.0,6144.0,20.32,145.31200000000004,1860096.0,297216.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",47,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.528,151.84000000000003,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",48,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,153.92000000000004,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",49,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.08,156.00000000000006,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",50,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.744,159.74400000000006,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",51,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.92,161.66400000000004,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",52,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,163.68000000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",53,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.688,166.36800000000002,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",54,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.688,169.056,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",55,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10225536.0,28000.0,13.184,182.24,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319548.0,875.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",56,70656.0,147456.0,0,0,0.0,147456.0,147456.0,0.0,96.0,0.0,24576.0,24576.0,2.336,184.57600000000002,6144.0,0.0,70656.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",57,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10226304.0,29120.0,14.144,198.72000000000003,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319572.0,910.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",58,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.112,200.83200000000002,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,59,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,76416.0,0.8317836010143702,9732096.0,49152.0,15.328,216.16000000000003,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,1536.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",60,0.0,13824.0,0,0,0.0,13824.0,13824.0,0.0,432.0,0.0,49152.0,6144.0,2.176,218.336,12288.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",61,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.112,220.448,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",62,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.112,222.56,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",63,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.616,226.17600000000002,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",64,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.92,228.096,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",65,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,230.112,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",66,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.656,232.768,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",67,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.592,235.36,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",68,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,6.816,242.17600000000002,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",69,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,6.88,249.056,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",70,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,7.104,256.16,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92256.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",71,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.72,258.88000000000005,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",72,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.656,261.53600000000006,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",73,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.424,264.96000000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",74,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.72,267.68000000000006,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",75,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.048,269.72800000000007,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",76,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.688,272.41600000000005,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",77,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.624,275.0400000000001,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",78,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.488,278.5280000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",79,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.656,281.1840000000001,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",80,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,283.26400000000007,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",81,24576.0,2206464.0,0,0,0.0,2206464.0,2206464.0,12480.0,24.0,0.9980806142034548,18432.0,6144.0,20.256,303.5200000000001,1860096.0,297216.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",82,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.528,310.0480000000001,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",83,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,312.1280000000001,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",84,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.048,314.1760000000001,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",85,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.648,317.8240000000001,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",86,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.984,319.8080000000001,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",87,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,321.8240000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",88,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.656,324.48000000000013,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",89,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.752,327.23200000000014,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",90,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10225280.0,29504.0,13.504,340.73600000000016,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319540.0,922.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",91,70656.0,147456.0,0,0,0.0,147456.0,147456.0,0.0,96.0,0.0,24576.0,24576.0,2.368,343.10400000000016,6144.0,0.0,70656.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",92,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10226048.0,31168.0,14.336,357.44000000000017,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319564.0,974.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",93,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.112,359.5520000000002,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,94,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,76416.0,0.8317836010143702,9732096.0,49152.0,15.328,374.88000000000017,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,1536.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",95,0.0,13824.0,0,0,0.0,13824.0,13824.0,0.0,432.0,0.0,49152.0,6144.0,2.208,377.0880000000002,12288.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",96,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,379.1680000000002,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",97,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.08,381.24800000000016,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",98,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.808,385.05600000000015,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",99,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.92,386.97600000000017,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",100,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,389.02400000000017,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",101,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.72,391.7440000000002,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",102,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.72,394.4640000000002,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",103,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,7.136,401.60000000000025,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",104,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,7.008,408.60800000000023,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",105,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,6.784,415.3920000000002,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92256.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",106,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.72,418.11200000000025,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",107,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.592,420.70400000000024,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",108,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.584,424.28800000000024,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",109,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.752,427.04000000000025,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",110,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.112,429.15200000000027,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",111,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.784,431.93600000000026,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",112,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.656,434.59200000000027,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",113,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.456,438.0480000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",114,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.656,440.7040000000003,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",115,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.048,442.7520000000003,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",116,24576.0,2206464.0,0,0,0.0,2206464.0,2206464.0,12480.0,24.0,0.9980806142034548,18432.0,6144.0,20.256,463.00800000000027,1860096.0,297216.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",117,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.592,469.60000000000025,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",118,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.144,471.74400000000026,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",119,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.048,473.79200000000026,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",120,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.808,477.60000000000025,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",121,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.984,479.58400000000023,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",122,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,481.60000000000025,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",123,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.656,484.25600000000026,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",124,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.688,486.94400000000024,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",125,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10223616.0,29568.0,13.824,500.76800000000026,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319488.0,924.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",126,70656.0,147456.0,0,0,0.0,147456.0,147456.0,0.0,96.0,0.0,24576.0,24576.0,2.464,503.23200000000026,6144.0,0.0,70656.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",127,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10229632.0,28128.0,13.376,516.6080000000003,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319676.0,879.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",128,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.08,518.6880000000003,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,129,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,76416.0,0.8317836010143702,9732096.0,49152.0,15.328,534.0160000000003,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,1536.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",130,0.0,13824.0,0,0,0.0,13824.0,13824.0,0.0,432.0,0.0,49152.0,6144.0,2.176,536.1920000000003,12288.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",131,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.016,538.2080000000003,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",132,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.08,540.2880000000004,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",133,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.648,543.9360000000004,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",134,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.016,545.9520000000003,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",135,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,547.9680000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",136,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.688,550.6560000000003,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",137,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.688,553.3440000000003,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",138,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,6.624,559.9680000000003,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",139,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,6.72,566.6880000000003,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",140,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,6.816,573.5040000000004,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92256.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",141,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.688,576.1920000000003,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",142,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.688,578.8800000000003,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",143,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.424,582.3040000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",144,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.816,585.1200000000003,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",145,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.112,587.2320000000003,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",146,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.88,590.1120000000003,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",147,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.592,592.7040000000003,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",148,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.424,596.1280000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",149,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.784,598.9120000000003,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",150,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.24,601.1520000000003,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",151,24576.0,2206464.0,0,0,0.0,2206464.0,2206464.0,12480.0,24.0,0.9980806142034548,18432.0,6144.0,20.32,621.4720000000003,1860096.0,297216.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",152,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.72,628.1920000000003,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",153,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.112,630.3040000000003,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",154,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.016,632.3200000000003,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",155,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.648,635.9680000000003,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",156,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.952,637.9200000000003,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",157,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,639.9360000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",158,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.816,642.7520000000003,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",159,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.72,645.4720000000003,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",160,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10224000.0,29600.0,13.248,658.7200000000004,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319500.0,925.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",161,70656.0,147456.0,0,0,0.0,147456.0,147456.0,0.0,96.0,0.0,24576.0,24576.0,2.272,660.9920000000004,6144.0,0.0,70656.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",162,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10227712.0,28704.0,13.408,674.4000000000004,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319616.0,897.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",163,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.048,676.4480000000004,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,164,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,76416.0,0.8317836010143702,9732096.0,49152.0,15.488,691.9360000000004,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,1536.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",165,0.0,13824.0,0,0,0.0,13824.0,13824.0,0.0,432.0,0.0,49152.0,6144.0,2.208,694.1440000000003,12288.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",166,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.112,696.2560000000003,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",167,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.048,698.3040000000003,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",168,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.744,702.0480000000003,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",169,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.984,704.0320000000004,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",170,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,706.0160000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",171,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.752,708.7680000000004,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",172,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.848,711.6160000000003,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",173,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,6.624,718.2400000000004,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",174,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,6.88,725.1200000000003,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",175,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,6.88,732.0000000000003,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92256.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",176,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.688,734.6880000000003,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",177,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.656,737.3440000000003,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",178,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.392,740.7360000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",179,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.656,743.3920000000003,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",180,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,745.4720000000003,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",181,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.72,748.1920000000003,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",182,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.72,750.9120000000004,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",183,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.488,754.4000000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",184,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.656,757.0560000000004,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",185,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.112,759.1680000000003,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",186,24576.0,2206464.0,0,0,0.0,2206464.0,2206464.0,12480.0,24.0,0.9980806142034548,18432.0,6144.0,20.224,779.3920000000004,1860096.0,297216.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",187,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.688,786.0800000000004,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",188,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.112,788.1920000000003,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",189,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.048,790.2400000000004,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",190,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.776,794.0160000000003,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",191,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.984,796.0000000000003,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",192,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,798.0160000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",193,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.688,800.7040000000003,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",194,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.656,803.3600000000002,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",195,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10225664.0,29248.0,13.44,816.8000000000003,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319552.0,914.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",196,70656.0,147456.0,0,0,0.0,147456.0,147456.0,0.0,96.0,0.0,24576.0,24576.0,2.272,819.0720000000003,6144.0,0.0,70656.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",197,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10225792.0,27712.0,14.144,833.2160000000003,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319556.0,866.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",198,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.144,835.3600000000004,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,199,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,76416.0,0.8317836010143702,9732096.0,49152.0,15.424,850.7840000000003,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,1536.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",200,0.0,13824.0,0,0,0.0,13824.0,13824.0,0.0,432.0,0.0,49152.0,6144.0,2.144,852.9280000000003,12288.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",201,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,855.0080000000004,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",202,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.048,857.0560000000004,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",203,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.616,860.6720000000004,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",204,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.952,862.6240000000004,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",205,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,864.6400000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",206,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.688,867.3280000000003,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",207,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.656,869.9840000000003,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",208,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,6.784,876.7680000000003,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",209,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,6.848,883.6160000000002,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",210,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,6.752,890.3680000000002,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92256.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",211,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.752,893.1200000000001,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",212,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.656,895.7760000000001,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",213,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.424,899.2,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",214,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.688,901.888,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",215,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.112,904.0,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",216,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.72,906.72,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",217,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.656,909.376,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",218,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.424,912.8,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",219,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.656,915.4559999999999,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",220,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.112,917.5679999999999,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",221,24576.0,2206464.0,0,0,0.0,2206464.0,2206464.0,12480.0,24.0,0.9980806142034548,18432.0,6144.0,20.128,937.6959999999999,1860096.0,297216.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",222,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.848,944.5439999999999,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",223,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.144,946.6879999999999,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",224,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.176,948.8639999999999,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",225,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.712,952.5759999999999,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",226,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.92,954.4959999999999,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",227,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,956.4799999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",228,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.656,959.1359999999999,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",229,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.688,961.8239999999998,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",230,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10227712.0,29408.0,13.408,975.2319999999999,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319616.0,919.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",231,70656.0,147456.0,0,0,0.0,147456.0,147456.0,0.0,96.0,0.0,24576.0,24576.0,2.272,977.5039999999999,6144.0,0.0,70656.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",232,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10225152.0,28576.0,13.76,991.2639999999999,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319536.0,893.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",233,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.112,993.3759999999999,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,234,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,76416.0,0.8317836010143702,9732096.0,49152.0,15.36,1008.7359999999999,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,1536.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",235,0.0,13824.0,0,0,0.0,13824.0,13824.0,0.0,432.0,0.0,49152.0,6144.0,2.208,1010.9439999999998,12288.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",236,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.112,1013.0559999999998,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",237,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.08,1015.1359999999999,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",238,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.776,1018.9119999999998,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",239,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.952,1020.8639999999998,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",240,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,1022.8799999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",241,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.72,1025.5999999999997,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",242,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.656,1028.2559999999996,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",243,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,6.752,1035.0079999999996,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",244,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,6.944,1041.9519999999995,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",245,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,6.88,1048.8319999999997,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92256.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",246,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.72,1051.5519999999997,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",247,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.624,1054.1759999999997,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",248,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.392,1057.5679999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",249,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.688,1060.2559999999999,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",250,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,1062.3359999999998,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",251,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.656,1064.9919999999997,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",252,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.624,1067.6159999999998,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",253,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.456,1071.0719999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",254,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.816,1073.8879999999997,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",255,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,1075.9679999999996,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",256,24576.0,2206464.0,0,0,0.0,2206464.0,2206464.0,12480.0,24.0,0.9980806142034548,18432.0,6144.0,20.256,1096.2239999999997,1860096.0,297216.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",257,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.88,1103.1039999999998,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",258,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,1105.1839999999997,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",259,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,1.984,1107.1679999999997,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",260,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.936,1111.1039999999996,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",261,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.952,1113.0559999999996,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",262,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,1115.1039999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",263,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.688,1117.7919999999997,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",264,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.688,1120.4799999999998,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",265,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10229376.0,28672.0,13.344,1133.8239999999998,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319668.0,896.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",266,70656.0,147456.0,0,0,0.0,147456.0,147456.0,0.0,96.0,0.0,24576.0,24576.0,2.272,1136.0959999999998,6144.0,0.0,70656.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",267,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10224768.0,29248.0,13.856,1149.9519999999998,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319524.0,914.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",268,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.112,1152.0639999999999,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,269,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,76416.0,0.8317836010143702,9732096.0,49152.0,15.52,1167.5839999999998,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,1536.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",270,0.0,13824.0,0,0,0.0,13824.0,13824.0,0.0,432.0,0.0,49152.0,6144.0,2.208,1169.792,12288.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",271,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.112,1171.904,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",272,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.048,1173.952,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",273,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.744,1177.696,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",274,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.952,1179.648,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",275,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,1181.6319999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",276,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.656,1184.2879999999998,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",277,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.688,1186.9759999999999,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",278,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,6.88,1193.856,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",279,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,6.688,1200.544,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",280,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,6.688,1207.2320000000002,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92256.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",281,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.72,1209.9520000000002,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",282,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.848,1212.8000000000002,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",283,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.36,1216.16,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",284,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.688,1218.8480000000002,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",285,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.048,1220.8960000000002,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",286,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.752,1223.6480000000001,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",287,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.624,1226.2720000000002,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",288,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.424,1229.6960000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",289,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.688,1232.3840000000002,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",290,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,1234.4640000000002,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",291,24576.0,2206464.0,0,0,0.0,2206464.0,2206464.0,12480.0,24.0,0.9980806142034548,18432.0,6144.0,20.224,1254.688,1860096.0,297216.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",292,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.656,1261.344,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",293,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.112,1263.4560000000001,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",294,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.08,1265.536,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",295,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.712,1269.248,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",296,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.952,1271.2,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",297,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,1273.248,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",298,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.688,1275.9360000000001,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",299,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.688,1278.6240000000003,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",300,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10226304.0,29504.0,13.344,1291.9680000000003,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319572.0,922.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",301,70656.0,147456.0,0,0,0.0,147456.0,147456.0,0.0,96.0,0.0,24576.0,24576.0,2.336,1294.3040000000003,6144.0,0.0,70656.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",302,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10224640.0,28512.0,13.92,1308.2240000000004,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319520.0,891.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",303,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.112,1310.3360000000005,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,304,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,76416.0,0.8317836010143702,9732096.0,49152.0,15.424,1325.7600000000004,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,1536.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",305,0.0,13824.0,0,0,0.0,13824.0,13824.0,0.0,432.0,0.0,49152.0,6144.0,2.272,1328.0320000000004,12288.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",306,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,1330.1120000000003,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",307,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.016,1332.1280000000004,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",308,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.744,1335.8720000000003,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",309,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.952,1337.8240000000003,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",310,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,1339.8720000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",311,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.688,1342.5600000000004,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",312,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.72,1345.2800000000004,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",313,233373696.0,515366912.0,0,0,0.0,515366912.0,515366912.0,5697600.0,4710016.0,0.5474452554744526,492847744.0,1626208.0,499.2,1844.4800000000005,19447808.0,29171712.0,233373696.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,15401492.0,50819.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",314,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,1846.1760000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",315,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,64.0,64.0,2.592,1848.7680000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",316,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,1850.7840000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",317,0.0,303872.0,0,0,0.0,303872.0,303872.0,0.0,4784.0,0.0,1215488.0,1215488.0,3.488,1854.2720000000006,0.0,303872.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,37984.0,37984.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",318,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.664,1855.9360000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",319,0.0,0.0,0,0,0.0,0.0,0.0,4768.0,14264.0,0.2505254308532997,1219584.0,85824.0,4.128,1860.0640000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,38112.0,2682.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",320,0.0,0.0,0,0,0.0,0.0,0.0,22052.0,359094.0,0.057857094131907455,19562144.0,0.0,11.104,1871.1680000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,611317.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",321,0.0,0.0,0,0,0.0,0.0,0.0,4768.0,14264.0,0.2505254308532997,1219584.0,82496.0,4.064,1875.2320000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,38112.0,2578.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",322,0.0,0.0,0,0,0.0,0.0,0.0,22052.0,360882.0,0.05758694709793333,19604736.0,0.0,10.976,1886.2080000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,612648.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",323,0.0,0.0,0,0,0.0,0.0,0.0,4768.0,14264.0,0.2505254308532997,1219584.0,83904.0,4.064,1890.2720000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,38112.0,2622.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",324,0.0,0.0,0,0,0.0,0.0,0.0,22052.0,359690.0,0.05776676394004328,19573760.0,0.0,11.008,1901.2800000000009,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,611680.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",325,0.0,0.0,0,0,0.0,0.0,0.0,4768.0,14264.0,0.2505254308532997,1219584.0,83136.0,4.128,1905.4080000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,38112.0,2598.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",326,0.0,0.0,0,0,0.0,0.0,0.0,22052.0,358796.0,0.05790236524807797,19554464.0,64.0,10.944,1916.3520000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,611077.0,2.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",327,0.0,0.0,0,0,0.0,0.0,0.0,0.0,30.0,0.0,9568.0,1216.0,2.912,1919.2640000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,299.0,38.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",328,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.664,1920.9280000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",329,0.0,0.0,0,0,0.0,0.0,0.0,497.0,28.0,0.9466666666666667,1216.0,0.0,3.68,1924.6080000000009,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,38.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",330,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.664,1926.2720000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",331,0.0,0.0,0,0,0.0,0.0,0.0,497.0,28.0,0.9466666666666667,1216.0,0.0,3.68,1929.952000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,38.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",332,0.0,0.0,0,0,0.0,0.0,0.0,112896.0,19196.0,0.8546770432728704,1245504.0,4960.0,6.496,1936.448000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,38922.0,155.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",333,0.0,0.0,0,0,0.0,0.0,0.0,916.0,16.0,0.9828326180257511,1280.0,192.0,6.464,1942.912000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,40.0,6.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",334,0.0,0.0,0,0,0.0,0.0,0.0,0.0,28488.0,0.0,1223232.0,131296.0,3.904,1946.816000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,38226.0,4103.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",335,0.0,0.0,0,0,0.0,0.0,0.0,0.0,7176.0,0.0,1519360.0,0.0,4.864,1951.680000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,47480.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",336,0.0,0.0,0,0,0.0,0.0,0.0,0.0,9496.0,0.0,0.0,2430976.0,3.232,1954.912000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,75968.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",337,0.0,0.0,0,0,0.0,0.0,0.0,98304.0,9496.0,0.9119109461966605,1215488.0,0.0,4.672,1959.584000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,37984.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",338,0.0,0.0,0,0,0.0,0.0,0.0,156.0,64.0,0.7090909090909091,8192.0,0.0,2.176,1961.760000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",339,0.0,0.0,0,0,0.0,0.0,0.0,87339.0,56044.0,0.6091307895636163,4777344.0,3009120.0,10.944,1972.7040000000009,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,149292.0,94035.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",340,0.0,0.0,0,0,0.0,0.0,0.0,34263.0,67196.0,0.33770291447776934,4894208.0,3747840.0,9.824,1982.528000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,152944.0,117120.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",341,0.0,0.0,0,0,0.0,0.0,0.0,35139.0,69114.0,0.3370550487755748,4920320.0,3747840.0,10.336,1992.864000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,153760.0,117120.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",342,0.0,0.0,0,0,0.0,0.0,0.0,35139.0,69839.0,0.33472727619120196,4887296.0,3343712.0,10.432,2003.296000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,152728.0,104491.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",343,0.0,0.0,0,0,0.0,0.0,0.0,14336.0,9496.0,0.6015441423296408,2430976.0,0.0,5.376,2008.672000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75968.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",344,0.0,0.0,0,0,0.0,0.0,0.0,39.0,16.0,0.7090909090909091,2048.0,0.0,2.176,2010.8480000000009,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",345,0.0,0.0,0,0,0.0,0.0,0.0,27928.0,47614.0,0.36970162293823305,3355648.0,2216096.0,9.216,2020.0640000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,104864.0,69253.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",346,0.0,0.0,0,0,0.0,0.0,0.0,0.0,37984.0,0.0,3660192.0,3646464.0,6.592,2026.6560000000009,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,114381.0,113952.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",347,4254208.0,10038336.0,0,0,0.0,10038336.0,10038336.0,264.0,9568.0,0.026851098454027666,3646464.0,1215488.0,61.632,2088.288000000001,1226048.0,303872.0,4254208.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,113952.0,37984.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",348,0.0,1526058.0,0,0,0.0,1526058.0,1526058.0,167436.0,18992.0,0.8981268908103933,1215488.0,1215488.0,210.88,2299.168000000001,1526058.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,37984.0,37984.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",349,0.0,0.0,0,0,0.0,0.0,0.0,0.0,4784.0,0.0,1215488.0,303296.0,3.424,2302.592000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,37984.0,9478.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",350,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,64.0,1.92,2304.512000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,2.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",351,0.0,0.0,0,0,0.0,0.0,0.0,0.0,28488.0,0.0,2734848.0,130688.0,8.096,2312.608000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,85464.0,4084.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",352,0.0,0.0,0,0,0.0,0.0,0.0,0.0,7176.0,0.0,1519360.0,0.0,4.896,2317.5040000000013,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,47480.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",353,4254208.0,10038336.0,0,0,0.0,10038336.0,10038336.0,264.0,9568.0,0.026851098454027666,3646464.0,1215488.0,61.824,2379.3280000000013,1226048.0,303872.0,4254208.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,113952.0,37984.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",354,0.0,0.0,0,0,0.0,0.0,0.0,3064.0,2415.0,0.5592261361562328,1215648.0,1248.0,6.72,2386.048000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,37989.0,39.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",355,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,2388.192000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",356,0.0,0.0,0,0,0.0,0.0,0.0,3064.0,2415.0,0.5592261361562328,1215648.0,1248.0,6.432,2394.6240000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,37989.0,39.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",357,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,2396.7680000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",358,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.08,2398.8480000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",359,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.008,2401.856,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",360,0.0,492838.0,0,0,0.0,492838.0,492838.0,3686.0,2416.0,0.6040642412323828,1215680.0,1280.0,6.688,2408.5440000000003,492838.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,37990.0,40.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",361,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,2410.5280000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",362,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,2413.7920000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",363,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2415.8080000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",364,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.912,2418.7200000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",365,1769472.0,4146688.0,0,0,0.0,4146688.0,4146688.0,0.0,9496.0,0.0,0.0,1215488.0,4.0,2422.7200000000003,0.0,607744.0,1769472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,37984.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",366,1519360.0,3038720.0,0,0,0.0,3038720.0,3038720.0,0.0,7176.0,0.0,2430976.0,0.0,5.824,2428.5440000000003,0.0,0.0,1519360.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75968.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",367,0.0,0.0,0,0,0.0,0.0,0.0,6726.0,2456.0,0.7325201481158788,1216128.0,1440.0,8.32,2436.8640000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,38004.0,45.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",368,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,64.0,64.0,2.656,2439.5200000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",369,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,2441.2160000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",370,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,2442.9120000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",371,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.048,2444.96,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",372,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,2446.944,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",373,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.816,2449.7599999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",374,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.136,2452.8959999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",375,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,2454.9759999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",376,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,2457.1199999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",377,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.36,2460.4799999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",378,0.0,0.0,0,0,0.0,0.0,0.0,36.0,2.0,0.9473684210526315,32.0,32.0,2.624,2463.1039999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",379,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,2465.0879999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",380,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2467.1039999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",381,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,2.208,2469.3119999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",382,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.304,2471.6159999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",383,0.0,0.0,0,0,0.0,0.0,0.0,0.0,144.0,0.0,6336.0,6144.0,4.032,2475.6479999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",384,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.72,2478.3679999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",385,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,2481.5999999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",386,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.464,2484.0639999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",387,0.0,256.0,0,0,0.0,256.0,256.0,16.0,12.0,0.5714285714285714,640.0,512.0,1.984,2486.0479999999993,0.0,256.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,20.0,16.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",388,0.0,0.0,0,0,0.0,0.0,0.0,0.0,10.0,0.0,1024.0,1024.0,2.56,2488.6079999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",389,2048.0,4608.0,0,0,0.0,4608.0,4608.0,0.0,16.0,0.0,1024.0,1024.0,2.784,2491.3919999999994,0.0,512.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",390,0.0,256.0,0,0,0.0,256.0,256.0,0.0,16.0,0.0,1024.0,1024.0,2.016,2493.4079999999994,0.0,256.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",391,1800.0,4112.0,0,0,0.0,4112.0,4112.0,0.0,16.0,0.0,1024.0,1024.0,2.592,2495.9999999999995,0.0,512.0,1800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",392,0.0,256.0,0,0,0.0,256.0,256.0,0.0,16.0,0.0,1024.0,1024.0,1.984,2497.9839999999995,0.0,256.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",393,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.144,2500.1279999999992,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",394,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.776,2503.903999999999,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",395,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.888,2505.791999999999,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",396,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2507.807999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",397,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.688,2510.495999999999,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",398,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.688,2513.1839999999993,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",399,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,6.944,2520.1279999999992,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",400,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,7.136,2527.263999999999,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",401,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,6.944,2534.207999999999,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92256.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",402,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.656,2536.863999999999,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",403,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.592,2539.455999999999,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",404,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.424,2542.879999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",405,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.72,2545.599999999999,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",406,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.112,2547.711999999999,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",407,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.72,2550.431999999999,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",408,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.624,2553.0559999999987,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",409,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.456,2556.511999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",410,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.72,2559.2319999999986,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",411,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.016,2561.2479999999987,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",412,0.0,0.0,0,0,0.0,0.0,0.0,0.0,120.0,0.0,12288.0,12288.0,2.656,2563.9039999999986,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",413,0.0,0.0,0,0,0.0,0.0,0.0,0.0,120.0,0.0,12288.0,12288.0,2.624,2566.5279999999984,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",414,24576.0,2207232.0,0,0,0.0,2207232.0,2207232.0,12480.0,24.0,0.9980806142034548,30720.0,6144.0,20.448,2586.9759999999983,1860864.0,297216.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,960.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",415,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.72,2593.695999999998,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",416,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,2595.775999999998,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",417,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.176,2597.951999999998,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",418,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.776,2601.727999999998,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",419,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.888,2603.6159999999977,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",420,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,2605.5999999999976,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",421,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.688,2608.2879999999977,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",422,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.72,2611.0079999999975,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",423,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10223616.0,28448.0,13.856,2624.8639999999978,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319488.0,889.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",424,70656.0,147456.0,0,0,0.0,147456.0,147456.0,0.0,96.0,0.0,24576.0,24576.0,2.272,2627.1359999999977,6144.0,0.0,70656.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",425,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10223872.0,29984.0,13.728,2640.8639999999978,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319496.0,937.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",426,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.08,2642.9439999999977,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,427,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,76416.0,0.8317836010143702,9732096.0,49152.0,15.712,2658.6559999999977,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,1536.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",428,0.0,13824.0,0,0,0.0,13824.0,13824.0,0.0,432.0,0.0,49152.0,6144.0,2.144,2660.7999999999975,12288.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",429,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,2662.8799999999974,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",430,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.112,2664.9919999999975,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",431,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.68,2668.6719999999973,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",432,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.92,2670.5919999999974,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",433,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,2672.639999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",434,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.656,2675.295999999997,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",435,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.656,2677.951999999997,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",436,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,7.072,2685.023999999997,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",437,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,6.816,2691.839999999997,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",438,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,7.136,2698.975999999997,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92256.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",439,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.752,2701.727999999997,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",440,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.656,2704.383999999997,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",441,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.488,2707.8719999999967,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",442,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.656,2710.5279999999966,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",443,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,2712.6079999999965,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",444,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.656,2715.2639999999965,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",445,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.688,2717.9519999999966,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",446,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.488,2721.4399999999964,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",447,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.752,2724.1919999999964,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",448,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.048,2726.239999999996,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",449,0.0,0.0,0,0,0.0,0.0,0.0,0.0,120.0,0.0,12288.0,12288.0,2.624,2728.863999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",450,0.0,0.0,0,0,0.0,0.0,0.0,0.0,120.0,0.0,12288.0,12288.0,2.592,2731.455999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",451,24576.0,2207232.0,0,0,0.0,2207232.0,2207232.0,12480.0,24.0,0.9980806142034548,30720.0,6144.0,20.192,2751.647999999996,1860864.0,297216.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,960.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",452,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.464,2758.111999999996,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",453,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.112,2760.223999999996,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",454,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.112,2762.335999999996,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",455,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.84,2766.1759999999963,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",456,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.92,2768.0959999999964,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",457,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,2770.143999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",458,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.624,2772.767999999996,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",459,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.656,2775.423999999996,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",460,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10228608.0,30496.0,13.184,2788.607999999996,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319644.0,953.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",461,70656.0,147456.0,0,0,0.0,147456.0,147456.0,0.0,96.0,0.0,24576.0,24576.0,2.304,2790.911999999996,6144.0,0.0,70656.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",462,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10228864.0,29888.0,13.28,2804.1919999999964,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319652.0,934.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",463,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.208,2806.3999999999965,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,464,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,76416.0,0.8317836010143702,9732096.0,49152.0,15.552,2821.9519999999966,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,1536.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",465,0.0,13824.0,0,0,0.0,13824.0,13824.0,0.0,432.0,0.0,49152.0,6144.0,2.24,2824.1919999999964,12288.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",466,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.048,2826.239999999996,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",467,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,1.984,2828.223999999996,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",468,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.808,2832.031999999996,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",469,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.984,2834.015999999996,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",470,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,2836.0639999999958,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",471,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.72,2838.7839999999956,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",472,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.656,2841.4399999999955,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",473,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,6.752,2848.1919999999955,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",474,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,6.944,2855.1359999999954,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",475,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,6.976,2862.1119999999955,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92256.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",476,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.688,2864.7999999999956,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",477,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.784,2867.5839999999957,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",478,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.456,2871.039999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",479,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.72,2873.7599999999957,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",480,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.208,2875.9679999999958,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",481,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.72,2878.6879999999956,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",482,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.624,2881.3119999999954,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",483,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.424,2884.7359999999953,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",484,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.752,2887.4879999999953,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",485,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,2889.567999999995,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",486,0.0,0.0,0,0,0.0,0.0,0.0,0.0,120.0,0.0,12288.0,12288.0,2.624,2892.191999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",487,0.0,0.0,0,0,0.0,0.0,0.0,0.0,120.0,0.0,12288.0,12288.0,2.624,2894.815999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",488,24576.0,2207232.0,0,0,0.0,2207232.0,2207232.0,12480.0,24.0,0.9980806142034548,30720.0,6144.0,20.192,2915.007999999995,1860864.0,297216.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,960.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",489,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.624,2921.6319999999946,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",490,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,2923.7119999999945,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",491,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.016,2925.7279999999946,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",492,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.776,2929.5039999999944,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",493,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.984,2931.4879999999944,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",494,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,2933.535999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",495,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.656,2936.191999999994,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",496,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.624,2938.815999999994,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",497,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10225024.0,29024.0,13.472,2952.287999999994,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319532.0,907.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",498,70656.0,147456.0,0,0,0.0,147456.0,147456.0,0.0,96.0,0.0,24576.0,24576.0,2.304,2954.591999999994,6144.0,0.0,70656.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",499,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10223872.0,29312.0,13.632,2968.2239999999942,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319496.0,916.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",500,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.048,2970.271999999994,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,501,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,76416.0,0.8317836010143702,9732096.0,49152.0,15.616,2985.887999999994,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,1536.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",502,0.0,13824.0,0,0,0.0,13824.0,13824.0,0.0,432.0,0.0,49152.0,6144.0,2.208,2988.095999999994,12288.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",503,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,2990.175999999994,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",504,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.112,2992.287999999994,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",505,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.776,2996.063999999994,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",506,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.92,2997.983999999994,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",507,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2999.999999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",508,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.656,3002.655999999994,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",509,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.688,3005.343999999994,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",510,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,6.752,3012.095999999994,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",511,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,6.624,3018.719999999994,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",512,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,6.784,3025.503999999994,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92256.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",513,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.72,3028.223999999994,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",514,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.592,3030.815999999994,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",515,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.392,3034.2079999999937,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",516,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.72,3036.9279999999935,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",517,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.144,3039.0719999999933,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",518,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.784,3041.8559999999934,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",519,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.816,3044.671999999993,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",520,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.392,3048.063999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",521,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.752,3050.815999999993,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",522,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,3052.895999999993,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",523,0.0,0.0,0,0,0.0,0.0,0.0,0.0,120.0,0.0,12288.0,12288.0,2.592,3055.487999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",524,0.0,0.0,0,0,0.0,0.0,0.0,0.0,120.0,0.0,12288.0,12288.0,2.592,3058.079999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",525,24576.0,2207232.0,0,0,0.0,2207232.0,2207232.0,12480.0,24.0,0.9980806142034548,30720.0,6144.0,20.16,3078.239999999993,1860864.0,297216.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,960.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",526,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.592,3084.831999999993,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",527,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.144,3086.975999999993,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",528,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.048,3089.0239999999926,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",529,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.648,3092.6719999999927,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",530,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.952,3094.623999999993,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",531,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,3096.607999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",532,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.688,3099.295999999993,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",533,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.656,3101.951999999993,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",534,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10228992.0,28160.0,13.024,3114.975999999993,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319656.0,880.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",535,70656.0,147456.0,0,0,0.0,147456.0,147456.0,0.0,96.0,0.0,24576.0,24576.0,2.304,3117.279999999993,6144.0,0.0,70656.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",536,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10230528.0,28544.0,13.376,3130.655999999993,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319704.0,892.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",537,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.144,3132.799999999993,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,538,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,76416.0,0.8317836010143702,9732096.0,49152.0,15.392,3148.1919999999927,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,1536.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",539,0.0,13824.0,0,0,0.0,13824.0,13824.0,0.0,432.0,0.0,49152.0,6144.0,2.272,3150.4639999999927,12288.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",540,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,3152.5439999999926,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",541,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.048,3154.5919999999924,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",542,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.808,3158.3999999999924,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",543,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.984,3160.3839999999923,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",544,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,3162.367999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",545,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.656,3165.023999999992,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",546,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.656,3167.679999999992,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",547,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,6.624,3174.303999999992,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",548,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,6.848,3181.151999999992,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",549,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,7.104,3188.2559999999917,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92256.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",550,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.72,3190.9759999999915,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",551,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.656,3193.6319999999914,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",552,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.392,3197.0239999999912,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",553,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.72,3199.743999999991,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",554,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.048,3201.791999999991,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",555,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.72,3204.5119999999906,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",556,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.624,3207.1359999999904,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",557,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.488,3210.6239999999902,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",558,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.752,3213.37599999999,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",559,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,3215.45599999999,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",560,0.0,0.0,0,0,0.0,0.0,0.0,0.0,120.0,0.0,12288.0,12288.0,2.592,3218.04799999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",561,0.0,0.0,0,0,0.0,0.0,0.0,0.0,120.0,0.0,12288.0,12288.0,2.624,3220.67199999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",562,24576.0,2207232.0,0,0,0.0,2207232.0,2207232.0,12480.0,24.0,0.9980806142034548,30720.0,6144.0,20.32,3240.99199999999,1860864.0,297216.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,960.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",563,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.784,3247.7759999999903,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",564,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.208,3249.9839999999904,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",565,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.112,3252.0959999999905,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",566,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.776,3255.8719999999903,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",567,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.952,3257.8239999999905,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",568,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,3259.8399999999906,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",569,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.656,3262.4959999999905,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",570,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.656,3265.1519999999905,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",571,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10231680.0,29856.0,13.376,3278.5279999999907,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319740.0,933.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",572,70656.0,147456.0,0,0,0.0,147456.0,147456.0,0.0,96.0,0.0,24576.0,24576.0,2.24,3280.7679999999905,6144.0,0.0,70656.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",573,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10230912.0,29344.0,13.12,3293.8879999999904,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319716.0,917.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",574,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.144,3296.03199999999,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,575,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,76416.0,0.8317836010143702,9732096.0,49152.0,15.552,3311.5839999999903,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,1536.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",576,0.0,13824.0,0,0,0.0,13824.0,13824.0,0.0,432.0,0.0,49152.0,6144.0,2.336,3313.91999999999,12288.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",577,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.112,3316.03199999999,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",578,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.016,3318.04799999999,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",579,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.68,3321.72799999999,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",580,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.016,3323.74399999999,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",581,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,3325.75999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",582,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.88,3328.6399999999903,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",583,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.784,3331.4239999999904,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",584,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,6.784,3338.2079999999905,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",585,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,6.912,3345.1199999999903,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",586,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,6.848,3351.9679999999903,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92256.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",587,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.624,3354.59199999999,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",588,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.624,3357.21599999999,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",589,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.488,3360.7039999999897,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",590,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.752,3363.4559999999897,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",591,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,3365.5359999999896,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",592,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.688,3368.2239999999897,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",593,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.656,3370.8799999999896,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",594,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.424,3374.3039999999896,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",595,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.656,3376.9599999999896,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",596,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,3379.0399999999895,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",597,0.0,0.0,0,0,0.0,0.0,0.0,0.0,120.0,0.0,12288.0,12288.0,2.656,3381.6959999999895,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",598,0.0,0.0,0,0,0.0,0.0,0.0,0.0,120.0,0.0,12288.0,12288.0,2.624,3384.3199999999892,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",599,24576.0,2207232.0,0,0,0.0,2207232.0,2207232.0,12480.0,24.0,0.9980806142034548,30720.0,6144.0,20.16,3404.479999999989,1860864.0,297216.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,960.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",600,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.528,3411.007999999989,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",601,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.112,3413.119999999989,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",602,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.016,3415.135999999989,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",603,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.616,3418.751999999989,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",604,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.952,3420.7039999999893,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",605,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,3422.751999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",606,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.72,3425.471999999989,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",607,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.816,3428.2879999999886,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",608,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10227328.0,28000.0,13.28,3441.567999999989,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319604.0,875.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",609,70656.0,147456.0,0,0,0.0,147456.0,147456.0,0.0,96.0,0.0,24576.0,24576.0,2.304,3443.871999999989,6144.0,0.0,70656.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",610,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10226432.0,28032.0,13.568,3457.439999999989,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319576.0,876.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",611,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.08,3459.519999999989,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,612,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,76416.0,0.8317836010143702,9732096.0,49152.0,15.104,3474.623999999989,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,1536.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",613,0.0,13824.0,0,0,0.0,13824.0,13824.0,0.0,432.0,0.0,49152.0,6144.0,2.24,3476.8639999999887,12288.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",614,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.144,3479.0079999999884,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",615,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.144,3481.151999999988,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",616,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.968,3485.119999999988,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",617,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.952,3487.0719999999883,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",618,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,3489.055999999988,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",619,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.592,3491.6479999999883,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",620,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.656,3494.3039999999883,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",621,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,6.944,3501.247999999988,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",622,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,6.944,3508.191999999988,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",623,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,6.944,3515.135999999988,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92256.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",624,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.72,3517.855999999988,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",625,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.624,3520.4799999999877,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",626,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.456,3523.935999999988,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",627,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.688,3526.623999999988,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",628,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,3528.703999999988,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",629,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.72,3531.4239999999877,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",630,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.688,3534.111999999988,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",631,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.456,3537.567999999988,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",632,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.72,3540.2879999999877,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",633,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.112,3542.399999999988,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",634,0.0,0.0,0,0,0.0,0.0,0.0,0.0,120.0,0.0,12288.0,12288.0,2.592,3544.991999999988,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",635,0.0,0.0,0,0,0.0,0.0,0.0,0.0,120.0,0.0,12288.0,12288.0,2.592,3547.583999999988,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",636,24576.0,2207232.0,0,0,0.0,2207232.0,2207232.0,12480.0,24.0,0.9980806142034548,30720.0,6144.0,20.288,3567.871999999988,1860864.0,297216.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,960.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",637,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.752,3574.623999999988,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",638,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.144,3576.7679999999878,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",639,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.08,3578.8479999999877,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",640,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.936,3582.783999999988,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",641,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.984,3584.7679999999878,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",642,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,3586.783999999988,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",643,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.592,3589.375999999988,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",644,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.688,3592.063999999988,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",645,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10228992.0,29664.0,13.472,3605.5359999999882,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319656.0,927.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",646,70656.0,147456.0,0,0,0.0,147456.0,147456.0,0.0,96.0,0.0,24576.0,24576.0,2.304,3607.8399999999883,6144.0,0.0,70656.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",647,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10228224.0,28608.0,13.632,3621.4719999999884,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319632.0,894.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",648,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.08,3623.5519999999883,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,649,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,76416.0,0.8317836010143702,9732096.0,49152.0,15.52,3639.0719999999883,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,1536.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",650,0.0,13824.0,0,0,0.0,13824.0,13824.0,0.0,432.0,0.0,49152.0,6144.0,2.336,3641.407999999988,12288.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",651,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.048,3643.455999999988,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",652,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.016,3645.471999999988,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",653,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.68,3649.1519999999878,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",654,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.952,3651.103999999988,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",655,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,3653.1519999999878,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",656,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.624,3655.7759999999876,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",657,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.656,3658.4319999999875,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",658,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,7.008,3665.4399999999873,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",659,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,6.688,3672.1279999999874,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",660,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,7.008,3679.1359999999872,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92256.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",661,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.688,3681.8239999999873,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",662,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.656,3684.4799999999873,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",663,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.424,3687.9039999999873,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",664,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.656,3690.559999999987,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",665,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.112,3692.6719999999873,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",666,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.72,3695.391999999987,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",667,0.0,768.0,0,0,0.0,768.0,768.0,0.0,48.0,0.0,3072.0,3072.0,2.656,3698.047999999987,768.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",668,0.0,0.0,0,0,0.0,0.0,0.0,0.0,96.0,0.0,6144.0,6144.0,3.424,3701.471999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",669,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,9216.0,6144.0,2.688,3704.159999999987,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",670,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.144,3706.303999999987,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",671,0.0,0.0,0,0,0.0,0.0,0.0,0.0,120.0,0.0,12288.0,12288.0,2.624,3708.9279999999867,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",672,0.0,0.0,0,0,0.0,0.0,0.0,0.0,120.0,0.0,12288.0,12288.0,2.656,3711.5839999999866,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",673,24576.0,2207232.0,0,0,0.0,2207232.0,2207232.0,12480.0,24.0,0.9980806142034548,30720.0,6144.0,20.192,3731.7759999999867,1860864.0,297216.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,960.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",674,1179648.0,2605056.0,0,0,0.0,2605056.0,2605056.0,28800.0,23808.0,0.5474452554744526,2949120.0,6144.0,6.656,3738.4319999999866,98304.0,147456.0,1179648.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,92160.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",675,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.048,3740.4799999999864,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",676,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.016,3742.4959999999865,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",677,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.712,3746.2079999999864,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",678,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.984,3748.1919999999864,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",679,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,3750.2079999999864,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",680,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.624,3752.8319999999862,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",681,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.688,3755.5199999999863,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",682,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10226048.0,29024.0,13.312,3768.8319999999862,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319564.0,907.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",683,70656.0,147456.0,0,0,0.0,147456.0,147456.0,0.0,96.0,0.0,24576.0,24576.0,2.24,3771.071999999986,6144.0,0.0,70656.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",684,4718592.0,10420224.0,0,0,0.0,10420224.0,10420224.0,115200.0,95232.0,0.5474452554744526,10233088.0,29696.0,13.568,3784.6399999999862,393216.0,589824.0,4718592.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,319784.0,928.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",685,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.112,3786.7519999999863,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,686,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,76416.0,0.8317836010143702,9732096.0,49152.0,15.488,3802.239999999986,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,304128.0,1536.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",687,0.0,13824.0,0,0,0.0,13824.0,13824.0,0.0,432.0,0.0,49152.0,6144.0,2.208,3804.447999999986,12288.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",688,1536.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,12288.0,6144.0,2.08,3806.527999999986,0.0,0.0,1536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",689,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,48.0,0.0,6144.0,6144.0,2.08,3808.607999999986,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",690,0.0,3778.0,0,0,0.0,3778.0,3778.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.808,3812.415999999986,3776.0,2.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",691,2.0,4.0,0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,1.92,3814.335999999986,0.0,0.0,2.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",692,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,3816.319999999986,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",693,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,2.72,3819.039999999986,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",694,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,12288.0,6144.0,2.752,3821.791999999986,0.0,1536.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",695,233373696.0,515366912.0,0,0,0.0,515366912.0,515366912.0,5697600.0,4710016.0,0.5474452554744526,493780096.0,1625824.0,498.592,4320.3839999999855,19447808.0,29171712.0,233373696.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,15430628.0,50807.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",696,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,4322.079999999985,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",697,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,64.0,64.0,2.624,4324.703999999985,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",698,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,4326.719999999985,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",699,0.0,303872.0,0,0,0.0,303872.0,303872.0,0.0,4784.0,0.0,1215488.0,1215488.0,3.52,4330.239999999985,0.0,303872.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,37984.0,37984.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",700,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.76,4331.999999999985,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",701,0.0,0.0,0,0,0.0,0.0,0.0,4768.0,14264.0,0.2505254308532997,1219584.0,83840.0,4.224,4336.223999999986,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,38112.0,2620.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",702,0.0,0.0,0,0,0.0,0.0,0.0,22052.0,359094.0,0.057857094131907455,19562144.0,0.0,10.912,4347.135999999986,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,611317.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",703,0.0,0.0,0,0,0.0,0.0,0.0,4768.0,14264.0,0.2505254308532997,1219584.0,84224.0,4.064,4351.199999999986,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,38112.0,2632.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",704,0.0,0.0,0,0,0.0,0.0,0.0,22052.0,360882.0,0.05758694709793333,19604480.0,0.0,10.496,4361.695999999986,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,612640.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",705,0.0,0.0,0,0,0.0,0.0,0.0,4768.0,14264.0,0.2505254308532997,1219584.0,83648.0,4.096,4365.791999999986,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,38112.0,2614.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",706,0.0,0.0,0,0,0.0,0.0,0.0,22052.0,359541.0,0.05778932003469665,19572288.0,0.0,10.496,4376.287999999986,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,611634.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",707,0.0,0.0,0,0,0.0,0.0,0.0,4768.0,14264.0,0.2505254308532997,1219584.0,83968.0,4.128,4380.415999999986,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,38112.0,2624.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",708,0.0,0.0,0,0,0.0,0.0,0.0,22052.0,360882.0,0.05758694709793333,19609248.0,64.0,10.784,4391.199999999985,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,612789.0,2.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",709,0.0,0.0,0,0,0.0,0.0,0.0,0.0,30.0,0.0,9568.0,1216.0,2.784,4393.983999999985,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,299.0,38.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",710,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.664,4395.647999999985,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",711,0.0,0.0,0,0,0.0,0.0,0.0,497.0,28.0,0.9466666666666667,1216.0,0.0,3.616,4399.263999999985,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,38.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",712,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.664,4400.927999999984,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",713,0.0,0.0,0,0,0.0,0.0,0.0,497.0,28.0,0.9466666666666667,1216.0,0.0,3.712,4404.639999999985,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,38.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",714,0.0,0.0,0,0,0.0,0.0,0.0,77184.0,19198.0,0.8008134298935485,1245504.0,5440.0,6.304,4410.943999999985,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,38922.0,170.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",715,0.0,0.0,0,0,0.0,0.0,0.0,916.0,16.0,0.9828326180257511,1280.0,192.0,6.432,4417.375999999985,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,40.0,6.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",716,0.0,0.0,0,0,0.0,0.0,0.0,0.0,28488.0,0.0,1223232.0,129888.0,4.032,4421.407999999985,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,38226.0,4059.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",717,0.0,0.0,0,0,0.0,0.0,0.0,0.0,7176.0,0.0,1519360.0,0.0,5.408,4426.815999999985,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,47480.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",718,0.0,0.0,0,0,0.0,0.0,0.0,0.0,9496.0,0.0,0.0,2430976.0,3.328,4430.143999999986,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,75968.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",719,0.0,0.0,0,0,0.0,0.0,0.0,98304.0,9496.0,0.9119109461966605,1215488.0,0.0,4.512,4434.655999999985,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,37984.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",720,0.0,0.0,0,0,0.0,0.0,0.0,156.0,64.0,0.7090909090909091,8192.0,0.0,2.176,4436.831999999986,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",721,0.0,0.0,0,0,0.0,0.0,0.0,85539.0,56903.0,0.6005181056149169,4816640.0,3070144.0,11.072,4447.903999999986,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,150520.0,95942.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",722,0.0,0.0,0,0,0.0,0.0,0.0,34263.0,70588.0,0.3267779992560872,4878080.0,3747840.0,9.568,4457.471999999986,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,152440.0,117120.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",723,0.0,0.0,0,0,0.0,0.0,0.0,35139.0,66958.0,0.34417269851219917,4872576.0,3747840.0,10.4,4467.871999999986,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,152268.0,117120.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",724,0.0,0.0,0,0,0.0,0.0,0.0,35139.0,69377.0,0.33620689655172414,4839168.0,3348032.0,10.048,4477.9199999999855,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,151224.0,104626.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",725,0.0,0.0,0,0,0.0,0.0,0.0,14336.0,9496.0,0.6015441423296408,2430976.0,0.0,5.344,4483.263999999986,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75968.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",726,0.0,0.0,0,0,0.0,0.0,0.0,39.0,16.0,0.7090909090909091,2048.0,0.0,2.24,4485.503999999985,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",727,0.0,0.0,0,0,0.0,0.0,0.0,27928.0,49065.0,0.36273427454443913,3335808.0,2221312.0,9.312,4494.815999999985,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,104244.0,69416.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",728,0.0,0.0,0,0,0.0,0.0,0.0,0.0,37984.0,0.0,3661472.0,3646464.0,6.528,4501.3439999999855,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,114421.0,113952.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",729,4254208.0,10038336.0,0,0,0.0,10038336.0,10038336.0,264.0,9568.0,0.026851098454027666,3646464.0,1215488.0,61.792,4563.135999999986,1226048.0,303872.0,4254208.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,113952.0,37984.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",730,0.0,1526058.0,0,0,0.0,1526058.0,1526058.0,167436.0,18992.0,0.8981268908103933,1215488.0,1215488.0,211.52,4774.655999999986,1526058.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,37984.0,37984.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",731,0.0,0.0,0,0,0.0,0.0,0.0,0.0,4784.0,0.0,1215488.0,303296.0,3.584,4778.239999999986,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,37984.0,9478.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",732,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,64.0,1.92,4780.159999999986,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,2.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",733,0.0,0.0,0,0,0.0,0.0,0.0,0.0,28488.0,0.0,2734848.0,135168.0,8.032,4788.191999999986,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,85464.0,4224.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",734,0.0,0.0,0,0,0.0,0.0,0.0,0.0,7176.0,0.0,1519360.0,0.0,4.8,4792.991999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,47480.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",735,4254208.0,10038336.0,0,0,0.0,10038336.0,10038336.0,264.0,9568.0,0.026851098454027666,3646464.0,1215488.0,61.92,4854.911999999987,1226048.0,303872.0,4254208.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,113952.0,37984.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",736,0.0,0.0,0,0,0.0,0.0,0.0,3064.0,2415.0,0.5592261361562328,1215648.0,1248.0,6.272,4861.183999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,37989.0,39.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",737,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,4863.327999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",738,0.0,0.0,0,0,0.0,0.0,0.0,3064.0,2415.0,0.5592261361562328,1215648.0,1248.0,6.304,4869.631999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,37989.0,39.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",739,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,4871.775999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",740,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.016,4873.791999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",741,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.944,4876.735999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",742,0.0,492838.0,0,0,0.0,492838.0,492838.0,3686.0,2416.0,0.6040642412323828,1215680.0,1280.0,6.496,4883.231999999987,492838.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,37990.0,40.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",743,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.112,4885.343999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",744,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,4888.575999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",745,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,4890.623999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",746,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.976,4893.599999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",747,1769472.0,4146688.0,0,0,0.0,4146688.0,4146688.0,0.0,9496.0,0.0,0.0,1215488.0,4.0,4897.599999999987,0.0,607744.0,1769472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,37984.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",748,1519360.0,3038720.0,0,0,0.0,3038720.0,3038720.0,0.0,7176.0,0.0,2430976.0,0.0,5.792,4903.391999999987,0.0,0.0,1519360.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75968.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",749,0.0,0.0,0,0,0.0,0.0,0.0,6726.0,2456.0,0.7325201481158788,1216128.0,1344.0,8.192,4911.583999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,38004.0,42.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",750,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,64.0,64.0,2.624,4914.207999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",751,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.76,4915.967999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",752,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,4917.695999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",753,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.048,4919.743999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",754,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,4921.791999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",755,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.04,4924.831999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",756,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.04,4927.871999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",757,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,4929.919999999986,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
