Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.856,1.856,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,3.584,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,5.312,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.016,7.328,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.336,9.664,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",6,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.272,11.936,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",7,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,15.264,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",8,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,18.496,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",9,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,21.055999999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",10,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,22.752,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",11,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,24.448,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.76,26.208000000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,0.0,0.0,0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,2.4,28.608,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,30.592,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",15,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.208,32.8,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",16,0.0,0.0,0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,32.0,32.0,2.496,35.296,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",17,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,37.312,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",18,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,39.36,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",19,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,2.144,41.504,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",20,0.0,0.0,0,0,0.0,0.0,0.0,0.0,288.0,0.0,3264.0,12288.0,3.808,45.312,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,102.0,384.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",21,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.464,47.775999999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",22,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,51.135999999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",23,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.4,53.535999999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",24,0.0,512.0,0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,2.016,55.55199999999999,0.0,512.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",25,0.0,0.0,0,0,0.0,0.0,0.0,0.0,20.0,0.0,2048.0,2048.0,2.624,58.175999999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",26,4096.0,9216.0,0,0,0.0,9216.0,9216.0,0.0,32.0,0.0,2048.0,2048.0,2.976,61.151999999999994,0.0,1024.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",27,0.0,512.0,0,0,0.0,512.0,512.0,0.0,32.0,0.0,2048.0,2048.0,2.08,63.23199999999999,0.0,512.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",28,3584.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,32.0,0.0,2048.0,2048.0,2.912,66.14399999999999,0.0,1024.0,3584.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",29,0.0,512.0,0,0,0.0,512.0,512.0,0.0,32.0,0.0,2048.0,2048.0,2.08,68.22399999999999,0.0,512.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",30,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.016,70.24,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",31,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,4.032,74.27199999999999,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",32,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,76.192,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",33,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,78.208,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",34,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.688,80.896,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",35,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.688,83.584,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,36,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2752736.0,61440.0,7.968,91.552,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86023.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",37,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.688,94.24000000000001,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,38,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2757408.0,61440.0,7.648,101.888,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86169.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",39,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.464,104.352,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,40,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2756032.0,61440.0,7.808,112.16,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86126.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",41,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.528,114.688,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",42,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.752,117.44,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",43,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.656,120.096,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",44,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,3.968,124.06400000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",45,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.72,126.784,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",46,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.048,128.832,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",47,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.656,131.488,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",48,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.592,134.08,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",49,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.0,138.08,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",50,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.752,140.83200000000002,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",51,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.112,142.94400000000002,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",52,49152.0,4412928.0,0,0,0.0,4412928.0,4412928.0,24960.0,48.0,0.9980806142034548,36864.0,12288.0,20.224,163.168,3720192.0,594432.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,53,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2752672.0,61440.0,7.712,170.88,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86021.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",54,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.56,173.44,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",55,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.048,175.488,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",56,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.016,177.504,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",57,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.84,181.344,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",58,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.016,183.35999999999999,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",59,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,185.408,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",60,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.656,188.064,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",61,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.656,190.72,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",62,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11076352.0,64192.0,14.496,205.216,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,346136.0,2006.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",63,141312.0,294912.0,0,0,0.0,294912.0,294912.0,0.0,192.0,0.0,49152.0,49152.0,2.368,207.584,12288.0,0.0,141312.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",64,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11067904.0,68736.0,14.592,222.17600000000002,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,345872.0,2148.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",65,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.176,224.352,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,66,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,79104.0,0.826890756302521,10027008.0,98304.0,15.552,239.904,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313344.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",67,0.0,27648.0,0,0,0.0,27648.0,27648.0,0.0,864.0,0.0,98304.0,12288.0,2.272,242.176,24576.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",68,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.08,244.256,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",69,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.016,246.272,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",70,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.84,250.112,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",71,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,252.03199999999998,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",72,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,254.04799999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",73,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.688,256.736,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",74,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.688,259.424,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,75,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2752768.0,61440.0,7.968,267.392,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86024.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",76,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.432,269.824,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,77,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2756800.0,61440.0,7.712,277.536,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86150.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",78,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.464,280.0,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,79,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2755968.0,61440.0,7.744,287.744,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86124.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",80,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.432,290.17600000000004,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",81,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.72,292.8960000000001,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",82,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.688,295.58400000000006,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",83,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.096,299.68000000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",84,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.752,302.4320000000001,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",85,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.048,304.4800000000001,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",86,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.88,307.36000000000007,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",87,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.592,309.95200000000006,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",88,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.032,313.98400000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",89,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.88,316.86400000000003,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",90,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.112,318.97600000000006,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",91,49152.0,4412928.0,0,0,0.0,4412928.0,4412928.0,24960.0,48.0,0.9980806142034548,36864.0,12288.0,20.128,339.10400000000004,3720192.0,594432.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,92,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2753632.0,61440.0,7.776,346.88000000000005,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86051.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",93,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.656,349.53600000000006,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",94,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.048,351.58400000000006,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",95,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.016,353.6000000000001,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",96,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.872,357.4720000000001,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",97,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,359.4240000000001,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",98,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,361.4720000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",99,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.688,364.1600000000001,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",100,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.656,366.8160000000001,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",101,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11044224.0,66208.0,14.368,381.1840000000001,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,345132.0,2069.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",102,141312.0,294912.0,0,0,0.0,294912.0,294912.0,0.0,192.0,0.0,49152.0,49152.0,2.272,383.4560000000001,12288.0,0.0,141312.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",103,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11034752.0,67776.0,14.656,398.1120000000001,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,344836.0,2118.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",104,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.112,400.2240000000001,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,105,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,79104.0,0.826890756302521,10027008.0,98304.0,15.616,415.8400000000001,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313344.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",106,0.0,27648.0,0,0,0.0,27648.0,27648.0,0.0,864.0,0.0,98304.0,12288.0,2.24,418.0800000000001,24576.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",107,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.112,420.1920000000001,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",108,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.08,422.2720000000001,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",109,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.84,426.1120000000001,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",110,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,428.0640000000001,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",111,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.952,430.0160000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",112,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.656,432.6720000000001,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",113,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.688,435.36000000000007,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,114,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2753408.0,61440.0,8.032,443.39200000000005,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86044.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",115,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.688,446.08000000000004,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,116,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2757504.0,61440.0,7.968,454.04800000000006,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86172.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",117,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.656,456.70400000000006,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,118,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2758208.0,61440.0,7.712,464.41600000000005,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86194.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",119,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.496,466.91200000000003,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",120,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.688,469.6,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",121,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.592,472.192,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",122,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.032,476.224,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",123,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.72,478.944,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",124,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.048,480.992,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",125,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.688,483.68,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",126,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.656,486.336,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",127,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,3.968,490.30400000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",128,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.688,492.992,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",129,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.08,495.072,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",130,49152.0,4412928.0,0,0,0.0,4412928.0,4412928.0,24960.0,48.0,0.9980806142034548,36864.0,12288.0,20.256,515.328,3720192.0,594432.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,131,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2753280.0,61440.0,7.808,523.136,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86040.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",132,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.464,525.6,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",133,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.112,527.712,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",134,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,1.984,529.696,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",135,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.872,533.568,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",136,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,535.4879999999999,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",137,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,537.536,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",138,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.816,540.352,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",139,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.72,543.072,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",140,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11128320.0,66144.0,13.472,556.544,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,347760.0,2067.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",141,141312.0,294912.0,0,0,0.0,294912.0,294912.0,0.0,192.0,0.0,49152.0,49152.0,2.336,558.88,12288.0,0.0,141312.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",142,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11042176.0,65248.0,14.752,573.632,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,345068.0,2039.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",143,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.112,575.7439999999999,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,144,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,79104.0,0.826890756302521,10027008.0,98304.0,15.488,591.232,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313344.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",145,0.0,27648.0,0,0,0.0,27648.0,27648.0,0.0,864.0,0.0,98304.0,12288.0,2.24,593.472,24576.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",146,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.112,595.584,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",147,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.048,597.632,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",148,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.872,601.5039999999999,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",149,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,603.4559999999999,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",150,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,605.4399999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",151,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.624,608.064,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",152,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.656,610.7199999999999,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,153,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2753088.0,61440.0,8.032,618.752,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86034.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",154,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.464,621.216,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,155,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2758304.0,61440.0,7.808,629.024,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86197.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",156,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.56,631.584,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,157,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2756512.0,61440.0,7.712,639.2959999999999,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86141.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",158,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.464,641.76,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",159,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.656,644.4159999999999,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",160,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.656,647.0719999999999,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",161,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.032,651.1039999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",162,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.784,653.8879999999999,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",163,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.112,655.9999999999999,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",164,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.752,658.7519999999998,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",165,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.592,661.3439999999998,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",166,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,3.968,665.3119999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",167,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.752,668.0639999999997,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",168,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.048,670.1119999999997,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",169,49152.0,4412928.0,0,0,0.0,4412928.0,4412928.0,24960.0,48.0,0.9980806142034548,36864.0,12288.0,20.288,690.3999999999997,3720192.0,594432.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,170,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2753088.0,61440.0,7.808,698.2079999999997,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86034.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",171,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.592,700.7999999999997,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",172,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.08,702.8799999999998,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",173,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.048,704.9279999999998,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",174,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.84,708.7679999999998,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",175,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,710.6879999999998,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",176,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,712.7039999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",177,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.784,715.4879999999997,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",178,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.688,718.1759999999997,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",179,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11029120.0,66912.0,14.24,732.4159999999997,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,344660.0,2091.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",180,141312.0,294912.0,0,0,0.0,294912.0,294912.0,0.0,192.0,0.0,49152.0,49152.0,2.304,734.7199999999997,12288.0,0.0,141312.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",181,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11104000.0,68736.0,13.92,748.6399999999996,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,347000.0,2148.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",182,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.24,750.8799999999997,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,183,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,79104.0,0.826890756302521,10027008.0,98304.0,15.584,766.4639999999996,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313344.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",184,0.0,27648.0,0,0,0.0,27648.0,27648.0,0.0,864.0,0.0,98304.0,12288.0,2.208,768.6719999999996,24576.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",185,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.112,770.7839999999995,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",186,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.08,772.8639999999996,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",187,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.808,776.6719999999996,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",188,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,778.6239999999996,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",189,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,780.6399999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",190,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.816,783.4559999999996,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",191,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.72,786.1759999999996,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,192,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2753088.0,61440.0,7.68,793.8559999999995,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86034.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",193,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.528,796.3839999999996,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,194,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2757248.0,61440.0,7.968,804.3519999999995,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86164.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",195,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.528,806.8799999999995,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,196,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2756992.0,61440.0,8.064,814.9439999999995,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86156.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",197,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.624,817.5679999999995,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",198,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.688,820.2559999999995,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",199,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.56,822.8159999999995,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",200,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.0,826.8159999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",201,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.72,829.5359999999995,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",202,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.112,831.6479999999995,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",203,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.88,834.5279999999995,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",204,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.72,837.2479999999995,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",205,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.064,841.3119999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",206,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.688,843.9999999999994,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",207,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.048,846.0479999999994,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",208,49152.0,4412928.0,0,0,0.0,4412928.0,4412928.0,24960.0,48.0,0.9980806142034548,36864.0,12288.0,20.224,866.2719999999995,3720192.0,594432.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,209,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2753536.0,61440.0,7.968,874.2399999999994,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86048.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",210,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.688,876.9279999999994,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",211,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.08,879.0079999999995,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",212,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.048,881.0559999999995,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",213,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.872,884.9279999999994,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",214,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,886.8799999999994,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",215,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,888.8639999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",216,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.688,891.5519999999995,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",217,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.656,894.2079999999994,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",218,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11108096.0,65536.0,13.984,908.1919999999994,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,347128.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",219,141312.0,294912.0,0,0,0.0,294912.0,294912.0,0.0,192.0,0.0,49152.0,49152.0,2.272,910.4639999999995,12288.0,0.0,141312.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",220,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11058048.0,67936.0,14.24,924.7039999999995,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,345564.0,2123.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",221,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.144,926.8479999999995,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,222,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,79104.0,0.826890756302521,10027008.0,98304.0,15.616,942.4639999999995,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313344.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",223,0.0,27648.0,0,0,0.0,27648.0,27648.0,0.0,864.0,0.0,98304.0,12288.0,2.208,944.6719999999995,24576.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",224,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.08,946.7519999999995,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",225,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.016,948.7679999999995,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",226,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.904,952.6719999999995,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",227,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,954.6559999999995,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",228,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,956.6719999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",229,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.752,959.4239999999994,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",230,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.816,962.2399999999994,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,231,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2752608.0,61440.0,7.968,970.2079999999994,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86019.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",232,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.464,972.6719999999995,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,233,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2757376.0,61440.0,7.936,980.6079999999995,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86168.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",234,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.528,983.1359999999995,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,235,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2758048.0,61440.0,7.808,990.9439999999995,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86189.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",236,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.528,993.4719999999995,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",237,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.72,996.1919999999996,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",238,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.688,998.8799999999995,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",239,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.0,1002.8799999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",240,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.752,1005.6319999999995,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",241,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.048,1007.6799999999995,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",242,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.72,1010.3999999999995,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",243,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.656,1013.0559999999995,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",244,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.16,1017.2159999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",245,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.688,1019.9039999999994,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",246,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.048,1021.9519999999994,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",247,49152.0,4412928.0,0,0,0.0,4412928.0,4412928.0,24960.0,48.0,0.9980806142034548,36864.0,12288.0,20.096,1042.0479999999993,3720192.0,594432.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,248,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2753888.0,61440.0,7.968,1050.0159999999994,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86059.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",249,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.624,1052.6399999999994,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",250,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.176,1054.8159999999993,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",251,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.048,1056.8639999999994,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",252,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.872,1060.7359999999994,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",253,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,1062.7199999999993,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",254,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,1064.7359999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",255,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.784,1067.5199999999995,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",256,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.656,1070.1759999999995,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",257,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11052416.0,66176.0,13.952,1084.1279999999995,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,345388.0,2068.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",258,141312.0,294912.0,0,0,0.0,294912.0,294912.0,0.0,192.0,0.0,49152.0,49152.0,2.368,1086.4959999999994,12288.0,0.0,141312.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",259,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11038592.0,66400.0,14.56,1101.0559999999994,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,344956.0,2075.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",260,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.144,1103.1999999999994,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,261,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,79104.0,0.826890756302521,10027008.0,98304.0,15.712,1118.9119999999994,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313344.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",262,0.0,27648.0,0,0,0.0,27648.0,27648.0,0.0,864.0,0.0,98304.0,12288.0,2.208,1121.1199999999994,24576.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",263,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.048,1123.1679999999994,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",264,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,1.984,1125.1519999999994,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",265,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.872,1129.0239999999994,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",266,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,1131.0079999999994,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",267,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,1133.0239999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",268,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.688,1135.7119999999995,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",269,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.656,1138.3679999999995,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,270,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2752832.0,61440.0,8.032,1146.3999999999994,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86026.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",271,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.528,1148.9279999999994,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,272,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2757088.0,61440.0,8.0,1156.9279999999994,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86159.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",273,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.528,1159.4559999999994,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,274,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2757280.0,61440.0,7.84,1167.2959999999994,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86165.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",275,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.528,1169.8239999999994,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",276,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.816,1172.6399999999994,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",277,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.688,1175.3279999999995,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",278,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.032,1179.3599999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",279,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.688,1182.0479999999995,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",280,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.048,1184.0959999999995,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",281,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.688,1186.7839999999997,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",282,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.72,1189.5039999999997,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",283,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.0,1193.5039999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",284,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.688,1196.1919999999998,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",285,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.08,1198.2719999999997,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",286,49152.0,4412928.0,0,0,0.0,4412928.0,4412928.0,24960.0,48.0,0.9980806142034548,36864.0,12288.0,20.192,1218.4639999999997,3720192.0,594432.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,287,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2753728.0,61440.0,7.84,1226.3039999999996,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86054.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",288,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.464,1228.7679999999996,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",289,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.048,1230.8159999999996,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",290,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.08,1232.8959999999995,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",291,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.808,1236.7039999999995,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",292,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,1238.6879999999994,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",293,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,1240.7359999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",294,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.624,1243.3599999999994,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",295,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.624,1245.9839999999995,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",296,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11055360.0,64384.0,14.336,1260.3199999999995,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,345480.0,2012.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",297,141312.0,294912.0,0,0,0.0,294912.0,294912.0,0.0,192.0,0.0,49152.0,49152.0,2.272,1262.5919999999994,12288.0,0.0,141312.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",298,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11110016.0,67200.0,13.92,1276.5119999999995,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,347188.0,2100.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",299,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.336,1278.8479999999995,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,300,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,79104.0,0.826890756302521,10027008.0,98304.0,15.584,1294.4319999999996,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313344.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",301,0.0,27648.0,0,0,0.0,27648.0,27648.0,0.0,864.0,0.0,98304.0,12288.0,2.24,1296.6719999999996,24576.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",302,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.08,1298.7519999999995,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",303,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,1.984,1300.7359999999994,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",304,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.84,1304.5759999999993,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",305,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,1306.5599999999993,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",306,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,1308.6079999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",307,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.656,1311.2639999999992,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",308,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.656,1313.9199999999992,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,309,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2752576.0,61440.0,7.776,1321.6959999999992,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86018.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",310,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.528,1324.2239999999993,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,311,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2757216.0,61440.0,8.096,1332.3199999999993,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86163.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",312,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.592,1334.9119999999994,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,313,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2756448.0,61440.0,7.904,1342.8159999999993,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86139.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",314,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.528,1345.3439999999994,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",315,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.72,1348.0639999999994,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",316,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.656,1350.7199999999993,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",317,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.032,1354.7519999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",318,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.656,1357.4079999999992,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",319,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.016,1359.4239999999993,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",320,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.816,1362.2399999999993,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",321,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.624,1364.8639999999994,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",322,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.224,1369.0879999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",323,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.688,1371.7759999999994,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",324,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.048,1373.8239999999994,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",325,49152.0,4412928.0,0,0,0.0,4412928.0,4412928.0,24960.0,48.0,0.9980806142034548,36864.0,12288.0,20.064,1393.8879999999995,3720192.0,594432.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,326,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2754400.0,61440.0,8.0,1401.8879999999995,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86075.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",327,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.496,1404.3839999999996,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",328,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.08,1406.4639999999995,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",329,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.016,1408.4799999999996,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",330,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.872,1412.3519999999996,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",331,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,1414.3039999999996,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",332,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,1416.3199999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",333,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.752,1419.0719999999997,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",334,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.688,1421.7599999999998,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",335,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11057024.0,64832.0,14.08,1435.8399999999997,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,345532.0,2026.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",336,141312.0,294912.0,0,0,0.0,294912.0,294912.0,0.0,192.0,0.0,49152.0,49152.0,2.304,1438.1439999999998,12288.0,0.0,141312.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",337,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11072128.0,67488.0,13.824,1451.9679999999998,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,346004.0,2109.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",338,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.176,1454.1439999999998,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,339,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,79104.0,0.826890756302521,10027008.0,98304.0,15.456,1469.5999999999997,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313344.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",340,0.0,27648.0,0,0,0.0,27648.0,27648.0,0.0,864.0,0.0,98304.0,12288.0,2.176,1471.7759999999996,24576.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",341,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.112,1473.8879999999997,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",342,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,1.984,1475.8719999999996,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",343,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.84,1479.7119999999995,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",344,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,1481.6639999999995,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",345,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,1483.6479999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",346,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.72,1486.3679999999995,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",347,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.848,1489.2159999999994,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",348,98304000.0,217088000.0,0,0,0.0,217088000.0,217088000.0,1520000.0,1216000.0,0.5555555555555556,128067456.0,833312.0,109.504,1598.7199999999993,8192000.0,12288000.0,98304000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4002108.0,26041.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",349,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,1600.4479999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",350,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,64.0,128.0,2.688,1603.1359999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",351,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,1605.1199999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",352,0.0,128000.0,0,0,0.0,128000.0,128000.0,0.0,2000.0,0.0,512000.0,512000.0,2.592,1607.7119999999995,0.0,128000.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,16000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",353,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.76,1609.4719999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",354,0.0,0.0,0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,34496.0,3.584,1613.0559999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16128.0,1078.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",355,0.0,0.0,0,0,0.0,0.0,0.0,9472.0,34440.0,0.2157041355438149,2109440.0,0.0,4.48,1617.5359999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",356,0.0,0.0,0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,34176.0,3.584,1621.1199999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16128.0,1068.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",357,0.0,0.0,0,0,0.0,0.0,0.0,9472.0,35208.0,0.21199641897940913,2109440.0,0.0,4.48,1625.5999999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",358,0.0,0.0,0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,34176.0,3.424,1629.0239999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16128.0,1068.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",359,0.0,0.0,0,0,0.0,0.0,0.0,9472.0,34440.0,0.2157041355438149,2109440.0,0.0,4.384,1633.4079999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",360,0.0,0.0,0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,34880.0,3.488,1636.8959999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16128.0,1090.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",361,0.0,0.0,0,0,0.0,0.0,0.0,9472.0,34312.0,0.216334734149461,2109440.0,128.0,4.512,1641.4079999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,65920.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",362,0.0,0.0,0,0,0.0,0.0,0.0,0.0,12.0,0.0,4128.0,512.0,2.432,1643.8399999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,129.0,16.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",363,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.696,1645.5359999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",364,0.0,0.0,0,0,0.0,0.0,0.0,497.0,16.0,0.9688109161793372,512.0,0.0,3.392,1648.9279999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",365,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.664,1650.5919999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",366,0.0,0.0,0,0,0.0,0.0,0.0,497.0,16.0,0.9688109161793372,512.0,0.0,3.392,1653.9839999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",367,0.0,0.0,0,0,0.0,0.0,0.0,41472.0,8424.0,0.8311688311688312,527232.0,7392.0,5.728,1659.7119999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16476.0,231.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",368,0.0,0.0,0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,544.0,6.432,1666.1439999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,80.0,17.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",369,0.0,0.0,0,0,0.0,0.0,0.0,0.0,12000.0,0.0,520064.0,59296.0,3.776,1669.9199999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16252.0,1853.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",370,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3000.0,0.0,640000.0,0.0,2.752,1672.6719999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,20000.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",371,0.0,0.0,0,0,0.0,0.0,0.0,0.0,4000.0,0.0,0.0,1024000.0,2.368,1675.0399999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,32000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",372,0.0,0.0,0,0,0.0,0.0,0.0,98304.0,4000.0,0.960900844541758,512000.0,0.0,4.128,1679.1679999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",373,0.0,0.0,0,0,0.0,0.0,0.0,156.0,64.0,0.7090909090909091,8192.0,0.0,2.208,1681.3759999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",374,0.0,0.0,0,0,0.0,0.0,0.0,51858.0,19626.0,0.725449051536008,1903872.0,1289408.0,9.664,1691.0399999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,59496.0,40294.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",375,0.0,0.0,0,0,0.0,0.0,0.0,18654.0,19622.0,0.4873550005225206,1903232.0,1109792.0,8.064,1699.1039999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,59476.0,34681.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",376,0.0,0.0,0,0,0.0,0.0,0.0,15858.0,19768.0,0.44512434738674,1904512.0,1579008.0,8.032,1707.1359999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,59516.0,49344.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",377,0.0,0.0,0,0,0.0,0.0,0.0,15858.0,19755.0,0.44528683345969167,1895168.0,1203840.0,8.32,1715.4559999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,59224.0,37620.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",378,0.0,0.0,0,0,0.0,0.0,0.0,14336.0,4000.0,0.7818499127399651,1024000.0,0.0,3.872,1719.3279999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",379,0.0,0.0,0,0,0.0,0.0,0.0,39.0,16.0,0.7090909090909091,2048.0,0.0,2.24,1721.5679999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",380,0.0,0.0,0,0,0.0,0.0,0.0,13650.0,10458.0,0.5662020905923345,1270272.0,896672.0,6.592,1728.1599999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,39696.0,28021.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",381,0.0,0.0,0,0,0.0,0.0,0.0,0.0,16000.0,0.0,1548992.0,1536000.0,4.032,1732.1919999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48406.0,48000.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",382,1792000.0,4245120.0,0,0,0.0,4245120.0,4245120.0,528.0,5248.0,0.09141274238227147,1010432.0,512000.0,17.376,1749.5679999999998,533120.0,128000.0,1792000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,31576.0,16000.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",383,0.0,655488.0,0,0,0.0,655488.0,655488.0,71840.0,8000.0,0.8997995991983968,512000.0,512000.0,46.72,1796.2879999999998,655488.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,16000.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",384,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2000.0,0.0,512000.0,128000.0,2.848,1799.1359999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,4000.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",385,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,1.952,1801.0879999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",386,0.0,0.0,0,0,0.0,0.0,0.0,0.0,12000.0,0.0,1152000.0,54112.0,7.584,1808.6719999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,36000.0,1691.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",387,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3000.0,0.0,640000.0,0.0,2.912,1811.5839999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,20000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",388,1792000.0,4245120.0,0,0,0.0,4245120.0,4245120.0,528.0,5248.0,0.09141274238227147,1032320.0,512000.0,16.992,1828.5759999999998,533120.0,128000.0,1792000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32260.0,16000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",389,0.0,0.0,0,0,0.0,0.0,0.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,21.728,1850.3039999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",390,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.176,1852.4799999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",391,0.0,0.0,0,0,0.0,0.0,0.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,22.112,1874.5919999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",392,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.176,1876.7679999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",393,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.016,1878.7839999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",394,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.944,1881.7279999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",395,0.0,147456.0,0,0,0.0,147456.0,147456.0,320.0,1004.0,0.24169184290030213,512000.0,128.0,8.256,1889.984,147456.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",396,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.952,1891.936,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",397,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.2,1895.136,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",398,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,1897.184,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",399,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.976,1900.16,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",400,1152000.0,2560000.0,0,0,0.0,2560000.0,2560000.0,0.0,4000.0,0.0,0.0,512000.0,3.264,1903.424,0.0,256000.0,1152000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,16000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",401,640000.0,1280000.0,0,0,0.0,1280000.0,1280000.0,0.0,3000.0,0.0,1024000.0,0.0,4.064,1907.488,0.0,0.0,640000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",402,0.0,0.0,0,0,0.0,0.0,0.0,640.0,1004.0,0.38929440389294406,512000.0,128.0,11.52,1919.008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",403,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.016,1921.0240000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",404,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,1923.0400000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",405,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.24,1925.2800000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",406,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.048,1927.3280000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",407,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,64.0,128.0,2.656,1929.9840000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",408,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,1931.68,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",409,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,1933.376,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",410,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.08,1935.456,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",411,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,1937.1519999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",412,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,32.0,2.24,1939.3919999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",413,0.0,0.0,0,0,0.0,0.0,0.0,0.0,5.0,0.0,32.0,32.0,4.704,1944.0959999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",414,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.112,1946.2079999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",415,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,1948.2559999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",416,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.88,1951.136,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",417,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.2,1954.336,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",418,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.112,1956.448,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",419,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,1958.592,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",420,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,32.0,3.424,1962.016,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",421,0.0,0.0,0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,64.0,32.0,2.592,1964.6080000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",422,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.016,1966.6240000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",423,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,2.048,1968.6720000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",424,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,0.0,2.112,1970.7840000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",425,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,2.24,1973.0240000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",426,0.0,0.0,0,0,0.0,0.0,0.0,0.0,288.0,0.0,9408.0,12288.0,4.192,1977.2160000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,294.0,384.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",427,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,2.688,1979.9040000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",428,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,1983.1360000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",429,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,1985.6960000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",430,0.0,512.0,0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,2.048,1987.7440000000004,0.0,512.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",431,0.0,0.0,0,0,0.0,0.0,0.0,0.0,20.0,0.0,2048.0,2048.0,2.56,1990.3040000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",432,4096.0,9216.0,0,0,0.0,9216.0,9216.0,0.0,32.0,0.0,2048.0,2048.0,2.912,1993.2160000000003,0.0,1024.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",433,0.0,512.0,0,0,0.0,512.0,512.0,0.0,32.0,0.0,2048.0,2048.0,2.112,1995.3280000000004,0.0,512.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",434,3600.0,8224.0,0,0,0.0,8224.0,8224.0,0.0,32.0,0.0,2048.0,2048.0,2.816,1998.1440000000005,0.0,1024.0,3600.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",435,0.0,512.0,0,0,0.0,512.0,512.0,0.0,32.0,0.0,2048.0,2048.0,2.048,2000.1920000000005,0.0,512.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",436,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.176,2002.3680000000004,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",437,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.84,2006.2080000000003,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",438,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,2008.1920000000002,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",439,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,2010.1760000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",440,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.656,2012.832,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",441,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.656,2015.488,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,442,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2753024.0,61440.0,7.808,2023.296,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86032.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",443,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.464,2025.76,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,444,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2757888.0,61440.0,7.68,2033.44,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86184.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",445,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.528,2035.968,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,446,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2756896.0,61440.0,7.872,2043.8400000000001,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86153.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",447,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.656,2046.496,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",448,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.752,2049.248,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",449,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.752,2052.0,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",450,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,3.968,2055.968,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",451,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.688,2058.656,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",452,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.048,2060.7039999999997,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",453,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.72,2063.4239999999995,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",454,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.688,2066.1119999999996,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",455,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.0,2070.1119999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",456,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.752,2072.8639999999996,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",457,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.048,2074.9119999999994,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",458,0.0,0.0,0,0,0.0,0.0,0.0,0.0,240.0,0.0,24576.0,24576.0,2.592,2077.5039999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",459,0.0,0.0,0,0,0.0,0.0,0.0,0.0,240.0,0.0,24576.0,24576.0,2.592,2080.0959999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",460,49152.0,4414464.0,0,0,0.0,4414464.0,4414464.0,24960.0,48.0,0.9980806142034548,61440.0,12288.0,20.384,2100.4799999999996,3721728.0,594432.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,461,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2752096.0,61440.0,8.032,2108.5119999999997,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86003.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",462,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.528,2111.0399999999995,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",463,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.048,2113.0879999999993,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",464,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.08,2115.167999999999,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",465,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.872,2119.039999999999,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",466,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,2120.959999999999,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",467,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,2122.943999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",468,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.688,2125.631999999999,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",469,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.72,2128.351999999999,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",470,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11107840.0,64704.0,13.824,2142.175999999999,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,347120.0,2022.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",471,141312.0,294912.0,0,0,0.0,294912.0,294912.0,0.0,192.0,0.0,49152.0,49152.0,2.304,2144.479999999999,12288.0,0.0,141312.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",472,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11062528.0,67136.0,13.824,2158.303999999999,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,345704.0,2098.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",473,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.112,2160.4159999999993,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,474,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,79104.0,0.826890756302521,10027008.0,98304.0,15.584,2175.999999999999,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313344.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",475,0.0,27648.0,0,0,0.0,27648.0,27648.0,0.0,864.0,0.0,98304.0,12288.0,2.272,2178.271999999999,24576.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",476,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.08,2180.351999999999,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",477,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.048,2182.3999999999987,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",478,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.84,2186.239999999999,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",479,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,2188.191999999999,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",480,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2190.207999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",481,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.656,2192.863999999999,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",482,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.656,2195.519999999999,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,483,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2753856.0,61440.0,8.0,2203.519999999999,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86058.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",484,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.528,2206.047999999999,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,485,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2757312.0,61440.0,7.776,2213.8239999999987,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86166.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",486,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.496,2216.319999999999,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,487,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2757728.0,61440.0,7.904,2224.223999999999,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86179.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",488,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.528,2226.7519999999986,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",489,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.88,2229.6319999999987,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",490,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.656,2232.2879999999986,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",491,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.0,2236.2879999999986,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",492,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.752,2239.0399999999986,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",493,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.08,2241.1199999999985,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",494,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.688,2243.8079999999986,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",495,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.656,2246.4639999999986,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",496,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.064,2250.5279999999984,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",497,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.72,2253.2479999999982,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",498,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.016,2255.2639999999983,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",499,0.0,0.0,0,0,0.0,0.0,0.0,0.0,240.0,0.0,24576.0,24576.0,2.624,2257.887999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",500,0.0,0.0,0,0,0.0,0.0,0.0,0.0,240.0,0.0,24576.0,24576.0,2.624,2260.511999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",501,49152.0,4414464.0,0,0,0.0,4414464.0,4414464.0,24960.0,48.0,0.9980806142034548,61440.0,12288.0,20.288,2280.799999999998,3721728.0,594432.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,502,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2753824.0,61440.0,7.904,2288.703999999998,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86057.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",503,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.496,2291.199999999998,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",504,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.176,2293.375999999998,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",505,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.016,2295.391999999998,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",506,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.84,2299.231999999998,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",507,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,2301.1839999999984,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",508,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2303.1999999999985,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",509,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.688,2305.8879999999986,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",510,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.656,2308.5439999999985,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",511,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11083008.0,65696.0,14.112,2322.6559999999986,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,346344.0,2053.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",512,141312.0,294912.0,0,0,0.0,294912.0,294912.0,0.0,192.0,0.0,49152.0,49152.0,2.336,2324.9919999999984,12288.0,0.0,141312.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",513,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11101696.0,66016.0,13.472,2338.4639999999986,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,346928.0,2063.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",514,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.112,2340.5759999999987,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,515,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,79104.0,0.826890756302521,10027008.0,98304.0,15.552,2356.127999999999,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313344.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",516,0.0,27648.0,0,0,0.0,27648.0,27648.0,0.0,864.0,0.0,98304.0,12288.0,2.24,2358.3679999999986,24576.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",517,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.112,2360.4799999999987,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",518,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.016,2362.4959999999987,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",519,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.872,2366.3679999999986,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",520,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,2368.319999999999,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",521,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.176,2370.4959999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",522,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.688,2373.183999999999,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",523,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.848,2376.031999999999,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,524,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2753312.0,61440.0,7.904,2383.935999999999,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86041.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",525,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.496,2386.431999999999,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,526,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2756992.0,61440.0,7.712,2394.143999999999,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86156.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",527,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.432,2396.5759999999987,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,528,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2757376.0,61440.0,8.032,2404.607999999999,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86168.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",529,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.464,2407.0719999999988,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",530,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.688,2409.759999999999,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",531,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.592,2412.351999999999,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",532,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.064,2416.415999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",533,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.72,2419.1359999999986,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",534,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.08,2421.2159999999985,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",535,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.656,2423.8719999999985,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",536,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.656,2426.5279999999984,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",537,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.032,2430.5599999999986,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",538,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.688,2433.2479999999987,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",539,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.048,2435.2959999999985,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",540,0.0,0.0,0,0,0.0,0.0,0.0,0.0,240.0,0.0,24576.0,24576.0,2.656,2437.9519999999984,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",541,0.0,0.0,0,0,0.0,0.0,0.0,0.0,240.0,0.0,24576.0,24576.0,2.752,2440.7039999999984,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",542,49152.0,4414464.0,0,0,0.0,4414464.0,4414464.0,24960.0,48.0,0.9980806142034548,61440.0,12288.0,20.128,2460.8319999999985,3721728.0,594432.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,543,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2752640.0,61440.0,7.808,2468.6399999999985,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86020.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",544,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.496,2471.1359999999986,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",545,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.08,2473.2159999999985,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",546,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,1.952,2475.1679999999988,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",547,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.84,2479.007999999999,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",548,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,2480.959999999999,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",549,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,2483.007999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",550,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.688,2485.695999999999,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",551,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.688,2488.383999999999,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",552,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11079040.0,64736.0,14.208,2502.591999999999,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,346220.0,2023.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",553,141312.0,294912.0,0,0,0.0,294912.0,294912.0,0.0,192.0,0.0,49152.0,49152.0,2.304,2504.8959999999993,12288.0,0.0,141312.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",554,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11065344.0,68512.0,13.824,2518.7199999999993,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,345792.0,2141.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",555,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.112,2520.8319999999994,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,556,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,79104.0,0.826890756302521,10027008.0,98304.0,15.584,2536.4159999999993,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313344.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",557,0.0,27648.0,0,0,0.0,27648.0,27648.0,0.0,864.0,0.0,98304.0,12288.0,2.24,2538.655999999999,24576.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",558,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.112,2540.767999999999,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",559,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,1.984,2542.751999999999,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",560,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.808,2546.559999999999,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",561,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,2548.479999999999,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",562,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.952,2550.4319999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",563,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.688,2553.1199999999994,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",564,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.688,2555.8079999999995,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,565,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2753280.0,61440.0,7.648,2563.4559999999997,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86040.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",566,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.56,2566.0159999999996,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,567,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2757664.0,61440.0,7.744,2573.7599999999998,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86177.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",568,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.528,2576.2879999999996,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,569,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2757568.0,61440.0,7.712,2583.9999999999995,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86174.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",570,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.464,2586.4639999999995,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",571,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.656,2589.1199999999994,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",572,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.624,2591.7439999999992,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",573,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.064,2595.807999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",574,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.72,2598.527999999999,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",575,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.048,2600.5759999999987,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",576,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.72,2603.2959999999985,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",577,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.624,2605.9199999999983,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",578,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,3.968,2609.887999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",579,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.688,2612.575999999998,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",580,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.048,2614.623999999998,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",581,0.0,0.0,0,0,0.0,0.0,0.0,0.0,240.0,0.0,24576.0,24576.0,2.656,2617.279999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",582,0.0,0.0,0,0,0.0,0.0,0.0,0.0,240.0,0.0,24576.0,24576.0,2.624,2619.9039999999977,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",583,49152.0,4414464.0,0,0,0.0,4414464.0,4414464.0,24960.0,48.0,0.9980806142034548,61440.0,12288.0,20.224,2640.127999999998,3721728.0,594432.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,584,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2752960.0,61440.0,7.744,2647.871999999998,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86030.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",585,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.464,2650.335999999998,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",586,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.048,2652.3839999999977,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",587,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.08,2654.4639999999977,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",588,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.84,2658.303999999998,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",589,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,2660.2879999999977,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",590,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2662.303999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",591,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.624,2664.9279999999976,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",592,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.688,2667.6159999999977,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",593,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11057664.0,64576.0,13.888,2681.5039999999976,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,345552.0,2018.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",594,141312.0,294912.0,0,0,0.0,294912.0,294912.0,0.0,192.0,0.0,49152.0,49152.0,2.304,2683.8079999999977,12288.0,0.0,141312.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",595,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11133312.0,66688.0,13.408,2697.2159999999976,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,347916.0,2084.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",596,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.176,2699.3919999999976,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,597,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,79104.0,0.826890756302521,10027008.0,98304.0,15.552,2714.9439999999977,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313344.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",598,0.0,27648.0,0,0,0.0,27648.0,27648.0,0.0,864.0,0.0,98304.0,12288.0,2.272,2717.2159999999976,24576.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",599,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.08,2719.2959999999975,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",600,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.048,2721.3439999999973,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",601,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.872,2725.215999999997,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",602,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,2727.1359999999972,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",603,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,2729.119999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",604,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.688,2731.8079999999973,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",605,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.688,2734.4959999999974,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,606,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2753696.0,61440.0,7.808,2742.3039999999974,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86053.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",607,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.496,2744.7999999999975,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,608,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2758368.0,61440.0,7.744,2752.5439999999976,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86199.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",609,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.432,2754.9759999999974,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,610,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2757312.0,61440.0,7.68,2762.655999999997,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86166.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",611,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.464,2765.119999999997,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",612,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.752,2767.871999999997,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",613,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.656,2770.527999999997,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",614,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.032,2774.559999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",615,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.688,2777.2479999999973,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",616,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.08,2779.3279999999972,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",617,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.656,2781.983999999997,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",618,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.656,2784.639999999997,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",619,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.032,2788.6719999999973,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",620,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.752,2791.4239999999972,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",621,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.08,2793.503999999997,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",622,0.0,0.0,0,0,0.0,0.0,0.0,0.0,240.0,0.0,24576.0,24576.0,2.624,2796.127999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",623,0.0,0.0,0,0,0.0,0.0,0.0,0.0,240.0,0.0,24576.0,24576.0,2.592,2798.719999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",624,49152.0,4414464.0,0,0,0.0,4414464.0,4414464.0,24960.0,48.0,0.9980806142034548,61440.0,12288.0,20.064,2818.783999999997,3721728.0,594432.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,625,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2752768.0,61440.0,7.84,2826.623999999997,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86024.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",626,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.656,2829.279999999997,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",627,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.08,2831.359999999997,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",628,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.016,2833.375999999997,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",629,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.872,2837.247999999997,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",630,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,2839.199999999997,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",631,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2841.215999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",632,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.688,2843.9039999999973,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",633,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.656,2846.559999999997,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",634,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11035904.0,67808.0,14.4,2860.9599999999973,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,344872.0,2119.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",635,141312.0,294912.0,0,0,0.0,294912.0,294912.0,0.0,192.0,0.0,49152.0,49152.0,2.304,2863.2639999999974,12288.0,0.0,141312.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",636,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11027712.0,66432.0,14.176,2877.4399999999973,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,344616.0,2076.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",637,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.176,2879.6159999999973,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,638,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,79104.0,0.826890756302521,10027008.0,98304.0,15.392,2895.007999999997,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313344.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",639,0.0,27648.0,0,0,0.0,27648.0,27648.0,0.0,864.0,0.0,98304.0,12288.0,2.176,2897.183999999997,24576.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",640,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.08,2899.263999999997,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",641,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,1.984,2901.247999999997,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",642,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.808,2905.055999999997,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",643,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,2906.975999999997,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",644,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2908.991999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",645,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.784,2911.775999999997,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",646,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.72,2914.495999999997,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,647,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2753728.0,61440.0,7.84,2922.335999999997,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86054.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",648,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.528,2924.863999999997,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,649,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2757216.0,61440.0,7.936,2932.799999999997,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86163.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",650,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.464,2935.263999999997,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,651,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2755456.0,61440.0,7.648,2942.911999999997,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86108.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",652,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.656,2945.567999999997,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",653,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.752,2948.319999999997,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",654,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.624,2950.943999999997,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",655,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.0,2954.943999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",656,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.752,2957.6959999999967,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",657,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.112,2959.807999999997,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",658,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.72,2962.5279999999966,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",659,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.592,2965.1199999999967,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",660,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.064,2969.1839999999966,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",661,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.752,2971.9359999999965,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",662,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.112,2974.0479999999966,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",663,0.0,0.0,0,0,0.0,0.0,0.0,0.0,240.0,0.0,24576.0,24576.0,2.624,2976.6719999999964,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",664,0.0,0.0,0,0,0.0,0.0,0.0,0.0,240.0,0.0,24576.0,24576.0,2.656,2979.3279999999963,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",665,49152.0,4414464.0,0,0,0.0,4414464.0,4414464.0,24960.0,48.0,0.9980806142034548,61440.0,12288.0,20.256,2999.583999999996,3721728.0,594432.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,666,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2753312.0,61440.0,7.904,3007.487999999996,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86041.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",667,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.464,3009.951999999996,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",668,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.112,3012.063999999996,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",669,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.08,3014.143999999996,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",670,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.904,3018.047999999996,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",671,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,3019.9999999999964,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",672,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,3022.143999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",673,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.784,3024.9279999999962,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",674,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.656,3027.583999999996,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",675,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11048064.0,66176.0,14.4,3041.9839999999963,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,345252.0,2068.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",676,141312.0,294912.0,0,0,0.0,294912.0,294912.0,0.0,192.0,0.0,49152.0,49152.0,2.4,3044.3839999999964,12288.0,0.0,141312.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",677,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11157120.0,66432.0,13.792,3058.1759999999963,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,348660.0,2076.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",678,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.144,3060.319999999996,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,679,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,79104.0,0.826890756302521,10027008.0,98304.0,15.488,3075.807999999996,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313344.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",680,0.0,27648.0,0,0,0.0,27648.0,27648.0,0.0,864.0,0.0,98304.0,12288.0,2.24,3078.0479999999957,24576.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",681,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.112,3080.1599999999958,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",682,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,1.984,3082.1439999999957,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",683,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.936,3086.079999999996,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",684,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,3088.031999999996,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",685,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,3090.079999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",686,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.72,3092.7999999999956,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",687,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.656,3095.4559999999956,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,688,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2752800.0,61440.0,7.68,3103.1359999999954,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86025.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",689,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.464,3105.5999999999954,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,690,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2758208.0,61440.0,7.776,3113.375999999995,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86194.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",691,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.464,3115.839999999995,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,692,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2757024.0,61440.0,7.776,3123.615999999995,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86157.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",693,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.688,3126.303999999995,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",694,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.72,3129.023999999995,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",695,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.784,3131.807999999995,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",696,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.064,3135.871999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",697,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.688,3138.559999999995,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",698,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.016,3140.575999999995,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",699,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.656,3143.231999999995,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",700,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.624,3145.8559999999948,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",701,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.032,3149.887999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",702,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.72,3152.6079999999947,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",703,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.08,3154.6879999999946,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",704,0.0,0.0,0,0,0.0,0.0,0.0,0.0,240.0,0.0,24576.0,24576.0,2.656,3157.3439999999946,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",705,0.0,0.0,0,0,0.0,0.0,0.0,0.0,240.0,0.0,24576.0,24576.0,2.592,3159.9359999999947,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",706,49152.0,4414464.0,0,0,0.0,4414464.0,4414464.0,24960.0,48.0,0.9980806142034548,61440.0,12288.0,20.224,3180.159999999995,3721728.0,594432.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,707,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2753184.0,61440.0,7.744,3187.903999999995,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86037.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",708,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.528,3190.431999999995,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",709,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.176,3192.6079999999947,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",710,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.016,3194.623999999995,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",711,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.872,3198.4959999999946,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",712,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,3200.447999999995,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",713,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,3202.431999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",714,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.688,3205.119999999995,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",715,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.816,3207.9359999999947,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",716,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11087872.0,66048.0,13.984,3221.9199999999946,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,346496.0,2064.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",717,141312.0,294912.0,0,0,0.0,294912.0,294912.0,0.0,192.0,0.0,49152.0,49152.0,2.336,3224.2559999999944,12288.0,0.0,141312.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",718,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11114752.0,66432.0,13.824,3238.0799999999945,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,347336.0,2076.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",719,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.112,3240.1919999999946,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,720,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,79104.0,0.826890756302521,10027008.0,98304.0,15.552,3255.7439999999947,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313344.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",721,0.0,27648.0,0,0,0.0,27648.0,27648.0,0.0,864.0,0.0,98304.0,12288.0,2.208,3257.9519999999948,24576.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",722,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.016,3259.967999999995,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",723,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.048,3262.0159999999946,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",724,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.84,3265.8559999999948,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",725,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,3267.8399999999947,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",726,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,3269.8879999999945,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",727,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.752,3272.6399999999944,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",728,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.72,3275.359999999994,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,729,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2752832.0,61440.0,7.68,3283.039999999994,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86026.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",730,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.56,3285.599999999994,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,731,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2752352.0,61440.0,7.68,3293.279999999994,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86011.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",732,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.56,3295.839999999994,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,733,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2755296.0,61440.0,8.032,3303.871999999994,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86103.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",734,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.496,3306.367999999994,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",735,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.72,3309.087999999994,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",736,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.656,3311.743999999994,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",737,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.032,3315.775999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",738,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.624,3318.3999999999937,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",739,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.048,3320.4479999999935,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",740,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.72,3323.1679999999933,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",741,0.0,1536.0,0,0,0.0,1536.0,1536.0,0.0,96.0,0.0,6144.0,6144.0,2.688,3325.8559999999934,1536.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",742,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,12288.0,12288.0,4.0,3329.8559999999934,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",743,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,18432.0,12288.0,2.688,3332.5439999999935,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",744,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.08,3334.6239999999934,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",745,0.0,0.0,0,0,0.0,0.0,0.0,0.0,240.0,0.0,24576.0,24576.0,2.624,3337.247999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",746,0.0,0.0,0,0,0.0,0.0,0.0,0.0,240.0,0.0,24576.0,24576.0,2.592,3339.8399999999933,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",747,49152.0,4414464.0,0,0,0.0,4414464.0,4414464.0,24960.0,48.0,0.9980806142034548,61440.0,12288.0,20.288,3360.1279999999933,3721728.0,594432.0,49152.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
ampere_sgemm_32x32_sliced1x4_tn,748,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,22080.0,0.8516129032258064,2753568.0,61440.0,7.872,3367.999999999993,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,86049.0,1920.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",749,0.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,61440.0,12288.0,2.56,3370.559999999993,15360.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1920.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",750,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.144,3372.703999999993,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",751,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.016,3374.719999999993,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",752,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.808,3378.527999999993,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",753,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,3380.447999999993,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",754,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.952,3382.3999999999933,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",755,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.656,3385.055999999993,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",756,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.688,3387.7439999999933,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",757,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11089792.0,66560.0,14.016,3401.7599999999934,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,346556.0,2080.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",758,141312.0,294912.0,0,0,0.0,294912.0,294912.0,0.0,192.0,0.0,49152.0,49152.0,2.336,3404.095999999993,12288.0,0.0,141312.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",759,9437184.0,20840448.0,0,0,0.0,20840448.0,20840448.0,145920.0,116736.0,0.5555555555555556,11123328.0,64800.0,13.568,3417.6639999999934,786432.0,1179648.0,9437184.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,347604.0,2025.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",760,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.144,3419.807999999993,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,761,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,79104.0,0.826890756302521,10027008.0,98304.0,15.584,3435.391999999993,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,313344.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",762,0.0,27648.0,0,0,0.0,27648.0,27648.0,0.0,864.0,0.0,98304.0,12288.0,2.208,3437.599999999993,24576.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",763,3072.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.08,3439.679999999993,0.0,0.0,3072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",764,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.016,3441.695999999993,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",765,0.0,7556.0,0,0,0.0,7556.0,7556.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.872,3445.567999999993,7552.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",766,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,3447.519999999993,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",767,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,3449.503999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",768,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,12672.0,12288.0,2.72,3452.223999999993,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",769,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,288.0,0.0,24576.0,12288.0,2.688,3454.911999999993,0.0,3072.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",770,98304000.0,217088000.0,0,0,0.0,217088000.0,217088000.0,1520000.0,1216000.0,0.5555555555555556,127810688.0,826560.0,107.52,3562.431999999993,8192000.0,12288000.0,98304000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3994084.0,25830.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",771,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,3564.127999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",772,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,96.0,160.0,2.592,3566.719999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",773,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,3568.799999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",774,0.0,128000.0,0,0,0.0,128000.0,128000.0,0.0,2000.0,0.0,512000.0,512000.0,2.656,3571.455999999993,0.0,128000.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,16000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",775,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,3573.1519999999928,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",776,0.0,0.0,0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,37504.0,3.776,3576.9279999999926,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16128.0,1172.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",777,0.0,0.0,0,0,0.0,0.0,0.0,9472.0,34440.0,0.2157041355438149,2109440.0,0.0,4.288,3581.2159999999926,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",778,0.0,0.0,0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,37504.0,3.488,3584.7039999999924,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16128.0,1172.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",779,0.0,0.0,0,0,0.0,0.0,0.0,9472.0,35208.0,0.21199641897940913,2109440.0,0.0,4.256,3588.9599999999923,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",780,0.0,0.0,0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,37376.0,3.776,3592.735999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16128.0,1168.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",781,0.0,0.0,0,0,0.0,0.0,0.0,9472.0,34376.0,0.2160189746396643,2109440.0,0.0,4.448,3597.183999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",782,0.0,0.0,0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,37760.0,3.52,3600.703999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16128.0,1180.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",783,0.0,0.0,0,0,0.0,0.0,0.0,9472.0,34760.0,0.21414360643877736,2109440.0,128.0,4.416,3605.119999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,65920.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",784,0.0,0.0,0,0,0.0,0.0,0.0,0.0,12.0,0.0,4128.0,512.0,2.4,3607.5199999999923,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,129.0,16.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",785,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.664,3609.1839999999925,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",786,0.0,0.0,0,0,0.0,0.0,0.0,497.0,16.0,0.9688109161793372,512.0,0.0,3.52,3612.7039999999924,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",787,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.728,3614.4319999999925,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",788,0.0,0.0,0,0,0.0,0.0,0.0,497.0,16.0,0.9688109161793372,512.0,0.0,3.456,3617.8879999999926,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",789,0.0,0.0,0,0,0.0,0.0,0.0,32832.0,8424.0,0.7958115183246073,527232.0,7360.0,5.92,3623.8079999999927,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16476.0,230.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",790,0.0,0.0,0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,544.0,6.432,3630.2399999999925,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,80.0,17.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",791,0.0,0.0,0,0,0.0,0.0,0.0,0.0,12000.0,0.0,520064.0,58464.0,3.84,3634.0799999999927,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16252.0,1827.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",792,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3000.0,0.0,640000.0,0.0,2.816,3636.8959999999925,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,20000.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",793,0.0,0.0,0,0,0.0,0.0,0.0,0.0,4000.0,0.0,0.0,1024000.0,2.272,3639.1679999999924,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,32000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",794,0.0,0.0,0,0,0.0,0.0,0.0,98304.0,4000.0,0.960900844541758,512000.0,0.0,4.128,3643.2959999999925,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",795,0.0,0.0,0,0,0.0,0.0,0.0,156.0,64.0,0.7090909090909091,8192.0,0.0,2.208,3645.5039999999926,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",796,0.0,0.0,0,0,0.0,0.0,0.0,51858.0,19346.0,0.7283017807988316,1905152.0,1296352.0,9.792,3655.2959999999925,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,59536.0,40511.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",797,0.0,0.0,0,0,0.0,0.0,0.0,15054.0,19588.0,0.4345592055885919,1888256.0,1579008.0,7.616,3662.9119999999925,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,59008.0,49344.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",798,0.0,0.0,0,0,0.0,0.0,0.0,15858.0,19583.0,0.44744787110973167,1905920.0,1579008.0,8.416,3671.3279999999927,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,59560.0,49344.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",799,0.0,0.0,0,0,0.0,0.0,0.0,15858.0,19633.0,0.4468175030289369,1897984.0,1205056.0,8.416,3679.743999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,59312.0,37658.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",800,0.0,0.0,0,0,0.0,0.0,0.0,14336.0,4000.0,0.7818499127399651,1024000.0,0.0,3.872,3683.6159999999927,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",801,0.0,0.0,0,0,0.0,0.0,0.0,39.0,16.0,0.7090909090909091,2048.0,0.0,2.176,3685.7919999999926,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",802,0.0,0.0,0,0,0.0,0.0,0.0,13650.0,10428.0,0.5669075504610017,1271296.0,889056.0,6.72,3692.5119999999924,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,39728.0,27783.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",803,0.0,0.0,0,0,0.0,0.0,0.0,0.0,16000.0,0.0,1549248.0,1536000.0,4.128,3696.6399999999926,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48414.0,48000.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",804,1792000.0,4245120.0,0,0,0.0,4245120.0,4245120.0,528.0,5248.0,0.09141274238227147,1026304.0,512000.0,17.152,3713.7919999999926,533120.0,128000.0,1792000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32072.0,16000.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",805,0.0,655488.0,0,0,0.0,655488.0,655488.0,71840.0,8000.0,0.8997995991983968,512000.0,512000.0,46.944,3760.7359999999926,655488.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,16000.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",806,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2000.0,0.0,512000.0,128000.0,2.72,3763.4559999999924,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,4000.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",807,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,1.92,3765.3759999999925,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",808,0.0,0.0,0,0,0.0,0.0,0.0,0.0,12000.0,0.0,1152000.0,55520.0,7.488,3772.8639999999923,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,36000.0,1735.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",809,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3000.0,0.0,640000.0,0.0,2.912,3775.775999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,20000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",810,1792000.0,4245120.0,0,0,0.0,4245120.0,4245120.0,528.0,5248.0,0.09141274238227147,1009792.0,512000.0,17.088,3792.8639999999923,533120.0,128000.0,1792000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,31556.0,16000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",811,0.0,0.0,0,0,0.0,0.0,0.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,21.984,3814.847999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",812,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,3816.991999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",813,0.0,0.0,0,0,0.0,0.0,0.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,22.08,3839.071999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",814,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,3841.2159999999917,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",815,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.048,3843.2639999999915,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",816,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.976,3846.2399999999916,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",817,0.0,147456.0,0,0,0.0,147456.0,147456.0,320.0,1004.0,0.24169184290030213,512000.0,128.0,8.192,3854.4319999999916,147456.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",818,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,3856.5119999999915,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",819,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.2,3859.7119999999913,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",820,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,3861.7279999999914,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",821,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.976,3864.7039999999915,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",822,1152000.0,2560000.0,0,0,0.0,2560000.0,2560000.0,0.0,4000.0,0.0,0.0,512000.0,3.232,3867.9359999999915,0.0,256000.0,1152000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,16000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",823,640000.0,1280000.0,0,0,0.0,1280000.0,1280000.0,0.0,3000.0,0.0,1024000.0,0.0,4.064,3871.9999999999914,0.0,0.0,640000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",824,0.0,0.0,0,0,0.0,0.0,0.0,640.0,1004.0,0.38929440389294406,512000.0,128.0,11.68,3883.679999999991,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",825,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.016,3885.6959999999913,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",826,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,3887.775999999991,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",827,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.272,3890.047999999991,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",828,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.048,3892.095999999991,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",829,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,96.0,160.0,2.624,3894.7199999999907,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",830,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,3896.4159999999906,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",831,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.664,3898.079999999991,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",832,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.048,3900.1279999999906,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",833,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,3901.8239999999905,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",834,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,128.0,32.0,2.304,3904.1279999999906,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",835,0.0,0.0,0,0,0.0,0.0,0.0,0.0,5.0,0.0,32.0,32.0,4.8,3908.927999999991,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",836,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.08,3911.0079999999907,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",837,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,3912.9919999999906,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",838,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.688,3915.6799999999907,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",839,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.2,3918.8799999999906,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",840,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,3920.9599999999905,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
