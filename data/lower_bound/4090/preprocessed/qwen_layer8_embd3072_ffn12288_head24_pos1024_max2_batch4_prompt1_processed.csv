Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.001824,0.001824,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.001696,0.00352,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",3,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,0.0024,0.00592,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",4,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003392,0.009312,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",5,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003296,0.012608000000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",6,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002144,0.014752000000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",7,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.00176,0.016512000000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",8,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.001664,0.018176,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",9,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,0.001664,0.01984,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",10,0.0,0.0,0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,0.002432,0.022272,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",11,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.001984,0.024256,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",12,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002112,0.026368,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",13,0.0,0.0,0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,32.0,32.0,0.002464,0.028832,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.001984,0.030816,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",15,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002112,0.032928,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",16,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,0.002048,0.034976,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",17,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1152.0,0.0,13056.0,49152.0,0.003808,0.038784,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,408.0,1536.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",18,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002624,0.041408,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",19,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00336,0.044768,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",20,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002528,0.047296000000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",21,0.0,512.0,0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,0.001984,0.049280000000000004,0.0,512.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",22,0.0,0.0,0,0,0.0,0.0,0.0,0.0,20.0,0.0,2048.0,2048.0,0.00256,0.051840000000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",23,4096.0,9216.0,0,0,0.0,9216.0,9216.0,0.0,32.0,0.0,2048.0,2048.0,0.00304,0.054880000000000005,0.0,1024.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",24,0.0,512.0,0,0,0.0,512.0,512.0,0.0,32.0,0.0,2048.0,2048.0,0.00208,0.056960000000000004,0.0,512.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",25,3584.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,32.0,0.0,2048.0,2048.0,0.00288,0.059840000000000004,0.0,1024.0,3584.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",26,0.0,512.0,0,0,0.0,512.0,512.0,0.0,32.0,0.0,2048.0,2048.0,0.002016,0.061856,0.0,512.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",27,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.001984,0.06384000000000001,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",28,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.005088,0.068928,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",29,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,0.001888,0.070816,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",30,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.001984,0.0728,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",31,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,0.002656,0.07545600000000001,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",32,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,0.00272,0.07817600000000001,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_128x32_sliced1x4_tn,33,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,318720.0,0.7764309764309765,41949664.0,245760.0,0.048032,0.12620800000000001,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1310927.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",34,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,0.00272,0.12892800000000001,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
ampere_sgemm_128x32_sliced1x4_tn,35,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,318720.0,0.7764309764309765,41950688.0,245760.0,0.048,0.17692800000000003,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1310959.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",36,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,0.002688,0.17961600000000003,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
ampere_sgemm_128x32_sliced1x4_tn,37,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,318720.0,0.7764309764309765,41953504.0,245760.0,0.048128,0.22774400000000003,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1311047.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",38,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,0.00288,0.23062400000000002,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",39,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.002656,0.23328000000000002,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",40,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,0.002656,0.235936,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",41,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,0.003968,0.239904,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",42,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.002688,0.242592,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",43,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002048,0.24464,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",44,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.002624,0.24726399999999998,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",45,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,0.00256,0.249824,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",46,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,0.004128,0.253952,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",47,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.002816,0.256768,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",48,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002144,0.258912,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",49,196608.0,17651712.0,0,0,0.0,17651712.0,17651712.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,0.020512,0.27942399999999995,14880768.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,50,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,0.049408,0.32883199999999996,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",51,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,0.00256,0.33139199999999996,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",52,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002112,0.33350399999999997,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",53,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.002016,0.33552,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",54,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.005056,0.340576,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",55,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,0.001984,0.34256,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",56,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002048,0.34460799999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",57,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,0.002592,0.34719999999999995,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",58,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,0.002688,0.349888,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",59,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,203310720.0,295680.0,0.168128,0.518016,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6353460.0,9240.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",60,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,0.002368,0.5203840000000001,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",61,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,206788864.0,306240.0,0.16848,0.688864,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6462152.0,9570.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",62,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,0.002336,0.6912,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_128x32_sliced1x4_tn,63,1245708288.0,2503802880.0,0,0,0.0,2503802880.0,2503802880.0,4344192.0,1261440.0,0.7749691738594328,169292736.0,884736.0,0.202528,0.8937280000000001,5308416.0,7077888.0,1245708288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5290398.0,27648.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",64,0.0,233472.0,0,0,0.0,233472.0,233472.0,0.0,7296.0,0.0,884736.0,49152.0,0.003712,0.8974400000000001,221184.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,27648.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",65,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002048,0.8994880000000002,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",66,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.002048,0.9015360000000002,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",67,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.00512,0.9066560000000002,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",68,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,0.00192,0.9085760000000003,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",69,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.001984,0.9105600000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",70,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,0.002624,0.9131840000000002,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",71,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,0.002624,0.9158080000000002,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_128x32_sliced1x4_tn,72,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,318720.0,0.7764309764309765,41961152.0,245760.0,0.04816,0.9639680000000002,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1311286.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",73,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,0.003008,0.9669760000000002,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
ampere_sgemm_128x32_sliced1x4_tn,74,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,318720.0,0.7764309764309765,41946464.0,245760.0,0.048064,1.0150400000000002,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1310827.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",75,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,0.002752,1.0177920000000003,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
ampere_sgemm_128x32_sliced1x4_tn,76,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,318720.0,0.7764309764309765,41945664.0,245760.0,0.04848,1.0662720000000003,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1310802.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",77,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,0.002688,1.0689600000000004,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",78,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.002624,1.0715840000000003,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",79,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,0.00256,1.0741440000000002,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",80,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,0.004,1.0781440000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",81,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.002688,1.0808320000000002,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",82,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002112,1.0829440000000001,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",83,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.002656,1.0856000000000001,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",84,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,0.002592,1.088192,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",85,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,0.003968,1.09216,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",86,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.002688,1.094848,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",87,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.00208,1.0969280000000001,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",88,196608.0,17651712.0,0,0,0.0,17651712.0,17651712.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,0.020416,1.1173440000000001,14880768.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,89,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,0.049056,1.1664,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",90,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,0.002432,1.168832,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",91,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.00208,1.1709120000000002,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",92,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.001984,1.1728960000000002,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",93,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.005056,1.177952,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",94,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,0.00192,1.179872,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",95,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.001984,1.181856,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",96,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,0.002656,1.184512,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",97,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,0.002656,1.187168,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",98,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,206557696.0,301888.0,0.168608,1.355776,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6454928.0,9434.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",99,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,0.002464,1.3582400000000001,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",100,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,205148800.0,303520.0,0.168544,1.5267840000000001,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6410900.0,9485.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",101,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,0.002528,1.5293120000000002,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_128x32_sliced1x4_tn,102,1245708288.0,2503802880.0,0,0,0.0,2503802880.0,2503802880.0,4344192.0,1261440.0,0.7749691738594328,169258464.0,884736.0,0.203424,1.7327360000000003,5308416.0,7077888.0,1245708288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5289327.0,27648.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",103,0.0,233472.0,0,0,0.0,233472.0,233472.0,0.0,7296.0,0.0,884736.0,49152.0,0.00368,1.7364160000000002,221184.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,27648.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",104,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002112,1.738528,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",105,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.002016,1.740544,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",106,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.005088,1.745632,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",107,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,0.00192,1.747552,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",108,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.001984,1.749536,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",109,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,0.002624,1.75216,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",110,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,0.00272,1.75488,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_128x32_sliced1x4_tn,111,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,318720.0,0.7764309764309765,41947264.0,245760.0,0.048352,1.803232,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1310852.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",112,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,0.002976,1.806208,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
ampere_sgemm_128x32_sliced1x4_tn,113,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,318720.0,0.7764309764309765,41953792.0,245760.0,0.048448,1.854656,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1311056.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",114,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,0.00272,1.8573760000000001,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
ampere_sgemm_128x32_sliced1x4_tn,115,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,318720.0,0.7764309764309765,41950400.0,245760.0,0.04848,1.9058560000000002,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1310950.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",116,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,0.002848,1.9087040000000002,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",117,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.002656,1.9113600000000002,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",118,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,0.002592,1.913952,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",119,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,0.003936,1.917888,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",120,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.002816,1.920704,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",121,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002112,1.9228159999999999,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",122,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.002656,1.9254719999999999,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",123,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,0.00256,1.9280319999999997,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",124,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,0.004032,1.9320639999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",125,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.002688,1.9347519999999998,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",126,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002368,1.9371199999999997,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",127,196608.0,17651712.0,0,0,0.0,17651712.0,17651712.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,0.020384,1.9575039999999997,14880768.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,128,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,0.051776,2.0092799999999995,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",129,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,0.002464,2.0117439999999993,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",130,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.00208,2.013823999999999,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",131,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.001984,2.0158079999999994,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",132,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.005088,2.0208959999999996,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",133,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,0.001888,2.0227839999999997,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",134,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.001984,2.024768,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",135,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,0.002592,2.02736,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",136,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,0.00272,2.03008,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",137,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,205026304.0,294240.0,0.167968,2.198048,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6407072.0,9195.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",138,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,0.0024,2.200448,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",139,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,205802240.0,303104.0,0.16928,2.3697280000000003,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6431320.0,9472.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",140,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,0.00256,2.372288,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_128x32_sliced1x4_tn,141,1245708288.0,2503802880.0,0,0,0.0,2503802880.0,2503802880.0,4344192.0,1261440.0,0.7749691738594328,169265408.0,884736.0,0.20288,2.575168,5308416.0,7077888.0,1245708288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5289544.0,27648.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",142,0.0,233472.0,0,0,0.0,233472.0,233472.0,0.0,7296.0,0.0,884736.0,49152.0,0.003744,2.5789120000000003,221184.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,27648.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",143,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.00208,2.580992,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",144,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.00208,2.583072,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",145,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.00512,2.588192,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",146,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,0.00192,2.590112,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",147,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.001984,2.592096,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",148,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,0.002688,2.594784,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",149,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,0.002656,2.59744,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_128x32_sliced1x4_tn,150,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,318720.0,0.7764309764309765,41955648.0,245760.0,0.048128,2.6455680000000004,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1311114.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",151,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,0.002752,2.6483200000000005,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
ampere_sgemm_128x32_sliced1x4_tn,152,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,318720.0,0.7764309764309765,41963968.0,245760.0,0.048352,2.6966720000000004,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1311374.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",153,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,0.002816,2.6994880000000006,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
ampere_sgemm_128x32_sliced1x4_tn,154,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,318720.0,0.7764309764309765,41956256.0,245760.0,0.047872,2.7473600000000005,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1311133.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",155,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,0.002752,2.7501120000000006,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",156,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.002656,2.7527680000000005,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",157,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,0.002528,2.7552960000000004,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",158,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,0.003968,2.7592640000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",159,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.00272,2.7619840000000004,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",160,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.00208,2.7640640000000003,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",161,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.002688,2.7667520000000003,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",162,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,0.002688,2.7694400000000003,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",163,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,0.003968,2.7734080000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",164,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.002752,2.7761600000000004,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",165,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002112,2.7782720000000003,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",166,196608.0,17651712.0,0,0,0.0,17651712.0,17651712.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,0.020352,2.7986240000000002,14880768.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,167,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,0.049664,2.848288,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",168,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,0.002464,2.850752,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",169,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.00208,2.852832,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",170,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.002016,2.8548479999999996,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",171,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.005088,2.859936,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",172,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,0.001888,2.861824,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",173,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.001952,2.863776,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",174,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,0.002688,2.866464,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",175,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,0.002656,2.86912,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",176,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,204164096.0,299904.0,0.169248,3.038368,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6380128.0,9372.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",177,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,0.002432,3.0408000000000004,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",178,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,205932928.0,305568.0,0.169696,3.2104960000000005,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6435404.0,9549.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",179,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,0.002464,3.2129600000000003,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_128x32_sliced1x4_tn,180,1245708288.0,2503802880.0,0,0,0.0,2503802880.0,2503802880.0,4344192.0,1261440.0,0.7749691738594328,169290496.0,884736.0,0.20336,3.4163200000000002,5308416.0,7077888.0,1245708288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5290328.0,27648.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",181,0.0,233472.0,0,0,0.0,233472.0,233472.0,0.0,7296.0,0.0,884736.0,49152.0,0.003712,3.4200320000000004,221184.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,27648.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",182,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002112,3.4221440000000003,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",183,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.001984,3.4241280000000005,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",184,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.00496,3.4290880000000006,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",185,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,0.002016,3.4311040000000004,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",186,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00208,3.4331840000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",187,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,0.002624,3.435808,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",188,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,0.002752,3.4385600000000003,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_128x32_sliced1x4_tn,189,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,318720.0,0.7764309764309765,41952928.0,245760.0,0.048288,3.486848,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1311029.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",190,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,0.00272,3.4895680000000002,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
ampere_sgemm_128x32_sliced1x4_tn,191,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,318720.0,0.7764309764309765,41944640.0,245760.0,0.047712,3.5372800000000004,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1310770.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",192,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,0.002912,3.5401920000000002,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
ampere_sgemm_128x32_sliced1x4_tn,193,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,318720.0,0.7764309764309765,41960128.0,245760.0,0.048384,3.588576,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1311254.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",194,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,0.00272,3.5912960000000003,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",195,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.002784,3.5940800000000004,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",196,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,0.002624,3.5967040000000003,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",197,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,0.004,3.6007040000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",198,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.00272,3.6034240000000004,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",199,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.00208,3.6055040000000003,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",200,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.002752,3.6082560000000004,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",201,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,0.002592,3.6108480000000003,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",202,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,0.004,3.6148480000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",203,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.002656,3.6175040000000003,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",204,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.00208,3.619584,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",205,196608.0,17651712.0,0,0,0.0,17651712.0,17651712.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,0.0208,3.640384,14880768.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,206,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,0.050336,3.6907200000000002,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",207,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,0.002432,3.6931520000000004,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",208,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002144,3.6952960000000004,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",209,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.001984,3.6972800000000006,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",210,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.005248,3.7025280000000005,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",211,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,0.00192,3.7044480000000006,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",212,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.001984,3.706432000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",213,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,0.002624,3.709056000000001,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",214,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,0.002624,3.7116800000000008,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",215,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,207892608.0,306176.0,0.168,3.879680000000001,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6496644.0,9568.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",216,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,0.002432,3.882112000000001,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",217,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,204768640.0,300320.0,0.168576,4.050688000000001,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6399020.0,9385.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",218,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,0.002656,4.053344000000001,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_128x32_sliced1x4_tn,219,1245708288.0,2503802880.0,0,0,0.0,2503802880.0,2503802880.0,4344192.0,1261440.0,0.7749691738594328,169259168.0,884736.0,0.203552,4.256896000000001,5308416.0,7077888.0,1245708288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5289349.0,27648.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",220,0.0,233472.0,0,0,0.0,233472.0,233472.0,0.0,7296.0,0.0,884736.0,49152.0,0.003712,4.260608000000001,221184.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,27648.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",221,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002112,4.262720000000002,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",222,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.002048,4.264768000000002,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",223,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.005088,4.269856000000002,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",224,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,0.001952,4.271808000000002,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",225,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.001984,4.273792000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",226,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,0.002656,4.276448000000002,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",227,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,0.002656,4.279104000000002,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_128x32_sliced1x4_tn,228,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,318720.0,0.7764309764309765,41948000.0,245760.0,0.047744,4.326848000000002,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1310875.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",229,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,0.00272,4.329568000000002,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
ampere_sgemm_128x32_sliced1x4_tn,230,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,318720.0,0.7764309764309765,41953376.0,245760.0,0.048416,4.377984000000001,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1311043.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",231,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,0.00288,4.380864000000002,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
ampere_sgemm_128x32_sliced1x4_tn,232,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,318720.0,0.7764309764309765,41951392.0,245760.0,0.04848,4.429344000000001,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1310981.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",233,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,0.00272,4.432064000000001,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",234,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.00272,4.434784000000001,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",235,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,0.00256,4.437344000000001,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",236,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,0.004,4.441344000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",237,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.002688,4.444032000000001,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",238,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.00208,4.446112000000001,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",239,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.002688,4.448800000000001,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",240,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,0.002624,4.451424000000001,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",241,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,0.003968,4.455392000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",242,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.002656,4.458048000000002,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",243,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002048,4.460096000000002,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",244,196608.0,17651712.0,0,0,0.0,17651712.0,17651712.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,0.020384,4.480480000000002,14880768.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,245,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,0.04992,4.530400000000002,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",246,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,0.0024,4.532800000000002,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",247,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.00208,4.534880000000002,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",248,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.00208,4.536960000000002,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",249,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.00496,4.541920000000002,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",250,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,0.00192,4.543840000000002,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",251,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.001984,4.545824000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",252,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,0.002656,4.548480000000002,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",253,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,0.002592,4.551072000000002,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",254,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,205162752.0,295680.0,0.1688,4.719872000000002,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6411336.0,9240.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",255,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,0.002464,4.722336000000002,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",256,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,206318976.0,296064.0,0.168288,4.8906240000000025,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6447468.0,9252.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",257,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,0.002464,4.893088000000002,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_128x32_sliced1x4_tn,258,1245708288.0,2503802880.0,0,0,0.0,2503802880.0,2503802880.0,4344192.0,1261440.0,0.7749691738594328,169295520.0,884736.0,0.2048,5.097888000000002,5308416.0,7077888.0,1245708288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5290485.0,27648.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",259,0.0,233472.0,0,0,0.0,233472.0,233472.0,0.0,7296.0,0.0,884736.0,49152.0,0.003584,5.101472000000002,221184.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,27648.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",260,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002208,5.103680000000002,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",261,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.001984,5.105664000000003,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",262,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.005024,5.110688000000002,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",263,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,0.001888,5.1125760000000025,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",264,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002016,5.114592000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",265,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,0.002624,5.117216000000003,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",266,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,0.002656,5.119872000000003,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_128x32_sliced1x4_tn,267,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,318720.0,0.7764309764309765,41948096.0,245760.0,0.047872,5.167744000000003,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1310878.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",268,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,0.002752,5.170496000000003,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
ampere_sgemm_128x32_sliced1x4_tn,269,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,318720.0,0.7764309764309765,41964128.0,245760.0,0.048416,5.218912000000002,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1311379.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",270,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,0.00272,5.221632000000002,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
ampere_sgemm_128x32_sliced1x4_tn,271,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,318720.0,0.7764309764309765,41960320.0,245760.0,0.048256,5.269888000000003,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1311260.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",272,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,0.002784,5.272672000000003,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",273,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.002656,5.275328000000003,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",274,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,0.002592,5.277920000000003,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",275,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,0.003968,5.281888000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",276,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.002688,5.284576000000003,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",277,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.00224,5.286816000000003,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",278,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.002816,5.289632000000003,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",279,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,0.00256,5.292192000000003,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",280,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,0.004032,5.296224000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",281,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.002656,5.298880000000002,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",282,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002176,5.301056000000003,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",283,196608.0,17651712.0,0,0,0.0,17651712.0,17651712.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,0.02048,5.321536000000003,14880768.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,284,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,0.050144,5.371680000000003,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",285,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,0.0024,5.374080000000003,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",286,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002112,5.376192000000003,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",287,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.002112,5.3783040000000035,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",288,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.004992,5.383296000000003,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",289,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,0.00192,5.385216000000003,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",290,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002016,5.387232000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",291,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,0.002592,5.3898240000000035,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",292,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,0.002624,5.3924480000000035,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",293,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,207951104.0,297856.0,0.167392,5.559840000000004,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6498472.0,9308.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",294,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,0.002528,5.562368000000004,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",295,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,204328320.0,299808.0,0.168384,5.730752000000003,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6385260.0,9369.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",296,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,0.002656,5.733408000000003,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_128x32_sliced1x4_tn,297,1245708288.0,2503802880.0,0,0,0.0,2503802880.0,2503802880.0,4344192.0,1261440.0,0.7749691738594328,169208864.0,884736.0,0.202592,5.9360000000000035,5308416.0,7077888.0,1245708288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5287777.0,27648.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",298,0.0,233472.0,0,0,0.0,233472.0,233472.0,0.0,7296.0,0.0,884736.0,49152.0,0.003584,5.9395840000000035,221184.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,27648.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",299,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.00208,5.941664000000004,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",300,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.002016,5.943680000000004,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",301,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.005088,5.948768000000004,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",302,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,0.001888,5.950656000000004,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",303,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.001984,5.952640000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",304,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,0.002688,5.955328000000004,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",305,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,0.002624,5.957952000000004,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_128x32_sliced1x4_tn,306,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,318720.0,0.7764309764309765,41956544.0,245760.0,0.048416,6.006368000000004,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1311142.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",307,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,0.002752,6.009120000000004,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
ampere_sgemm_128x32_sliced1x4_tn,308,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,318720.0,0.7764309764309765,41958048.0,245760.0,0.04896,6.058080000000004,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1311189.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",309,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,0.002752,6.060832000000004,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
ampere_sgemm_128x32_sliced1x4_tn,310,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,318720.0,0.7764309764309765,41966432.0,245760.0,0.048096,6.108928000000004,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1311451.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",311,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,0.002752,6.111680000000004,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",312,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.002752,6.114432000000004,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",313,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,0.002592,6.117024000000004,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",314,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,0.003968,6.120992000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",315,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.002656,6.123648000000005,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",316,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002112,6.125760000000005,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",317,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.002688,6.128448000000005,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",318,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,0.00256,6.131008000000005,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",319,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,0.003968,6.134976000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",320,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.002848,6.1378240000000055,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",321,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002144,6.139968000000006,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",322,196608.0,17651712.0,0,0,0.0,17651712.0,17651712.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,0.020352,6.160320000000006,14880768.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,323,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,0.049472,6.2097920000000055,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",324,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,0.0024,6.212192000000005,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",325,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002048,6.2142400000000055,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",326,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.002048,6.216288000000006,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",327,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.005152,6.221440000000006,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",328,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,0.001952,6.223392000000006,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",329,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.001952,6.225344000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",330,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,0.002624,6.227968000000006,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",331,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,0.002624,6.230592000000006,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",332,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,206775040.0,300672.0,0.16816,6.398752000000006,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6461720.0,9396.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",333,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,0.002464,6.401216000000006,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",334,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,206232960.0,297376.0,0.167872,6.569088000000006,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6444780.0,9293.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",335,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,0.0024,6.571488000000006,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_128x32_sliced1x4_tn,336,1245708288.0,2503802880.0,0,0,0.0,2503802880.0,2503802880.0,4344192.0,1261440.0,0.7749691738594328,169209056.0,884736.0,0.202144,6.773632000000005,5308416.0,7077888.0,1245708288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5287783.0,27648.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",337,0.0,233472.0,0,0,0.0,233472.0,233472.0,0.0,7296.0,0.0,884736.0,49152.0,0.00352,6.777152000000005,221184.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,27648.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",338,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002112,6.779264000000006,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",339,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.002112,6.781376000000006,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",340,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.004928,6.786304000000006,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",341,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,0.00192,6.788224000000006,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",342,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.001984,6.790208000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",343,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,0.002784,6.792992000000006,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",344,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,0.002688,6.795680000000006,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_128x32_sliced1x4_tn,345,14940778496.0,29949624320.0,0,0,0.0,29949624320.0,29949624320.0,49550128.0,15110510.0,0.7663105334655065,1928067840.0,4937920.0,2.170048,8.965728000000006,29171712.0,38895616.0,14940778496.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,60252120.0,154310.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",346,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.001664,8.967392000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",347,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,64.0,128.0,0.002592,8.969984000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",348,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.001952,8.971936000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",349,0.0,607744.0,0,0,0.0,607744.0,607744.0,0.0,9520.0,0.0,2430976.0,2430976.0,0.004736,8.976672000000004,0.0,607744.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75968.0,75968.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",350,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.001664,8.978336000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",351,0.0,0.0,0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435072.0,168512.0,0.005184,8.983520000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76096.0,5266.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",352,0.0,0.0,0,0,0.0,0.0,0.0,44104.0,718188.0,0.057857094131907455,27401536.0,896.0,0.012448,8.995968000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,856298.0,28.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",353,0.0,0.0,0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435072.0,167360.0,0.005216,9.001184000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76096.0,5230.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",354,0.0,0.0,0,0,0.0,0.0,0.0,44104.0,719380.0,0.05776676394004328,27434880.0,800.0,0.012352,9.013536000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,857340.0,25.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",355,0.0,0.0,0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435072.0,165312.0,0.005312,9.018848000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76096.0,5166.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",356,0.0,0.0,0,0,0.0,0.0,0.0,44104.0,719380.0,0.05776676394004328,27497760.0,1024.0,0.012448,9.031296000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,859305.0,32.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",357,0.0,0.0,0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435072.0,165888.0,0.005184,9.036480000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76096.0,5184.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",358,0.0,0.0,0,0,0.0,0.0,0.0,44104.0,718188.0,0.057857094131907455,27422112.0,1056.0,0.012448,9.048928000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,856941.0,33.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",359,0.0,0.0,0,0,0.0,0.0,0.0,0.0,57.0,0.0,19104.0,2400.0,0.003296,9.052224000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,597.0,75.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",360,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,0.001664,9.053888000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",361,0.0,0.0,0,0,0.0,0.0,0.0,497.0,46.0,0.9152854511970534,2400.0,0.0,0.003616,9.057504000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",362,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,0.001664,9.059168000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",363,0.0,0.0,0,0,0.0,0.0,0.0,497.0,46.0,0.9152854511970534,2400.0,0.0,0.003616,9.062784,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",364,0.0,0.0,0,0,0.0,0.0,0.0,172032.0,38400.0,0.8175182481751825,2472160.0,9856.0,0.007072,9.069856000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,77255.0,308.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",365,0.0,0.0,0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,544.0,0.006464,9.07632,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,80.0,17.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",366,0.0,0.0,0,0,0.0,0.0,0.0,0.0,56976.0,0.0,2445120.0,246496.0,0.004992,9.081312,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76410.0,7703.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",367,0.0,0.0,0,0,0.0,0.0,0.0,0.0,14280.0,0.0,3038720.0,0.0,0.005664,9.086976,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,94960.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",368,0.0,0.0,0,0,0.0,0.0,0.0,0.0,18992.0,0.0,0.0,4861952.0,0.00464,9.091616,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,151936.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",369,0.0,0.0,0,0,0.0,0.0,0.0,98304.0,18992.0,0.8380848451780112,2430976.0,0.0,0.005728,9.097344,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75968.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",370,0.0,0.0,0,0,0.0,0.0,0.0,156.0,64.0,0.7090909090909091,8192.0,0.0,0.002144,9.099488,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",371,0.0,0.0,0,0,0.0,0.0,0.0,180978.0,99849.0,0.644446580991144,9433216.0,6094048.0,0.017696,9.117184,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,294788.0,190439.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",372,0.0,0.0,0,0,0.0,0.0,0.0,71226.0,120271.0,0.37194316360047414,9509504.0,5256576.0,0.015072,9.132256,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,297172.0,164268.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",373,0.0,0.0,0,0,0.0,0.0,0.0,68478.0,118146.0,0.36693029835390945,9451648.0,5693152.0,0.01568,9.147936,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,295364.0,177911.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",374,0.0,0.0,0,0,0.0,0.0,0.0,67578.0,120091.0,0.3600914375842574,9445632.0,7495680.0,0.015552,9.163488,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,295176.0,234240.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",375,0.0,0.0,0,0,0.0,0.0,0.0,14336.0,18992.0,0.4301488238118099,4861952.0,0.0,0.007776,9.171263999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,151936.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",376,0.0,0.0,0,0,0.0,0.0,0.0,39.0,16.0,0.7090909090909091,2048.0,0.0,0.002144,9.173407999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",377,0.0,0.0,0,0,0.0,0.0,0.0,55759.0,132609.0,0.29601099974517964,7432832.0,4245632.0,0.01408,9.187487999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,232276.0,132676.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",378,0.0,0.0,0,0,0.0,0.0,0.0,0.0,75968.0,0.0,7326336.0,7292928.0,0.010176,9.197663999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,228948.0,227904.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",379,8508416.0,20076672.0,0,0,0.0,20076672.0,20076672.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,0.06192,9.259583999999998,2452096.0,607744.0,8508416.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,227904.0,75968.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",380,0.0,3052116.0,0,0,0.0,3052116.0,3052116.0,334872.0,37984.0,0.8981268908103933,2430976.0,2430976.0,0.211232,9.470816,3052116.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75968.0,75968.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",381,0.0,0.0,0,0,0.0,0.0,0.0,0.0,9520.0,0.0,2430976.0,607456.0,0.004736,9.475551999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75968.0,18983.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",382,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,0.001888,9.477439999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",383,0.0,0.0,0,0,0.0,0.0,0.0,0.0,56976.0,0.0,5469696.0,272000.0,0.010336,9.487775999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,170928.0,8500.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",384,0.0,0.0,0,0,0.0,0.0,0.0,0.0,14280.0,0.0,3038720.0,0.0,0.006048,9.493823999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,94960.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",385,8508416.0,20076672.0,0,0,0.0,20076672.0,20076672.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,0.062336,9.556159999999998,2452096.0,607744.0,8508416.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,227904.0,75968.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",386,0.0,0.0,0,0,0.0,0.0,0.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,0.007936,9.564096,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",387,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00208,9.566175999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",388,0.0,0.0,0,0,0.0,0.0,0.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,0.007616,9.573792,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",389,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00208,9.575871999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",390,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,0.002048,9.577919999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",391,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,0.00304,9.58096,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",392,0.0,990796.0,0,0,0.0,990796.0,990796.0,7692.0,4832.0,0.6141807729160013,2431392.0,2560.0,0.007712,9.588671999999999,990796.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75981.0,80.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",393,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.001984,9.590656,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",394,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003264,9.593919999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",395,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.001984,9.595903999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",396,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,0.003008,9.598911999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",397,1769472.0,4754432.0,0,0,0.0,4754432.0,4754432.0,0.0,18992.0,0.0,0.0,2430976.0,0.00416,9.603072,0.0,1215488.0,1769472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,75968.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",398,3038720.0,6077440.0,0,0,0.0,6077440.0,6077440.0,0.0,14280.0,0.0,4861952.0,0.0,0.008224,9.611296,0.0,0.0,3038720.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,151936.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",399,0.0,0.0,0,0,0.0,0.0,0.0,14092.0,4912.0,0.7415280993475057,2432256.0,2656.0,0.009248,9.620543999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76008.0,83.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",400,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,64.0,128.0,0.002656,9.623199999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",401,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.001664,9.624863999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",402,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.001664,9.626527999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",403,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,0.002016,9.628543999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",404,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.001984,9.630527999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",405,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,0.002752,9.633279999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",406,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00336,9.636639999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",407,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.001984,9.638623999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",408,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002144,9.640767999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",409,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,32.0,0.003296,9.644063999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",410,0.0,0.0,0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,64.0,32.0,0.002496,9.64656,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",411,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,0.001952,9.648511999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",412,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,0.002048,9.650559999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",413,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,0.0,0.002048,9.652607999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",414,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,0.002176,9.654784,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",415,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1152.0,0.0,49920.0,49152.0,0.005472,9.660255999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1560.0,1536.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",416,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,0.002496,9.662752,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",417,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.0032,9.665951999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",418,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002464,9.668415999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",419,0.0,512.0,0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,0.001984,9.670399999999999,0.0,512.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",420,0.0,0.0,0,0,0.0,0.0,0.0,0.0,20.0,0.0,2048.0,2048.0,0.00256,9.67296,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",421,4096.0,9216.0,0,0,0.0,9216.0,9216.0,0.0,32.0,0.0,2048.0,2048.0,0.002912,9.675872,0.0,1024.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",422,0.0,512.0,0,0,0.0,512.0,512.0,0.0,32.0,0.0,2048.0,2048.0,0.002016,9.677888,0.0,512.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",423,3600.0,8224.0,0,0,0.0,8224.0,8224.0,0.0,32.0,0.0,2048.0,2048.0,0.002816,9.680703999999999,0.0,1024.0,3600.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",424,0.0,512.0,0,0,0.0,512.0,512.0,0.0,32.0,0.0,2048.0,2048.0,0.002016,9.682719999999998,0.0,512.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",425,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.002016,9.684735999999997,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",426,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.005056,9.689791999999997,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",427,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,0.001888,9.691679999999996,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",428,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.001952,9.693631999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",429,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,0.002656,9.696287999999996,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",430,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,0.002656,9.698943999999996,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_128x32_sliced1x4_tn,431,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,318720.0,0.7764309764309765,41957088.0,245760.0,0.048384,9.747327999999996,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1311159.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",432,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,0.002912,9.750239999999996,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
ampere_sgemm_128x32_sliced1x4_tn,433,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,318720.0,0.7764309764309765,41968416.0,245760.0,0.047872,9.798111999999996,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1311513.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",434,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,0.00272,9.800831999999996,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
ampere_sgemm_128x32_sliced1x4_tn,435,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,318720.0,0.7764309764309765,41954464.0,245760.0,0.047808,9.848639999999996,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1311077.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",436,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,0.00272,9.851359999999996,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",437,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.002688,9.854047999999995,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",438,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,0.002592,9.856639999999995,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",439,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,0.004064,9.860703999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",440,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.002816,9.863519999999994,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",441,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.00208,9.865599999999993,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",442,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.002656,9.868255999999993,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",443,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,0.00256,9.870815999999994,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",444,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,0.004032,9.874847999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",445,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.002656,9.877503999999995,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",446,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.00208,9.879583999999994,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",447,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,0.002688,9.882271999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",448,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,0.00352,9.885791999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",449,196608.0,17657856.0,0,0,0.0,17657856.0,17657856.0,99840.0,192.0,0.9980806142034548,245760.0,49152.0,0.020448,9.906239999999993,14886912.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,450,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,0.048096,9.954335999999993,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",451,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,0.002592,9.956927999999992,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",452,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.00208,9.959007999999992,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",453,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.001984,9.960991999999992,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",454,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.005056,9.966047999999992,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",455,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,0.001952,9.967999999999991,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",456,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.001984,9.969983999999991,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",457,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,0.002624,9.972607999999992,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",458,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,0.002656,9.975263999999992,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",459,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,203552896.0,294272.0,0.168416,10.143679999999993,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6361028.0,9196.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",460,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,0.0024,10.146079999999992,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",461,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,206184704.0,304704.0,0.167744,10.313823999999993,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6443272.0,9522.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",462,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,0.00256,10.316383999999994,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_128x32_sliced1x4_tn,463,1245708288.0,2503802880.0,0,0,0.0,2503802880.0,2503802880.0,4344192.0,1261440.0,0.7749691738594328,169221408.0,884736.0,0.202368,10.518751999999994,5308416.0,7077888.0,1245708288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5288169.0,27648.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",464,0.0,233472.0,0,0,0.0,233472.0,233472.0,0.0,7296.0,0.0,884736.0,49152.0,0.003712,10.522463999999994,221184.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,27648.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",465,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.00208,10.524543999999993,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",466,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.002016,10.526559999999993,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",467,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.005152,10.531711999999994,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",468,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,0.00192,10.533631999999994,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",469,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.001952,10.535583999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",470,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,0.002752,10.538335999999992,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",471,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,0.002688,10.541023999999991,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_128x32_sliced1x4_tn,472,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,318720.0,0.7764309764309765,41950080.0,245760.0,0.047872,10.588895999999991,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1310940.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",473,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,0.00272,10.591615999999991,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
ampere_sgemm_128x32_sliced1x4_tn,474,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,318720.0,0.7764309764309765,41941920.0,245760.0,0.047904,10.639519999999992,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1310685.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",475,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,0.002848,10.642367999999992,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
ampere_sgemm_128x32_sliced1x4_tn,476,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,318720.0,0.7764309764309765,41964160.0,245760.0,0.048128,10.690495999999992,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1311380.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",477,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,0.00288,10.693375999999992,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",478,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.002688,10.696063999999991,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",479,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,0.002656,10.698719999999991,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",480,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,0.004,10.70271999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",481,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.002656,10.70537599999999,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",482,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002176,10.70755199999999,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",483,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.002656,10.71020799999999,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",484,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,0.002592,10.71279999999999,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",485,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,0.003968,10.716767999999991,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",486,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.002688,10.71945599999999,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",487,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.00224,10.72169599999999,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",488,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,0.002688,10.72438399999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",489,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,0.002656,10.72703999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",490,196608.0,17657856.0,0,0,0.0,17657856.0,17657856.0,99840.0,192.0,0.9980806142034548,245760.0,49152.0,0.020576,10.74761599999999,14886912.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,491,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,0.047968,10.79558399999999,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",492,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,0.002592,10.79817599999999,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",493,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002144,10.800319999999989,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",494,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.002016,10.802335999999988,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",495,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.004992,10.807327999999988,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",496,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,0.00192,10.809247999999988,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",497,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.001984,10.811231999999988,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",498,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,0.002656,10.813887999999988,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",499,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,0.002624,10.816511999999989,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",500,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,207337344.0,299392.0,0.169152,10.98566399999999,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6479292.0,9356.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",501,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,0.0024,10.988063999999989,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",502,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,206869632.0,305216.0,0.168256,11.156319999999988,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6464676.0,9538.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",503,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,0.0024,11.158719999999988,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_128x32_sliced1x4_tn,504,1245708288.0,2503802880.0,0,0,0.0,2503802880.0,2503802880.0,4344192.0,1261440.0,0.7749691738594328,169268864.0,884736.0,0.204672,11.363391999999989,5308416.0,7077888.0,1245708288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5289652.0,27648.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",505,0.0,233472.0,0,0,0.0,233472.0,233472.0,0.0,7296.0,0.0,884736.0,49152.0,0.003648,11.367039999999989,221184.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,27648.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",506,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.00208,11.369119999999988,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",507,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.001984,11.371103999999988,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",508,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.00512,11.376223999999988,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",509,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,0.001888,11.378111999999987,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",510,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.001952,11.380063999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",511,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,0.002752,11.382815999999986,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",512,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,0.002784,11.385599999999986,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_128x32_sliced1x4_tn,513,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,318720.0,0.7764309764309765,41963744.0,245760.0,0.048384,11.433983999999986,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1311367.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",514,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,0.00272,11.436703999999986,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
ampere_sgemm_128x32_sliced1x4_tn,515,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,318720.0,0.7764309764309765,41961984.0,245760.0,0.047936,11.484639999999986,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1311312.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",516,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,0.002688,11.487327999999986,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
ampere_sgemm_128x32_sliced1x4_tn,517,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,318720.0,0.7764309764309765,41950944.0,245760.0,0.048512,11.535839999999986,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1310967.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",518,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,0.002656,11.538495999999986,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",519,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.00272,11.541215999999986,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",520,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,0.002624,11.543839999999987,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",521,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,0.004,11.547839999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",522,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.00272,11.550559999999987,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",523,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.00224,11.552799999999987,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",524,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.002688,11.555487999999986,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",525,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,0.002624,11.558111999999987,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",526,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,0.004,11.562111999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",527,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.00272,11.564831999999987,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",528,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002048,11.566879999999987,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",529,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,0.002656,11.569535999999987,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",530,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,0.002688,11.572223999999986,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",531,196608.0,17657856.0,0,0,0.0,17657856.0,17657856.0,99840.0,192.0,0.9980806142034548,245760.0,49152.0,0.020416,11.592639999999987,14886912.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,532,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,0.05008,11.642719999999986,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",533,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,0.0024,11.645119999999986,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",534,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.00208,11.647199999999986,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",535,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.00208,11.649279999999985,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",536,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.00512,11.654399999999985,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",537,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,0.00192,11.656319999999985,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",538,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.001952,11.658271999999984,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",539,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,0.002592,11.660863999999984,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",540,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,0.002624,11.663487999999985,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",541,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,207555200.0,299616.0,0.168,11.831487999999984,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6486100.0,9363.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",542,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,0.002368,11.833855999999985,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",543,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,205455872.0,291744.0,0.168864,12.002719999999984,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6420496.0,9117.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",544,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,0.002528,12.005247999999984,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_128x32_sliced1x4_tn,545,1245708288.0,2503802880.0,0,0,0.0,2503802880.0,2503802880.0,4344192.0,1261440.0,0.7749691738594328,169318336.0,884736.0,0.202592,12.207839999999983,5308416.0,7077888.0,1245708288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5291198.0,27648.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",546,0.0,233472.0,0,0,0.0,233472.0,233472.0,0.0,7296.0,0.0,884736.0,49152.0,0.003776,12.211615999999983,221184.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,27648.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",547,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.00208,12.213695999999983,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",548,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.002048,12.215743999999983,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",549,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.005024,12.220767999999984,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",550,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,0.002016,12.222783999999983,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",551,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002016,12.224799999999982,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",552,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,0.002592,12.227391999999982,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",553,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,0.002656,12.230047999999982,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_128x32_sliced1x4_tn,554,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,318720.0,0.7764309764309765,41969280.0,245760.0,0.048256,12.278303999999983,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1311540.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",555,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,0.00272,12.281023999999983,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
ampere_sgemm_128x32_sliced1x4_tn,556,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,318720.0,0.7764309764309765,41953376.0,245760.0,0.048576,12.329599999999983,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1311043.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",557,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,0.002688,12.332287999999982,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
ampere_sgemm_128x32_sliced1x4_tn,558,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,318720.0,0.7764309764309765,41952256.0,245760.0,0.048288,12.380575999999982,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1311008.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",559,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,0.002848,12.383423999999982,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",560,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.00272,12.386143999999982,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",561,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,0.002656,12.388799999999982,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",562,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,0.00416,12.392959999999983,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",563,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.002656,12.395615999999983,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",564,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.00208,12.397695999999982,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",565,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.00272,12.400415999999982,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",566,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,0.00256,12.402975999999983,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",567,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,0.004032,12.407007999999983,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",568,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.00272,12.409727999999983,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",569,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.00208,12.411807999999983,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",570,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,0.002688,12.414495999999982,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",571,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,0.002656,12.417151999999982,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",572,196608.0,17657856.0,0,0,0.0,17657856.0,17657856.0,99840.0,192.0,0.9980806142034548,245760.0,49152.0,0.020544,12.437695999999981,14886912.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,573,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,0.048768,12.486463999999982,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",574,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,0.002432,12.488895999999983,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",575,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002112,12.491007999999983,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",576,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.001984,12.492991999999983,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",577,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.005056,12.498047999999983,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",578,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,0.00192,12.499967999999983,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",579,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.001952,12.501919999999982,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",580,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,0.002656,12.504575999999982,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",581,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,0.002688,12.507263999999982,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",582,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,203206400.0,299872.0,0.169888,12.677151999999982,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6350200.0,9371.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",583,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,0.002432,12.679583999999982,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",584,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,205296512.0,300192.0,0.168032,12.847615999999983,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6415516.0,9381.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",585,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,0.00256,12.850175999999983,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_128x32_sliced1x4_tn,586,1245708288.0,2503802880.0,0,0,0.0,2503802880.0,2503802880.0,4344192.0,1261440.0,0.7749691738594328,169310912.0,884736.0,0.2032,13.053375999999984,5308416.0,7077888.0,1245708288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5290966.0,27648.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",587,0.0,233472.0,0,0,0.0,233472.0,233472.0,0.0,7296.0,0.0,884736.0,49152.0,0.00352,13.056895999999984,221184.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,27648.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",588,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002144,13.059039999999984,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",589,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.002016,13.061055999999983,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",590,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.005248,13.066303999999983,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",591,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,0.001952,13.068255999999982,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",592,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.001952,13.070207999999981,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",593,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,0.002624,13.072831999999982,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",594,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,0.002624,13.075455999999983,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_128x32_sliced1x4_tn,595,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,318720.0,0.7764309764309765,41944288.0,245760.0,0.047904,13.123359999999984,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1310759.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",596,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,0.00272,13.126079999999984,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
ampere_sgemm_128x32_sliced1x4_tn,597,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,318720.0,0.7764309764309765,41963072.0,245760.0,0.047968,13.174047999999983,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1311346.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",598,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,0.002688,13.176735999999982,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
ampere_sgemm_128x32_sliced1x4_tn,599,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,318720.0,0.7764309764309765,41963392.0,245760.0,0.04816,13.224895999999982,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1311356.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",600,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,0.00272,13.227615999999982,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",601,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.002688,13.23030399999998,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",602,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,0.002592,13.23289599999998,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",603,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,0.003968,13.236863999999981,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",604,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.002784,13.239647999999981,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",605,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002048,13.241695999999981,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",606,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.002656,13.244351999999981,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",607,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,0.002624,13.246975999999982,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",608,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,0.004,13.250975999999982,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",609,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.002752,13.253727999999981,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",610,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.00208,13.25580799999998,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",611,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,0.002688,13.25849599999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",612,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,0.002656,13.26115199999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",613,196608.0,17657856.0,0,0,0.0,17657856.0,17657856.0,99840.0,192.0,0.9980806142034548,245760.0,49152.0,0.020224,13.28137599999998,14886912.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,614,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,0.0488,13.33017599999998,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",615,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,0.002464,13.33263999999998,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",616,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.00208,13.33471999999998,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",617,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.002016,13.336735999999979,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",618,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.005152,13.34188799999998,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",619,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,0.00192,13.34380799999998,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",620,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.001984,13.34579199999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",621,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,0.002624,13.34841599999998,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",622,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,0.002688,13.35110399999998,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",623,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,205076224.0,303264.0,0.16848,13.51958399999998,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6408632.0,9477.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",624,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,0.002528,13.52211199999998,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",625,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,203870848.0,302944.0,0.16784,13.68995199999998,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6370964.0,9467.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",626,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,0.002592,13.69254399999998,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_128x32_sliced1x4_tn,627,1245708288.0,2503802880.0,0,0,0.0,2503802880.0,2503802880.0,4344192.0,1261440.0,0.7749691738594328,169231232.0,884736.0,0.201248,13.89379199999998,5308416.0,7077888.0,1245708288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5288476.0,27648.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",628,0.0,233472.0,0,0,0.0,233472.0,233472.0,0.0,7296.0,0.0,884736.0,49152.0,0.003552,13.89734399999998,221184.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,27648.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",629,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.00208,13.89942399999998,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",630,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.001984,13.90140799999998,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",631,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.004992,13.90639999999998,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",632,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,0.00192,13.90831999999998,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",633,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.001952,13.91027199999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",634,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,0.002656,13.91292799999998,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",635,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,0.002656,13.91558399999998,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_128x32_sliced1x4_tn,636,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,318720.0,0.7764309764309765,41943264.0,245760.0,0.04768,13.96326399999998,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1310727.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",637,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,0.002688,13.965951999999978,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
ampere_sgemm_128x32_sliced1x4_tn,638,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,318720.0,0.7764309764309765,41954784.0,245760.0,0.049056,14.015007999999979,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1311087.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",639,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,0.002784,14.017791999999979,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
ampere_sgemm_128x32_sliced1x4_tn,640,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,318720.0,0.7764309764309765,41954752.0,245760.0,0.04832,14.066111999999979,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1311086.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",641,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,0.00272,14.06883199999998,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",642,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.002688,14.071519999999978,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",643,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,0.002624,14.07414399999998,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",644,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,0.004,14.078143999999979,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",645,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.002656,14.080799999999979,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",646,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.00208,14.082879999999978,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",647,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.00272,14.085599999999978,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",648,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,0.002592,14.088191999999978,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",649,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,0.004032,14.092223999999979,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",650,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.002688,14.094911999999978,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",651,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002016,14.096927999999977,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",652,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,0.002688,14.099615999999976,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",653,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,0.002656,14.102271999999976,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",654,196608.0,17657856.0,0,0,0.0,17657856.0,17657856.0,99840.0,192.0,0.9980806142034548,245760.0,49152.0,0.020544,14.122815999999975,14886912.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,655,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,0.049472,14.172287999999975,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",656,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,0.0024,14.174687999999975,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",657,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.00208,14.176767999999974,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",658,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.002016,14.178783999999974,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",659,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.00496,14.183743999999974,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",660,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,0.00192,14.185663999999974,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",661,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.001984,14.187647999999975,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",662,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,0.002624,14.190271999999975,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",663,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,0.002688,14.192959999999974,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",664,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,204463616.0,299712.0,0.168384,14.361343999999974,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6389488.0,9366.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",665,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,0.0024,14.363743999999974,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",666,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,204071680.0,297952.0,0.16896,14.532703999999974,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6377240.0,9311.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",667,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,0.002656,14.535359999999974,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_128x32_sliced1x4_tn,668,1245708288.0,2503802880.0,0,0,0.0,2503802880.0,2503802880.0,4344192.0,1261440.0,0.7749691738594328,169305632.0,884736.0,0.20416,14.739519999999974,5308416.0,7077888.0,1245708288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5290801.0,27648.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",669,0.0,233472.0,0,0,0.0,233472.0,233472.0,0.0,7296.0,0.0,884736.0,49152.0,0.003744,14.743263999999973,221184.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,27648.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",670,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.00208,14.745343999999973,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",671,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.002208,14.747551999999972,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",672,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.00512,14.752671999999972,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",673,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,0.00192,14.754591999999972,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",674,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.001984,14.756575999999972,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",675,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,0.002624,14.759199999999973,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",676,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,0.002752,14.761951999999972,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_128x32_sliced1x4_tn,677,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,318720.0,0.7764309764309765,41954144.0,245760.0,0.048096,14.810047999999972,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1311067.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",678,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,0.002848,14.812895999999972,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
ampere_sgemm_128x32_sliced1x4_tn,679,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,318720.0,0.7764309764309765,41954592.0,245760.0,0.04784,14.860735999999973,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1311081.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",680,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,0.002912,14.863647999999973,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
ampere_sgemm_128x32_sliced1x4_tn,681,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,318720.0,0.7764309764309765,41964896.0,245760.0,0.048032,14.911679999999972,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1311403.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",682,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,0.002912,14.914591999999972,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",683,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.002656,14.917247999999972,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",684,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,0.002624,14.919871999999973,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",685,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,0.003968,14.923839999999974,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",686,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.002656,14.926495999999974,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",687,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002304,14.928799999999974,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",688,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.00272,14.931519999999974,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",689,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,0.002592,14.934111999999974,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",690,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,0.003968,14.938079999999974,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",691,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.002656,14.940735999999974,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",692,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.00224,14.942975999999975,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",693,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,0.002656,14.945631999999975,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",694,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,0.002816,14.948447999999974,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",695,196608.0,17657856.0,0,0,0.0,17657856.0,17657856.0,99840.0,192.0,0.9980806142034548,245760.0,49152.0,0.020448,14.968895999999974,14886912.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,696,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,0.050592,15.019487999999974,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",697,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,0.0024,15.021887999999974,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",698,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.00224,15.024127999999974,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",699,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.001984,15.026111999999975,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",700,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.00512,15.031231999999974,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",701,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,0.001984,15.033215999999975,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",702,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.001984,15.035199999999975,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",703,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,0.002784,15.037983999999975,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",704,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,0.00272,15.040703999999975,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",705,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,208623744.0,301056.0,0.1672,15.207903999999974,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6519492.0,9408.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",706,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,0.002528,15.210431999999974,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",707,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,205968384.0,293440.0,0.168608,15.379039999999975,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6436512.0,9170.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",708,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,0.002464,15.381503999999975,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_128x32_sliced1x4_tn,709,1245708288.0,2503802880.0,0,0,0.0,2503802880.0,2503802880.0,4344192.0,1261440.0,0.7749691738594328,169225600.0,884736.0,0.20336,15.584863999999975,5308416.0,7077888.0,1245708288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5288300.0,27648.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",710,0.0,233472.0,0,0,0.0,233472.0,233472.0,0.0,7296.0,0.0,884736.0,49152.0,0.003616,15.588479999999974,221184.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,27648.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",711,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002112,15.590591999999974,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",712,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.002016,15.592607999999974,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",713,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.005024,15.597631999999974,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",714,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,0.001888,15.599519999999973,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",715,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.001952,15.601471999999973,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",716,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,0.002656,15.604127999999973,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",717,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,0.002624,15.606751999999974,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_128x32_sliced1x4_tn,718,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,318720.0,0.7764309764309765,41960416.0,245760.0,0.04848,15.655231999999973,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1311263.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",719,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,0.002912,15.658143999999973,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
ampere_sgemm_128x32_sliced1x4_tn,720,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,318720.0,0.7764309764309765,41954240.0,245760.0,0.048544,15.706687999999973,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1311070.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",721,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,0.00288,15.709567999999972,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
ampere_sgemm_128x32_sliced1x4_tn,722,314572800.0,632586240.0,0,0,0.0,632586240.0,632586240.0,1106880.0,318720.0,0.7764309764309765,41965376.0,245760.0,0.048224,15.757791999999972,1474560.0,1966080.0,314572800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1311418.0,7680.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",723,0.0,86016.0,0,0,0.0,86016.0,86016.0,0.0,4608.0,0.0,258048.0,49152.0,0.002848,15.760639999999972,73728.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8064.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",724,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.002688,15.763327999999971,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",725,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,0.002656,15.765983999999971,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",726,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,0.003936,15.76991999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",727,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.002784,15.77270399999997,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",728,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.00208,15.77478399999997,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",729,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.00272,15.77750399999997,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",730,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,384.0,0.0,24576.0,24576.0,0.002624,15.780127999999971,6144.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",731,0.0,0.0,0,0,0.0,0.0,0.0,0.0,768.0,0.0,49152.0,49152.0,0.004,15.78412799999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",732,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,73728.0,49152.0,0.002656,15.78678399999997,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",733,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002112,15.788895999999971,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",734,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,0.002656,15.791551999999971,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",735,0.0,0.0,0,0,0.0,0.0,0.0,0.0,960.0,0.0,98304.0,98304.0,0.00272,15.794271999999971,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",736,196608.0,17657856.0,0,0,0.0,17657856.0,17657856.0,99840.0,192.0,0.9980806142034548,245760.0,49152.0,0.020512,15.814783999999971,14886912.0,2377728.0,196608.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7680.0,1536.0
ampere_sgemm_64x32_sliced1x4_tn,737,301989888.0,606044160.0,0,0,0.0,606044160.0,606044160.0,1396224.0,314496.0,0.8161616161616162,40108032.0,147456.0,0.048864,15.863647999999971,884736.0,1179648.0,301989888.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1253376.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",738,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,147456.0,49152.0,0.002496,15.866143999999972,36864.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4608.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",739,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.00208,15.868223999999971,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",740,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.002016,15.87023999999997,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",741,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.005024,15.875263999999971,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",742,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,0.00192,15.877183999999971,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",743,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002048,15.879231999999972,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",744,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,0.002656,15.881887999999972,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",745,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,0.00272,15.884607999999972,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",746,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,205405184.0,296576.0,0.16896,16.05356799999997,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6418912.0,9268.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",747,565248.0,1179648.0,0,0,0.0,1179648.0,1179648.0,0.0,768.0,0.0,196608.0,196608.0,0.002528,16.05609599999997,49152.0,0.0,565248.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",748,150994944.0,331087872.0,0,0,0.0,331087872.0,331087872.0,2021376.0,1794048.0,0.5297906602254429,205620736.0,294560.0,0.168416,16.224511999999972,10223616.0,18874368.0,150994944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6425648.0,9205.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",749,0.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,0.002528,16.227039999999974,0.0,49152.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,6144.0
ampere_sgemm_128x32_sliced1x4_tn,750,1245708288.0,2503802880.0,0,0,0.0,2503802880.0,2503802880.0,4344192.0,1261440.0,0.7749691738594328,169251328.0,884736.0,0.202752,16.429791999999974,5308416.0,7077888.0,1245708288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5289104.0,27648.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",751,0.0,233472.0,0,0,0.0,233472.0,233472.0,0.0,7296.0,0.0,884736.0,49152.0,0.003776,16.433567999999973,221184.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,27648.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",752,12288.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002048,16.43561599999997,0.0,0.0,12288.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",753,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.002016,16.437631999999972,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",754,0.0,16772.0,0,0,0.0,16772.0,16772.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.005088,16.442719999999973,16768.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",755,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,0.001888,16.444607999999974,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",756,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.001984,16.446591999999974,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",757,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,50688.0,49152.0,0.002624,16.449215999999975,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",758,0.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,1152.0,0.0,98304.0,49152.0,0.002656,16.451871999999977,0.0,12288.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,1536.0
ampere_sgemm_128x32_sliced1x4_tn,759,14940778496.0,29949624320.0,0,0,0.0,29949624320.0,29949624320.0,49550128.0,15110510.0,0.7663105334655065,1928067840.0,4937920.0,2.169728,18.621599999999976,29171712.0,38895616.0,14940778496.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,60252120.0,154310.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",760,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.001664,18.623263999999978,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",761,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,96.0,160.0,0.002592,18.625855999999978,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",762,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.001984,18.627839999999978,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",763,0.0,607744.0,0,0,0.0,607744.0,607744.0,0.0,9520.0,0.0,2430976.0,2430976.0,0.004672,18.632511999999977,0.0,607744.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75968.0,75968.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",764,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.001696,18.634207999999976,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",765,0.0,0.0,0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435072.0,168512.0,0.005184,18.639391999999976,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76096.0,5266.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",766,0.0,0.0,0,0,0.0,0.0,0.0,44104.0,718188.0,0.057857094131907455,27394528.0,992.0,0.0128,18.652191999999975,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,856079.0,31.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",767,0.0,0.0,0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435072.0,167296.0,0.004992,18.657183999999976,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76096.0,5228.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",768,0.0,0.0,0,0,0.0,0.0,0.0,44104.0,719380.0,0.05776676394004328,27469760.0,896.0,0.013056,18.670239999999975,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,858430.0,28.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",769,0.0,0.0,0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435072.0,165248.0,0.004992,18.675231999999976,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76096.0,5164.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",770,0.0,0.0,0,0,0.0,0.0,0.0,44104.0,718784.0,0.05781189375111419,27362048.0,896.0,0.012736,18.687967999999977,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,855064.0,28.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",771,0.0,0.0,0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435072.0,165696.0,0.00512,18.693087999999978,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76096.0,5178.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",772,0.0,0.0,0,0,0.0,0.0,0.0,44104.0,719678.0,0.057744225446527936,27441152.0,1024.0,0.013056,18.706143999999977,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,857536.0,32.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",773,0.0,0.0,0,0,0.0,0.0,0.0,0.0,57.0,0.0,19104.0,2400.0,0.0032,18.709343999999977,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,597.0,75.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",774,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,0.00176,18.711103999999978,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",775,0.0,0.0,0,0,0.0,0.0,0.0,497.0,46.0,0.9152854511970534,2400.0,0.0,0.00368,18.714783999999977,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",776,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,0.001664,18.71644799999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",777,0.0,0.0,0,0,0.0,0.0,0.0,497.0,46.0,0.9152854511970534,2400.0,0.0,0.003744,18.72019199999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",778,0.0,0.0,0,0,0.0,0.0,0.0,172992.0,38396.0,0.8183624425227544,2472160.0,9600.0,0.006912,18.72710399999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,77255.0,300.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",779,0.0,0.0,0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,544.0,0.006368,18.733471999999978,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,80.0,17.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",780,0.0,0.0,0,0,0.0,0.0,0.0,0.0,56976.0,0.0,2445120.0,249696.0,0.005088,18.73855999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76410.0,7803.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",781,0.0,0.0,0,0,0.0,0.0,0.0,0.0,14280.0,0.0,3038720.0,0.0,0.005984,18.74454399999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,94960.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",782,0.0,0.0,0,0,0.0,0.0,0.0,0.0,18992.0,0.0,0.0,4861952.0,0.00432,18.74886399999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,151936.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",783,0.0,0.0,0,0,0.0,0.0,0.0,98304.0,18992.0,0.8380848451780112,2430976.0,0.0,0.00576,18.75462399999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75968.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",784,0.0,0.0,0,0,0.0,0.0,0.0,156.0,64.0,0.7090909090909091,8192.0,0.0,0.002144,18.75676799999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",785,0.0,0.0,0,0,0.0,0.0,0.0,177378.0,103591.0,0.6313080802508462,9314688.0,5907040.0,0.017312,18.77407999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,291084.0,184595.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",786,0.0,0.0,0,0,0.0,0.0,0.0,68526.0,122407.0,0.3589007662373712,9552256.0,6707648.0,0.015328,18.78940799999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,298508.0,209614.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",787,0.0,0.0,0,0,0.0,0.0,0.0,68478.0,125386.0,0.3532270044979986,9442560.0,5692608.0,0.016032,18.80543999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,295080.0,177894.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",788,0.0,0.0,0,0,0.0,0.0,0.0,67578.0,122489.0,0.35554830664976034,9413120.0,7495680.0,0.015872,18.82131199999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,294160.0,234240.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",789,0.0,0.0,0,0,0.0,0.0,0.0,14336.0,18992.0,0.4301488238118099,4861952.0,0.0,0.007872,18.82918399999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,151936.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",790,0.0,0.0,0,0,0.0,0.0,0.0,39.0,16.0,0.7090909090909091,2048.0,0.0,0.002208,18.83139199999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",791,0.0,0.0,0,0,0.0,0.0,0.0,55759.0,125715.0,0.3072561358651928,7383680.0,4254976.0,0.013984,18.84537599999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,230740.0,132968.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",792,0.0,0.0,0,0,0.0,0.0,0.0,0.0,75968.0,0.0,7324736.0,7292928.0,0.01024,18.85561599999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,228898.0,227904.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",793,8508416.0,20076672.0,0,0,0.0,20076672.0,20076672.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,0.062496,18.91811199999998,2452096.0,607744.0,8508416.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,227904.0,75968.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",794,0.0,3052116.0,0,0,0.0,3052116.0,3052116.0,334872.0,37984.0,0.8981268908103933,2430976.0,2430976.0,0.210592,19.128703999999978,3052116.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75968.0,75968.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",795,0.0,0.0,0,0,0.0,0.0,0.0,0.0,9520.0,0.0,2430976.0,607360.0,0.004608,19.13331199999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75968.0,18980.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",796,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,0.001856,19.13516799999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",797,0.0,0.0,0,0,0.0,0.0,0.0,0.0,56976.0,0.0,5469696.0,270528.0,0.010112,19.14527999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,170928.0,8454.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",798,0.0,0.0,0,0,0.0,0.0,0.0,0.0,14280.0,0.0,3038720.0,0.0,0.005888,19.151167999999977,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,94960.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",799,8508416.0,20076672.0,0,0,0.0,20076672.0,20076672.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,0.061952,19.21311999999998,2452096.0,607744.0,8508416.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,227904.0,75968.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",800,0.0,0.0,0,0,0.0,0.0,0.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,0.007552,19.22067199999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",801,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002112,19.22278399999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",802,0.0,0.0,0,0,0.0,0.0,0.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,0.007552,19.23033599999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",803,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002112,19.23244799999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",804,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,0.001984,19.23443199999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",805,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,0.002912,19.23734399999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",806,0.0,990796.0,0,0,0.0,990796.0,990796.0,7692.0,4832.0,0.6141807729160013,2431392.0,2560.0,0.007872,19.245215999999978,990796.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75981.0,80.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",807,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002016,19.24723199999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",808,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003168,19.250399999999978,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",809,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.001984,19.252383999999978,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",810,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,0.002912,19.255295999999976,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",811,1769472.0,4754432.0,0,0,0.0,4754432.0,4754432.0,0.0,18992.0,0.0,0.0,2430976.0,0.004128,19.259423999999978,0.0,1215488.0,1769472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,75968.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",812,3038720.0,6077440.0,0,0,0.0,6077440.0,6077440.0,0.0,14280.0,0.0,4861952.0,3584.0,0.008224,19.267647999999976,0.0,0.0,3038720.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,151936.0,112.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",813,0.0,0.0,0,0,0.0,0.0,0.0,14092.0,4912.0,0.7415280993475057,2432256.0,2752.0,0.00944,19.277087999999978,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,76008.0,86.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",814,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,96.0,160.0,0.002624,19.27971199999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",815,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.001696,19.281407999999978,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",816,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.001632,19.28303999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",817,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,0.002048,19.285087999999977,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",818,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002048,19.287135999999975,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",819,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,0.00288,19.290015999999977,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",820,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003232,19.293247999999977,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",821,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002016,19.295263999999978,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
