Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.001824,0.001824,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.001696,0.00352,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.001728,0.005248,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,0.002048,0.007296,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.0024,0.009696,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",6,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,0.0024,0.012095999999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",7,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003264,0.015359999999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",8,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003232,0.018591999999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",9,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002464,0.021056,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",10,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.001696,0.022751999999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",11,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.001728,0.02448,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,0.001728,0.026208,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,0.0,0.0,0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,0.002464,0.028672,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00208,0.030751999999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",15,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002176,0.032928,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",16,0.0,0.0,0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,32.0,32.0,0.002496,0.035424,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",17,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002016,0.037439999999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",18,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00208,0.03951999999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",19,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,0.002144,0.04166399999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",20,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2304.0,0.0,26112.0,98304.0,0.003808,0.04547199999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,816.0,3072.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",21,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2304.0,0.0,26112.0,98304.0,0.003872,0.04934399999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,816.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",22,24576.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,0.002176,0.05151999999999999,0.0,0.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",23,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002016,0.053535999999999986,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",24,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00336,0.05689599999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",25,133188.0,437492.0,0,0,0.0,437492.0,437492.0,80.0,2120.0,0.03636363636363636,295808.0,98560.0,0.011456,0.06835199999999998,133680.0,37436.0,133188.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,9244.0,3080.0
ampere_sgemm_128x32_sliced1x4_nn,26,3625648128.0,7263682560.0,0,0,0.0,7263682560.0,7263682560.0,11892096.0,3666096.0,0.7643623372175893,468099072.0,898560.0,0.502272,0.570624,5308416.0,7077888.0,3625648128.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,14628096.0,28080.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",27,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,0.002784,0.573408,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",28,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,0.00272,0.576128,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",29,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,0.002816,0.578944,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",30,786432.0,26124288.0,0,0,0.0,26124288.0,26124288.0,204288.0,384.0,0.99812382739212,294912.0,98304.0,0.031328,0.610272,19759104.0,4792320.0,786432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,9216.0,3072.0
ampere_sgemm_128x32_sliced1x4_nn,31,1208352768.0,2419458048.0,0,0,0.0,2419458048.0,2419458048.0,3920640.0,5778662.0,0.40421877780483584,156011488.0,199680.0,0.166848,0.77712,1179648.0,1572864.0,1208352768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4875359.0,6240.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",32,24576.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,0.002176,0.779296,0.0,0.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",33,133188.0,437492.0,0,0,0.0,437492.0,437492.0,80.0,2120.0,0.03636363636363636,294912.0,98560.0,0.011456,0.790752,133680.0,37436.0,133188.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,9216.0,3080.0
ampere_sgemm_128x32_sliced1x4_nn,34,4911267840.0,9850060800.0,0,0,0.0,9850060800.0,9850060800.0,16442880.0,4906176.0,0.7701923682246185,624489280.0,1996800.0,0.752224,1.542976,11796480.0,15728640.0,4911267840.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,19515290.0,62400.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",35,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,0.002688,1.545664,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",36,0.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,0.002528,1.548192,0.0,196608.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",37,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,0.002592,1.550784,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",38,98304.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,2304.0,0.0,786432.0,393216.0,0.002912,1.553696,0.0,0.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",39,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,0.0024,1.556096,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",40,527156.0,1349224.0,0,0,0.0,1349224.0,1349224.0,0.0,1536.0,0.0,393216.0,393216.0,0.002656,1.558752,98304.0,196608.0,527156.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",41,98304.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,0.002592,1.5613439999999998,0.0,0.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",42,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,2304.0,0.0,786432.0,393216.0,0.002944,1.564288,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,12288.0
ampere_sgemm_128x32_sliced1x4_nn,43,4869586944.0,9751560192.0,0,0,0.0,9751560192.0,9751560192.0,15845760.0,4874112.0,0.7647614811520071,623247424.0,884736.0,0.65456,2.218848,5308416.0,7077888.0,4869586944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,19476482.0,27648.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",44,0.0,270336.0,0,0,0.0,270336.0,270336.0,0.0,12288.0,0.0,909312.0,98304.0,0.003616,2.222464,245760.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,28416.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",45,24576.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,0.002496,2.22496,0.0,0.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",46,133188.0,437492.0,0,0,0.0,437492.0,437492.0,80.0,2120.0,0.03636363636363636,295936.0,98560.0,0.01136,2.2363199999999996,133680.0,37436.0,133188.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,9248.0,3080.0
ampere_sgemm_128x32_sliced1x4_nn,47,3625648128.0,7263682560.0,0,0,0.0,7263682560.0,7263682560.0,11892096.0,3666096.0,0.7643623372175893,468099072.0,898560.0,0.504192,2.740512,5308416.0,7077888.0,3625648128.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,14628096.0,28080.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",48,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,0.002752,2.743264,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",49,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,0.00272,2.745984,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",50,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,0.00272,2.748704,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",51,786432.0,26124288.0,0,0,0.0,26124288.0,26124288.0,204288.0,384.0,0.99812382739212,294912.0,98304.0,0.030176,2.77888,19759104.0,4792320.0,786432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,9216.0,3072.0
ampere_sgemm_128x32_sliced1x4_nn,52,1208352768.0,2419458048.0,0,0,0.0,2419458048.0,2419458048.0,3920640.0,5787594.0,0.40384687884531834,156087552.0,199680.0,0.166976,2.945856,1179648.0,1572864.0,1208352768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4877736.0,6240.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",53,24576.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,0.002208,2.948064,0.0,0.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",54,133188.0,437492.0,0,0,0.0,437492.0,437492.0,80.0,2120.0,0.03636363636363636,295424.0,98560.0,0.011552,2.959616,133680.0,37436.0,133188.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,9232.0,3080.0
ampere_sgemm_128x32_sliced1x4_nn,55,4911267840.0,9850060800.0,0,0,0.0,9850060800.0,9850060800.0,16442880.0,4906176.0,0.7701923682246185,624507072.0,1996800.0,0.75104,3.710656,11796480.0,15728640.0,4911267840.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,19515846.0,62400.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",56,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,0.002432,3.7130880000000004,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",57,0.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,0.002528,3.7156160000000003,0.0,196608.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",58,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,0.002656,3.7182720000000002,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",59,98304.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,2304.0,0.0,786432.0,393216.0,0.002976,3.721248,0.0,0.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",60,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,0.0024,3.7236480000000003,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",61,526840.0,1348592.0,0,0,0.0,1348592.0,1348592.0,0.0,1536.0,0.0,393216.0,393216.0,0.002496,3.726144,98304.0,196608.0,526840.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",62,98304.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,0.002368,3.7285120000000003,0.0,0.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",63,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,2304.0,0.0,786432.0,393216.0,0.002848,3.7313600000000005,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,12288.0
ampere_sgemm_128x32_sliced1x4_nn,64,4869586944.0,9751560192.0,0,0,0.0,9751560192.0,9751560192.0,15845760.0,4874112.0,0.7647614811520071,623272704.0,884736.0,0.660288,4.391648,5308416.0,7077888.0,4869586944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,19477272.0,27648.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",65,0.0,270336.0,0,0,0.0,270336.0,270336.0,0.0,12288.0,0.0,909312.0,98304.0,0.003552,4.3952,245760.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,28416.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",66,24576.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,0.002496,4.397696,0.0,0.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",67,133188.0,437492.0,0,0,0.0,437492.0,437492.0,80.0,2120.0,0.03636363636363636,295936.0,98560.0,0.011424,4.40912,133680.0,37436.0,133188.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,9248.0,3080.0
ampere_sgemm_128x32_sliced1x4_nn,68,3625648128.0,7263682560.0,0,0,0.0,7263682560.0,7263682560.0,11892096.0,3666096.0,0.7643623372175893,468099072.0,898560.0,0.505088,4.9142079999999995,5308416.0,7077888.0,3625648128.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,14628096.0,28080.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",69,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,0.002784,4.916992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",70,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,0.002784,4.919776,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",71,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,0.002688,4.922464,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",72,786432.0,26124288.0,0,0,0.0,26124288.0,26124288.0,204288.0,384.0,0.99812382739212,294912.0,98304.0,0.03024,4.952704,19759104.0,4792320.0,786432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,9216.0,3072.0
ampere_sgemm_128x32_sliced1x4_nn,73,1208352768.0,2419458048.0,0,0,0.0,2419458048.0,2419458048.0,3920640.0,4545712.0,0.46308492725083955,156016928.0,199680.0,0.166304,5.119008,1179648.0,1572864.0,1208352768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4875529.0,6240.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",74,24576.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,0.002304,5.121312,0.0,0.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",75,133188.0,437492.0,0,0,0.0,437492.0,437492.0,80.0,2120.0,0.03636363636363636,294912.0,98560.0,0.011584,5.132896,133680.0,37436.0,133188.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,9216.0,3080.0
ampere_sgemm_128x32_sliced1x4_nn,76,4911267840.0,9850060800.0,0,0,0.0,9850060800.0,9850060800.0,16442880.0,4906176.0,0.7701923682246185,624446464.0,1996800.0,0.750912,5.883808,11796480.0,15728640.0,4911267840.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,19513952.0,62400.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",77,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,0.002496,5.886304,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",78,0.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,0.0024,5.888704,0.0,196608.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",79,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,0.00256,5.891264,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",80,98304.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,2304.0,0.0,786432.0,393216.0,0.002784,5.894048,0.0,0.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",81,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,0.0024,5.8964479999999995,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",82,526924.0,1348760.0,0,0,0.0,1348760.0,1348760.0,0.0,1536.0,0.0,393216.0,393216.0,0.00272,5.8991679999999995,98304.0,196608.0,526924.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",83,98304.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,0.002656,5.9018239999999995,0.0,0.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",84,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,2304.0,0.0,786432.0,393216.0,0.00288,5.904704,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,12288.0
ampere_sgemm_128x32_sliced1x4_nn,85,4869586944.0,9751560192.0,0,0,0.0,9751560192.0,9751560192.0,15845760.0,4874112.0,0.7647614811520071,623268832.0,884736.0,0.65376,6.558464,5308416.0,7077888.0,4869586944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,19477151.0,27648.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",86,0.0,270336.0,0,0,0.0,270336.0,270336.0,0.0,12288.0,0.0,909312.0,98304.0,0.003424,6.561888,245760.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,28416.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",87,24576.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,0.002336,6.564223999999999,0.0,0.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",88,133188.0,437492.0,0,0,0.0,437492.0,437492.0,80.0,2120.0,0.03636363636363636,296960.0,98560.0,0.011328,6.575551999999999,133680.0,37436.0,133188.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,9280.0,3080.0
ampere_sgemm_128x32_sliced1x4_nn,89,3625648128.0,7263682560.0,0,0,0.0,7263682560.0,7263682560.0,11892096.0,3666096.0,0.7643623372175893,468099072.0,898560.0,0.50208,7.0776319999999995,5308416.0,7077888.0,3625648128.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,14628096.0,28080.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",90,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,0.002816,7.080448,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",91,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,0.00272,7.083168,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",92,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,0.002656,7.085824,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",93,786432.0,26124288.0,0,0,0.0,26124288.0,26124288.0,204288.0,384.0,0.99812382739212,294912.0,98304.0,0.031552,7.117375999999999,19759104.0,4792320.0,786432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,9216.0,3072.0
ampere_sgemm_128x32_sliced1x4_nn,94,1208352768.0,2419458048.0,0,0,0.0,2419458048.0,2419458048.0,3920640.0,4679077.0,0.45590337449476537,156065600.0,199680.0,0.166496,7.283872,1179648.0,1572864.0,1208352768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4877050.0,6240.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",95,24576.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,0.002336,7.286207999999999,0.0,0.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",96,133188.0,437492.0,0,0,0.0,437492.0,437492.0,80.0,2120.0,0.03636363636363636,295936.0,98560.0,0.011488,7.297695999999999,133680.0,37436.0,133188.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,9248.0,3080.0
ampere_sgemm_128x32_sliced1x4_nn,97,4911267840.0,9850060800.0,0,0,0.0,9850060800.0,9850060800.0,16442880.0,4906176.0,0.7701923682246185,624484000.0,1996800.0,0.751168,8.048864,11796480.0,15728640.0,4911267840.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,19515125.0,62400.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",98,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,0.002464,8.051328,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",99,0.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,0.0024,8.053728,0.0,196608.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",100,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,0.002432,8.05616,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",101,98304.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,2304.0,0.0,786432.0,393216.0,0.003136,8.059296,0.0,0.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",102,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,0.0024,8.061696,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",103,526464.0,1347840.0,0,0,0.0,1347840.0,1347840.0,0.0,1536.0,0.0,393216.0,393216.0,0.00272,8.064416,98304.0,196608.0,526464.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",104,98304.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,0.002368,8.066784,0.0,0.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",105,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,2304.0,0.0,786432.0,393216.0,0.003008,8.069792,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,12288.0
ampere_sgemm_128x32_sliced1x4_nn,106,4869586944.0,9751560192.0,0,0,0.0,9751560192.0,9751560192.0,15845760.0,4874112.0,0.7647614811520071,623277184.0,884736.0,0.657376,8.727167999999999,5308416.0,7077888.0,4869586944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,19477412.0,27648.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",107,0.0,270336.0,0,0,0.0,270336.0,270336.0,0.0,12288.0,0.0,909312.0,98304.0,0.003456,8.730623999999999,245760.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,28416.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",108,24576.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,0.002368,8.732992,0.0,0.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",109,133188.0,437492.0,0,0,0.0,437492.0,437492.0,80.0,2120.0,0.03636363636363636,295424.0,98560.0,0.011552,8.744544,133680.0,37436.0,133188.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,9232.0,3080.0
ampere_sgemm_128x32_sliced1x4_nn,110,3625648128.0,7263682560.0,0,0,0.0,7263682560.0,7263682560.0,11892096.0,3666096.0,0.7643623372175893,468099072.0,898560.0,0.505536,9.250079999999999,5308416.0,7077888.0,3625648128.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,14628096.0,28080.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",111,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,0.002848,9.252927999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",112,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,0.002688,9.255615999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",113,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,0.00272,9.258335999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",114,786432.0,26124288.0,0,0,0.0,26124288.0,26124288.0,204288.0,384.0,0.99812382739212,294912.0,98304.0,0.030368,9.288703999999997,19759104.0,4792320.0,786432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,9216.0,3072.0
ampere_sgemm_128x32_sliced1x4_nn,115,1208352768.0,2419458048.0,0,0,0.0,2419458048.0,2419458048.0,3920640.0,4136156.0,0.4866252043616346,156082368.0,199680.0,0.166816,9.455519999999998,1179648.0,1572864.0,1208352768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4877574.0,6240.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",116,24576.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,0.002336,9.457855999999998,0.0,0.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",117,133188.0,437492.0,0,0,0.0,437492.0,437492.0,80.0,2120.0,0.03636363636363636,294912.0,98560.0,0.011456,9.469311999999999,133680.0,37436.0,133188.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,9216.0,3080.0
ampere_sgemm_128x32_sliced1x4_nn,118,4911267840.0,9850060800.0,0,0,0.0,9850060800.0,9850060800.0,16442880.0,4906176.0,0.7701923682246185,624500256.0,1996800.0,0.75504,10.224351999999998,11796480.0,15728640.0,4911267840.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,19515633.0,62400.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",119,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,0.002368,10.226719999999998,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",120,0.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,0.00256,10.22928,0.0,196608.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",121,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,0.002432,10.231712,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",122,98304.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,2304.0,0.0,786432.0,393216.0,0.002976,10.234688,0.0,0.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",123,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,0.002592,10.23728,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",124,527240.0,1349392.0,0,0,0.0,1349392.0,1349392.0,0.0,1536.0,0.0,393216.0,393216.0,0.002496,10.239776,98304.0,196608.0,527240.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",125,98304.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,0.002432,10.242208000000002,0.0,0.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",126,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,2304.0,0.0,786432.0,393216.0,0.00288,10.245088,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,12288.0
ampere_sgemm_128x32_sliced1x4_nn,127,4869586944.0,9751560192.0,0,0,0.0,9751560192.0,9751560192.0,15845760.0,4874112.0,0.7647614811520071,623270720.0,884736.0,0.655456,10.900544,5308416.0,7077888.0,4869586944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,19477210.0,27648.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",128,0.0,270336.0,0,0,0.0,270336.0,270336.0,0.0,12288.0,0.0,909312.0,98304.0,0.003488,10.904032,245760.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,28416.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",129,24576.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,0.002208,10.90624,0.0,0.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",130,133188.0,437492.0,0,0,0.0,437492.0,437492.0,80.0,2120.0,0.03636363636363636,294912.0,98560.0,0.01152,10.917760000000001,133680.0,37436.0,133188.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,9216.0,3080.0
ampere_sgemm_128x32_sliced1x4_nn,131,3625648128.0,7263682560.0,0,0,0.0,7263682560.0,7263682560.0,11892096.0,3666096.0,0.7643623372175893,468099072.0,898560.0,0.503296,11.421056000000002,5308416.0,7077888.0,3625648128.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,14628096.0,28080.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",132,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,0.00272,11.423776000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",133,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,0.002688,11.426464000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",134,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,0.002816,11.42928,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",135,786432.0,26124288.0,0,0,0.0,26124288.0,26124288.0,204288.0,384.0,0.99812382739212,294912.0,98304.0,0.030112,11.459392000000001,19759104.0,4792320.0,786432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,9216.0,3072.0
ampere_sgemm_128x32_sliced1x4_nn,136,1208352768.0,2419458048.0,0,0,0.0,2419458048.0,2419458048.0,3920640.0,6241651.0,0.38580276829309457,156053344.0,199680.0,0.166592,11.625984,1179648.0,1572864.0,1208352768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4876667.0,6240.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",137,24576.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,0.002208,11.628192,0.0,0.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",138,133188.0,437492.0,0,0,0.0,437492.0,437492.0,80.0,2120.0,0.03636363636363636,294912.0,98560.0,0.011328,11.639520000000001,133680.0,37436.0,133188.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,9216.0,3080.0
ampere_sgemm_128x32_sliced1x4_nn,139,4911267840.0,9850060800.0,0,0,0.0,9850060800.0,9850060800.0,16442880.0,4906176.0,0.7701923682246185,624424416.0,1996800.0,0.749696,12.389216000000001,11796480.0,15728640.0,4911267840.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,19513263.0,62400.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",140,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,0.002592,12.391808000000001,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",141,0.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,0.0024,12.394208,0.0,196608.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",142,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,0.002368,12.396576000000001,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",143,98304.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,2304.0,0.0,786432.0,393216.0,0.002848,12.399424000000002,0.0,0.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",144,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,0.002496,12.401920000000002,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",145,526908.0,1348728.0,0,0,0.0,1348728.0,1348728.0,0.0,1536.0,0.0,393216.0,393216.0,0.002528,12.404448000000002,98304.0,196608.0,526908.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",146,98304.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,0.002624,12.407072000000003,0.0,0.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",147,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,2304.0,0.0,786432.0,393216.0,0.002848,12.409920000000003,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,12288.0
ampere_sgemm_128x32_sliced1x4_nn,148,4869586944.0,9751560192.0,0,0,0.0,9751560192.0,9751560192.0,15845760.0,4874112.0,0.7647614811520071,623268480.0,884736.0,0.656256,13.066176000000002,5308416.0,7077888.0,4869586944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,19477140.0,27648.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",149,0.0,270336.0,0,0,0.0,270336.0,270336.0,0.0,12288.0,0.0,909312.0,98304.0,0.003616,13.069792000000001,245760.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,28416.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",150,24576.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,0.002176,13.071968000000002,0.0,0.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",151,133188.0,437492.0,0,0,0.0,437492.0,437492.0,80.0,2120.0,0.03636363636363636,294912.0,98560.0,0.011424,13.083392000000002,133680.0,37436.0,133188.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,9216.0,3080.0
ampere_sgemm_128x32_sliced1x4_nn,152,3625648128.0,7263682560.0,0,0,0.0,7263682560.0,7263682560.0,11892096.0,3666096.0,0.7643623372175893,468099072.0,898560.0,0.502944,13.586336000000001,5308416.0,7077888.0,3625648128.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,14628096.0,28080.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",153,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,0.002688,13.589024,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",154,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,0.002752,13.591776,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",155,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,0.002912,13.594688,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",156,786432.0,26124288.0,0,0,0.0,26124288.0,26124288.0,204288.0,384.0,0.99812382739212,294912.0,98304.0,0.029504,13.624191999999999,19759104.0,4792320.0,786432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,9216.0,3072.0
ampere_sgemm_128x32_sliced1x4_nn,157,1208352768.0,2419458048.0,0,0,0.0,2419458048.0,2419458048.0,3920640.0,6243729.0,0.3857238949117255,156045824.0,199680.0,0.16672,13.790911999999999,1179648.0,1572864.0,1208352768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4876432.0,6240.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",158,24576.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,0.002368,13.79328,0.0,0.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",159,133188.0,437492.0,0,0,0.0,437492.0,437492.0,80.0,2120.0,0.03636363636363636,295936.0,98560.0,0.011424,13.804704,133680.0,37436.0,133188.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,9248.0,3080.0
ampere_sgemm_128x32_sliced1x4_nn,160,4911267840.0,9850060800.0,0,0,0.0,9850060800.0,9850060800.0,16442880.0,4906176.0,0.7701923682246185,624414176.0,1996800.0,0.752064,14.556768,11796480.0,15728640.0,4911267840.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,19512943.0,62400.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",161,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,0.002496,14.559264,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",162,0.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,0.002432,14.561696000000001,0.0,196608.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",163,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,0.0024,14.564096000000001,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",164,98304.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,2304.0,0.0,786432.0,393216.0,0.002912,14.567008000000001,0.0,0.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",165,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,0.002432,14.569440000000002,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",166,527440.0,1349792.0,0,0,0.0,1349792.0,1349792.0,0.0,1536.0,0.0,393216.0,393216.0,0.002688,14.572128000000001,98304.0,196608.0,527440.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",167,98304.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,0.002368,14.574496000000002,0.0,0.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",168,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,2304.0,0.0,786432.0,393216.0,0.00304,14.577536000000002,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,12288.0
ampere_sgemm_128x32_sliced1x4_nn,169,4869586944.0,9751560192.0,0,0,0.0,9751560192.0,9751560192.0,15845760.0,4874112.0,0.7647614811520071,623272032.0,884736.0,0.65456,15.232096000000002,5308416.0,7077888.0,4869586944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,19477251.0,27648.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",170,0.0,270336.0,0,0,0.0,270336.0,270336.0,0.0,12288.0,0.0,909312.0,98304.0,0.00352,15.235616000000002,245760.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,28416.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",171,24576.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,0.002368,15.237984000000003,0.0,0.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",172,133188.0,437492.0,0,0,0.0,437492.0,437492.0,80.0,2120.0,0.03636363636363636,294912.0,98560.0,0.011392,15.249376000000003,133680.0,37436.0,133188.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,9216.0,3080.0
ampere_sgemm_128x32_sliced1x4_nn,173,3625648128.0,7263682560.0,0,0,0.0,7263682560.0,7263682560.0,11892096.0,3666096.0,0.7643623372175893,468099072.0,898560.0,0.504448,15.753824000000003,5308416.0,7077888.0,3625648128.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,14628096.0,28080.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",174,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,0.002752,15.756576000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",175,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,0.002752,15.759328000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",176,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,0.00272,15.762048000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",177,786432.0,26124288.0,0,0,0.0,26124288.0,26124288.0,204288.0,384.0,0.99812382739212,294912.0,98304.0,0.029888,15.791936000000002,19759104.0,4792320.0,786432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,9216.0,3072.0
ampere_sgemm_128x32_sliced1x4_nn,178,1208352768.0,2419458048.0,0,0,0.0,2419458048.0,2419458048.0,3920640.0,6241088.0,0.38582414329531356,156074048.0,199680.0,0.166912,15.958848000000001,1179648.0,1572864.0,1208352768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4877314.0,6240.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",179,24576.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,0.00224,15.961088000000002,0.0,0.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",180,133188.0,437492.0,0,0,0.0,437492.0,437492.0,80.0,2120.0,0.03636363636363636,294912.0,98560.0,0.011456,15.972544000000003,133680.0,37436.0,133188.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,9216.0,3080.0
ampere_sgemm_128x32_sliced1x4_nn,181,4911267840.0,9850060800.0,0,0,0.0,9850060800.0,9850060800.0,16442880.0,4906176.0,0.7701923682246185,624453856.0,1996800.0,0.75376,16.726304000000003,11796480.0,15728640.0,4911267840.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,19514183.0,62400.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",182,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,0.002688,16.728992,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",183,0.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,0.002688,16.73168,0.0,196608.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",184,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,0.002592,16.734272,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",185,98304.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,2304.0,0.0,786432.0,393216.0,0.003072,16.737344,0.0,0.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",186,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,0.002464,16.739808,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",187,527100.0,1349112.0,0,0,0.0,1349112.0,1349112.0,0.0,1536.0,0.0,393216.0,393216.0,0.002752,16.74256,98304.0,196608.0,527100.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",188,98304.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,0.002464,16.745024,0.0,0.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",189,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,2304.0,0.0,786432.0,393216.0,0.002976,16.748,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,12288.0
ampere_sgemm_128x32_sliced1x4_nn,190,4869586944.0,9751560192.0,0,0,0.0,9751560192.0,9751560192.0,15845760.0,4874112.0,0.7647614811520071,623243904.0,884736.0,0.658112,17.406112,5308416.0,7077888.0,4869586944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,19476372.0,27648.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",191,0.0,270336.0,0,0,0.0,270336.0,270336.0,0.0,12288.0,0.0,909312.0,98304.0,0.003424,17.409536,245760.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,28416.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",192,24576.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,0.00224,17.411776,0.0,0.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",193,133188.0,437492.0,0,0,0.0,437492.0,437492.0,80.0,2120.0,0.03636363636363636,294912.0,98560.0,0.011424,17.4232,133680.0,37436.0,133188.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,9216.0,3080.0
ampere_sgemm_128x32_sliced1x4_tn,194,9890168832.0,19825410048.0,0,0,0.0,19825410048.0,19825410048.0,32810784.0,9976304.0,0.76683844434564,1273749504.0,2471040.0,1.552544,18.975744000000002,19316736.0,25755648.0,9890168832.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,39804672.0,77220.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",195,0.0,1005140.0,0,0,0.0,1005140.0,1005140.0,0.0,31420.0,0.0,3467008.0,822560.0,0.00672,18.982464000000004,804112.0,201028.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,108344.0,25705.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",196,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.001728,18.984192000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",197,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,64.0,128.0,0.002624,18.986816000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",198,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002048,18.988864000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",199,0.0,201028.0,0,0,0.0,201028.0,201028.0,0.0,3158.0,0.0,804128.0,804128.0,0.00304,18.991904,0.0,201028.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25129.0,25129.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",200,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.001696,18.9936,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",201,0.0,0.0,0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813024.0,58816.0,0.004096,18.997696,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25407.0,1838.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",202,0.0,0.0,0,0,0.0,0.0,0.0,14800.0,82608.0,0.15193823915900131,5134592.0,0.0,0.005568,19.003264,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160456.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",203,0.0,0.0,0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813024.0,57536.0,0.004,19.007264000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25407.0,1798.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",204,0.0,0.0,0,0,0.0,0.0,0.0,14800.0,82608.0,0.15193823915900131,5134592.0,0.0,0.005504,19.012768,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160456.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",205,0.0,0.0,0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813024.0,56320.0,0.003744,19.016512000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25407.0,1760.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",206,0.0,0.0,0,0,0.0,0.0,0.0,14800.0,83008.0,0.1513168656960576,5134592.0,0.0,0.005472,19.021984000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160456.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",207,0.0,0.0,0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813024.0,57088.0,0.003872,19.025856000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25407.0,1784.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",208,0.0,0.0,0,0,0.0,0.0,0.0,14800.0,83408.0,0.15070055392636036,5134592.0,128.0,0.00544,19.031296000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160456.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",209,0.0,0.0,0,0,0.0,0.0,0.0,0.0,21.0,0.0,6432.0,800.0,0.002496,19.033792000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,201.0,25.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",210,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,0.001728,19.035520000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",211,0.0,0.0,0,0,0.0,0.0,0.0,497.0,22.0,0.9576107899807321,800.0,0.0,0.003776,19.039296000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",212,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,0.001728,19.041024000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",213,0.0,0.0,0,0,0.0,0.0,0.0,497.0,22.0,0.9576107899807321,800.0,0.0,0.00352,19.044544000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",214,0.0,0.0,0,0,0.0,0.0,0.0,39936.0,13012.0,0.7542494522928156,831456.0,8704.0,0.005824,19.050368000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25983.0,272.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",215,0.0,0.0,0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,544.0,0.006464,19.056832000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,80.0,17.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",216,0.0,0.0,0,0,0.0,0.0,0.0,0.0,18849.0,0.0,814496.0,86976.0,0.003936,19.060768000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25453.0,2718.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",217,0.0,0.0,0,0,0.0,0.0,0.0,0.0,4737.0,0.0,1005184.0,0.0,0.003392,19.064160000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,31412.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",218,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6283.0,0.0,0.0,1608224.0,0.00272,19.06688000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,50257.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",219,0.0,0.0,0,0,0.0,0.0,0.0,98304.0,6283.0,0.9399256121697726,804128.0,0.0,0.004416,19.071296000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25129.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",220,0.0,0.0,0,0,0.0,0.0,0.0,156.0,64.0,0.7090909090909091,8192.0,0.0,0.002176,19.073472000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",221,0.0,0.0,0,0,0.0,0.0,0.0,77142.0,30018.0,0.7198768197088465,3090112.0,2050784.0,0.010368,19.083840000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96566.0,64087.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",222,0.0,0.0,0,0,0.0,0.0,0.0,23142.0,35987.0,0.3913815555818634,3110080.0,2479936.0,0.00864,19.092480000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,97190.0,77498.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",223,0.0,0.0,0,0,0.0,0.0,0.0,23883.0,35409.0,0.40280307630034407,3102656.0,1886592.0,0.009248,19.101728000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96958.0,58956.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",224,0.0,0.0,0,0,0.0,0.0,0.0,22983.0,36596.0,0.3857567263633159,3089984.0,2479936.0,0.00912,19.110848000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96562.0,77498.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",225,0.0,0.0,0,0,0.0,0.0,0.0,14336.0,6283.0,0.6952810514573937,1608224.0,0.0,0.004576,19.115424000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,50257.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",226,0.0,0.0,0,0,0.0,0.0,0.0,39.0,16.0,0.7090909090909091,2048.0,0.0,0.002208,19.117632000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",227,0.0,0.0,0,0,0.0,0.0,0.0,20059.0,17951.0,0.5277295448566167,2113056.0,1379904.0,0.007936,19.125568000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,66033.0,43122.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",228,0.0,0.0,0,0,0.0,0.0,0.0,0.0,25132.0,0.0,2428448.0,2412352.0,0.005408,19.130976000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75889.0,75386.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",229,2814392.0,6655044.0,0,0,0.0,6655044.0,6655044.0,528.0,6704.0,0.07300884955752213,2276736.0,753408.0,0.024,19.154976000000005,825232.0,201028.0,2814392.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,71148.0,23544.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",230,0.0,1024200.0,0,0,0.0,1024200.0,1024200.0,112284.0,12568.0,0.8993368147887099,804384.0,624864.0,0.072064,19.227040000000006,1024200.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25137.0,19527.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",231,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3158.0,0.0,804128.0,200800.0,0.002976,19.230016000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25129.0,6275.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",232,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,0.00192,19.231936000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",233,0.0,0.0,0,0,0.0,0.0,0.0,0.0,18849.0,0.0,1809280.0,82944.0,0.007712,19.239648000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,56540.0,2592.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",234,0.0,0.0,0,0,0.0,0.0,0.0,0.0,4737.0,0.0,1005184.0,0.0,0.003488,19.243136000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,31412.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",235,2814392.0,6655044.0,0,0,0.0,6655044.0,6655044.0,528.0,6704.0,0.07300884955752213,2276992.0,752704.0,0.024064,19.267200000000006,825232.0,201028.0,2814392.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,71156.0,23522.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",236,0.0,0.0,0,0,0.0,0.0,0.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,0.006336,19.273536000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",237,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002144,19.27568000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",238,0.0,0.0,0,0,0.0,0.0,0.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,0.0064,19.282080000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",239,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002208,19.284288000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",240,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,0.00208,19.286368000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",241,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,0.002944,19.289312000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",242,0.0,220484.0,0,0,0.0,220484.0,220484.0,320.0,1582.0,0.16824395373291273,804224.0,128.0,0.011168,19.300480000000007,220484.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25132.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",243,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.001984,19.302464000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",244,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.0032,19.305664000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",245,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00208,19.307744000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",246,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,0.002944,19.310688000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",247,1769472.0,3941000.0,0,0,0.0,3941000.0,3941000.0,0.0,6283.0,0.0,0.0,804128.0,0.004,19.314688000000007,0.0,402056.0,1769472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,25129.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",248,1005140.0,2010280.0,0,0,0.0,2010280.0,2010280.0,0.0,4737.0,0.0,1608256.0,0.0,0.005024,19.319712000000006,0.0,0.0,1005140.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,50258.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",249,0.0,0.0,0,0,0.0,0.0,0.0,640.0,1582.0,0.28802880288028804,804352.0,128.0,0.01584,19.335552000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25136.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",250,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,0.002048,19.337600000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",251,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.001984,19.339584000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",252,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,0.002208,19.341792000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",253,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,0.002048,19.343840000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",254,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,64.0,128.0,0.002624,19.346464000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",255,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.00176,19.348224000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",256,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.001696,19.349920000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",257,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,0.002016,19.351936000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",258,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.00176,19.353696000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",259,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,32.0,0.002304,19.356000000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",260,0.0,0.0,0,0,0.0,0.0,0.0,0.0,5.0,0.0,32.0,32.0,0.004768,19.360768000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",261,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,0.00208,19.362848000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",262,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002048,19.364896,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",263,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,0.002944,19.36784,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",264,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003104,19.370944,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",265,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00208,19.373024,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",266,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002176,19.3752,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",267,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,32.0,0.003328,19.378528,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",268,0.0,0.0,0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,64.0,32.0,0.00256,19.381088,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",269,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,0.002048,19.383135999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",270,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,0.002048,19.385183999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",271,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,0.0,0.00208,19.387263999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",272,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,0.00224,19.389503999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",273,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2304.0,0.0,75264.0,98304.0,0.003936,19.393439999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2352.0,3072.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",274,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2304.0,0.0,26112.0,98304.0,0.003392,19.396831999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,816.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",275,24576.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,0.002176,19.399007999999995,0.0,0.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",276,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,0.00208,19.401087999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",277,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003264,19.404351999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",278,133188.0,437492.0,0,0,0.0,437492.0,437492.0,80.0,2120.0,0.03636363636363636,295424.0,98560.0,0.011392,19.415743999999997,133680.0,37436.0,133188.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,9232.0,3080.0
ampere_sgemm_128x32_sliced1x4_nn,279,3625648128.0,7263682560.0,0,0,0.0,7263682560.0,7263682560.0,11892096.0,3666096.0,0.7643623372175893,468099072.0,898560.0,0.49968,19.915423999999998,5308416.0,7077888.0,3625648128.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,14628096.0,28080.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",280,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3072.0,0.0,196608.0,196608.0,0.004064,19.919487999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",281,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3072.0,0.0,196608.0,196608.0,0.004032,19.923519999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",282,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,0.002624,19.926143999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",283,786432.0,26148864.0,0,0,0.0,26148864.0,26148864.0,204288.0,384.0,0.99812382739212,491520.0,98304.0,0.030528,19.956671999999998,19783680.0,4792320.0,786432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,15360.0,3072.0
ampere_sgemm_128x32_sliced1x4_nn,284,1208352768.0,2419458048.0,0,0,0.0,2419458048.0,2419458048.0,3920640.0,5515532.0,0.41549051882479465,156028384.0,199680.0,0.1664,20.123071999999997,1179648.0,1572864.0,1208352768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4875887.0,6240.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",285,24576.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,0.002272,20.125344,0.0,0.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",286,133188.0,437492.0,0,0,0.0,437492.0,437492.0,80.0,2120.0,0.03636363636363636,295424.0,98560.0,0.011552,20.136895999999997,133680.0,37436.0,133188.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,9232.0,3080.0
ampere_sgemm_128x32_sliced1x4_nn,287,4911267840.0,9850060800.0,0,0,0.0,9850060800.0,9850060800.0,16442880.0,4906176.0,0.7701923682246185,624453536.0,1996800.0,0.751424,20.888319999999997,11796480.0,15728640.0,4911267840.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,19514173.0,62400.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",288,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,0.0024,20.890719999999998,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",289,0.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,0.0024,20.89312,0.0,196608.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",290,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,0.002368,20.895488,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",291,98304.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,2304.0,0.0,786432.0,393216.0,0.003008,20.898496,0.0,0.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",292,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,0.0024,20.900896000000003,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",293,527215.0,1349342.0,0,0,0.0,1349342.0,1349342.0,0.0,1536.0,0.0,393216.0,393216.0,0.002496,20.903392000000004,98304.0,196608.0,527215.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",294,98304.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,0.0024,20.905792000000005,0.0,0.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",295,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,2304.0,0.0,786432.0,393216.0,0.00288,20.908672000000006,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,12288.0
ampere_sgemm_128x32_sliced1x4_nn,296,4869586944.0,9751560192.0,0,0,0.0,9751560192.0,9751560192.0,15845760.0,4874112.0,0.7647614811520071,623262496.0,884736.0,0.655072,21.563744000000007,5308416.0,7077888.0,4869586944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,19476953.0,27648.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",297,0.0,270336.0,0,0,0.0,270336.0,270336.0,0.0,12288.0,0.0,909312.0,98304.0,0.003392,21.56713600000001,245760.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,28416.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",298,24576.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,0.002144,21.56928000000001,0.0,0.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",299,133188.0,437492.0,0,0,0.0,437492.0,437492.0,80.0,2120.0,0.03636363636363636,295936.0,98560.0,0.011392,21.58067200000001,133680.0,37436.0,133188.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,9248.0,3080.0
ampere_sgemm_128x32_sliced1x4_nn,300,3625648128.0,7263682560.0,0,0,0.0,7263682560.0,7263682560.0,11892096.0,3666096.0,0.7643623372175893,468099072.0,898560.0,0.502272,22.082944000000012,5308416.0,7077888.0,3625648128.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,14628096.0,28080.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",301,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3072.0,0.0,196608.0,196608.0,0.004064,22.08700800000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",302,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3072.0,0.0,196608.0,196608.0,0.004032,22.09104000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",303,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,0.002688,22.09372800000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",304,786432.0,26148864.0,0,0,0.0,26148864.0,26148864.0,204288.0,384.0,0.99812382739212,491520.0,98304.0,0.030528,22.12425600000001,19783680.0,4792320.0,786432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,15360.0,3072.0
ampere_sgemm_128x32_sliced1x4_nn,305,1208352768.0,2419458048.0,0,0,0.0,2419458048.0,2419458048.0,3920640.0,5505809.0,0.4159190804511858,156041120.0,199680.0,0.166304,22.29056000000001,1179648.0,1572864.0,1208352768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4876285.0,6240.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",306,24576.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,0.002176,22.29273600000001,0.0,0.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",307,133188.0,437492.0,0,0,0.0,437492.0,437492.0,80.0,2120.0,0.03636363636363636,295936.0,98560.0,0.011456,22.304192000000008,133680.0,37436.0,133188.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,9248.0,3080.0
ampere_sgemm_128x32_sliced1x4_nn,308,4911267840.0,9850060800.0,0,0,0.0,9850060800.0,9850060800.0,16442880.0,4906176.0,0.7701923682246185,624486624.0,1996800.0,0.75152,23.055712000000007,11796480.0,15728640.0,4911267840.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,19515207.0,62400.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",309,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,0.002464,23.058176000000007,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",310,0.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,0.0024,23.060576000000008,0.0,196608.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",311,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,0.002592,23.063168000000008,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",312,98304.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,2304.0,0.0,786432.0,393216.0,0.002912,23.066080000000007,0.0,0.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",313,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,0.0024,23.068480000000008,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",314,526913.0,1348738.0,0,0,0.0,1348738.0,1348738.0,0.0,1536.0,0.0,393216.0,393216.0,0.002528,23.07100800000001,98304.0,196608.0,526913.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",315,98304.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,0.002368,23.07337600000001,0.0,0.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",316,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,2304.0,0.0,786432.0,393216.0,0.00304,23.07641600000001,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,12288.0
ampere_sgemm_128x32_sliced1x4_nn,317,4869586944.0,9751560192.0,0,0,0.0,9751560192.0,9751560192.0,15845760.0,4874112.0,0.7647614811520071,623263712.0,884736.0,0.655136,23.731552000000008,5308416.0,7077888.0,4869586944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,19476991.0,27648.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",318,0.0,270336.0,0,0,0.0,270336.0,270336.0,0.0,12288.0,0.0,909312.0,98304.0,0.003552,23.735104000000007,245760.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,28416.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",319,24576.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,0.002464,23.737568000000007,0.0,0.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",320,133188.0,437492.0,0,0,0.0,437492.0,437492.0,80.0,2120.0,0.03636363636363636,295424.0,98560.0,0.011328,23.748896000000006,133680.0,37436.0,133188.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,9232.0,3080.0
ampere_sgemm_128x32_sliced1x4_nn,321,3625648128.0,7263682560.0,0,0,0.0,7263682560.0,7263682560.0,11892096.0,3666096.0,0.7643623372175893,468099072.0,898560.0,0.503072,24.251968000000005,5308416.0,7077888.0,3625648128.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,14628096.0,28080.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",322,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3072.0,0.0,196608.0,196608.0,0.004,24.255968000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",323,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3072.0,0.0,196608.0,196608.0,0.004064,24.260032000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",324,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,0.00272,24.262752000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",325,786432.0,26148864.0,0,0,0.0,26148864.0,26148864.0,204288.0,384.0,0.99812382739212,491520.0,98304.0,0.031744,24.294496000000006,19783680.0,4792320.0,786432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,15360.0,3072.0
ampere_sgemm_128x32_sliced1x4_nn,326,1208352768.0,2419458048.0,0,0,0.0,2419458048.0,2419458048.0,3920640.0,5511989.0,0.4156465816688009,156100192.0,199680.0,0.167616,24.462112000000005,1179648.0,1572864.0,1208352768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4878131.0,6240.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",327,24576.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,0.002176,24.464288000000003,0.0,0.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",328,133188.0,437492.0,0,0,0.0,437492.0,437492.0,80.0,2120.0,0.03636363636363636,295424.0,98560.0,0.011616,24.475904000000003,133680.0,37436.0,133188.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,9232.0,3080.0
ampere_sgemm_128x32_sliced1x4_nn,329,4911267840.0,9850060800.0,0,0,0.0,9850060800.0,9850060800.0,16442880.0,4906176.0,0.7701923682246185,624433536.0,1996800.0,0.752192,25.228096000000004,11796480.0,15728640.0,4911267840.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,19513548.0,62400.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",330,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,0.002688,25.230784000000003,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",331,0.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,0.002592,25.233376000000003,0.0,196608.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",332,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,0.0024,25.235776000000005,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",333,98304.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,2304.0,0.0,786432.0,393216.0,0.003168,25.238944000000004,0.0,0.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",334,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,0.0024,25.241344000000005,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",335,526920.0,1348752.0,0,0,0.0,1348752.0,1348752.0,0.0,1536.0,0.0,393216.0,393216.0,0.002464,25.243808000000005,98304.0,196608.0,526920.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",336,98304.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,0.002432,25.246240000000004,0.0,0.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",337,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,2304.0,0.0,786432.0,393216.0,0.00288,25.249120000000005,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,12288.0
ampere_sgemm_128x32_sliced1x4_nn,338,4869586944.0,9751560192.0,0,0,0.0,9751560192.0,9751560192.0,15845760.0,4874112.0,0.7647614811520071,623263680.0,884736.0,0.654688,25.903808000000005,5308416.0,7077888.0,4869586944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,19476990.0,27648.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",339,0.0,270336.0,0,0,0.0,270336.0,270336.0,0.0,12288.0,0.0,909312.0,98304.0,0.00336,25.907168000000006,245760.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,28416.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",340,24576.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,0.00224,25.909408000000006,0.0,0.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",341,133188.0,437492.0,0,0,0.0,437492.0,437492.0,80.0,2120.0,0.03636363636363636,295936.0,98560.0,0.011552,25.920960000000004,133680.0,37436.0,133188.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,9248.0,3080.0
ampere_sgemm_128x32_sliced1x4_nn,342,3625648128.0,7263682560.0,0,0,0.0,7263682560.0,7263682560.0,11892096.0,3666096.0,0.7643623372175893,468099072.0,898560.0,0.503392,26.424352000000006,5308416.0,7077888.0,3625648128.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,14628096.0,28080.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",343,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3072.0,0.0,196608.0,196608.0,0.004,26.428352000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",344,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3072.0,0.0,196608.0,196608.0,0.004224,26.432576000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",345,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,0.002656,26.43523200000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",346,786432.0,26148864.0,0,0,0.0,26148864.0,26148864.0,204288.0,384.0,0.99812382739212,491520.0,98304.0,0.030144,26.46537600000001,19783680.0,4792320.0,786432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,15360.0,3072.0
ampere_sgemm_128x32_sliced1x4_nn,347,1208352768.0,2419458048.0,0,0,0.0,2419458048.0,2419458048.0,3920640.0,5513244.0,0.4155912877453231,156039552.0,199680.0,0.166176,26.63155200000001,1179648.0,1572864.0,1208352768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4876236.0,6240.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",348,24576.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,0.002208,26.63376000000001,0.0,0.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",349,133188.0,437492.0,0,0,0.0,437492.0,437492.0,80.0,2120.0,0.03636363636363636,295424.0,98560.0,0.011552,26.645312000000008,133680.0,37436.0,133188.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,9232.0,3080.0
ampere_sgemm_128x32_sliced1x4_nn,350,4911267840.0,9850060800.0,0,0,0.0,9850060800.0,9850060800.0,16442880.0,4906176.0,0.7701923682246185,624465024.0,1996800.0,0.752256,27.397568000000007,11796480.0,15728640.0,4911267840.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,19514532.0,62400.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",351,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,0.002432,27.400000000000006,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",352,0.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,0.002496,27.402496000000006,0.0,196608.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",353,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,0.002528,27.405024000000008,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",354,98304.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,2304.0,0.0,786432.0,393216.0,0.00288,27.40790400000001,0.0,0.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",355,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,0.002624,27.41052800000001,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",356,527306.0,1349524.0,0,0,0.0,1349524.0,1349524.0,0.0,1536.0,0.0,393216.0,393216.0,0.002496,27.41302400000001,98304.0,196608.0,527306.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",357,98304.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,0.002624,27.41564800000001,0.0,0.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",358,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,2304.0,0.0,786432.0,393216.0,0.003104,27.418752000000012,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,12288.0
ampere_sgemm_128x32_sliced1x4_nn,359,4869586944.0,9751560192.0,0,0,0.0,9751560192.0,9751560192.0,15845760.0,4874112.0,0.7647614811520071,623255648.0,884736.0,0.65488,28.07363200000001,5308416.0,7077888.0,4869586944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,19476739.0,27648.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",360,0.0,270336.0,0,0,0.0,270336.0,270336.0,0.0,12288.0,0.0,909312.0,98304.0,0.003424,28.07705600000001,245760.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,28416.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",361,24576.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,0.002208,28.07926400000001,0.0,0.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",362,133188.0,437492.0,0,0,0.0,437492.0,437492.0,80.0,2120.0,0.03636363636363636,294912.0,98560.0,0.011488,28.09075200000001,133680.0,37436.0,133188.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,9216.0,3080.0
ampere_sgemm_128x32_sliced1x4_nn,363,3625648128.0,7263682560.0,0,0,0.0,7263682560.0,7263682560.0,11892096.0,3666096.0,0.7643623372175893,468099072.0,898560.0,0.5048,28.59555200000001,5308416.0,7077888.0,3625648128.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,14628096.0,28080.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",364,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3072.0,0.0,196608.0,196608.0,0.004096,28.59964800000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",365,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3072.0,0.0,196608.0,196608.0,0.004064,28.60371200000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",366,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,0.00272,28.60643200000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",367,786432.0,26148864.0,0,0,0.0,26148864.0,26148864.0,204288.0,384.0,0.99812382739212,491520.0,98304.0,0.03056,28.63699200000001,19783680.0,4792320.0,786432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,15360.0,3072.0
ampere_sgemm_128x32_sliced1x4_nn,368,1208352768.0,2419458048.0,0,0,0.0,2419458048.0,2419458048.0,3920640.0,5510945.0,0.4156925903758488,156061152.0,199680.0,0.171584,28.80857600000001,1179648.0,1572864.0,1208352768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4876911.0,6240.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",369,24576.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,0.002176,28.810752000000008,0.0,0.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",370,133188.0,437492.0,0,0,0.0,437492.0,437492.0,80.0,2120.0,0.03636363636363636,296448.0,98560.0,0.011488,28.822240000000008,133680.0,37436.0,133188.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,9264.0,3080.0
ampere_sgemm_128x32_sliced1x4_nn,371,4911267840.0,9850060800.0,0,0,0.0,9850060800.0,9850060800.0,16442880.0,4906176.0,0.7701923682246185,624446304.0,1996800.0,0.755264,29.57750400000001,11796480.0,15728640.0,4911267840.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,19513947.0,62400.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",372,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,0.002432,29.579936000000007,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",373,0.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,0.002656,29.58259200000001,0.0,196608.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",374,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,0.002432,29.585024000000008,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",375,98304.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,2304.0,0.0,786432.0,393216.0,0.00288,29.58790400000001,0.0,0.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",376,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,0.002592,29.59049600000001,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",377,527071.0,1349054.0,0,0,0.0,1349054.0,1349054.0,0.0,1536.0,0.0,393216.0,393216.0,0.002464,29.59296000000001,98304.0,196608.0,527071.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",378,98304.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,0.002368,29.59532800000001,0.0,0.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",379,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,2304.0,0.0,786432.0,393216.0,0.002976,29.59830400000001,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,12288.0
ampere_sgemm_128x32_sliced1x4_nn,380,4869586944.0,9751560192.0,0,0,0.0,9751560192.0,9751560192.0,15845760.0,4874112.0,0.7647614811520071,623278336.0,884736.0,0.65568,30.25398400000001,5308416.0,7077888.0,4869586944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,19477448.0,27648.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",381,0.0,270336.0,0,0,0.0,270336.0,270336.0,0.0,12288.0,0.0,909312.0,98304.0,0.003488,30.25747200000001,245760.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,28416.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",382,24576.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,0.002208,30.25968000000001,0.0,0.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",383,133188.0,437492.0,0,0,0.0,437492.0,437492.0,80.0,2120.0,0.03636363636363636,294912.0,98560.0,0.011392,30.27107200000001,133680.0,37436.0,133188.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,9216.0,3080.0
ampere_sgemm_128x32_sliced1x4_nn,384,3625648128.0,7263682560.0,0,0,0.0,7263682560.0,7263682560.0,11892096.0,3666096.0,0.7643623372175893,468099072.0,898560.0,0.507424,30.77849600000001,5308416.0,7077888.0,3625648128.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,14628096.0,28080.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",385,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3072.0,0.0,196608.0,196608.0,0.004,30.782496000000013,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",386,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3072.0,0.0,196608.0,196608.0,0.00416,30.78665600000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",387,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,0.002688,30.78934400000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",388,786432.0,26148864.0,0,0,0.0,26148864.0,26148864.0,204288.0,384.0,0.99812382739212,491520.0,98304.0,0.029664,30.81900800000001,19783680.0,4792320.0,786432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,15360.0,3072.0
ampere_sgemm_128x32_sliced1x4_nn,389,1208352768.0,2419458048.0,0,0,0.0,2419458048.0,2419458048.0,3920640.0,5509143.0,0.4157720278398771,156097120.0,199680.0,0.166752,30.98576000000001,1179648.0,1572864.0,1208352768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4878035.0,6240.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",390,24576.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,0.002208,30.98796800000001,0.0,0.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",391,133188.0,437492.0,0,0,0.0,437492.0,437492.0,80.0,2120.0,0.03636363636363636,295424.0,98560.0,0.01136,30.99932800000001,133680.0,37436.0,133188.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,9232.0,3080.0
ampere_sgemm_128x32_sliced1x4_nn,392,4911267840.0,9850060800.0,0,0,0.0,9850060800.0,9850060800.0,16442880.0,4906176.0,0.7701923682246185,624412704.0,1996800.0,0.753024,31.75235200000001,11796480.0,15728640.0,4911267840.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,19512897.0,62400.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",393,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,0.0024,31.75475200000001,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",394,0.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,0.002528,31.757280000000012,0.0,196608.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",395,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,0.002368,31.759648000000013,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",396,98304.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,2304.0,0.0,786432.0,393216.0,0.00304,31.76268800000001,0.0,0.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",397,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,0.002624,31.765312000000012,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",398,526413.0,1347738.0,0,0,0.0,1347738.0,1347738.0,0.0,1536.0,0.0,393216.0,393216.0,0.002528,31.767840000000014,98304.0,196608.0,526413.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",399,98304.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,0.002368,31.770208000000014,0.0,0.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",400,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,2304.0,0.0,786432.0,393216.0,0.003168,31.773376000000013,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,12288.0
ampere_sgemm_128x32_sliced1x4_nn,401,4869586944.0,9751560192.0,0,0,0.0,9751560192.0,9751560192.0,15845760.0,4874112.0,0.7647614811520071,623272992.0,884736.0,0.654048,32.427424000000016,5308416.0,7077888.0,4869586944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,19477281.0,27648.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",402,0.0,270336.0,0,0,0.0,270336.0,270336.0,0.0,12288.0,0.0,909312.0,98304.0,0.003584,32.43100800000001,245760.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,28416.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",403,24576.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,0.002176,32.43318400000001,0.0,0.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",404,133188.0,437492.0,0,0,0.0,437492.0,437492.0,80.0,2120.0,0.03636363636363636,295424.0,98560.0,0.011712,32.444896000000014,133680.0,37436.0,133188.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,9232.0,3080.0
ampere_sgemm_128x32_sliced1x4_nn,405,3625648128.0,7263682560.0,0,0,0.0,7263682560.0,7263682560.0,11892096.0,3666096.0,0.7643623372175893,468099072.0,898560.0,0.505184,32.950080000000014,5308416.0,7077888.0,3625648128.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,14628096.0,28080.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",406,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3072.0,0.0,196608.0,196608.0,0.004032,32.954112000000016,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",407,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3072.0,0.0,196608.0,196608.0,0.004032,32.95814400000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",408,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,0.002816,32.96096000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",409,786432.0,26148864.0,0,0,0.0,26148864.0,26148864.0,204288.0,384.0,0.99812382739212,491520.0,98304.0,0.03072,32.991680000000024,19783680.0,4792320.0,786432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,15360.0,3072.0
ampere_sgemm_128x32_sliced1x4_nn,410,1208352768.0,2419458048.0,0,0,0.0,2419458048.0,2419458048.0,3920640.0,5513200.0,0.4155932260882101,156072896.0,199680.0,0.167104,33.158784000000026,1179648.0,1572864.0,1208352768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4877278.0,6240.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",411,24576.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,0.002176,33.160960000000024,0.0,0.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",412,133188.0,437492.0,0,0,0.0,437492.0,437492.0,80.0,2120.0,0.03636363636363636,294912.0,98560.0,0.01152,33.17248000000002,133680.0,37436.0,133188.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,9216.0,3080.0
ampere_sgemm_128x32_sliced1x4_nn,413,4911267840.0,9850060800.0,0,0,0.0,9850060800.0,9850060800.0,16442880.0,4906176.0,0.7701923682246185,624442144.0,1996800.0,0.75264,33.92512000000002,11796480.0,15728640.0,4911267840.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,19513817.0,62400.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",414,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,0.002432,33.92755200000002,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",415,0.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,0.002592,33.93014400000002,0.0,196608.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",416,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,0.002592,33.93273600000002,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",417,98304.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,2304.0,0.0,786432.0,393216.0,0.002816,33.93555200000002,0.0,0.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",418,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,0.002368,33.93792000000002,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",419,527120.0,1349152.0,0,0,0.0,1349152.0,1349152.0,0.0,1536.0,0.0,393216.0,393216.0,0.002496,33.94041600000002,98304.0,196608.0,527120.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",420,98304.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,0.002464,33.942880000000024,0.0,0.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",421,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,2304.0,0.0,786432.0,393216.0,0.003072,33.94595200000003,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,12288.0
ampere_sgemm_128x32_sliced1x4_nn,422,4869586944.0,9751560192.0,0,0,0.0,9751560192.0,9751560192.0,15845760.0,4874112.0,0.7647614811520071,623276480.0,884736.0,0.655584,34.601536000000024,5308416.0,7077888.0,4869586944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,19477390.0,27648.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",423,0.0,270336.0,0,0,0.0,270336.0,270336.0,0.0,12288.0,0.0,909312.0,98304.0,0.003392,34.60492800000002,245760.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,28416.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",424,24576.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,0.002496,34.60742400000002,0.0,0.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",425,133188.0,437492.0,0,0,0.0,437492.0,437492.0,80.0,2120.0,0.03636363636363636,296448.0,98560.0,0.011424,34.61884800000002,133680.0,37436.0,133188.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,9264.0,3080.0
ampere_sgemm_128x32_sliced1x4_nn,426,3625648128.0,7263682560.0,0,0,0.0,7263682560.0,7263682560.0,11892096.0,3666096.0,0.7643623372175893,468099072.0,898560.0,0.501952,35.120800000000024,5308416.0,7077888.0,3625648128.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,14628096.0,28080.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",427,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3072.0,0.0,196608.0,196608.0,0.004192,35.12499200000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",428,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3072.0,0.0,196608.0,196608.0,0.004032,35.12902400000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,6144.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",429,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,98304.0,98304.0,0.00272,35.131744000000026,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",430,786432.0,26148864.0,0,0,0.0,26148864.0,26148864.0,204288.0,384.0,0.99812382739212,491520.0,98304.0,0.030464,35.16220800000003,19783680.0,4792320.0,786432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,15360.0,3072.0
ampere_sgemm_128x32_sliced1x4_nn,431,1208352768.0,2419458048.0,0,0,0.0,2419458048.0,2419458048.0,3920640.0,5509896.0,0.4157388296911225,156042656.0,199680.0,0.16608,35.32828800000003,1179648.0,1572864.0,1208352768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4876333.0,6240.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",432,24576.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,0.00224,35.33052800000003,0.0,0.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",433,133188.0,437492.0,0,0,0.0,437492.0,437492.0,80.0,2120.0,0.03636363636363636,295424.0,98560.0,0.011424,35.34195200000003,133680.0,37436.0,133188.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,9232.0,3080.0
ampere_sgemm_128x32_sliced1x4_nn,434,4911267840.0,9850060800.0,0,0,0.0,9850060800.0,9850060800.0,16442880.0,4906176.0,0.7701923682246185,624451872.0,1996800.0,0.749952,36.09190400000003,11796480.0,15728640.0,4911267840.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,19514121.0,62400.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",435,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,0.0024,36.09430400000003,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",436,0.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,0.0024,36.09670400000003,0.0,196608.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",437,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,0.002592,36.09929600000003,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",438,98304.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,2304.0,0.0,786432.0,393216.0,0.002912,36.10220800000003,0.0,0.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",439,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,0.0024,36.104608000000034,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",440,527215.0,1349342.0,0,0,0.0,1349342.0,1349342.0,0.0,1536.0,0.0,393216.0,393216.0,0.00272,36.10732800000003,98304.0,196608.0,527215.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",441,98304.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,0.002496,36.10982400000003,0.0,0.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",442,0.0,98304.0,0,0,0.0,98304.0,98304.0,0.0,2304.0,0.0,786432.0,393216.0,0.002976,36.11280000000003,0.0,98304.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,24576.0,12288.0
ampere_sgemm_128x32_sliced1x4_nn,443,4869586944.0,9751560192.0,0,0,0.0,9751560192.0,9751560192.0,15845760.0,4874112.0,0.7647614811520071,623269824.0,884736.0,0.655168,36.76796800000003,5308416.0,7077888.0,4869586944.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,19477182.0,27648.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",444,0.0,270336.0,0,0,0.0,270336.0,270336.0,0.0,12288.0,0.0,909312.0,98304.0,0.003424,36.771392000000034,245760.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,28416.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",445,24576.0,49152.0,0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,0.002272,36.77366400000003,0.0,0.0,24576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",446,133188.0,437492.0,0,0,0.0,437492.0,437492.0,80.0,2120.0,0.03636363636363636,296448.0,98560.0,0.011648,36.78531200000003,133680.0,37436.0,133188.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,9264.0,3080.0
ampere_sgemm_128x32_sliced1x4_tn,447,9890168832.0,19825410048.0,0,0,0.0,19825410048.0,19825410048.0,32810784.0,9976304.0,0.76683844434564,1273749504.0,2468512.0,1.554208,38.339520000000036,19316736.0,25755648.0,9890168832.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,39804672.0,77141.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",448,0.0,1005140.0,0,0,0.0,1005140.0,1005140.0,0.0,31420.0,0.0,3466752.0,825248.0,0.006656,38.346176000000035,804112.0,201028.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,108336.0,25789.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",449,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.001696,38.34787200000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",450,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,96.0,160.0,0.00256,38.35043200000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",451,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002048,38.35248000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",452,0.0,201028.0,0,0,0.0,201028.0,201028.0,0.0,3158.0,0.0,804128.0,804128.0,0.00304,38.35552000000004,0.0,201028.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25129.0,25129.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",453,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.001696,38.357216000000044,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",454,0.0,0.0,0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813024.0,58688.0,0.003808,38.36102400000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25407.0,1834.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",455,0.0,0.0,0,0,0.0,0.0,0.0,14800.0,82608.0,0.15193823915900131,5134592.0,0.0,0.005696,38.36672000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160456.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",456,0.0,0.0,0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813024.0,57728.0,0.003744,38.37046400000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25407.0,1804.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",457,0.0,0.0,0,0,0.0,0.0,0.0,14800.0,82608.0,0.15193823915900131,5134592.0,0.0,0.005536,38.37600000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160456.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",458,0.0,0.0,0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813024.0,57024.0,0.003776,38.37977600000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25407.0,1782.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",459,0.0,0.0,0,0,0.0,0.0,0.0,14800.0,83108.0,0.15116231564325694,5134592.0,0.0,0.005824,38.38560000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160456.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",460,0.0,0.0,0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813024.0,58048.0,0.003872,38.38947200000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25407.0,1814.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",461,0.0,0.0,0,0,0.0,0.0,0.0,14800.0,82908.0,0.15147173209972573,5134592.0,128.0,0.005696,38.39516800000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160456.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",462,0.0,0.0,0,0,0.0,0.0,0.0,0.0,21.0,0.0,6432.0,800.0,0.0024,38.39756800000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,201.0,25.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",463,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,0.001728,38.39929600000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",464,0.0,0.0,0,0,0.0,0.0,0.0,497.0,22.0,0.9576107899807321,800.0,0.0,0.003616,38.40291200000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",465,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,0.001664,38.40457600000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",466,0.0,0.0,0,0,0.0,0.0,0.0,497.0,22.0,0.9576107899807321,800.0,0.0,0.003584,38.40816000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",467,0.0,0.0,0,0,0.0,0.0,0.0,51984.0,13020.0,0.7997046335610116,831456.0,8992.0,0.006048,38.41420800000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25983.0,281.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",468,0.0,0.0,0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,544.0,0.006528,38.42073600000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,80.0,17.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",469,0.0,0.0,0,0,0.0,0.0,0.0,0.0,18849.0,0.0,814496.0,88832.0,0.003968,38.42470400000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25453.0,2776.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",470,0.0,0.0,0,0,0.0,0.0,0.0,0.0,4737.0,0.0,1005184.0,0.0,0.00336,38.42806400000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,31412.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",471,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6283.0,0.0,0.0,1608224.0,0.002624,38.43068800000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,50257.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",472,0.0,0.0,0,0,0.0,0.0,0.0,98304.0,6283.0,0.9399256121697726,804128.0,0.0,0.004384,38.43507200000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25129.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",473,0.0,0.0,0,0,0.0,0.0,0.0,156.0,64.0,0.7090909090909091,8192.0,0.0,0.002272,38.43734400000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",474,0.0,0.0,0,0,0.0,0.0,0.0,80583.0,30535.0,0.7252020374736766,3110976.0,2027488.0,0.010592,38.44793600000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,97218.0,63359.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",475,0.0,0.0,0,0,0.0,0.0,0.0,23142.0,36854.0,0.38572571504766984,3093824.0,2479936.0,0.008576,38.45651200000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96682.0,77498.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",476,0.0,0.0,0,0,0.0,0.0,0.0,23883.0,34900.0,0.4062909344538387,3098176.0,2243360.0,0.009056,38.46556800000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96818.0,70105.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",477,0.0,0.0,0,0,0.0,0.0,0.0,23883.0,37057.0,0.3919100754840827,3099712.0,2397760.0,0.009152,38.47472000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96866.0,74930.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",478,0.0,0.0,0,0,0.0,0.0,0.0,14336.0,6283.0,0.6952810514573937,1608224.0,0.0,0.004544,38.47926400000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,50257.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",479,0.0,0.0,0,0,0.0,0.0,0.0,39.0,16.0,0.7090909090909091,2048.0,0.0,0.002176,38.48144000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",480,0.0,0.0,0,0,0.0,0.0,0.0,20059.0,17145.0,0.5391624556499302,2107424.0,1390464.0,0.007872,38.48931200000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,65857.0,43452.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",481,0.0,0.0,0,0,0.0,0.0,0.0,0.0,25132.0,0.0,2427840.0,2412352.0,0.00528,38.49459200000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75870.0,75386.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",482,2814392.0,6655044.0,0,0,0.0,6655044.0,6655044.0,528.0,6704.0,0.07300884955752213,2281216.0,754176.0,0.023584,38.51817600000004,825232.0,201028.0,2814392.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,71288.0,23568.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",483,0.0,1024200.0,0,0,0.0,1024200.0,1024200.0,112284.0,12568.0,0.8993368147887099,804640.0,624192.0,0.072032,38.59020800000004,1024200.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25145.0,19506.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",484,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3158.0,0.0,804128.0,200864.0,0.003136,38.59334400000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25129.0,6277.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",485,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,0.00192,38.595264000000036,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",486,0.0,0.0,0,0,0.0,0.0,0.0,0.0,18849.0,0.0,1809280.0,86976.0,0.007744,38.60300800000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,56540.0,2718.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",487,0.0,0.0,0,0,0.0,0.0,0.0,0.0,4737.0,0.0,1005184.0,0.0,0.003328,38.60633600000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,31412.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",488,2814392.0,6655044.0,0,0,0.0,6655044.0,6655044.0,528.0,6704.0,0.07300884955752213,2279552.0,752704.0,0.023776,38.63011200000004,825232.0,201028.0,2814392.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,71236.0,23522.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",489,0.0,0.0,0,0,0.0,0.0,0.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,0.00624,38.63635200000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",490,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002336,38.63868800000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",491,0.0,0.0,0,0,0.0,0.0,0.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,0.006112,38.64480000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",492,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002176,38.64697600000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",493,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,0.00208,38.64905600000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",494,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,0.002976,38.652032000000034,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",495,0.0,220484.0,0,0,0.0,220484.0,220484.0,320.0,1582.0,0.16824395373291273,804320.0,128.0,0.01104,38.663072000000035,220484.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25135.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",496,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002016,38.66508800000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",497,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003168,38.668256000000035,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",498,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00208,38.670336000000034,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",499,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,0.002976,38.67331200000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",500,1769472.0,3941000.0,0,0,0.0,3941000.0,3941000.0,0.0,6283.0,0.0,0.0,804128.0,0.003968,38.67728000000003,0.0,402056.0,1769472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,25129.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",501,1005140.0,2010280.0,0,0,0.0,2010280.0,2010280.0,0.0,4737.0,0.0,1608256.0,0.0,0.004896,38.682176000000034,0.0,0.0,1005140.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,50258.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",502,0.0,0.0,0,0,0.0,0.0,0.0,640.0,1582.0,0.28802880288028804,804640.0,128.0,0.01616,38.69833600000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25145.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",503,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,0.001984,38.70032000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",504,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002048,38.702368000000035,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",505,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,0.002272,38.70464000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",506,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,0.002112,38.70675200000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",507,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,96.0,160.0,0.002752,38.70950400000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",508,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.001728,38.71123200000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",509,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.001728,38.71296000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",510,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,0.002048,38.71500800000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",511,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.001664,38.71667200000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",512,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,128.0,32.0,0.002336,38.71900800000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",513,0.0,0.0,0,0,0.0,0.0,0.0,0.0,5.0,0.0,32.0,32.0,0.004672,38.72368000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",514,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,0.00208,38.72576000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",515,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002048,38.72780800000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",516,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,0.002848,38.73065600000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",517,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003168,38.733824000000034,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",518,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002048,38.735872000000036,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
