Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.856,1.856,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,3.584,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,5.312,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.048,7.36,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.336,9.696,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",6,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.336,12.032,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",7,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,15.296,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",8,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,18.528,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",9,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.176,20.704,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",10,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,22.400000000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",11,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,24.128000000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.76,25.888000000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,0.0,0.0,0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,2.432,28.320000000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,30.336000000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",15,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.208,32.544000000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",16,0.0,0.0,0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,32.0,32.0,2.496,35.040000000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",17,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,37.08800000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",18,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.4,39.48800000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",19,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,2.144,41.632000000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",20,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,2176.0,8192.0,3.84,45.47200000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,68.0,256.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",21,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,48.00000000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",22,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,51.29600000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",23,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.496,53.79200000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",24,0.0,512.0,0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,2.112,55.90400000000001,0.0,512.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",25,0.0,0.0,0,0,0.0,0.0,0.0,0.0,20.0,0.0,2048.0,2048.0,2.624,58.52800000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",26,4096.0,9216.0,0,0,0.0,9216.0,9216.0,0.0,32.0,0.0,2048.0,2048.0,3.04,61.56800000000001,0.0,1024.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",27,0.0,512.0,0,0,0.0,512.0,512.0,0.0,32.0,0.0,2048.0,2048.0,2.08,63.64800000000001,0.0,512.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",28,3584.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,32.0,0.0,2048.0,2048.0,2.944,66.59200000000001,0.0,1024.0,3584.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",29,0.0,512.0,0,0,0.0,512.0,512.0,0.0,32.0,0.0,2048.0,2048.0,2.208,68.80000000000001,0.0,512.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",30,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,1.984,70.784,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",31,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.488,74.272,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",32,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,76.19200000000001,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",33,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,78.20800000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",34,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.72,80.92800000000001,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",35,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.656,83.58400000000002,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",36,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,9440.0,5.184,88.76800000000001,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,295.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",37,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,10176.0,4.896,93.66400000000002,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,318.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",38,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,10112.0,5.088,98.75200000000001,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,316.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",39,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.656,101.40800000000002,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",40,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.624,104.03200000000001,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",41,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.648,107.68,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",42,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.752,110.432,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",43,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.112,112.544,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",44,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.72,115.264,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",45,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.656,117.92,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",46,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.616,121.536,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",47,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.784,124.32000000000001,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",48,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.144,126.46400000000001,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",49,32768.0,2941952.0,0,0,0.0,2941952.0,2941952.0,16640.0,32.0,0.9980806142034548,24576.0,8192.0,20.256,146.72000000000003,2480128.0,396288.0,32768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",50,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,10112.0,5.184,151.90400000000002,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,316.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",51,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.112,154.01600000000002,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",52,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.048,156.06400000000002,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",53,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.488,159.55200000000002,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",54,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,161.472,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",55,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,163.45600000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",56,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.656,166.11200000000002,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",57,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.688,168.8,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",58,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5242880.0,53536.0,8.736,177.536,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,163840.0,1673.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",59,94208.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,128.0,0.0,32768.0,32768.0,2.304,179.84,8192.0,0.0,94208.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",60,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5243776.0,50080.0,8.064,187.904,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,163868.0,1565.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",61,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.144,190.048,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
ampere_sgemm_32x32_sliced1x4_tn,62,37748736.0,76873728.0,0,0,0.0,76873728.0,76873728.0,233472.0,42240.0,0.8467966573816156,5139968.0,98304.0,9.92,199.968,589824.0,786432.0,37748736.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160624.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",63,0.0,26624.0,0,0,0.0,26624.0,26624.0,0.0,832.0,0.0,98304.0,8192.0,2.56,202.528,24576.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",64,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.08,204.608,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",65,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.016,206.624,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",66,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.552,210.176,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",67,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,212.128,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",68,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,214.112,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",69,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.72,216.832,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",70,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.688,219.51999999999998,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",71,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,10208.0,4.896,224.41599999999997,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,319.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",72,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,10848.0,5.024,229.43999999999997,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,339.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",73,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,10528.0,5.056,234.49599999999998,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,329.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",74,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.752,237.248,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",75,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.624,239.87199999999999,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",76,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.584,243.456,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",77,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.848,246.304,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",78,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.08,248.38400000000001,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",79,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.656,251.04000000000002,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",80,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.624,253.66400000000002,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",81,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.712,257.37600000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",82,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.752,260.12800000000004,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",83,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.112,262.24000000000007,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",84,32768.0,2941952.0,0,0,0.0,2941952.0,2941952.0,16640.0,32.0,0.9980806142034548,24576.0,8192.0,20.512,282.75200000000007,2480128.0,396288.0,32768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",85,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,9728.0,5.056,287.80800000000005,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,304.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",86,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.08,289.88800000000003,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",87,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,1.984,291.872,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",88,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.552,295.42400000000004,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",89,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,297.37600000000003,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",90,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,299.42400000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",91,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.688,302.112,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",92,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.624,304.73600000000005,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",93,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5243648.0,53024.0,8.288,313.02400000000006,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,163864.0,1657.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",94,94208.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,128.0,0.0,32768.0,32768.0,2.272,315.29600000000005,8192.0,0.0,94208.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",95,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5243264.0,55008.0,8.096,323.39200000000005,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,163852.0,1719.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",96,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.112,325.5040000000001,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
ampere_sgemm_32x32_sliced1x4_tn,97,37748736.0,76873728.0,0,0,0.0,76873728.0,76873728.0,233472.0,42240.0,0.8467966573816156,5140224.0,98304.0,10.144,335.6480000000001,589824.0,786432.0,37748736.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160632.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",98,0.0,26624.0,0,0,0.0,26624.0,26624.0,0.0,832.0,0.0,98304.0,8192.0,2.688,338.33600000000007,24576.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",99,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.112,340.4480000000001,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",100,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,1.984,342.4320000000001,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",101,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.456,345.8880000000001,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",102,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,347.8400000000001,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",103,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,349.82400000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",104,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.656,352.4800000000001,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",105,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.688,355.16800000000006,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",106,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,9984.0,5.312,360.4800000000001,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,312.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",107,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,9728.0,4.992,365.4720000000001,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,304.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",108,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,10144.0,5.024,370.4960000000001,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,317.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",109,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.752,373.2480000000001,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",110,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.656,375.9040000000001,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",111,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.552,379.45600000000013,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",112,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.72,382.17600000000016,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",113,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.112,384.2880000000002,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",114,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.752,387.0400000000002,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",115,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.624,389.6640000000002,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",116,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.584,393.2480000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",117,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.816,396.0640000000002,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",118,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.048,398.1120000000002,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",119,32768.0,2941952.0,0,0,0.0,2941952.0,2941952.0,16640.0,32.0,0.9980806142034548,24576.0,8192.0,20.32,418.4320000000002,2480128.0,396288.0,32768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",120,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,10112.0,5.056,423.48800000000017,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,316.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",121,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.08,425.56800000000015,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",122,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.048,427.61600000000016,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",123,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.488,431.10400000000016,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",124,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,433.08800000000014,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",125,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,435.10400000000016,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",126,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.656,437.76000000000016,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",127,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.784,440.54400000000015,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",128,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5242880.0,53376.0,8.256,448.8000000000002,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,163840.0,1668.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",129,94208.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,128.0,0.0,32768.0,32768.0,2.496,451.29600000000016,8192.0,0.0,94208.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",130,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5244288.0,51776.0,8.32,459.61600000000016,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,163884.0,1618.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",131,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.144,461.76000000000016,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
ampere_sgemm_32x32_sliced1x4_tn,132,37748736.0,76873728.0,0,0,0.0,76873728.0,76873728.0,233472.0,42240.0,0.8467966573816156,5143968.0,98304.0,10.016,471.7760000000002,589824.0,786432.0,37748736.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160749.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",133,0.0,26624.0,0,0,0.0,26624.0,26624.0,0.0,832.0,0.0,98304.0,8192.0,2.528,474.3040000000002,24576.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",134,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.08,476.3840000000002,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",135,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,1.952,478.3360000000002,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",136,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.488,481.8240000000002,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",137,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,483.80800000000016,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",138,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,485.88800000000015,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",139,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.752,488.64000000000016,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",140,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.752,491.39200000000017,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",141,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,10016.0,5.312,496.7040000000002,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,313.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",142,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,10016.0,4.864,501.56800000000015,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,313.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",143,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,9984.0,5.088,506.6560000000002,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,312.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",144,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.72,509.3760000000002,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",145,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.592,511.9680000000002,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",146,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.648,515.6160000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",147,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.72,518.3360000000002,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",148,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.048,520.3840000000002,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",149,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.72,523.1040000000003,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",150,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.656,525.7600000000002,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",151,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.552,529.3120000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",152,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.688,532.0000000000002,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",153,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.112,534.1120000000002,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",154,32768.0,2941952.0,0,0,0.0,2941952.0,2941952.0,16640.0,32.0,0.9980806142034548,24576.0,8192.0,20.352,554.4640000000002,2480128.0,396288.0,32768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",155,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,9120.0,5.152,559.6160000000002,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,285.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",156,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.08,561.6960000000003,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",157,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.08,563.7760000000003,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",158,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.488,567.2640000000004,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",159,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.888,569.1520000000004,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",160,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,571.1680000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",161,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.72,573.8880000000004,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",162,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.688,576.5760000000004,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",163,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5242880.0,52480.0,8.256,584.8320000000003,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,163840.0,1640.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",164,94208.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,128.0,0.0,32768.0,32768.0,2.272,587.1040000000004,8192.0,0.0,94208.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",165,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5242880.0,51616.0,8.512,595.6160000000004,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,163840.0,1613.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",166,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.112,597.7280000000004,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
ampere_sgemm_32x32_sliced1x4_tn,167,37748736.0,76873728.0,0,0,0.0,76873728.0,76873728.0,233472.0,42240.0,0.8467966573816156,5133184.0,98304.0,10.016,607.7440000000004,589824.0,786432.0,37748736.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160412.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",168,0.0,26624.0,0,0,0.0,26624.0,26624.0,0.0,832.0,0.0,98304.0,8192.0,2.528,610.2720000000004,24576.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",169,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.144,612.4160000000004,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",170,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.08,614.4960000000004,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",171,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.488,617.9840000000005,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",172,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,619.9360000000005,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",173,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,621.9840000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",174,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.656,624.6400000000004,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",175,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.656,627.2960000000004,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",176,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,8896.0,4.864,632.1600000000004,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,278.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",177,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,9664.0,5.152,637.3120000000005,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,302.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",178,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,9376.0,5.184,642.4960000000004,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,293.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",179,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.816,645.3120000000005,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",180,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.592,647.9040000000005,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",181,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.648,651.5520000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",182,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.656,654.2080000000004,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",183,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.048,656.2560000000004,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",184,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.72,658.9760000000005,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",185,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.72,661.6960000000005,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",186,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.616,665.3120000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",187,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.72,668.0320000000005,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",188,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.048,670.0800000000005,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",189,32768.0,2941952.0,0,0,0.0,2941952.0,2941952.0,16640.0,32.0,0.9980806142034548,24576.0,8192.0,20.32,690.4000000000005,2480128.0,396288.0,32768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",190,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,10048.0,5.12,695.5200000000006,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,314.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",191,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.08,697.6000000000006,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",192,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.016,699.6160000000006,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",193,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.488,703.1040000000006,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",194,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,705.0880000000006,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",195,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,707.1360000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",196,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.688,709.8240000000006,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",197,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.656,712.4800000000006,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",198,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5242880.0,52160.0,8.16,720.6400000000006,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,163840.0,1630.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",199,94208.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,128.0,0.0,32768.0,32768.0,2.24,722.8800000000006,8192.0,0.0,94208.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",200,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5243008.0,49312.0,8.32,731.2000000000006,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,163844.0,1541.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",201,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.112,733.3120000000006,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
ampere_sgemm_32x32_sliced1x4_tn,202,37748736.0,76873728.0,0,0,0.0,76873728.0,76873728.0,233472.0,42240.0,0.8467966573816156,5139264.0,98304.0,10.08,743.3920000000006,589824.0,786432.0,37748736.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160602.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",203,0.0,26624.0,0,0,0.0,26624.0,26624.0,0.0,832.0,0.0,98304.0,8192.0,2.528,745.9200000000006,24576.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",204,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.112,748.0320000000006,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",205,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.048,750.0800000000006,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",206,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.552,753.6320000000006,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",207,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,755.5520000000006,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",208,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,757.6000000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",209,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.688,760.2880000000006,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",210,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.752,763.0400000000005,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",211,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,10432.0,5.088,768.1280000000005,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,326.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",212,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,9664.0,5.248,773.3760000000005,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,302.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",213,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,9984.0,5.088,778.4640000000005,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,312.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",214,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.688,781.1520000000005,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",215,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.56,783.7120000000004,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",216,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.584,787.2960000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",217,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.72,790.0160000000004,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",218,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.112,792.1280000000004,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",219,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.72,794.8480000000004,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",220,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.624,797.4720000000004,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",221,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.616,801.0880000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",222,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.688,803.7760000000004,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",223,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.048,805.8240000000004,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",224,32768.0,2941952.0,0,0,0.0,2941952.0,2941952.0,16640.0,32.0,0.9980806142034548,24576.0,8192.0,20.256,826.0800000000004,2480128.0,396288.0,32768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",225,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,9952.0,5.216,831.2960000000004,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,311.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",226,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.144,833.4400000000004,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",227,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.112,835.5520000000004,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",228,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.52,839.0720000000003,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",229,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,841.0560000000004,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",230,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.952,843.0080000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",231,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.656,845.6640000000003,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",232,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.624,848.2880000000004,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",233,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5243008.0,52096.0,8.192,856.4800000000004,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,163844.0,1628.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",234,94208.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,128.0,0.0,32768.0,32768.0,2.336,858.8160000000004,8192.0,0.0,94208.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",235,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5246848.0,52896.0,8.192,867.0080000000004,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,163964.0,1653.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",236,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.08,869.0880000000004,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
ampere_sgemm_32x32_sliced1x4_tn,237,37748736.0,76873728.0,0,0,0.0,76873728.0,76873728.0,233472.0,42240.0,0.8467966573816156,5142464.0,98304.0,9.952,879.0400000000004,589824.0,786432.0,37748736.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160702.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",238,0.0,26624.0,0,0,0.0,26624.0,26624.0,0.0,832.0,0.0,98304.0,8192.0,2.464,881.5040000000005,24576.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",239,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.048,883.5520000000005,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",240,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,1.984,885.5360000000005,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",241,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.52,889.0560000000005,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",242,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,891.0080000000005,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",243,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,893.0560000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",244,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.656,895.7120000000004,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",245,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.688,898.4000000000004,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",246,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,9824.0,5.056,903.4560000000005,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,307.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",247,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,9568.0,5.088,908.5440000000004,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,299.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",248,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,9824.0,4.864,913.4080000000005,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,307.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",249,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.784,916.1920000000005,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",250,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.624,918.8160000000005,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",251,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.616,922.4320000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",252,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.784,925.2160000000005,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",253,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.08,927.2960000000005,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",254,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.688,929.9840000000005,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",255,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.624,932.6080000000005,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",256,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.584,936.1920000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",257,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.752,938.9440000000004,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",258,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.112,941.0560000000004,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",259,32768.0,2941952.0,0,0,0.0,2941952.0,2941952.0,16640.0,32.0,0.9980806142034548,24576.0,8192.0,20.256,961.3120000000004,2480128.0,396288.0,32768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",260,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,10528.0,5.056,966.3680000000004,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,329.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",261,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.112,968.4800000000004,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",262,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.016,970.4960000000003,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",263,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.488,973.9840000000004,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",264,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,975.9040000000003,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",265,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,977.9520000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",266,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.72,980.6720000000004,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",267,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.688,983.3600000000004,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",268,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5244800.0,51744.0,8.096,991.4560000000004,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,163900.0,1617.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",269,94208.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,128.0,0.0,32768.0,32768.0,2.304,993.7600000000003,8192.0,0.0,94208.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",270,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5242880.0,52064.0,8.16,1001.9200000000003,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,163840.0,1627.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",271,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.08,1004.0000000000003,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
ampere_sgemm_32x32_sliced1x4_tn,272,37748736.0,76873728.0,0,0,0.0,76873728.0,76873728.0,233472.0,42240.0,0.8467966573816156,5140320.0,98304.0,9.952,1013.9520000000003,589824.0,786432.0,37748736.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160635.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",273,0.0,26624.0,0,0,0.0,26624.0,26624.0,0.0,832.0,0.0,98304.0,8192.0,2.528,1016.4800000000004,24576.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",274,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.144,1018.6240000000004,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",275,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.016,1020.6400000000003,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",276,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.52,1024.1600000000003,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",277,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,1026.1120000000003,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",278,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,1028.1280000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",279,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.624,1030.7520000000004,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",280,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.688,1033.4400000000005,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",281,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,9664.0,5.088,1038.5280000000005,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,302.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",282,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,9824.0,5.088,1043.6160000000004,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,307.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",283,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,9536.0,5.088,1048.7040000000004,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,298.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",284,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.88,1051.5840000000005,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",285,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.592,1054.1760000000006,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",286,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.584,1057.7600000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",287,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.656,1060.4160000000006,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",288,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.08,1062.4960000000005,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",289,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.72,1065.2160000000006,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",290,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.656,1067.8720000000005,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",291,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.584,1071.4560000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",292,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.688,1074.1440000000007,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",293,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.112,1076.2560000000008,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",294,32768.0,2941952.0,0,0,0.0,2941952.0,2941952.0,16640.0,32.0,0.9980806142034548,24576.0,8192.0,20.288,1096.5440000000008,2480128.0,396288.0,32768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",295,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,10144.0,5.056,1101.6000000000008,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,317.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",296,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.08,1103.6800000000007,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",297,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.176,1105.8560000000007,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",298,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.488,1109.3440000000007,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",299,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.016,1111.3600000000008,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",300,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,1113.3440000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",301,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.688,1116.0320000000008,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",302,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.624,1118.6560000000009,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",303,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5242880.0,51360.0,8.032,1126.6880000000008,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,163840.0,1605.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",304,94208.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,128.0,0.0,32768.0,32768.0,2.24,1128.9280000000008,8192.0,0.0,94208.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",305,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5242880.0,53024.0,7.968,1136.8960000000009,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,163840.0,1657.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",306,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.176,1139.0720000000008,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
ampere_sgemm_32x32_sliced1x4_tn,307,37748736.0,76873728.0,0,0,0.0,76873728.0,76873728.0,233472.0,42240.0,0.8467966573816156,5137728.0,98304.0,9.952,1149.0240000000008,589824.0,786432.0,37748736.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160554.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",308,0.0,26624.0,0,0,0.0,26624.0,26624.0,0.0,832.0,0.0,98304.0,8192.0,2.464,1151.4880000000007,24576.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",309,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.112,1153.6000000000008,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",310,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,1.984,1155.5840000000007,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",311,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.488,1159.0720000000008,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",312,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,1161.0240000000008,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",313,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,1163.0400000000009,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",314,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.688,1165.728000000001,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",315,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.752,1168.480000000001,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",316,65536000.0,145408000.0,0,0,0.0,145408000.0,145408000.0,1104000.0,832000.0,0.5702479338842975,80036352.0,814400.0,73.184,1241.664000000001,6144000.0,8192000.0,65536000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2501136.0,25450.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",317,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,1243.392000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",318,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,64.0,128.0,2.592,1245.984000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",319,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,1248.0000000000011,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",320,0.0,128000.0,0,0,0.0,128000.0,128000.0,0.0,2000.0,0.0,512000.0,512000.0,2.624,1250.6240000000012,0.0,128000.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,16000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",321,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,1252.3520000000012,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",322,0.0,0.0,0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,37184.0,3.808,1256.1600000000012,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16128.0,1162.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",323,0.0,0.0,0,0,0.0,0.0,0.0,9472.0,34440.0,0.2157041355438149,2109440.0,0.0,4.384,1260.5440000000012,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",324,0.0,0.0,0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,38080.0,3.808,1264.3520000000012,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16128.0,1190.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",325,0.0,0.0,0,0,0.0,0.0,0.0,9472.0,34440.0,0.2157041355438149,2109440.0,0.0,4.576,1268.9280000000012,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",326,0.0,0.0,0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,37824.0,3.68,1272.6080000000013,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16128.0,1182.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",327,0.0,0.0,0,0,0.0,0.0,0.0,9472.0,34312.0,0.216334734149461,2109440.0,0.0,4.512,1277.1200000000013,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",328,0.0,0.0,0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,38144.0,3.488,1280.6080000000013,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16128.0,1192.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",329,0.0,0.0,0,0,0.0,0.0,0.0,9472.0,34824.0,0.21383420624887123,2109440.0,128.0,4.48,1285.0880000000013,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,65920.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",330,0.0,0.0,0,0,0.0,0.0,0.0,0.0,12.0,0.0,4128.0,512.0,2.432,1287.5200000000013,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,129.0,16.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",331,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.696,1289.2160000000013,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",332,0.0,0.0,0,0,0.0,0.0,0.0,497.0,16.0,0.9688109161793372,512.0,0.0,3.424,1292.6400000000012,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",333,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.664,1294.3040000000012,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",334,0.0,0.0,0,0,0.0,0.0,0.0,497.0,16.0,0.9688109161793372,512.0,0.0,3.424,1297.7280000000012,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",335,0.0,0.0,0,0,0.0,0.0,0.0,43392.0,8432.0,0.8372954615622106,527232.0,6528.0,5.76,1303.4880000000012,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16476.0,204.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",336,0.0,0.0,0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,544.0,6.432,1309.9200000000012,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,80.0,17.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",337,0.0,0.0,0,0,0.0,0.0,0.0,0.0,12000.0,0.0,520064.0,57312.0,3.616,1313.5360000000012,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16252.0,1791.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",338,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3000.0,0.0,640000.0,0.0,2.88,1316.4160000000013,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,20000.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",339,0.0,0.0,0,0,0.0,0.0,0.0,0.0,4000.0,0.0,0.0,1024000.0,2.24,1318.6560000000013,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,32000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",340,0.0,0.0,0,0,0.0,0.0,0.0,98304.0,4000.0,0.960900844541758,512000.0,0.0,4.096,1322.7520000000013,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",341,0.0,0.0,0,0,0.0,0.0,0.0,156.0,64.0,0.7090909090909091,8192.0,0.0,2.176,1324.9280000000012,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",342,0.0,0.0,0,0,0.0,0.0,0.0,51858.0,19461.0,0.7271274134522357,1913472.0,1308896.0,9.664,1334.5920000000012,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,59796.0,40903.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",343,0.0,0.0,0,0,0.0,0.0,0.0,15054.0,19903.0,0.4306433618445519,1891968.0,1579008.0,7.52,1342.1120000000012,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,59124.0,49344.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",344,0.0,0.0,0,0,0.0,0.0,0.0,15858.0,19728.0,0.4456246838644411,1895936.0,1144160.0,8.032,1350.1440000000011,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,59248.0,35755.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",345,0.0,0.0,0,0,0.0,0.0,0.0,15858.0,19738.0,0.4454994943252051,1889152.0,975264.0,8.064,1358.2080000000012,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,59036.0,30477.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",346,0.0,0.0,0,0,0.0,0.0,0.0,14336.0,4000.0,0.7818499127399651,1024000.0,0.0,3.904,1362.1120000000012,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",347,0.0,0.0,0,0,0.0,0.0,0.0,39.0,16.0,0.7090909090909091,2048.0,0.0,2.176,1364.2880000000011,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",348,0.0,0.0,0,0,0.0,0.0,0.0,13650.0,10486.0,0.5655452436194895,1273344.0,886912.0,6.752,1371.040000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,39792.0,27716.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",349,0.0,0.0,0,0,0.0,0.0,0.0,0.0,16000.0,0.0,1549376.0,1536000.0,3.872,1374.9120000000012,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48418.0,48000.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",350,1792000.0,4245120.0,0,0,0.0,4245120.0,4245120.0,528.0,5248.0,0.09141274238227147,1036288.0,512000.0,17.184,1392.0960000000011,533120.0,128000.0,1792000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32384.0,16000.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",351,0.0,655488.0,0,0,0.0,655488.0,655488.0,71840.0,8000.0,0.8997995991983968,512000.0,512000.0,46.688,1438.7840000000012,655488.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,16000.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",352,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2000.0,0.0,512000.0,128000.0,2.592,1441.3760000000013,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,4000.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",353,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,1.984,1443.3600000000013,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",354,0.0,0.0,0,0,0.0,0.0,0.0,0.0,12000.0,0.0,1152000.0,53600.0,7.712,1451.0720000000013,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,36000.0,1675.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",355,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3000.0,0.0,640000.0,0.0,2.944,1454.0160000000012,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,20000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",356,1792000.0,4245120.0,0,0,0.0,4245120.0,4245120.0,528.0,5248.0,0.09141274238227147,1017216.0,512000.0,17.216,1471.232000000001,533120.0,128000.0,1792000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,31788.0,16000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",357,0.0,0.0,0,0,0.0,0.0,0.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,22.016,1493.2480000000012,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",358,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.176,1495.4240000000011,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",359,0.0,0.0,0,0,0.0,0.0,0.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,21.792,1517.216000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",360,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,1519.360000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",361,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.08,1521.440000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",362,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.976,1524.416000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",363,0.0,147456.0,0,0,0.0,147456.0,147456.0,320.0,1004.0,0.24169184290030213,512000.0,128.0,8.256,1532.6720000000012,147456.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",364,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,1534.656000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",365,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.168,1537.824000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",366,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,1539.904000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",367,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.04,1542.9440000000009,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",368,1152000.0,2560000.0,0,0,0.0,2560000.0,2560000.0,0.0,4000.0,0.0,0.0,512000.0,3.264,1546.2080000000008,0.0,256000.0,1152000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,16000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",369,640000.0,1280000.0,0,0,0.0,1280000.0,1280000.0,0.0,3000.0,0.0,1024000.0,0.0,4.256,1550.4640000000009,0.0,0.0,640000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",370,0.0,0.0,0,0,0.0,0.0,0.0,640.0,1004.0,0.38929440389294406,512000.0,128.0,11.936,1562.4000000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",371,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,1.984,1564.3840000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",372,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,1566.3680000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",373,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.24,1568.6080000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",374,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.08,1570.6880000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",375,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,64.0,128.0,2.656,1573.3440000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",376,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,1575.0720000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",377,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,1576.7680000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",378,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.112,1578.8800000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",379,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,1580.5760000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",380,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,32.0,2.24,1582.8160000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",381,0.0,0.0,0,0,0.0,0.0,0.0,0.0,5.0,0.0,32.0,32.0,4.832,1587.6480000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",382,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.112,1589.7600000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",383,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,1591.8080000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",384,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.816,1594.6240000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",385,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,1597.8880000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",386,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,1599.9040000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",387,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.112,1602.0160000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",388,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,32.0,3.264,1605.2800000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",389,0.0,0.0,0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,64.0,32.0,2.56,1607.8400000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",390,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.048,1609.8880000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",391,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,2.048,1611.9360000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",392,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,0.0,2.144,1614.0800000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",393,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,2.24,1616.3200000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",394,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,8320.0,8192.0,4.448,1620.7680000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,260.0,256.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",395,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,2.592,1623.3600000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",396,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,1626.6560000000009,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",397,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.496,1629.152000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",398,0.0,512.0,0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,2.048,1631.200000000001,0.0,512.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",399,0.0,0.0,0,0,0.0,0.0,0.0,0.0,20.0,0.0,2048.0,2048.0,2.624,1633.824000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",400,4096.0,9216.0,0,0,0.0,9216.0,9216.0,0.0,32.0,0.0,2048.0,2048.0,2.848,1636.672000000001,0.0,1024.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",401,0.0,512.0,0,0,0.0,512.0,512.0,0.0,32.0,0.0,2048.0,2048.0,2.048,1638.720000000001,0.0,512.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",402,3600.0,8224.0,0,0,0.0,8224.0,8224.0,0.0,32.0,0.0,2048.0,2048.0,2.784,1641.504000000001,0.0,1024.0,3600.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",403,0.0,512.0,0,0,0.0,512.0,512.0,0.0,32.0,0.0,2048.0,2048.0,2.08,1643.584000000001,0.0,512.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",404,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.048,1645.632000000001,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",405,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.52,1649.152000000001,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",406,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,1651.1360000000009,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",407,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,1653.1840000000009,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",408,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.688,1655.872000000001,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",409,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.656,1658.528000000001,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",410,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,8576.0,5.024,1663.5520000000008,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,268.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",411,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,9760.0,5.024,1668.5760000000007,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,305.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",412,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,9888.0,5.088,1673.6640000000007,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,309.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",413,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.72,1676.3840000000007,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",414,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.688,1679.0720000000008,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",415,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.616,1682.6880000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",416,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.72,1685.4080000000008,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",417,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.112,1687.520000000001,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",418,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.688,1690.208000000001,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",419,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.656,1692.864000000001,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",420,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.616,1696.480000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",421,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.72,1699.200000000001,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",422,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.112,1701.312000000001,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",423,0.0,0.0,0,0,0.0,0.0,0.0,0.0,160.0,0.0,16384.0,16384.0,2.592,1703.9040000000011,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",424,0.0,0.0,0,0,0.0,0.0,0.0,0.0,160.0,0.0,16384.0,16384.0,3.264,1707.168000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",425,30816.0,2937854.0,0,0,0.0,2937854.0,2937854.0,16697.0,32.0,0.9980871540438759,40960.0,8192.0,20.256,1727.4240000000011,2480115.0,396107.0,30816.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1280.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",426,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,10048.0,5.152,1732.5760000000012,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,314.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",427,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.08,1734.656000000001,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",428,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.016,1736.6720000000012,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",429,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.52,1740.1920000000011,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",430,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,1742.176000000001,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",431,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,1744.1920000000011,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",432,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.688,1746.8800000000012,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",433,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.688,1749.5680000000013,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",434,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5244928.0,50400.0,8.192,1757.7600000000014,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,163904.0,1575.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",435,94208.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,128.0,0.0,32768.0,32768.0,2.336,1760.0960000000014,8192.0,0.0,94208.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",436,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5244160.0,50176.0,8.128,1768.2240000000013,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,163880.0,1568.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",437,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.144,1770.3680000000013,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
ampere_sgemm_32x32_sliced1x4_tn,438,37748736.0,76873728.0,0,0,0.0,76873728.0,76873728.0,233472.0,42240.0,0.8467966573816156,5140000.0,98304.0,10.08,1780.4480000000012,589824.0,786432.0,37748736.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160625.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",439,0.0,26624.0,0,0,0.0,26624.0,26624.0,0.0,832.0,0.0,98304.0,8192.0,2.528,1782.9760000000012,24576.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",440,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.08,1785.0560000000012,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",441,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,1.984,1787.040000000001,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",442,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.488,1790.5280000000012,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",443,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,1792.4480000000012,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",444,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,1794.4960000000012,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",445,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.72,1797.2160000000013,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",446,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.688,1799.9040000000014,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",447,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,10592.0,4.928,1804.8320000000015,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,331.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",448,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,9280.0,5.056,1809.8880000000015,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,290.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",449,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,10144.0,5.088,1814.9760000000015,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,317.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",450,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.656,1817.6320000000014,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",451,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.592,1820.2240000000015,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",452,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.616,1823.8400000000015,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",453,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.72,1826.5600000000015,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",454,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.144,1828.7040000000015,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",455,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.656,1831.3600000000015,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",456,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.688,1834.0480000000016,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",457,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.584,1837.6320000000017,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",458,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.72,1840.3520000000017,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",459,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.08,1842.4320000000016,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",460,0.0,0.0,0,0,0.0,0.0,0.0,0.0,160.0,0.0,16384.0,16384.0,2.816,1845.2480000000016,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",461,0.0,0.0,0,0,0.0,0.0,0.0,0.0,160.0,0.0,16384.0,16384.0,2.752,1848.0000000000016,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",462,31456.0,2939532.0,0,0,0.0,2939532.0,2939532.0,16691.0,32.0,0.9980864677390421,40960.0,8192.0,20.448,1868.4480000000017,2480455.0,396165.0,31456.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1280.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",463,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,10560.0,5.088,1873.5360000000016,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,330.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",464,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.112,1875.6480000000017,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",465,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,1.984,1877.6320000000017,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",466,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.456,1881.0880000000016,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",467,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,1883.0080000000016,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",468,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,1885.0560000000016,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",469,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.688,1887.7440000000017,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",470,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.72,1890.4640000000018,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",471,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5250432.0,52064.0,8.192,1898.6560000000018,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,164076.0,1627.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",472,94208.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,128.0,0.0,32768.0,32768.0,2.304,1900.9600000000019,8192.0,0.0,94208.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",473,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5248256.0,49408.0,7.936,1908.8960000000018,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,164008.0,1544.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",474,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.08,1910.9760000000017,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
ampere_sgemm_32x32_sliced1x4_tn,475,37748736.0,76873728.0,0,0,0.0,76873728.0,76873728.0,233472.0,42240.0,0.8467966573816156,5135424.0,98304.0,10.08,1921.0560000000016,589824.0,786432.0,37748736.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160482.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",476,0.0,26624.0,0,0,0.0,26624.0,26624.0,0.0,832.0,0.0,98304.0,8192.0,2.72,1923.7760000000017,24576.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",477,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.112,1925.8880000000017,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",478,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.08,1927.9680000000017,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",479,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.52,1931.4880000000016,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",480,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,1933.4400000000016,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",481,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.208,1935.6480000000017,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",482,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.624,1938.2720000000018,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",483,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.656,1940.9280000000017,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",484,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,10528.0,5.12,1946.0480000000016,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,329.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",485,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,9920.0,5.088,1951.1360000000016,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,310.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",486,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,9952.0,5.088,1956.2240000000015,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,311.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",487,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.688,1958.9120000000016,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",488,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.624,1961.5360000000016,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",489,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.552,1965.0880000000016,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",490,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.72,1967.8080000000016,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",491,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.048,1969.8560000000016,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",492,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.72,1972.5760000000016,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",493,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.656,1975.2320000000016,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",494,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.648,1978.8800000000015,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",495,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.848,1981.7280000000014,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",496,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.24,1983.9680000000014,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",497,0.0,0.0,0,0,0.0,0.0,0.0,0.0,160.0,0.0,16384.0,16384.0,2.56,1986.5280000000014,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",498,0.0,0.0,0,0,0.0,0.0,0.0,0.0,160.0,0.0,16384.0,16384.0,2.592,1989.1200000000015,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",499,31936.0,2940792.0,0,0,0.0,2940792.0,2940792.0,16682.0,32.0,0.9980854373579036,40960.0,8192.0,20.384,2009.5040000000015,2480710.0,396210.0,31936.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1280.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",500,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,9088.0,5.216,2014.7200000000014,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,284.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",501,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.112,2016.8320000000015,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",502,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.016,2018.8480000000015,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",503,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.52,2022.3680000000015,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",504,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,2024.3520000000015,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",505,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2026.3680000000015,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",506,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.624,2028.9920000000016,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",507,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.656,2031.6480000000015,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",508,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5246336.0,54432.0,8.128,2039.7760000000014,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,163948.0,1701.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",509,94208.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,128.0,0.0,32768.0,32768.0,2.336,2042.1120000000014,8192.0,0.0,94208.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",510,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5243520.0,48256.0,8.16,2050.2720000000013,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,163860.0,1508.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",511,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.08,2052.352000000001,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
ampere_sgemm_32x32_sliced1x4_tn,512,37748736.0,76873728.0,0,0,0.0,76873728.0,76873728.0,233472.0,42240.0,0.8467966573816156,5141184.0,98304.0,10.24,2062.592000000001,589824.0,786432.0,37748736.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160662.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",513,0.0,26624.0,0,0,0.0,26624.0,26624.0,0.0,832.0,0.0,98304.0,8192.0,2.528,2065.120000000001,24576.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",514,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.048,2067.1680000000006,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",515,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.016,2069.1840000000007,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",516,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.584,2072.7680000000005,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",517,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,2074.7520000000004,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",518,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,2076.8320000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",519,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.784,2079.6160000000004,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",520,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.688,2082.3040000000005,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",521,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,9440.0,5.408,2087.7120000000004,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,295.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",522,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,10720.0,4.864,2092.5760000000005,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,335.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",523,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,10144.0,4.992,2097.5680000000007,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,317.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",524,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.752,2100.3200000000006,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",525,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.688,2103.0080000000007,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",526,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.616,2106.6240000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",527,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.688,2109.312000000001,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",528,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.112,2111.424000000001,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",529,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.688,2114.112000000001,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",530,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.592,2116.704000000001,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",531,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.584,2120.288000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",532,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.688,2122.976000000001,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",533,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.176,2125.152000000001,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",534,0.0,0.0,0,0,0.0,0.0,0.0,0.0,160.0,0.0,16384.0,16384.0,2.624,2127.7760000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",535,0.0,0.0,0,0,0.0,0.0,0.0,0.0,160.0,0.0,16384.0,16384.0,2.656,2130.4320000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",536,32768.0,2942976.0,0,0,0.0,2942976.0,2942976.0,16640.0,32.0,0.9980806142034548,40960.0,8192.0,20.352,2150.7840000000006,2481152.0,396288.0,32768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1280.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",537,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,9824.0,5.024,2155.8080000000004,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,307.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",538,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.08,2157.8880000000004,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",539,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.016,2159.9040000000005,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",540,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.552,2163.4560000000006,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",541,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,2165.4400000000005,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",542,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,2167.4240000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",543,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.656,2170.0800000000004,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",544,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.688,2172.7680000000005,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",545,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5249152.0,50240.0,8.256,2181.0240000000003,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,164036.0,1570.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",546,94208.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,128.0,0.0,32768.0,32768.0,2.24,2183.264,8192.0,0.0,94208.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",547,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5242880.0,51072.0,8.224,2191.4880000000003,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,163840.0,1596.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",548,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.144,2193.632,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
ampere_sgemm_32x32_sliced1x4_tn,549,37748736.0,76873728.0,0,0,0.0,76873728.0,76873728.0,233472.0,42240.0,0.8467966573816156,5140768.0,98304.0,9.952,2203.5840000000003,589824.0,786432.0,37748736.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160649.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",550,0.0,26624.0,0,0,0.0,26624.0,26624.0,0.0,832.0,0.0,98304.0,8192.0,2.592,2206.1760000000004,24576.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",551,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.08,2208.2560000000003,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",552,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.048,2210.304,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",553,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.52,2213.824,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",554,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,2215.744,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",555,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,2217.728,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",556,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.656,2220.384,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",557,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.72,2223.104,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",558,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,9600.0,5.152,2228.256,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,300.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",559,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,10240.0,5.12,2233.3759999999997,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,320.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",560,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,9664.0,4.992,2238.368,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,302.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",561,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.688,2241.056,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",562,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.624,2243.68,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",563,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.584,2247.2639999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",564,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.688,2249.9519999999998,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",565,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.144,2252.0959999999995,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",566,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.688,2254.7839999999997,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",567,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.592,2257.3759999999997,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",568,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.616,2260.9919999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",569,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.688,2263.68,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",570,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.048,2265.7279999999996,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",571,0.0,0.0,0,0,0.0,0.0,0.0,0.0,160.0,0.0,16384.0,16384.0,2.528,2268.2559999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",572,0.0,0.0,0,0,0.0,0.0,0.0,0.0,160.0,0.0,16384.0,16384.0,2.624,2270.879999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",573,32768.0,2942976.0,0,0,0.0,2942976.0,2942976.0,16640.0,32.0,0.9980806142034548,40960.0,8192.0,20.384,2291.263999999999,2481152.0,396288.0,32768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1280.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",574,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,9600.0,5.312,2296.575999999999,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,300.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",575,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.08,2298.655999999999,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",576,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.048,2300.703999999999,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",577,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.552,2304.255999999999,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",578,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,2306.175999999999,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",579,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,2308.159999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",580,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.656,2310.815999999999,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",581,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.72,2313.5359999999987,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",582,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5243264.0,52928.0,8.16,2321.6959999999985,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,163852.0,1654.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",583,94208.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,128.0,0.0,32768.0,32768.0,2.272,2323.9679999999985,8192.0,0.0,94208.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",584,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5244672.0,50752.0,8.288,2332.2559999999985,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,163896.0,1586.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",585,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.08,2334.3359999999984,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
ampere_sgemm_32x32_sliced1x4_tn,586,37748736.0,76873728.0,0,0,0.0,76873728.0,76873728.0,233472.0,42240.0,0.8467966573816156,5132832.0,98304.0,9.92,2344.2559999999985,589824.0,786432.0,37748736.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160401.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",587,0.0,26624.0,0,0,0.0,26624.0,26624.0,0.0,832.0,0.0,98304.0,8192.0,2.528,2346.7839999999983,24576.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",588,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.08,2348.863999999998,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",589,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.048,2350.911999999998,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",590,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.456,2354.367999999998,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",591,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,2356.287999999998,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",592,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2358.3039999999983,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",593,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.624,2360.927999999998,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",594,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.656,2363.583999999998,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",595,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,9600.0,5.056,2368.639999999998,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,300.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",596,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,10656.0,5.088,2373.7279999999982,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,333.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",597,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,9216.0,5.024,2378.751999999998,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,288.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",598,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.752,2381.503999999998,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",599,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.656,2384.159999999998,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",600,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.616,2387.775999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",601,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.688,2390.463999999998,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",602,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.048,2392.511999999998,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",603,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.784,2395.295999999998,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",604,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.624,2397.919999999998,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",605,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.712,2401.631999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",606,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.72,2404.3519999999976,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",607,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.08,2406.4319999999975,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",608,0.0,0.0,0,0,0.0,0.0,0.0,0.0,160.0,0.0,16384.0,16384.0,2.624,2409.0559999999973,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",609,0.0,0.0,0,0,0.0,0.0,0.0,0.0,160.0,0.0,16384.0,16384.0,2.624,2411.679999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",610,32768.0,2942976.0,0,0,0.0,2942976.0,2942976.0,16640.0,32.0,0.9980806142034548,40960.0,8192.0,20.32,2431.9999999999973,2481152.0,396288.0,32768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1280.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",611,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,9056.0,5.28,2437.2799999999975,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,283.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",612,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.112,2439.3919999999976,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",613,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.112,2441.5039999999976,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",614,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.456,2444.9599999999978,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",615,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,2446.911999999998,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",616,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2448.927999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",617,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.624,2451.551999999998,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",618,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.656,2454.207999999998,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",619,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5246080.0,51104.0,8.192,2462.399999999998,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,163940.0,1597.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",620,94208.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,128.0,0.0,32768.0,32768.0,2.304,2464.703999999998,8192.0,0.0,94208.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",621,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5248384.0,49920.0,8.288,2472.991999999998,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,164012.0,1560.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",622,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.08,2475.071999999998,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
ampere_sgemm_32x32_sliced1x4_tn,623,37748736.0,76873728.0,0,0,0.0,76873728.0,76873728.0,233472.0,42240.0,0.8467966573816156,5140512.0,98304.0,9.792,2484.8639999999978,589824.0,786432.0,37748736.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160641.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",624,0.0,26624.0,0,0,0.0,26624.0,26624.0,0.0,832.0,0.0,98304.0,8192.0,2.592,2487.455999999998,24576.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",625,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.08,2489.535999999998,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",626,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.016,2491.551999999998,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",627,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.52,2495.071999999998,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",628,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,2497.0559999999978,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",629,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,2499.1039999999975,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",630,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.656,2501.7599999999975,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",631,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.848,2504.6079999999974,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",632,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,9920.0,4.992,2509.5999999999976,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,310.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",633,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,9632.0,4.928,2514.5279999999975,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,301.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",634,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,9408.0,5.184,2519.7119999999977,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,294.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",635,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.688,2522.399999999998,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",636,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.656,2525.0559999999978,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",637,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.648,2528.703999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",638,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.656,2531.359999999998,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",639,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.08,2533.439999999998,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",640,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.848,2536.2879999999977,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",641,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.624,2538.9119999999975,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",642,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.584,2542.4959999999974,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",643,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.656,2545.1519999999973,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",644,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.08,2547.2319999999972,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",645,0.0,0.0,0,0,0.0,0.0,0.0,0.0,160.0,0.0,16384.0,16384.0,2.656,2549.887999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",646,0.0,0.0,0,0,0.0,0.0,0.0,0.0,160.0,0.0,16384.0,16384.0,2.624,2552.511999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",647,32768.0,2942976.0,0,0,0.0,2942976.0,2942976.0,16640.0,32.0,0.9980806142034548,40960.0,8192.0,20.448,2572.959999999997,2481152.0,396288.0,32768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1280.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",648,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,10016.0,5.312,2578.2719999999968,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,313.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",649,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.08,2580.3519999999967,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",650,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.08,2582.4319999999966,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",651,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.488,2585.9199999999964,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",652,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,2587.8719999999967,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",653,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2589.8879999999967,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",654,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.688,2592.575999999997,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",655,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.656,2595.231999999997,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",656,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5243776.0,53056.0,8.256,2603.4879999999966,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,163868.0,1658.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",657,94208.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,128.0,0.0,32768.0,32768.0,2.272,2605.7599999999966,8192.0,0.0,94208.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",658,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5243008.0,52864.0,8.224,2613.9839999999967,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,163844.0,1652.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",659,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.112,2616.095999999997,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
ampere_sgemm_32x32_sliced1x4_tn,660,37748736.0,76873728.0,0,0,0.0,76873728.0,76873728.0,233472.0,42240.0,0.8467966573816156,5137536.0,98304.0,10.144,2626.2399999999966,589824.0,786432.0,37748736.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160548.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",661,0.0,26624.0,0,0,0.0,26624.0,26624.0,0.0,832.0,0.0,98304.0,8192.0,2.528,2628.7679999999964,24576.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",662,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.112,2630.8799999999965,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",663,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.016,2632.8959999999965,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",664,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.456,2636.3519999999967,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",665,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,2638.303999999997,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",666,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,2640.287999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",667,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.656,2642.943999999997,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",668,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.72,2645.6639999999966,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",669,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,9600.0,5.12,2650.7839999999965,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,300.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",670,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,9696.0,5.216,2655.9999999999964,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,303.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",671,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,9664.0,4.96,2660.9599999999964,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,302.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",672,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.752,2663.7119999999964,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",673,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.688,2666.3999999999965,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",674,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.584,2669.9839999999963,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",675,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.72,2672.703999999996,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",676,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.112,2674.815999999996,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",677,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.784,2677.5999999999963,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",678,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,64.0,0.0,4096.0,4096.0,2.624,2680.223999999996,1024.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",679,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,3.712,2683.935999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",680,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,12288.0,8192.0,2.752,2686.687999999996,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",681,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.112,2688.799999999996,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",682,0.0,0.0,0,0,0.0,0.0,0.0,0.0,160.0,0.0,16384.0,16384.0,2.56,2691.359999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",683,0.0,0.0,0,0,0.0,0.0,0.0,0.0,160.0,0.0,16384.0,16384.0,2.688,2694.047999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",684,32768.0,2942976.0,0,0,0.0,2942976.0,2942976.0,16640.0,32.0,0.9980806142034548,40960.0,8192.0,20.352,2714.399999999996,2481152.0,396288.0,32768.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1280.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",685,1048576.0,2326528.0,0,0,0.0,2326528.0,2326528.0,17664.0,13312.0,0.5702479338842975,1572864.0,10080.0,5.152,2719.551999999996,98304.0,131072.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,49152.0,315.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",686,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.144,2721.695999999996,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",687,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,1.984,2723.6799999999957,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",688,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.488,2727.1679999999956,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",689,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,2729.0879999999956,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",690,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2731.1039999999957,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",691,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.656,2733.7599999999957,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",692,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.752,2736.5119999999956,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",693,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5243136.0,49056.0,8.192,2744.7039999999956,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,163848.0,1533.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",694,94208.0,196608.0,0,0,0.0,196608.0,196608.0,0.0,128.0,0.0,32768.0,32768.0,2.304,2747.0079999999957,8192.0,0.0,94208.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",695,4194304.0,9306112.0,0,0,0.0,9306112.0,9306112.0,70656.0,53248.0,0.5702479338842975,5246080.0,53472.0,8.0,2755.0079999999957,393216.0,524288.0,4194304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,163940.0,1671.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",696,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.176,2757.1839999999956,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
ampere_sgemm_32x32_sliced1x4_tn,697,37748736.0,76873728.0,0,0,0.0,76873728.0,76873728.0,233472.0,42240.0,0.8467966573816156,5136704.0,98304.0,10.208,2767.3919999999957,589824.0,786432.0,37748736.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160522.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",698,0.0,26624.0,0,0,0.0,26624.0,26624.0,0.0,832.0,0.0,98304.0,8192.0,2.464,2769.8559999999957,24576.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",699,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.08,2771.9359999999956,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",700,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.016,2773.9519999999957,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",701,0.0,6532.0,0,0,0.0,6532.0,6532.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.488,2777.4399999999955,6528.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",702,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.048,2779.4879999999953,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",703,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2781.5039999999954,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",704,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,8448.0,8192.0,2.72,2784.223999999995,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",705,0.0,2048.0,0,0,0.0,2048.0,2048.0,0.0,192.0,0.0,16384.0,8192.0,2.656,2786.879999999995,0.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",706,65536000.0,145408000.0,0,0,0.0,145408000.0,145408000.0,1104000.0,832000.0,0.5702479338842975,79799168.0,827136.0,72.96,2859.839999999995,6144000.0,8192000.0,65536000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2493724.0,25848.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",707,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.792,2861.631999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",708,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,96.0,160.0,2.592,2864.223999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",709,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,2866.303999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",710,0.0,128000.0,0,0,0.0,128000.0,128000.0,0.0,2000.0,0.0,512000.0,512000.0,2.688,2868.991999999995,0.0,128000.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,16000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",711,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,2870.687999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",712,0.0,0.0,0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,37504.0,3.712,2874.399999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16128.0,1172.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",713,0.0,0.0,0,0,0.0,0.0,0.0,9472.0,34440.0,0.2157041355438149,2109440.0,0.0,4.352,2878.751999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",714,0.0,0.0,0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,37952.0,3.552,2882.303999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16128.0,1186.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",715,0.0,0.0,0,0,0.0,0.0,0.0,9472.0,34440.0,0.2157041355438149,2109440.0,0.0,4.448,2886.751999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",716,0.0,0.0,0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,37760.0,3.584,2890.335999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16128.0,1180.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",717,0.0,0.0,0,0,0.0,0.0,0.0,9472.0,34472.0,0.21554705989441106,2109440.0,0.0,4.448,2894.7839999999946,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",718,0.0,0.0,0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,37824.0,3.52,2898.3039999999946,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16128.0,1182.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",719,0.0,0.0,0,0,0.0,0.0,0.0,9472.0,34920.0,0.21337177869886467,2109440.0,128.0,4.48,2902.7839999999946,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,65920.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",720,0.0,0.0,0,0,0.0,0.0,0.0,0.0,12.0,0.0,4128.0,512.0,2.336,2905.1199999999944,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,129.0,16.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",721,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.664,2906.7839999999946,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",722,0.0,0.0,0,0,0.0,0.0,0.0,497.0,16.0,0.9688109161793372,512.0,0.0,3.488,2910.2719999999945,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",723,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.696,2911.9679999999944,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",724,0.0,0.0,0,0,0.0,0.0,0.0,497.0,16.0,0.9688109161793372,512.0,0.0,3.456,2915.4239999999945,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",725,0.0,0.0,0,0,0.0,0.0,0.0,37968.0,8418.0,0.8185228301642737,527232.0,7072.0,5.888,2921.3119999999944,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16476.0,221.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",726,0.0,0.0,0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,544.0,6.432,2927.7439999999942,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,80.0,17.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",727,0.0,0.0,0,0,0.0,0.0,0.0,0.0,12000.0,0.0,520064.0,57024.0,3.552,2931.2959999999944,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16252.0,1782.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",728,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3000.0,0.0,640000.0,0.0,2.976,2934.2719999999945,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,20000.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",729,0.0,0.0,0,0,0.0,0.0,0.0,0.0,4000.0,0.0,0.0,1024000.0,2.24,2936.5119999999943,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,32000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",730,0.0,0.0,0,0,0.0,0.0,0.0,98304.0,4000.0,0.960900844541758,512000.0,0.0,4.16,2940.671999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",731,0.0,0.0,0,0,0.0,0.0,0.0,156.0,64.0,0.7090909090909091,8192.0,0.0,2.368,2943.039999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",732,0.0,0.0,0,0,0.0,0.0,0.0,51858.0,19316.0,0.7286087616264366,1902208.0,1275520.0,9.696,2952.735999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,59444.0,39860.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",733,0.0,0.0,0,0,0.0,0.0,0.0,16854.0,19502.0,0.46358235229398176,1902720.0,1368256.0,7.648,2960.383999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,59460.0,42758.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",734,0.0,0.0,0,0,0.0,0.0,0.0,15858.0,19583.0,0.44744787110973167,1889280.0,1161408.0,8.352,2968.735999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,59040.0,36294.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",735,0.0,0.0,0,0,0.0,0.0,0.0,15858.0,19583.0,0.44744787110973167,1901056.0,1091392.0,8.192,2976.927999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,59408.0,34106.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",736,0.0,0.0,0,0,0.0,0.0,0.0,14336.0,4000.0,0.7818499127399651,1024000.0,0.0,3.872,2980.799999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",737,0.0,0.0,0,0,0.0,0.0,0.0,39.0,16.0,0.7090909090909091,2048.0,0.0,2.208,2983.007999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",738,0.0,0.0,0,0,0.0,0.0,0.0,13650.0,10464.0,0.5660612092560339,1277824.0,882336.0,6.72,2989.7279999999937,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,39932.0,27573.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",739,0.0,0.0,0,0,0.0,0.0,0.0,0.0,16000.0,0.0,1548960.0,1536000.0,4.064,2993.7919999999935,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48405.0,48000.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",740,1792000.0,4245120.0,0,0,0.0,4245120.0,4245120.0,528.0,5248.0,0.09141274238227147,1005952.0,512000.0,16.96,3010.7519999999936,533120.0,128000.0,1792000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,31436.0,16000.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",741,0.0,655488.0,0,0,0.0,655488.0,655488.0,71840.0,8000.0,0.8997995991983968,512000.0,512000.0,46.752,3057.5039999999935,655488.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,16000.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",742,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2000.0,0.0,512000.0,128000.0,2.624,3060.1279999999933,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,4000.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",743,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,1.92,3062.0479999999934,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",744,0.0,0.0,0,0,0.0,0.0,0.0,0.0,12000.0,0.0,1152000.0,53408.0,7.424,3069.4719999999934,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,36000.0,1669.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",745,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3000.0,0.0,640000.0,0.0,2.752,3072.2239999999933,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,20000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",746,1792000.0,4245120.0,0,0,0.0,4245120.0,4245120.0,528.0,5248.0,0.09141274238227147,1026816.0,512000.0,17.44,3089.6639999999934,533120.0,128000.0,1792000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32088.0,16000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",747,0.0,0.0,0,0,0.0,0.0,0.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,21.984,3111.6479999999933,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",748,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,3113.791999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",749,0.0,0.0,0,0,0.0,0.0,0.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,21.824,3135.615999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",750,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.112,3137.7279999999932,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",751,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,1.984,3139.711999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",752,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.944,3142.655999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",753,0.0,147456.0,0,0,0.0,147456.0,147456.0,320.0,1004.0,0.24169184290030213,512000.0,128.0,8.032,3150.6879999999933,147456.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",754,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,3152.735999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",755,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.2,3155.935999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",756,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,3158.015999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",757,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.976,3160.991999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",758,1152000.0,2560000.0,0,0,0.0,2560000.0,2560000.0,0.0,4000.0,0.0,0.0,512000.0,3.232,3164.223999999993,0.0,256000.0,1152000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,16000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",759,640000.0,1280000.0,0,0,0.0,1280000.0,1280000.0,0.0,3000.0,0.0,1024000.0,0.0,4.352,3168.5759999999927,0.0,0.0,640000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",760,0.0,0.0,0,0,0.0,0.0,0.0,640.0,1004.0,0.38929440389294406,512000.0,128.0,11.776,3180.3519999999926,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",761,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.048,3182.3999999999924,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",762,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,3184.4799999999923,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",763,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.24,3186.719999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",764,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.08,3188.799999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",765,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,96.0,160.0,2.624,3191.423999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",766,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,3193.151999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",767,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.664,3194.815999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",768,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.048,3196.863999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",769,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,3198.5599999999918,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",770,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,128.0,32.0,2.432,3200.9919999999915,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",771,0.0,0.0,0,0,0.0,0.0,0.0,0.0,5.0,0.0,32.0,32.0,4.704,3205.6959999999917,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",772,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.112,3207.807999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",773,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,3209.823999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",774,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.784,3212.607999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",775,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.2,3215.807999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",776,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,3217.8559999999916,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
