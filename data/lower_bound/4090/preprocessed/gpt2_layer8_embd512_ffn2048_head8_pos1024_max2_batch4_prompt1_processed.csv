Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.856,1.856,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,3.584,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,5.312,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.048,7.36,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.368,9.728,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",6,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.304,12.032,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",7,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,15.392,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",8,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,18.688,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",9,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.176,20.863999999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",10,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,22.56,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",11,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,24.256,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.728,25.984,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,0.0,0.0,0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,2.464,28.448,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,30.496000000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",15,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.208,32.704,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",16,0.0,0.0,0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,32.0,32.0,2.496,35.2,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",17,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,37.216,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",18,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,39.296,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",19,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,2.112,41.408,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",20,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,2176.0,8192.0,3.808,45.216,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,68.0,256.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",21,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,2176.0,8192.0,3.552,48.768,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,68.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",22,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.048,50.816,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",23,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,52.832,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",24,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,56.224000000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",25,20548.0,77044.0,0,0,0.0,77044.0,77044.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,3.488,59.712,21040.0,14908.0,20548.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,264.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),26,25165824.0,50724864.0,0,0,0.0,50724864.0,50724864.0,99456.0,1536.0,0.9847908745247148,3244032.0,196608.0,7.296,67.00800000000001,0.0,393216.0,25165824.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,101376.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",27,0.0,61440.0,0,0,0.0,61440.0,61440.0,0.0,2880.0,0.0,202752.0,24576.0,2.496,69.504,55296.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6336.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",28,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,2.656,72.16000000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",29,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,2.656,74.81600000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",30,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,2.624,77.44000000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",31,65536.0,2177024.0,0,0,0.0,2177024.0,2177024.0,17024.0,32.0,0.99812382739212,24576.0,8192.0,12.32,89.76000000000002,1646592.0,399360.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,256.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",32,1048576.0,2129920.0,0,0,0.0,2129920.0,2129920.0,9536.0,8832.0,0.519163763066202,1116160.0,8192.0,8.896,98.65600000000002,16384.0,16384.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,34880.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",33,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.112,100.76800000000001,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",34,20548.0,77044.0,0,0,0.0,77044.0,77044.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,3.584,104.35200000000002,21040.0,14908.0,20548.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,264.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),35,33554432.0,67633152.0,0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,8.352,112.70400000000002,0.0,524288.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",36,0.0,81920.0,0,0,0.0,81920.0,81920.0,0.0,3840.0,0.0,270336.0,32768.0,2.496,115.20000000000002,73728.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8448.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",37,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.048,117.24800000000002,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",38,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,2.176,119.42400000000002,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",39,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,1.984,121.40800000000002,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",40,8192.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.08,123.48800000000001,0.0,0.0,8192.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",41,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.048,125.53600000000002,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",42,48232.0,121040.0,0,0,0.0,121040.0,121040.0,0.0,128.0,0.0,32768.0,32768.0,2.208,127.74400000000001,8192.0,16384.0,48232.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",43,8192.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,2.144,129.888,0.0,0.0,8192.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",44,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.112,132.0,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),45,33554432.0,67633152.0,0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,9.184,141.184,0.0,524288.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",46,0.0,69632.0,0,0,0.0,69632.0,69632.0,0.0,2496.0,0.0,264192.0,8192.0,2.912,144.096,67584.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8256.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",47,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.048,146.144,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",48,20548.0,77044.0,0,0,0.0,77044.0,77044.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,3.52,149.66400000000002,21040.0,14908.0,20548.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,264.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),49,25165824.0,50724864.0,0,0,0.0,50724864.0,50724864.0,99456.0,1536.0,0.9847908745247148,3244032.0,196608.0,7.072,156.73600000000002,0.0,393216.0,25165824.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,101376.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",50,0.0,61440.0,0,0,0.0,61440.0,61440.0,0.0,2880.0,0.0,202752.0,24576.0,2.464,159.20000000000002,55296.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6336.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",51,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,2.976,162.17600000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",52,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,2.656,164.83200000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",53,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,2.688,167.52,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",54,65536.0,2177024.0,0,0,0.0,2177024.0,2177024.0,17024.0,32.0,0.99812382739212,24576.0,8192.0,12.256,179.776,1646592.0,399360.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,256.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",55,1048576.0,2129920.0,0,0,0.0,2129920.0,2129920.0,9536.0,8832.0,0.519163763066202,1116160.0,8192.0,8.992,188.768,16384.0,16384.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,34880.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",56,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.048,190.816,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",57,20548.0,77044.0,0,0,0.0,77044.0,77044.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,3.52,194.336,21040.0,14908.0,20548.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,264.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),58,33554432.0,67633152.0,0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,8.064,202.4,0.0,524288.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",59,0.0,81920.0,0,0,0.0,81920.0,81920.0,0.0,3840.0,0.0,270336.0,32768.0,2.56,204.96,73728.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8448.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",60,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.048,207.008,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",61,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,2.08,209.08800000000002,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",62,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.016,211.104,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",63,8192.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.08,213.18400000000003,0.0,0.0,8192.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",64,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.048,215.23200000000003,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",65,48240.0,121056.0,0,0,0.0,121056.0,121056.0,0.0,128.0,0.0,32768.0,32768.0,2.24,217.47200000000004,8192.0,16384.0,48240.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",66,8192.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,2.112,219.58400000000003,0.0,0.0,8192.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",67,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.112,221.69600000000003,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),68,33554432.0,67633152.0,0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,8.992,230.68800000000002,0.0,524288.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",69,0.0,69632.0,0,0,0.0,69632.0,69632.0,0.0,2496.0,0.0,264192.0,8192.0,2.88,233.568,67584.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8256.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",70,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.08,235.64800000000002,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",71,20548.0,77044.0,0,0,0.0,77044.0,77044.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,3.488,239.13600000000002,21040.0,14908.0,20548.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,264.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),72,25165824.0,50724864.0,0,0,0.0,50724864.0,50724864.0,99456.0,1536.0,0.9847908745247148,3244032.0,196608.0,7.104,246.24000000000004,0.0,393216.0,25165824.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,101376.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",73,0.0,61440.0,0,0,0.0,61440.0,61440.0,0.0,2880.0,0.0,202752.0,24576.0,2.464,248.70400000000004,55296.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6336.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",74,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,2.688,251.39200000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",75,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,2.688,254.08,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",76,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,2.752,256.832,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",77,65536.0,2177024.0,0,0,0.0,2177024.0,2177024.0,17024.0,32.0,0.99812382739212,24576.0,8192.0,11.296,268.128,1646592.0,399360.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,256.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",78,1048576.0,2129920.0,0,0,0.0,2129920.0,2129920.0,9536.0,8832.0,0.519163763066202,1116160.0,8192.0,8.992,277.12,16384.0,16384.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,34880.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",79,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.048,279.168,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",80,20548.0,77044.0,0,0,0.0,77044.0,77044.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,3.552,282.72,21040.0,14908.0,20548.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,264.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),81,33554432.0,67633152.0,0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,8.096,290.81600000000003,0.0,524288.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",82,0.0,81920.0,0,0,0.0,81920.0,81920.0,0.0,3840.0,0.0,270336.0,32768.0,2.592,293.408,73728.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8448.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",83,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.08,295.488,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",84,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,2.048,297.536,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",85,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.048,299.584,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",86,8192.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.112,301.696,0.0,0.0,8192.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",87,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,1.984,303.68,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",88,48332.0,121240.0,0,0,0.0,121240.0,121240.0,0.0,128.0,0.0,32768.0,32768.0,2.112,305.79200000000003,8192.0,16384.0,48332.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",89,8192.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,2.048,307.84000000000003,0.0,0.0,8192.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",90,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.144,309.98400000000004,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),91,33554432.0,67633152.0,0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,8.16,318.14400000000006,0.0,524288.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",92,0.0,69632.0,0,0,0.0,69632.0,69632.0,0.0,2496.0,0.0,264192.0,8192.0,2.848,320.9920000000001,67584.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8256.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",93,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.08,323.07200000000006,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",94,20548.0,77044.0,0,0,0.0,77044.0,77044.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,3.552,326.6240000000001,21040.0,14908.0,20548.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,264.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),95,25165824.0,50724864.0,0,0,0.0,50724864.0,50724864.0,99456.0,1536.0,0.9847908745247148,3244032.0,196608.0,7.136,333.7600000000001,0.0,393216.0,25165824.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,101376.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",96,0.0,61440.0,0,0,0.0,61440.0,61440.0,0.0,2880.0,0.0,202752.0,24576.0,2.56,336.3200000000001,55296.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6336.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",97,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,2.688,339.0080000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",98,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,2.688,341.6960000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",99,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,2.656,344.3520000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",100,65536.0,2177024.0,0,0,0.0,2177024.0,2177024.0,17024.0,32.0,0.99812382739212,24576.0,8192.0,11.296,355.6480000000001,1646592.0,399360.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,256.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",101,1048576.0,2129920.0,0,0,0.0,2129920.0,2129920.0,9536.0,8832.0,0.519163763066202,1116160.0,8192.0,9.056,364.70400000000006,16384.0,16384.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,34880.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",102,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.048,366.75200000000007,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",103,20548.0,77044.0,0,0,0.0,77044.0,77044.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,3.424,370.17600000000004,21040.0,14908.0,20548.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,264.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),104,33554432.0,67633152.0,0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,8.544,378.72,0.0,524288.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",105,0.0,81920.0,0,0,0.0,81920.0,81920.0,0.0,3840.0,0.0,270336.0,32768.0,2.528,381.24800000000005,73728.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8448.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",106,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.048,383.29600000000005,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",107,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,2.08,385.37600000000003,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",108,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.016,387.39200000000005,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",109,8192.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.208,389.6000000000001,0.0,0.0,8192.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",110,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.016,391.6160000000001,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",111,48284.0,121144.0,0,0,0.0,121144.0,121144.0,0.0,128.0,0.0,32768.0,32768.0,2.112,393.7280000000001,8192.0,16384.0,48284.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",112,8192.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,2.048,395.7760000000001,0.0,0.0,8192.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",113,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.112,397.88800000000015,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),114,33554432.0,67633152.0,0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,8.256,406.1440000000001,0.0,524288.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",115,0.0,69632.0,0,0,0.0,69632.0,69632.0,0.0,2496.0,0.0,264192.0,8192.0,2.816,408.9600000000001,67584.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8256.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",116,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.08,411.0400000000001,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",117,20548.0,77044.0,0,0,0.0,77044.0,77044.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,3.456,414.4960000000001,21040.0,14908.0,20548.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,264.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),118,25165824.0,50724864.0,0,0,0.0,50724864.0,50724864.0,99456.0,1536.0,0.9847908745247148,3244032.0,196608.0,7.136,421.6320000000001,0.0,393216.0,25165824.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,101376.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",119,0.0,61440.0,0,0,0.0,61440.0,61440.0,0.0,2880.0,0.0,202752.0,24576.0,2.624,424.25600000000014,55296.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6336.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",120,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,2.688,426.94400000000013,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",121,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,2.656,429.60000000000014,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",122,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,2.688,432.2880000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",123,65536.0,2177024.0,0,0,0.0,2177024.0,2177024.0,17024.0,32.0,0.99812382739212,24576.0,8192.0,11.328,443.6160000000001,1646592.0,399360.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,256.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",124,1048576.0,2129920.0,0,0,0.0,2129920.0,2129920.0,9536.0,8832.0,0.519163763066202,1116160.0,8192.0,9.056,452.6720000000001,16384.0,16384.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,34880.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",125,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.08,454.75200000000007,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",126,20548.0,77044.0,0,0,0.0,77044.0,77044.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,3.552,458.3040000000001,21040.0,14908.0,20548.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,264.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),127,33554432.0,67633152.0,0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,8.384,466.6880000000001,0.0,524288.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",128,0.0,81920.0,0,0,0.0,81920.0,81920.0,0.0,3840.0,0.0,270336.0,32768.0,2.464,469.1520000000001,73728.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8448.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",129,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.08,471.2320000000001,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",130,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,2.048,473.2800000000001,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",131,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.048,475.3280000000001,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",132,8192.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.08,477.4080000000001,0.0,0.0,8192.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",133,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.048,479.4560000000001,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",134,48224.0,121024.0,0,0,0.0,121024.0,121024.0,0.0,128.0,0.0,32768.0,32768.0,2.112,481.5680000000001,8192.0,16384.0,48224.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",135,8192.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,2.048,483.6160000000001,0.0,0.0,8192.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",136,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.08,485.6960000000001,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),137,33554432.0,67633152.0,0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,8.192,493.8880000000001,0.0,524288.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",138,0.0,69632.0,0,0,0.0,69632.0,69632.0,0.0,2496.0,0.0,264192.0,8192.0,2.848,496.7360000000001,67584.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8256.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",139,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.208,498.94400000000013,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",140,20548.0,77044.0,0,0,0.0,77044.0,77044.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,3.584,502.52800000000013,21040.0,14908.0,20548.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,264.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),141,25165824.0,50724864.0,0,0,0.0,50724864.0,50724864.0,99456.0,1536.0,0.9847908745247148,3244032.0,196608.0,6.944,509.47200000000015,0.0,393216.0,25165824.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,101376.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",142,0.0,61440.0,0,0,0.0,61440.0,61440.0,0.0,2880.0,0.0,202752.0,24576.0,2.432,511.90400000000017,55296.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6336.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",143,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,2.624,514.5280000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",144,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,2.656,517.1840000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",145,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,2.688,519.8720000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",146,65536.0,2177024.0,0,0,0.0,2177024.0,2177024.0,17024.0,32.0,0.99812382739212,24576.0,8192.0,11.328,531.2,1646592.0,399360.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,256.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",147,1048576.0,2129920.0,0,0,0.0,2129920.0,2129920.0,9536.0,8832.0,0.519163763066202,1116160.0,8192.0,9.184,540.384,16384.0,16384.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,34880.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",148,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.112,542.496,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",149,20548.0,77044.0,0,0,0.0,77044.0,77044.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,3.52,546.016,21040.0,14908.0,20548.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,264.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),150,33554432.0,67633152.0,0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,8.256,554.2719999999999,0.0,524288.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",151,0.0,81920.0,0,0,0.0,81920.0,81920.0,0.0,3840.0,0.0,270336.0,32768.0,2.496,556.7679999999999,73728.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8448.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",152,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.048,558.8159999999999,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",153,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,2.08,560.896,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",154,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.08,562.976,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",155,8192.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.336,565.312,0.0,0.0,8192.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",156,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.016,567.328,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",157,48196.0,120968.0,0,0,0.0,120968.0,120968.0,0.0,128.0,0.0,32768.0,32768.0,2.24,569.568,8192.0,16384.0,48196.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",158,8192.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,2.08,571.648,0.0,0.0,8192.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",159,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.08,573.7280000000001,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),160,33554432.0,67633152.0,0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,8.224,581.9520000000001,0.0,524288.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",161,0.0,69632.0,0,0,0.0,69632.0,69632.0,0.0,2496.0,0.0,264192.0,8192.0,2.976,584.9280000000001,67584.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8256.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",162,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.144,587.0720000000001,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",163,20548.0,77044.0,0,0,0.0,77044.0,77044.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,3.52,590.5920000000001,21040.0,14908.0,20548.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,264.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),164,25165824.0,50724864.0,0,0,0.0,50724864.0,50724864.0,99456.0,1536.0,0.9847908745247148,3244032.0,196608.0,7.04,597.6320000000001,0.0,393216.0,25165824.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,101376.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",165,0.0,61440.0,0,0,0.0,61440.0,61440.0,0.0,2880.0,0.0,202752.0,24576.0,2.496,600.128,55296.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6336.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",166,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,2.656,602.784,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",167,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,2.656,605.4399999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",168,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,2.656,608.0959999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",169,65536.0,2177024.0,0,0,0.0,2177024.0,2177024.0,17024.0,32.0,0.99812382739212,24576.0,8192.0,11.264,619.3599999999999,1646592.0,399360.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,256.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",170,1048576.0,2129920.0,0,0,0.0,2129920.0,2129920.0,9536.0,8832.0,0.519163763066202,1116160.0,8192.0,9.184,628.5439999999999,16384.0,16384.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,34880.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",171,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.08,630.6239999999999,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",172,20548.0,77044.0,0,0,0.0,77044.0,77044.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,3.584,634.2079999999999,21040.0,14908.0,20548.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,264.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),173,33554432.0,67633152.0,0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,8.192,642.3999999999999,0.0,524288.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",174,0.0,81920.0,0,0,0.0,81920.0,81920.0,0.0,3840.0,0.0,270336.0,32768.0,2.656,645.0559999999998,73728.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8448.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",175,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.016,647.0719999999998,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",176,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,2.048,649.1199999999998,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",177,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.048,651.1679999999998,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",178,8192.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.144,653.3119999999998,0.0,0.0,8192.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",179,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.048,655.3599999999998,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",180,48216.0,121008.0,0,0,0.0,121008.0,121008.0,0.0,128.0,0.0,32768.0,32768.0,2.144,657.5039999999998,8192.0,16384.0,48216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",181,8192.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,2.048,659.5519999999998,0.0,0.0,8192.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",182,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.048,661.5999999999998,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),183,33554432.0,67633152.0,0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,8.256,669.8559999999998,0.0,524288.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",184,0.0,69632.0,0,0,0.0,69632.0,69632.0,0.0,2496.0,0.0,264192.0,8192.0,2.816,672.6719999999998,67584.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8256.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",185,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.08,674.7519999999998,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",186,20548.0,77044.0,0,0,0.0,77044.0,77044.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,3.52,678.2719999999998,21040.0,14908.0,20548.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,264.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),187,25165824.0,50724864.0,0,0,0.0,50724864.0,50724864.0,99456.0,1536.0,0.9847908745247148,3244032.0,196608.0,6.912,685.1839999999999,0.0,393216.0,25165824.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,101376.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",188,0.0,61440.0,0,0,0.0,61440.0,61440.0,0.0,2880.0,0.0,202752.0,24576.0,2.4,687.5839999999998,55296.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6336.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",189,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,2.656,690.2399999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",190,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,2.656,692.8959999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",191,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,2.656,695.5519999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",192,65536.0,2177024.0,0,0,0.0,2177024.0,2177024.0,17024.0,32.0,0.99812382739212,24576.0,8192.0,11.296,706.8479999999997,1646592.0,399360.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,256.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",193,1048576.0,2129920.0,0,0,0.0,2129920.0,2129920.0,9536.0,8832.0,0.519163763066202,1116160.0,8192.0,9.216,716.0639999999997,16384.0,16384.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,34880.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",194,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.144,718.2079999999997,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",195,20548.0,77044.0,0,0,0.0,77044.0,77044.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,3.584,721.7919999999997,21040.0,14908.0,20548.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,264.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),196,33554432.0,67633152.0,0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,8.288,730.0799999999997,0.0,524288.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",197,0.0,81920.0,0,0,0.0,81920.0,81920.0,0.0,3840.0,0.0,270336.0,32768.0,2.752,732.8319999999997,73728.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8448.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",198,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.048,734.8799999999997,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",199,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,2.016,736.8959999999996,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",200,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.048,738.9439999999996,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",201,8192.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.144,741.0879999999996,0.0,0.0,8192.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",202,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.08,743.1679999999997,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",203,48348.0,121272.0,0,0,0.0,121272.0,121272.0,0.0,128.0,0.0,32768.0,32768.0,2.176,745.3439999999997,8192.0,16384.0,48348.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",204,8192.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,2.112,747.4559999999997,0.0,0.0,8192.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",205,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.144,749.5999999999997,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),206,33554432.0,67633152.0,0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,8.224,757.8239999999997,0.0,524288.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",207,0.0,69632.0,0,0,0.0,69632.0,69632.0,0.0,2496.0,0.0,264192.0,8192.0,2.816,760.6399999999998,67584.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8256.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",208,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.112,762.7519999999997,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",209,20548.0,77044.0,0,0,0.0,77044.0,77044.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,3.52,766.2719999999997,21040.0,14908.0,20548.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,264.0
ampere_sgemm_64x32_sliced1x4_tn,210,824180736.0,1659629568.0,0,0,0.0,1659629568.0,1659629568.0,3999168.0,860700.0,0.8228964243473279,104147968.0,767360.0,124.448,890.7199999999997,4829184.0,6438912.0,824180736.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3254624.0,23980.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",211,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,892.4159999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",212,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,64.0,128.0,2.624,895.0399999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",213,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,897.1199999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",214,0.0,201028.0,0,0,0.0,201028.0,201028.0,0.0,3158.0,0.0,804128.0,804128.0,2.912,900.0319999999998,0.0,201028.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25129.0,25129.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",215,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,901.7279999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",216,0.0,0.0,0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813024.0,57152.0,3.936,905.6639999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25407.0,1786.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",217,0.0,0.0,0,0,0.0,0.0,0.0,14800.0,82608.0,0.15193823915900131,5134592.0,0.0,5.664,911.3279999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160456.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",218,0.0,0.0,0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813024.0,56320.0,4.064,915.3919999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25407.0,1760.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",219,0.0,0.0,0,0,0.0,0.0,0.0,14800.0,82608.0,0.15193823915900131,5134592.0,0.0,5.568,920.9599999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160456.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",220,0.0,0.0,0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813024.0,56192.0,4.096,925.0559999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25407.0,1756.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",221,0.0,0.0,0,0,0.0,0.0,0.0,14800.0,83608.0,0.15039427688805787,5134592.0,0.0,5.696,930.7519999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160456.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",222,0.0,0.0,0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813024.0,56256.0,3.68,934.4319999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25407.0,1758.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",223,0.0,0.0,0,0,0.0,0.0,0.0,14800.0,83008.0,0.1513168656960576,5134592.0,128.0,5.696,940.1279999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160456.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",224,0.0,0.0,0,0,0.0,0.0,0.0,0.0,21.0,0.0,6432.0,800.0,2.432,942.5599999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,201.0,25.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",225,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.728,944.2879999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",226,0.0,0.0,0,0,0.0,0.0,0.0,497.0,22.0,0.9576107899807321,800.0,0.0,3.552,947.8399999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",227,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.696,949.5359999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",228,0.0,0.0,0,0,0.0,0.0,0.0,497.0,22.0,0.9576107899807321,800.0,0.0,3.552,953.0879999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",229,0.0,0.0,0,0,0.0,0.0,0.0,56448.0,13020.0,0.8125755743651754,831456.0,8928.0,6.112,959.1999999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25983.0,279.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",230,0.0,0.0,0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,544.0,6.56,965.7599999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,80.0,17.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",231,0.0,0.0,0,0,0.0,0.0,0.0,0.0,18849.0,0.0,814496.0,88000.0,3.776,969.5359999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25453.0,2750.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",232,0.0,0.0,0,0,0.0,0.0,0.0,0.0,4737.0,0.0,1005184.0,0.0,3.712,973.2479999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,31412.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",233,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6283.0,0.0,0.0,1608224.0,2.688,975.9359999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,50257.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",234,0.0,0.0,0,0,0.0,0.0,0.0,98304.0,6283.0,0.9399256121697726,804128.0,0.0,4.352,980.2879999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25129.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",235,0.0,0.0,0,0,0.0,0.0,0.0,156.0,64.0,0.7090909090909091,8192.0,0.0,2.176,982.4639999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",236,0.0,0.0,0,0,0.0,0.0,0.0,78783.0,29380.0,0.7283729186505552,3098432.0,2030944.0,10.368,992.8319999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96826.0,63467.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",237,0.0,0.0,0,0,0.0,0.0,0.0,23142.0,35062.0,0.3976015394130988,3123392.0,2479936.0,8.32,1001.1519999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,97606.0,77498.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",238,0.0,0.0,0,0,0.0,0.0,0.0,23883.0,35816.0,0.4000569523777618,3120960.0,1955456.0,9.12,1010.2719999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,97530.0,61108.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",239,0.0,0.0,0,0,0.0,0.0,0.0,23883.0,35989.0,0.39890098877605557,3099840.0,1955072.0,8.832,1019.1039999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96870.0,61096.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",240,0.0,0.0,0,0,0.0,0.0,0.0,14336.0,6283.0,0.6952810514573937,1608224.0,0.0,4.48,1023.5839999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,50257.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",241,0.0,0.0,0,0,0.0,0.0,0.0,39.0,16.0,0.7090909090909091,2048.0,0.0,2.208,1025.792,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",242,0.0,0.0,0,0,0.0,0.0,0.0,20059.0,18183.0,0.5245280058574342,2090272.0,1396096.0,7.968,1033.76,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,65321.0,43628.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",243,0.0,0.0,0,0,0.0,0.0,0.0,0.0,25132.0,0.0,2427520.0,2412352.0,5.248,1039.008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75860.0,75386.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",244,2814392.0,6655044.0,0,0,0.0,6655044.0,6655044.0,528.0,6704.0,0.07300884955752213,2278784.0,752896.0,23.776,1062.784,825232.0,201028.0,2814392.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,71212.0,23528.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",245,0.0,1024200.0,0,0,0.0,1024200.0,1024200.0,112284.0,12568.0,0.8993368147887099,804480.0,623840.0,72.16,1134.9440000000002,1024200.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25140.0,19495.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",246,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3158.0,0.0,804128.0,200832.0,3.072,1138.016,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25129.0,6276.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",247,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,1.92,1139.9360000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",248,0.0,0.0,0,0,0.0,0.0,0.0,0.0,18849.0,0.0,1809280.0,85664.0,7.712,1147.6480000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,56540.0,2677.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",249,0.0,0.0,0,0,0.0,0.0,0.0,0.0,4737.0,0.0,1005184.0,0.0,3.488,1151.1360000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,31412.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",250,2814392.0,6655044.0,0,0,0.0,6655044.0,6655044.0,528.0,6704.0,0.07300884955752213,2280320.0,752640.0,23.936,1175.0720000000001,825232.0,201028.0,2814392.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,71260.0,23520.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",251,0.0,0.0,0,0,0.0,0.0,0.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,6.272,1181.344,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",252,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.112,1183.4560000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",253,0.0,0.0,0,0,0.0,0.0,0.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,6.144,1189.6000000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",254,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.176,1191.776,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",255,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.112,1193.8880000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",256,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.976,1196.8640000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",257,0.0,220484.0,0,0,0.0,220484.0,220484.0,320.0,1582.0,0.16824395373291273,804256.0,128.0,10.88,1207.7440000000004,220484.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25133.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",258,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,1209.7920000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",259,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,1213.0560000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",260,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,1215.0720000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",261,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.912,1217.9840000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",262,1769472.0,3941000.0,0,0,0.0,3941000.0,3941000.0,0.0,6283.0,0.0,0.0,804128.0,4.0,1221.9840000000004,0.0,402056.0,1769472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,25129.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",263,1005140.0,2010280.0,0,0,0.0,2010280.0,2010280.0,0.0,4737.0,0.0,1608256.0,0.0,4.96,1226.9440000000004,0.0,0.0,1005140.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,50258.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",264,0.0,0.0,0,0,0.0,0.0,0.0,640.0,1582.0,0.28802880288028804,804832.0,128.0,15.808,1242.7520000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25151.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",265,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.016,1244.7680000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",266,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,1246.8160000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",267,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.24,1249.0560000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",268,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,1.984,1251.0400000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",269,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,64.0,128.0,2.56,1253.6000000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",270,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,1255.2960000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",271,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,1256.9920000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",272,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.048,1259.0400000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",273,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,1260.736,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",274,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,32.0,2.336,1263.0720000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",275,0.0,0.0,0,0,0.0,0.0,0.0,0.0,5.0,0.0,32.0,32.0,4.768,1267.8400000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",276,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.016,1269.8560000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",277,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,1271.8720000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",278,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.816,1274.6880000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",279,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.168,1277.8560000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",280,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,1279.9040000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",281,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.176,1282.0800000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",282,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,32.0,3.328,1285.4080000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",283,0.0,0.0,0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,64.0,32.0,2.592,1288.0000000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",284,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.048,1290.0480000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",285,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,2.112,1292.1600000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",286,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,0.0,2.112,1294.2720000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",287,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,2.432,1296.7040000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",288,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,8320.0,8192.0,4.224,1300.9280000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,260.0,256.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",289,0.0,0.0,0,0,0.0,0.0,0.0,0.0,192.0,0.0,2176.0,8192.0,3.584,1304.5120000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,68.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",290,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.048,1306.5600000000004,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",291,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,2.048,1308.6080000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",292,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,1311.9040000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",293,20548.0,77044.0,0,0,0.0,77044.0,77044.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,3.552,1315.4560000000004,21040.0,14908.0,20548.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,264.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),294,25165824.0,50724864.0,0,0,0.0,50724864.0,50724864.0,99456.0,1536.0,0.9847908745247148,3244032.0,196608.0,7.072,1322.5280000000002,0.0,393216.0,25165824.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,101376.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",295,0.0,61440.0,0,0,0.0,61440.0,61440.0,0.0,2880.0,0.0,202752.0,24576.0,2.592,1325.1200000000003,55296.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6336.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",296,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.032,1329.1520000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",297,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.032,1333.1840000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",298,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,2.656,1335.8400000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",299,65536.0,2179072.0,0,0,0.0,2179072.0,2179072.0,17024.0,32.0,0.99812382739212,40960.0,8192.0,11.52,1347.3600000000001,1648640.0,399360.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1280.0,256.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",300,1048576.0,2129920.0,0,0,0.0,2129920.0,2129920.0,9536.0,8832.0,0.519163763066202,1116160.0,8192.0,9.248,1356.6080000000002,16384.0,16384.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,34880.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",301,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.112,1358.7200000000003,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",302,20548.0,77044.0,0,0,0.0,77044.0,77044.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,3.52,1362.2400000000002,21040.0,14908.0,20548.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,264.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),303,33554432.0,67633152.0,0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,8.224,1370.4640000000002,0.0,524288.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",304,0.0,81920.0,0,0,0.0,81920.0,81920.0,0.0,3840.0,0.0,270336.0,32768.0,2.56,1373.0240000000001,73728.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8448.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",305,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.016,1375.0400000000002,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",306,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,1.984,1377.0240000000001,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",307,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.048,1379.0720000000001,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",308,8192.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.144,1381.2160000000001,0.0,0.0,8192.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",309,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.112,1383.3280000000002,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",310,48295.0,121166.0,0,0,0.0,121166.0,121166.0,0.0,128.0,0.0,32768.0,32768.0,2.176,1385.5040000000001,8192.0,16384.0,48295.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",311,8192.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,2.048,1387.5520000000001,0.0,0.0,8192.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",312,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.112,1389.6640000000002,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),313,33554432.0,67633152.0,0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,8.288,1397.9520000000002,0.0,524288.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",314,0.0,69632.0,0,0,0.0,69632.0,69632.0,0.0,2496.0,0.0,264192.0,8192.0,2.88,1400.8320000000003,67584.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8256.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",315,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.08,1402.9120000000003,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",316,20548.0,77044.0,0,0,0.0,77044.0,77044.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,3.52,1406.4320000000002,21040.0,14908.0,20548.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,264.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),317,25165824.0,50724864.0,0,0,0.0,50724864.0,50724864.0,99456.0,1536.0,0.9847908745247148,3244032.0,196608.0,7.072,1413.5040000000001,0.0,393216.0,25165824.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,101376.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",318,0.0,61440.0,0,0,0.0,61440.0,61440.0,0.0,2880.0,0.0,202752.0,24576.0,2.496,1416.0000000000002,55296.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6336.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",319,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.032,1420.0320000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",320,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.064,1424.0960000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",321,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,2.688,1426.7840000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",322,65536.0,2179072.0,0,0,0.0,2179072.0,2179072.0,17024.0,32.0,0.99812382739212,40960.0,8192.0,11.2,1437.9840000000004,1648640.0,399360.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1280.0,256.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",323,1048576.0,2129920.0,0,0,0.0,2129920.0,2129920.0,9536.0,8832.0,0.519163763066202,1116160.0,8192.0,9.024,1447.0080000000003,16384.0,16384.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,34880.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",324,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.048,1449.0560000000003,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",325,20548.0,77044.0,0,0,0.0,77044.0,77044.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,3.552,1452.6080000000002,21040.0,14908.0,20548.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,264.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),326,33554432.0,67633152.0,0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,8.128,1460.736,0.0,524288.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",327,0.0,81920.0,0,0,0.0,81920.0,81920.0,0.0,3840.0,0.0,270336.0,32768.0,2.528,1463.2640000000001,73728.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8448.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",328,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.08,1465.344,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",329,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,2.016,1467.3600000000001,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",330,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.016,1469.3760000000002,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",331,8192.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.208,1471.5840000000003,0.0,0.0,8192.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",332,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.176,1473.7600000000002,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",333,48322.0,121220.0,0,0,0.0,121220.0,121220.0,0.0,128.0,0.0,32768.0,32768.0,2.208,1475.9680000000003,8192.0,16384.0,48322.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",334,8192.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,2.048,1478.0160000000003,0.0,0.0,8192.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",335,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.08,1480.0960000000002,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),336,33554432.0,67633152.0,0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,8.32,1488.4160000000002,0.0,524288.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",337,0.0,69632.0,0,0,0.0,69632.0,69632.0,0.0,2496.0,0.0,264192.0,8192.0,2.88,1491.2960000000003,67584.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8256.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",338,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.016,1493.3120000000004,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",339,20548.0,77044.0,0,0,0.0,77044.0,77044.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,3.52,1496.8320000000003,21040.0,14908.0,20548.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,264.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),340,25165824.0,50724864.0,0,0,0.0,50724864.0,50724864.0,99456.0,1536.0,0.9847908745247148,3244032.0,196608.0,7.104,1503.9360000000004,0.0,393216.0,25165824.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,101376.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",341,0.0,61440.0,0,0,0.0,61440.0,61440.0,0.0,2880.0,0.0,202752.0,24576.0,2.464,1506.4000000000003,55296.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6336.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",342,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.032,1510.4320000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",343,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,3.968,1514.4000000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",344,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,2.656,1517.0560000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",345,65536.0,2179072.0,0,0,0.0,2179072.0,2179072.0,17024.0,32.0,0.99812382739212,40960.0,8192.0,11.36,1528.4160000000002,1648640.0,399360.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1280.0,256.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",346,1048576.0,2129920.0,0,0,0.0,2129920.0,2129920.0,9536.0,8832.0,0.519163763066202,1116160.0,8192.0,8.864,1537.2800000000002,16384.0,16384.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,34880.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",347,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.08,1539.3600000000001,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",348,20548.0,77044.0,0,0,0.0,77044.0,77044.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,3.456,1542.816,21040.0,14908.0,20548.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,264.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),349,33554432.0,67633152.0,0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,8.096,1550.912,0.0,524288.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",350,0.0,81920.0,0,0,0.0,81920.0,81920.0,0.0,3840.0,0.0,270336.0,32768.0,2.528,1553.44,73728.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8448.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",351,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.208,1555.6480000000001,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",352,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,2.048,1557.6960000000001,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",353,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.112,1559.8080000000002,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",354,8192.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.112,1561.9200000000003,0.0,0.0,8192.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",355,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.112,1564.0320000000004,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",356,48221.0,121018.0,0,0,0.0,121018.0,121018.0,0.0,128.0,0.0,32768.0,32768.0,2.176,1566.2080000000003,8192.0,16384.0,48221.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",357,8192.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,2.08,1568.2880000000002,0.0,0.0,8192.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",358,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.144,1570.4320000000002,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),359,33554432.0,67633152.0,0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,8.192,1578.6240000000003,0.0,524288.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",360,0.0,69632.0,0,0,0.0,69632.0,69632.0,0.0,2496.0,0.0,264192.0,8192.0,2.88,1581.5040000000004,67584.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8256.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",361,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.08,1583.5840000000003,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",362,20548.0,77044.0,0,0,0.0,77044.0,77044.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,3.488,1587.0720000000003,21040.0,14908.0,20548.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,264.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),363,25165824.0,50724864.0,0,0,0.0,50724864.0,50724864.0,99456.0,1536.0,0.9847908745247148,3244032.0,196608.0,7.168,1594.2400000000002,0.0,393216.0,25165824.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,101376.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",364,0.0,61440.0,0,0,0.0,61440.0,61440.0,0.0,2880.0,0.0,202752.0,24576.0,2.464,1596.7040000000002,55296.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6336.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",365,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.096,1600.8000000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",366,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.0,1604.8000000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",367,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,2.624,1607.4240000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",368,65536.0,2179072.0,0,0,0.0,2179072.0,2179072.0,17024.0,32.0,0.99812382739212,40960.0,8192.0,11.456,1618.88,1648640.0,399360.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1280.0,256.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",369,1048576.0,2129920.0,0,0,0.0,2129920.0,2129920.0,9536.0,8832.0,0.519163763066202,1116160.0,8192.0,8.768,1627.6480000000001,16384.0,16384.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,34880.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",370,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.048,1629.6960000000001,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",371,20548.0,77044.0,0,0,0.0,77044.0,77044.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,3.488,1633.1840000000002,21040.0,14908.0,20548.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,264.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),372,33554432.0,67633152.0,0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,8.224,1641.4080000000001,0.0,524288.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",373,0.0,81920.0,0,0,0.0,81920.0,81920.0,0.0,3840.0,0.0,270336.0,32768.0,2.688,1644.0960000000002,73728.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8448.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",374,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.048,1646.1440000000002,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",375,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,2.08,1648.2240000000002,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",376,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.048,1650.2720000000002,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",377,8192.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.112,1652.3840000000002,0.0,0.0,8192.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",378,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.176,1654.5600000000002,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",379,48307.0,121190.0,0,0,0.0,121190.0,121190.0,0.0,128.0,0.0,32768.0,32768.0,2.144,1656.7040000000002,8192.0,16384.0,48307.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",380,8192.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,2.048,1658.7520000000002,0.0,0.0,8192.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",381,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.176,1660.928,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),382,33554432.0,67633152.0,0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,8.256,1669.1840000000002,0.0,524288.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",383,0.0,69632.0,0,0,0.0,69632.0,69632.0,0.0,2496.0,0.0,264192.0,8192.0,2.816,1672.0000000000002,67584.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8256.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",384,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.08,1674.0800000000002,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",385,20548.0,77044.0,0,0,0.0,77044.0,77044.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,3.552,1677.632,21040.0,14908.0,20548.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,264.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),386,25165824.0,50724864.0,0,0,0.0,50724864.0,50724864.0,99456.0,1536.0,0.9847908745247148,3244032.0,196608.0,7.136,1684.768,0.0,393216.0,25165824.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,101376.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",387,0.0,61440.0,0,0,0.0,61440.0,61440.0,0.0,2880.0,0.0,202752.0,24576.0,2.56,1687.328,55296.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6336.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",388,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.0,1691.328,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",389,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.032,1695.36,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",390,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,2.656,1698.0159999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",391,65536.0,2179072.0,0,0,0.0,2179072.0,2179072.0,17024.0,32.0,0.99812382739212,40960.0,8192.0,11.36,1709.3759999999997,1648640.0,399360.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1280.0,256.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",392,1048576.0,2129920.0,0,0,0.0,2129920.0,2129920.0,9536.0,8832.0,0.519163763066202,1116160.0,8192.0,9.152,1718.5279999999998,16384.0,16384.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,34880.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",393,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.112,1720.6399999999999,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",394,20548.0,77044.0,0,0,0.0,77044.0,77044.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,3.456,1724.0959999999998,21040.0,14908.0,20548.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,264.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),395,33554432.0,67633152.0,0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,8.256,1732.3519999999999,0.0,524288.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",396,0.0,81920.0,0,0,0.0,81920.0,81920.0,0.0,3840.0,0.0,270336.0,32768.0,2.528,1734.8799999999999,73728.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8448.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",397,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.08,1736.9599999999998,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",398,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,2.08,1739.0399999999997,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",399,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.048,1741.0879999999997,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",400,8192.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.144,1743.2319999999997,0.0,0.0,8192.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",401,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.08,1745.3119999999997,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",402,48209.0,120994.0,0,0,0.0,120994.0,120994.0,0.0,128.0,0.0,32768.0,32768.0,2.112,1747.4239999999998,8192.0,16384.0,48209.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",403,8192.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,2.048,1749.4719999999998,0.0,0.0,8192.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",404,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.144,1751.6159999999998,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),405,33554432.0,67633152.0,0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,8.256,1759.8719999999998,0.0,524288.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",406,0.0,69632.0,0,0,0.0,69632.0,69632.0,0.0,2496.0,0.0,264192.0,8192.0,2.944,1762.8159999999998,67584.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8256.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",407,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.08,1764.8959999999997,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",408,20548.0,77044.0,0,0,0.0,77044.0,77044.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,3.52,1768.4159999999997,21040.0,14908.0,20548.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,264.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),409,25165824.0,50724864.0,0,0,0.0,50724864.0,50724864.0,99456.0,1536.0,0.9847908745247148,3244032.0,196608.0,7.104,1775.5199999999998,0.0,393216.0,25165824.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,101376.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",410,0.0,61440.0,0,0,0.0,61440.0,61440.0,0.0,2880.0,0.0,202752.0,24576.0,2.432,1777.9519999999998,55296.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6336.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",411,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.032,1781.9839999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",412,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.096,1786.0799999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",413,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,2.72,1788.7999999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",414,65536.0,2179072.0,0,0,0.0,2179072.0,2179072.0,17024.0,32.0,0.99812382739212,40960.0,8192.0,11.232,1800.0319999999997,1648640.0,399360.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1280.0,256.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",415,1048576.0,2129920.0,0,0,0.0,2129920.0,2129920.0,9536.0,8832.0,0.519163763066202,1116160.0,8192.0,9.088,1809.1199999999997,16384.0,16384.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,34880.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",416,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.112,1811.2319999999997,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",417,20548.0,77044.0,0,0,0.0,77044.0,77044.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,3.552,1814.7839999999997,21040.0,14908.0,20548.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,264.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),418,33554432.0,67633152.0,0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,8.288,1823.0719999999997,0.0,524288.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",419,0.0,81920.0,0,0,0.0,81920.0,81920.0,0.0,3840.0,0.0,270336.0,32768.0,2.56,1825.6319999999996,73728.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8448.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",420,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.048,1827.6799999999996,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",421,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,2.08,1829.7599999999995,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",422,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.176,1831.9359999999995,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",423,8192.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.08,1834.0159999999994,0.0,0.0,8192.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",424,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.048,1836.0639999999994,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",425,48297.0,121170.0,0,0,0.0,121170.0,121170.0,0.0,128.0,0.0,32768.0,32768.0,2.144,1838.2079999999994,8192.0,16384.0,48297.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",426,8192.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,1.984,1840.1919999999993,0.0,0.0,8192.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",427,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.112,1842.3039999999994,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),428,33554432.0,67633152.0,0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,8.384,1850.6879999999994,0.0,524288.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",429,0.0,69632.0,0,0,0.0,69632.0,69632.0,0.0,2496.0,0.0,264192.0,8192.0,2.88,1853.5679999999995,67584.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8256.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",430,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.08,1855.6479999999995,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",431,20548.0,77044.0,0,0,0.0,77044.0,77044.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,3.552,1859.1999999999994,21040.0,14908.0,20548.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,264.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),432,25165824.0,50724864.0,0,0,0.0,50724864.0,50724864.0,99456.0,1536.0,0.9847908745247148,3244032.0,196608.0,7.2,1866.3999999999994,0.0,393216.0,25165824.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,101376.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",433,0.0,61440.0,0,0,0.0,61440.0,61440.0,0.0,2880.0,0.0,202752.0,24576.0,2.432,1868.8319999999994,55296.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6336.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",434,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.032,1872.8639999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",435,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.064,1876.9279999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",436,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,2.656,1879.5839999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",437,65536.0,2179072.0,0,0,0.0,2179072.0,2179072.0,17024.0,32.0,0.99812382739212,40960.0,8192.0,11.36,1890.9439999999993,1648640.0,399360.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1280.0,256.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",438,1048576.0,2129920.0,0,0,0.0,2129920.0,2129920.0,9536.0,8832.0,0.519163763066202,1116160.0,8192.0,9.056,1899.9999999999993,16384.0,16384.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,34880.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",439,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.24,1902.2399999999993,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",440,20548.0,77044.0,0,0,0.0,77044.0,77044.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,3.488,1905.7279999999994,21040.0,14908.0,20548.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,264.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),441,33554432.0,67633152.0,0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,8.192,1913.9199999999994,0.0,524288.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",442,0.0,81920.0,0,0,0.0,81920.0,81920.0,0.0,3840.0,0.0,270336.0,32768.0,2.688,1916.6079999999995,73728.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8448.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",443,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.016,1918.6239999999996,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",444,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,2.048,1920.6719999999996,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",445,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.112,1922.7839999999997,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",446,8192.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.112,1924.8959999999997,0.0,0.0,8192.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",447,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.048,1926.9439999999997,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",448,48275.0,121126.0,0,0,0.0,121126.0,121126.0,0.0,128.0,0.0,32768.0,32768.0,2.176,1929.1199999999997,8192.0,16384.0,48275.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",449,8192.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,2.048,1931.1679999999997,0.0,0.0,8192.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",450,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.048,1933.2159999999997,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),451,33554432.0,67633152.0,0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,8.192,1941.4079999999997,0.0,524288.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",452,0.0,69632.0,0,0,0.0,69632.0,69632.0,0.0,2496.0,0.0,264192.0,8192.0,2.848,1944.2559999999996,67584.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8256.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",453,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.144,1946.3999999999996,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",454,20548.0,77044.0,0,0,0.0,77044.0,77044.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,3.52,1949.9199999999996,21040.0,14908.0,20548.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,264.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),455,25165824.0,50724864.0,0,0,0.0,50724864.0,50724864.0,99456.0,1536.0,0.9847908745247148,3244032.0,196608.0,7.072,1956.9919999999995,0.0,393216.0,25165824.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,101376.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",456,0.0,61440.0,0,0,0.0,61440.0,61440.0,0.0,2880.0,0.0,202752.0,24576.0,2.56,1959.5519999999995,55296.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6336.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",457,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.0,1963.5519999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",458,0.0,0.0,0,0,0.0,0.0,0.0,0.0,256.0,0.0,16384.0,16384.0,4.032,1967.5839999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",459,0.0,0.0,0,0,0.0,0.0,0.0,0.0,128.0,0.0,8192.0,8192.0,2.688,1970.2719999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,256.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",460,65536.0,2179072.0,0,0,0.0,2179072.0,2179072.0,17024.0,32.0,0.99812382739212,40960.0,8192.0,11.296,1981.5679999999995,1648640.0,399360.0,65536.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1280.0,256.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",461,1048576.0,2129920.0,0,0,0.0,2129920.0,2129920.0,9536.0,8832.0,0.519163763066202,1116160.0,8192.0,9.216,1990.7839999999994,16384.0,16384.0,1048576.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,34880.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",462,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.112,1992.8959999999995,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",463,20548.0,77044.0,0,0,0.0,77044.0,77044.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,3.552,1996.4479999999994,21040.0,14908.0,20548.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,264.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),464,33554432.0,67633152.0,0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,8.192,2004.6399999999994,0.0,524288.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",465,0.0,81920.0,0,0,0.0,81920.0,81920.0,0.0,3840.0,0.0,270336.0,32768.0,2.528,2007.1679999999994,73728.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8448.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",466,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.016,2009.1839999999995,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",467,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,2.176,2011.3599999999994,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",468,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.048,2013.4079999999994,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",469,8192.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.144,2015.5519999999995,0.0,0.0,8192.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",470,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.016,2017.5679999999995,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",471,48287.0,121150.0,0,0,0.0,121150.0,121150.0,0.0,128.0,0.0,32768.0,32768.0,2.144,2019.7119999999995,8192.0,16384.0,48287.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",472,8192.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,2.112,2021.8239999999996,0.0,0.0,8192.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",473,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.08,2023.9039999999995,0.0,8192.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),474,33554432.0,67633152.0,0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,8.224,2032.1279999999995,0.0,524288.0,33554432.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",475,0.0,69632.0,0,0,0.0,69632.0,69632.0,0.0,2496.0,0.0,264192.0,8192.0,2.816,2034.9439999999995,67584.0,2048.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,8256.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",476,2048.0,4096.0,0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.048,2036.9919999999995,0.0,0.0,2048.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",477,20548.0,77044.0,0,0,0.0,77044.0,77044.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,3.552,2040.5439999999994,21040.0,14908.0,20548.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,264.0
ampere_sgemm_64x32_sliced1x4_tn,478,824180736.0,1659629568.0,0,0,0.0,1659629568.0,1659629568.0,3999168.0,860700.0,0.8228964243473279,104148736.0,763872.0,124.032,2164.5759999999996,4829184.0,6438912.0,824180736.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3254648.0,23871.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",479,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.664,2166.24,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",480,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,96.0,160.0,2.656,2168.8959999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",481,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2170.912,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",482,0.0,201028.0,0,0,0.0,201028.0,201028.0,0.0,3158.0,0.0,804128.0,804128.0,2.976,2173.888,0.0,201028.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25129.0,25129.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",483,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,2175.584,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",484,0.0,0.0,0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813024.0,57984.0,3.776,2179.3599999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25407.0,1812.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",485,0.0,0.0,0,0,0.0,0.0,0.0,14800.0,82608.0,0.15193823915900131,5134592.0,0.0,5.824,2185.1839999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160456.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",486,0.0,0.0,0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813024.0,57472.0,3.936,2189.12,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25407.0,1796.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",487,0.0,0.0,0,0,0.0,0.0,0.0,14800.0,82508.0,0.1520943807292309,5134592.0,0.0,5.696,2194.816,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160456.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",488,0.0,0.0,0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813024.0,58048.0,3.712,2198.528,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25407.0,1814.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",489,0.0,0.0,0,0,0.0,0.0,0.0,14800.0,83108.0,0.15116231564325694,5134592.0,0.0,5.728,2204.256,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160456.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",490,0.0,0.0,0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813024.0,57856.0,3.808,2208.064,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25407.0,1808.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",491,0.0,0.0,0,0,0.0,0.0,0.0,14800.0,83208.0,0.1510080809729818,5134592.0,128.0,5.728,2213.792,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160456.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",492,0.0,0.0,0,0,0.0,0.0,0.0,0.0,21.0,0.0,6432.0,800.0,2.496,2216.288,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,201.0,25.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",493,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.696,2217.984,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",494,0.0,0.0,0,0,0.0,0.0,0.0,497.0,22.0,0.9576107899807321,800.0,0.0,3.616,2221.6,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",495,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.696,2223.296,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",496,0.0,0.0,0,0,0.0,0.0,0.0,497.0,22.0,0.9576107899807321,800.0,0.0,3.648,2226.944,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",497,0.0,0.0,0,0,0.0,0.0,0.0,56928.0,13012.0,0.813954818415785,831456.0,8640.0,5.984,2232.928,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25983.0,270.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",498,0.0,0.0,0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,544.0,6.592,2239.52,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,80.0,17.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",499,0.0,0.0,0,0,0.0,0.0,0.0,0.0,18849.0,0.0,814496.0,85920.0,3.744,2243.264,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25453.0,2685.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",500,0.0,0.0,0,0,0.0,0.0,0.0,0.0,4737.0,0.0,1005184.0,0.0,3.392,2246.656,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,31412.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",501,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6283.0,0.0,0.0,1608224.0,2.688,2249.344,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,50257.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",502,0.0,0.0,0,0,0.0,0.0,0.0,98304.0,6283.0,0.9399256121697726,804128.0,0.0,4.256,2253.6,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25129.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",503,0.0,0.0,0,0,0.0,0.0,0.0,156.0,64.0,0.7090909090909091,8192.0,0.0,2.144,2255.7439999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",504,0.0,0.0,0,0,0.0,0.0,0.0,78783.0,28917.0,0.7315041782729805,3114944.0,2036256.0,10.656,2266.3999999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,97342.0,63633.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",505,0.0,0.0,0,0,0.0,0.0,0.0,24042.0,35172.0,0.40601884689431555,3111232.0,1748160.0,8.864,2275.2639999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,97226.0,54630.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",506,0.0,0.0,0,0,0.0,0.0,0.0,23883.0,36344.0,0.3965497202251482,3124672.0,1555936.0,9.152,2284.4159999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,97646.0,48623.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",507,0.0,0.0,0,0,0.0,0.0,0.0,23883.0,35665.0,0.40107140458117824,3110848.0,1963136.0,9.312,2293.7279999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,97214.0,61348.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",508,0.0,0.0,0,0,0.0,0.0,0.0,14336.0,6283.0,0.6952810514573937,1608224.0,0.0,4.512,2298.24,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,50257.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",509,0.0,0.0,0,0,0.0,0.0,0.0,39.0,16.0,0.7090909090909091,2048.0,0.0,2.24,2300.4799999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",510,0.0,0.0,0,0,0.0,0.0,0.0,20059.0,17828.0,0.5294428167973183,2115104.0,1385984.0,8.128,2308.6079999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,66097.0,43312.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",511,0.0,0.0,0,0,0.0,0.0,0.0,0.0,25132.0,0.0,2427872.0,2412352.0,5.28,2313.888,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,75871.0,75386.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",512,2814392.0,6655044.0,0,0,0.0,6655044.0,6655044.0,528.0,6704.0,0.07300884955752213,2277248.0,753344.0,23.712,2337.6,825232.0,201028.0,2814392.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,71164.0,23542.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",513,0.0,1024200.0,0,0,0.0,1024200.0,1024200.0,112284.0,12568.0,0.8993368147887099,804608.0,623456.0,72.064,2409.6639999999998,1024200.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25144.0,19483.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",514,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3158.0,0.0,804128.0,200800.0,3.104,2412.7679999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25129.0,6275.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",515,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,1.92,2414.6879999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",516,0.0,0.0,0,0,0.0,0.0,0.0,0.0,18849.0,0.0,1809280.0,85888.0,7.808,2422.4959999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,56540.0,2684.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",517,0.0,0.0,0,0,0.0,0.0,0.0,0.0,4737.0,0.0,1005184.0,0.0,3.328,2425.8239999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,31412.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",518,2814392.0,6655044.0,0,0,0.0,6655044.0,6655044.0,528.0,6704.0,0.07300884955752213,2280576.0,753472.0,23.84,2449.6639999999998,825232.0,201028.0,2814392.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,71268.0,23546.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",519,0.0,0.0,0,0,0.0,0.0,0.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,6.144,2455.8079999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",520,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.208,2458.0159999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",521,0.0,0.0,0,0,0.0,0.0,0.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,5.92,2463.9359999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",522,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.176,2466.1119999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",523,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.112,2468.2239999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",524,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.976,2471.2,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",525,0.0,220484.0,0,0,0.0,220484.0,220484.0,320.0,1582.0,0.16824395373291273,804256.0,128.0,10.976,2482.176,220484.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25133.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",526,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2484.192,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",527,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,2487.424,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",528,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2489.44,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",529,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.976,2492.416,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",530,1769472.0,3941000.0,0,0,0.0,3941000.0,3941000.0,0.0,6283.0,0.0,0.0,804128.0,4.0,2496.416,0.0,402056.0,1769472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,25129.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",531,1005140.0,2010280.0,0,0,0.0,2010280.0,2010280.0,0.0,4737.0,0.0,1608256.0,0.0,4.96,2501.376,0.0,0.0,1005140.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,50258.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",532,0.0,0.0,0,0,0.0,0.0,0.0,640.0,1582.0,0.28802880288028804,804480.0,128.0,16.16,2517.536,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,25140.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",533,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.08,2519.616,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",534,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2521.632,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",535,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.24,2523.872,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",536,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.048,2525.9199999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",537,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,96.0,160.0,2.656,2528.5759999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",538,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,2530.3039999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",539,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,2531.9999999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",540,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.08,2534.0799999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",541,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,2535.8079999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",542,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,128.0,32.0,2.304,2538.1119999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",543,0.0,0.0,0,0,0.0,0.0,0.0,0.0,5.0,0.0,32.0,32.0,4.8,2542.912,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",544,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.08,2544.9919999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",545,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,2547.0719999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",546,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.784,2549.8559999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",547,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,2553.1839999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",548,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,2555.2639999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
