Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.824,1.824,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,3.52,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.664,5.184,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.016,7.2,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.24,9.440000000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",6,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.304,11.744000000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",7,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.488,15.232000000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",8,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,18.528000000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",9,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,20.672000000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",10,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.664,22.336000000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",11,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,24.032000000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.632,25.66400000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,0.0,0.0,0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,2.464,28.128000000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,30.17600000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",15,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.112,32.28800000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",16,0.0,0.0,0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,32.0,32.0,2.464,34.75200000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",17,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,36.73600000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",18,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,38.75200000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",19,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,2.048,40.80000000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",20,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,17408.0,65536.0,3.808,44.60800000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,544.0,2048.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",21,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.464,47.07200000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",22,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,50.40000000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",23,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.496,52.896000000000015,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",24,0.0,512.0,0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,1.984,54.88000000000002,0.0,512.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",25,0.0,0.0,0,0,0.0,0.0,0.0,0.0,20.0,0.0,2048.0,2048.0,2.528,57.408000000000015,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",26,4096.0,9216.0,0,0,0.0,9216.0,9216.0,0.0,32.0,0.0,2048.0,2048.0,2.912,60.320000000000014,0.0,1024.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",27,0.0,512.0,0,0,0.0,512.0,512.0,0.0,32.0,0.0,2048.0,2048.0,2.016,62.33600000000001,0.0,512.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",28,3584.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,32.0,0.0,2048.0,2048.0,2.976,65.31200000000001,0.0,1024.0,3584.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",29,0.0,512.0,0,0,0.0,512.0,512.0,0.0,32.0,0.0,2048.0,2048.0,2.048,67.36000000000001,0.0,512.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",30,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.016,69.37600000000002,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",31,0.0,20868.0,0,0,0.0,20868.0,20868.0,40.0,132.0,0.23255813953488372,65536.0,32.0,5.696,75.07200000000002,20864.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",32,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.888,76.96000000000002,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",33,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,78.94400000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",34,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,67584.0,65536.0,2.624,81.56800000000001,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",35,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,131072.0,65536.0,2.624,84.19200000000001,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,36,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73240832.0,196608.0,85.376,169.568,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2288776.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",37,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.432,172.0,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,38,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73259104.0,196608.0,84.416,256.416,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2289347.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",39,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.432,258.848,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,40,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73233632.0,196608.0,86.336,345.184,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2288551.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",41,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.496,347.68,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",42,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.752,350.432,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",43,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,512.0,0.0,32768.0,32768.0,2.592,353.024,8192.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",44,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,4.032,357.056,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",45,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.688,359.74399999999997,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",46,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.08,361.82399999999996,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",47,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.688,364.51199999999994,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",48,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,512.0,0.0,32768.0,32768.0,2.624,367.13599999999997,8192.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",49,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,3.968,371.104,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",50,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.784,373.888,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",51,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.176,376.06399999999996,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",52,262144.0,23535616.0,0,0,0.0,23535616.0,23535616.0,133120.0,256.0,0.9980806142034548,196608.0,65536.0,20.48,396.544,19841024.0,3170304.0,262144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,53,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73250304.0,196608.0,85.408,481.952,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2289072.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",54,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.464,484.416,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",55,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.144,486.56,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",56,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,1.984,488.544,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",57,0.0,20868.0,0,0,0.0,20868.0,20868.0,40.0,132.0,0.23255813953488372,65536.0,32.0,5.6,494.144,20864.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",58,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,496.064,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",59,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,498.08000000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",60,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,67584.0,65536.0,2.752,500.83200000000005,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",61,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,131072.0,65536.0,2.688,503.52000000000004,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",62,180355072.0,395231232.0,0,0,0.0,395231232.0,395231232.0,2383232.0,2135552.0,0.5274056029232643,241970176.0,262976.0,196.864,700.384,11976704.0,22544384.0,180355072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7561568.0,8218.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",63,506368.0,1056768.0,0,0,0.0,1056768.0,1056768.0,0.0,688.0,0.0,176128.0,176128.0,2.56,702.944,44032.0,0.0,506368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5504.0,5504.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",64,180355072.0,395231232.0,0,0,0.0,395231232.0,395231232.0,2383232.0,2135552.0,0.5274056029232643,243676288.0,269600.0,195.648,898.592,11976704.0,22544384.0,180355072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7614884.0,8425.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",65,0.0,44032.0,0,0,0.0,44032.0,44032.0,0.0,1032.0,0.0,352256.0,176128.0,2.528,901.12,0.0,44032.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,11008.0,5504.0
ampere_sgemm_64x32_sliced1x4_tn,66,1447034880.0,2896822272.0,0,0,0.0,2896822272.0,2896822272.0,6451200.0,1502976.0,0.8110456695954427,198373152.0,196608.0,222.272,1123.392,1179648.0,1572864.0,1447034880.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6199161.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",67,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.464,1125.856,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",68,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.144,1128.0,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",69,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.048,1130.048,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",70,0.0,20868.0,0,0,0.0,20868.0,20868.0,40.0,132.0,0.23255813953488372,65536.0,32.0,5.632,1135.68,20864.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",71,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,1137.632,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",72,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,1139.616,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",73,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,67584.0,65536.0,2.688,1142.304,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",74,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,131072.0,65536.0,2.624,1144.928,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,75,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73222272.0,196608.0,85.312,1230.24,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2288196.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",76,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.496,1232.736,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,77,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73258144.0,196608.0,84.96,1317.6960000000001,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2289317.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",78,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.432,1320.1280000000002,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,79,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73232096.0,196608.0,85.376,1405.5040000000001,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2288503.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",80,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.464,1407.968,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",81,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.688,1410.6560000000002,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",82,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,512.0,0.0,32768.0,32768.0,2.624,1413.2800000000002,8192.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",83,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,4.0,1417.2800000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",84,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.816,1420.0960000000002,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",85,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.176,1422.2720000000002,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",86,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.656,1424.928,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",87,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,512.0,0.0,32768.0,32768.0,2.592,1427.5200000000002,8192.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",88,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,3.968,1431.4880000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",89,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.72,1434.2080000000003,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",90,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.08,1436.2880000000002,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",91,262144.0,23535616.0,0,0,0.0,23535616.0,23535616.0,133120.0,256.0,0.9980806142034548,196608.0,65536.0,20.48,1456.7680000000003,19841024.0,3170304.0,262144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,92,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73220000.0,196608.0,85.6,1542.3680000000002,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2288125.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",93,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.432,1544.8000000000002,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",94,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.208,1547.0080000000003,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",95,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.176,1549.1840000000002,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",96,0.0,20868.0,0,0,0.0,20868.0,20868.0,40.0,132.0,0.23255813953488372,65536.0,32.0,5.664,1554.8480000000002,20864.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",97,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,1556.7680000000003,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",98,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,1558.7520000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",99,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,67584.0,65536.0,2.656,1561.4080000000001,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",100,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,131072.0,65536.0,2.752,1564.16,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",101,180355072.0,395231232.0,0,0,0.0,395231232.0,395231232.0,2383232.0,2135552.0,0.5274056029232643,243340544.0,264896.0,197.728,1761.8880000000001,11976704.0,22544384.0,180355072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7604392.0,8278.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",102,506368.0,1056768.0,0,0,0.0,1056768.0,1056768.0,0.0,688.0,0.0,176128.0,176128.0,2.368,1764.256,44032.0,0.0,506368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5504.0,5504.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",103,180355072.0,395231232.0,0,0,0.0,395231232.0,395231232.0,2383232.0,2135552.0,0.5274056029232643,241956352.0,261760.0,198.496,1962.7520000000002,11976704.0,22544384.0,180355072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7561136.0,8180.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",104,0.0,44032.0,0,0,0.0,44032.0,44032.0,0.0,1032.0,0.0,352256.0,176128.0,2.336,1965.0880000000002,0.0,44032.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,11008.0,5504.0
ampere_sgemm_64x32_sliced1x4_tn,105,1447034880.0,2896822272.0,0,0,0.0,2896822272.0,2896822272.0,6451200.0,1502976.0,0.8110456695954427,198357856.0,196608.0,222.112,2187.2000000000003,1179648.0,1572864.0,1447034880.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6198683.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",106,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.464,2189.664,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",107,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.176,2191.84,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",108,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.08,2193.92,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",109,0.0,20868.0,0,0,0.0,20868.0,20868.0,40.0,132.0,0.23255813953488372,65536.0,32.0,5.856,2199.7760000000003,20864.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",110,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,2201.6960000000004,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",111,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,2203.6800000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",112,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,67584.0,65536.0,2.624,2206.304,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",113,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,131072.0,65536.0,2.752,2209.056,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,114,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73208000.0,196608.0,85.568,2294.6240000000003,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2287750.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",115,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.464,2297.088,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,116,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73275552.0,196608.0,84.48,2381.568,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2289861.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",117,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.464,2384.032,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,118,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73215648.0,196608.0,84.768,2468.8,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2287989.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",119,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.592,2471.3920000000003,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",120,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.752,2474.1440000000002,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",121,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,512.0,0.0,32768.0,32768.0,2.624,2476.768,8192.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",122,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,3.936,2480.704,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",123,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.688,2483.3920000000003,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",124,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.176,2485.568,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",125,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.656,2488.224,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",126,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,512.0,0.0,32768.0,32768.0,2.592,2490.8160000000003,8192.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",127,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,4.0,2494.8160000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",128,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.784,2497.6000000000004,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",129,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.144,2499.744,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",130,262144.0,23535616.0,0,0,0.0,23535616.0,23535616.0,133120.0,256.0,0.9980806142034548,196608.0,65536.0,20.544,2520.288,19841024.0,3170304.0,262144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,131,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73263296.0,196608.0,85.76,2606.0480000000002,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2289478.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",132,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.464,2608.512,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",133,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.144,2610.656,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",134,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.016,2612.672,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",135,0.0,20868.0,0,0,0.0,20868.0,20868.0,40.0,132.0,0.23255813953488372,65536.0,32.0,5.632,2618.304,20864.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",136,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.888,2620.192,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",137,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,2622.176,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",138,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,67584.0,65536.0,2.656,2624.832,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",139,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,131072.0,65536.0,2.72,2627.5519999999997,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",140,180355072.0,395231232.0,0,0,0.0,395231232.0,395231232.0,2383232.0,2135552.0,0.5274056029232643,243790592.0,266720.0,197.824,2825.3759999999997,11976704.0,22544384.0,180355072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7618456.0,8335.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",141,506368.0,1056768.0,0,0,0.0,1056768.0,1056768.0,0.0,688.0,0.0,176128.0,176128.0,2.432,2827.8079999999995,44032.0,0.0,506368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5504.0,5504.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",142,180355072.0,395231232.0,0,0,0.0,395231232.0,395231232.0,2383232.0,2135552.0,0.5274056029232643,241797888.0,259520.0,196.416,3024.2239999999997,11976704.0,22544384.0,180355072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7556184.0,8110.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",143,0.0,44032.0,0,0,0.0,44032.0,44032.0,0.0,1032.0,0.0,352256.0,176128.0,2.304,3026.528,0.0,44032.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,11008.0,5504.0
ampere_sgemm_64x32_sliced1x4_tn,144,1447034880.0,2896822272.0,0,0,0.0,2896822272.0,2896822272.0,6451200.0,1502976.0,0.8110456695954427,198371392.0,196608.0,224.448,3250.9759999999997,1179648.0,1572864.0,1447034880.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6199106.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",145,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.464,3253.4399999999996,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",146,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.112,3255.5519999999997,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",147,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.016,3257.5679999999998,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",148,0.0,20868.0,0,0,0.0,20868.0,20868.0,40.0,132.0,0.23255813953488372,65536.0,32.0,5.696,3263.2639999999997,20864.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",149,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,3265.1839999999997,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",150,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.952,3267.136,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",151,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,67584.0,65536.0,2.688,3269.824,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",152,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,131072.0,65536.0,2.688,3272.512,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,153,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73235808.0,196608.0,84.768,3357.28,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2288619.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",154,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.432,3359.712,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,155,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73194464.0,196608.0,84.32,3444.032,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2287327.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",156,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.496,3446.5280000000002,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,157,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73202080.0,196608.0,85.888,3532.416,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2287565.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",158,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.432,3534.848,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",159,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.72,3537.5679999999998,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",160,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,512.0,0.0,32768.0,32768.0,2.56,3540.1279999999997,8192.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",161,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,3.968,3544.0959999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",162,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.752,3546.8479999999995,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",163,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.08,3548.9279999999994,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",164,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.688,3551.6159999999995,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",165,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,512.0,0.0,32768.0,32768.0,2.592,3554.2079999999996,8192.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",166,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,4.096,3558.3039999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",167,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.688,3560.9919999999997,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",168,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.08,3563.0719999999997,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",169,262144.0,23535616.0,0,0,0.0,23535616.0,23535616.0,133120.0,256.0,0.9980806142034548,196608.0,65536.0,20.512,3583.584,19841024.0,3170304.0,262144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,170,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73211648.0,196608.0,83.616,3667.2,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2287864.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",171,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.464,3669.6639999999998,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",172,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.176,3671.8399999999997,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",173,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.016,3673.8559999999998,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",174,0.0,20868.0,0,0,0.0,20868.0,20868.0,40.0,132.0,0.23255813953488372,65536.0,32.0,5.696,3679.5519999999997,20864.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",175,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,3681.4719999999998,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",176,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.952,3683.424,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",177,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,67584.0,65536.0,2.72,3686.144,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",178,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,131072.0,65536.0,2.624,3688.7679999999996,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",179,180355072.0,395231232.0,0,0,0.0,395231232.0,395231232.0,2383232.0,2135552.0,0.5274056029232643,244535680.0,257216.0,195.488,3884.2559999999994,11976704.0,22544384.0,180355072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7641740.0,8038.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",180,506368.0,1056768.0,0,0,0.0,1056768.0,1056768.0,0.0,688.0,0.0,176128.0,176128.0,2.528,3886.783999999999,44032.0,0.0,506368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5504.0,5504.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",181,180355072.0,395231232.0,0,0,0.0,395231232.0,395231232.0,2383232.0,2135552.0,0.5274056029232643,241718016.0,262304.0,197.472,4084.2559999999994,11976704.0,22544384.0,180355072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7553688.0,8197.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",182,0.0,44032.0,0,0,0.0,44032.0,44032.0,0.0,1032.0,0.0,352256.0,176128.0,2.464,4086.7199999999993,0.0,44032.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,11008.0,5504.0
ampere_sgemm_64x32_sliced1x4_tn,183,1447034880.0,2896822272.0,0,0,0.0,2896822272.0,2896822272.0,6451200.0,1502976.0,0.8110456695954427,198380576.0,196608.0,220.32,4307.039999999999,1179648.0,1572864.0,1447034880.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6199393.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",184,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.432,4309.471999999999,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",185,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.24,4311.711999999999,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",186,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.016,4313.727999999998,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",187,0.0,20868.0,0,0,0.0,20868.0,20868.0,40.0,132.0,0.23255813953488372,65536.0,32.0,5.888,4319.615999999998,20864.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",188,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,4321.567999999998,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",189,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.952,4323.519999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",190,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,67584.0,65536.0,2.624,4326.143999999998,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",191,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,131072.0,65536.0,2.656,4328.799999999998,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,192,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73201984.0,196608.0,85.216,4414.015999999999,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2287562.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",193,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.432,4416.4479999999985,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,194,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73233952.0,196608.0,83.968,4500.415999999998,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2288561.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",195,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.56,4502.975999999999,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,196,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73220928.0,196608.0,85.088,4588.0639999999985,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2288154.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",197,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.464,4590.527999999998,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",198,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.816,4593.343999999998,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",199,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,512.0,0.0,32768.0,32768.0,2.592,4595.935999999998,8192.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",200,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,3.968,4599.903999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",201,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.688,4602.591999999998,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",202,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.112,4604.703999999998,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",203,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.688,4607.391999999998,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",204,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,512.0,0.0,32768.0,32768.0,2.656,4610.047999999998,8192.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",205,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,3.936,4613.983999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",206,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.688,4616.671999999998,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",207,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.112,4618.783999999998,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",208,262144.0,23535616.0,0,0,0.0,23535616.0,23535616.0,133120.0,256.0,0.9980806142034548,196608.0,65536.0,20.512,4639.295999999998,19841024.0,3170304.0,262144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,209,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73226016.0,196608.0,85.696,4724.9919999999975,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2288313.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",210,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.432,4727.423999999997,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",211,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.112,4729.535999999997,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",212,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.048,4731.583999999997,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",213,0.0,20868.0,0,0,0.0,20868.0,20868.0,40.0,132.0,0.23255813953488372,65536.0,32.0,5.792,4737.3759999999975,20864.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",214,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,4739.295999999998,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",215,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,4741.343999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",216,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,67584.0,65536.0,2.656,4743.999999999997,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",217,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,131072.0,65536.0,2.656,4746.655999999997,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",218,180355072.0,395231232.0,0,0,0.0,395231232.0,395231232.0,2383232.0,2135552.0,0.5274056029232643,240883968.0,267264.0,197.152,4943.807999999997,11976704.0,22544384.0,180355072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7527624.0,8352.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",219,506368.0,1056768.0,0,0,0.0,1056768.0,1056768.0,0.0,688.0,0.0,176128.0,176128.0,2.432,4946.239999999997,44032.0,0.0,506368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5504.0,5504.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",220,180355072.0,395231232.0,0,0,0.0,395231232.0,395231232.0,2383232.0,2135552.0,0.5274056029232643,243162752.0,258784.0,198.912,5145.151999999997,11976704.0,22544384.0,180355072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7598836.0,8087.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",221,0.0,44032.0,0,0,0.0,44032.0,44032.0,0.0,1032.0,0.0,352256.0,176128.0,2.464,5147.615999999997,0.0,44032.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,11008.0,5504.0
ampere_sgemm_64x32_sliced1x4_tn,222,1447034880.0,2896822272.0,0,0,0.0,2896822272.0,2896822272.0,6451200.0,1502976.0,0.8110456695954427,198335616.0,196608.0,219.648,5367.263999999997,1179648.0,1572864.0,1447034880.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6197988.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",223,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.432,5369.695999999997,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",224,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.272,5371.967999999997,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",225,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.048,5374.015999999997,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",226,0.0,20868.0,0,0,0.0,20868.0,20868.0,40.0,132.0,0.23255813953488372,65536.0,32.0,5.664,5379.679999999997,20864.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",227,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,5381.599999999997,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",228,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,5383.583999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",229,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,67584.0,65536.0,2.72,5386.303999999997,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",230,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,131072.0,65536.0,2.656,5388.959999999997,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,231,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73233728.0,196608.0,85.184,5474.1439999999975,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2288554.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",232,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.432,5476.575999999997,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,233,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73196704.0,196608.0,83.168,5559.743999999997,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2287397.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",234,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.56,5562.303999999997,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,235,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73244896.0,196608.0,86.048,5648.351999999997,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2288903.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",236,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.496,5650.847999999997,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",237,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.656,5653.503999999997,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",238,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,512.0,0.0,32768.0,32768.0,2.592,5656.095999999997,8192.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",239,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,4.128,5660.2239999999965,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",240,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.656,5662.8799999999965,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",241,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.08,5664.959999999996,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",242,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.688,5667.6479999999965,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",243,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,512.0,0.0,32768.0,32768.0,2.592,5670.239999999996,8192.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",244,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,4.032,5674.271999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",245,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.688,5676.959999999996,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",246,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.112,5679.0719999999965,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",247,262144.0,23535616.0,0,0,0.0,23535616.0,23535616.0,133120.0,256.0,0.9980806142034548,196608.0,65536.0,20.544,5699.615999999996,19841024.0,3170304.0,262144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,248,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73275840.0,196608.0,84.672,5784.287999999996,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2289870.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",249,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.432,5786.719999999996,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",250,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.112,5788.831999999996,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",251,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.016,5790.847999999995,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",252,0.0,20868.0,0,0,0.0,20868.0,20868.0,40.0,132.0,0.23255813953488372,65536.0,32.0,5.664,5796.511999999995,20864.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",253,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,5798.431999999995,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",254,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,5800.415999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",255,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,67584.0,65536.0,2.688,5803.103999999996,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",256,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,131072.0,65536.0,2.624,5805.7279999999955,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",257,180355072.0,395231232.0,0,0,0.0,395231232.0,395231232.0,2383232.0,2135552.0,0.5274056029232643,241321344.0,263744.0,196.288,6002.015999999996,11976704.0,22544384.0,180355072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7541292.0,8242.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",258,506368.0,1056768.0,0,0,0.0,1056768.0,1056768.0,0.0,688.0,0.0,176128.0,176128.0,2.688,6004.703999999996,44032.0,0.0,506368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5504.0,5504.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",259,180355072.0,395231232.0,0,0,0.0,395231232.0,395231232.0,2383232.0,2135552.0,0.5274056029232643,245470592.0,258944.0,197.344,6202.047999999996,11976704.0,22544384.0,180355072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7670956.0,8092.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",260,0.0,44032.0,0,0,0.0,44032.0,44032.0,0.0,1032.0,0.0,352256.0,176128.0,2.56,6204.6079999999965,0.0,44032.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,11008.0,5504.0
ampere_sgemm_64x32_sliced1x4_tn,261,1447034880.0,2896822272.0,0,0,0.0,2896822272.0,2896822272.0,6451200.0,1502976.0,0.8110456695954427,198402912.0,196608.0,224.0,6428.6079999999965,1179648.0,1572864.0,1447034880.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6200091.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",262,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.432,6431.039999999996,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",263,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.112,6433.151999999996,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",264,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.016,6435.167999999996,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",265,0.0,20868.0,0,0,0.0,20868.0,20868.0,40.0,132.0,0.23255813953488372,65536.0,32.0,5.664,6440.831999999996,20864.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",266,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,6442.751999999996,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",267,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,6444.735999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",268,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,67584.0,65536.0,2.688,6447.423999999996,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",269,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,131072.0,65536.0,2.816,6450.239999999996,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,270,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73268128.0,196608.0,85.536,6535.775999999996,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2289629.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",271,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.464,6538.239999999996,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,272,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73223392.0,196608.0,84.096,6622.335999999996,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2288231.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",273,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.464,6624.799999999996,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,274,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73206752.0,196608.0,85.568,6710.367999999996,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2287711.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",275,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.464,6712.831999999996,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",276,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.688,6715.519999999996,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",277,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,512.0,0.0,32768.0,32768.0,2.592,6718.1119999999955,8192.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",278,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,3.936,6722.047999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",279,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.752,6724.799999999996,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",280,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.24,6727.039999999995,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",281,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.656,6729.695999999995,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",282,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,512.0,0.0,32768.0,32768.0,2.56,6732.255999999996,8192.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",283,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,3.968,6736.223999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",284,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.72,6738.943999999996,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",285,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.144,6741.087999999996,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",286,262144.0,23535616.0,0,0,0.0,23535616.0,23535616.0,133120.0,256.0,0.9980806142034548,196608.0,65536.0,20.48,6761.567999999996,19841024.0,3170304.0,262144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,287,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73254624.0,196608.0,85.696,6847.263999999996,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2289207.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",288,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.432,6849.695999999995,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",289,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.112,6851.807999999995,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",290,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.016,6853.823999999995,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",291,0.0,20868.0,0,0,0.0,20868.0,20868.0,40.0,132.0,0.23255813953488372,65536.0,32.0,5.664,6859.487999999995,20864.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",292,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.984,6861.471999999995,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",293,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,6863.455999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",294,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,67584.0,65536.0,2.688,6866.143999999996,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",295,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,131072.0,65536.0,2.688,6868.831999999996,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",296,180355072.0,395231232.0,0,0,0.0,395231232.0,395231232.0,2383232.0,2135552.0,0.5274056029232643,242081152.0,268224.0,196.096,7064.927999999996,11976704.0,22544384.0,180355072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7565036.0,8382.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",297,506368.0,1056768.0,0,0,0.0,1056768.0,1056768.0,0.0,688.0,0.0,176128.0,176128.0,2.368,7067.295999999997,44032.0,0.0,506368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5504.0,5504.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",298,180355072.0,395231232.0,0,0,0.0,395231232.0,395231232.0,2383232.0,2135552.0,0.5274056029232643,243356672.0,263520.0,198.272,7265.567999999997,11976704.0,22544384.0,180355072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7604896.0,8235.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",299,0.0,44032.0,0,0,0.0,44032.0,44032.0,0.0,1032.0,0.0,352256.0,176128.0,2.336,7267.903999999997,0.0,44032.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,11008.0,5504.0
ampere_sgemm_64x32_sliced1x4_tn,300,1447034880.0,2896822272.0,0,0,0.0,2896822272.0,2896822272.0,6451200.0,1502976.0,0.8110456695954427,198336864.0,196608.0,222.592,7490.4959999999965,1179648.0,1572864.0,1447034880.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6198027.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",301,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.496,7492.991999999997,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",302,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.112,7495.103999999997,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",303,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.016,7497.119999999996,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",304,0.0,20868.0,0,0,0.0,20868.0,20868.0,40.0,132.0,0.23255813953488372,65536.0,32.0,5.632,7502.751999999996,20864.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",305,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,7504.671999999996,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",306,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,7506.655999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",307,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,67584.0,65536.0,2.656,7509.311999999996,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",308,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,131072.0,65536.0,2.88,7512.191999999996,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,309,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73206432.0,196608.0,84.608,7596.7999999999965,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2287701.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",310,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.432,7599.231999999996,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,311,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73231680.0,196608.0,84.576,7683.807999999996,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2288490.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",312,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.432,7686.239999999996,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,313,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73200096.0,196608.0,84.512,7770.751999999996,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2287503.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",314,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.432,7773.183999999996,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",315,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.72,7775.903999999996,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",316,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,512.0,0.0,32768.0,32768.0,2.624,7778.527999999996,8192.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",317,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,4.0,7782.527999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",318,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.656,7785.183999999996,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",319,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.08,7787.263999999996,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",320,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.656,7789.9199999999955,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",321,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,512.0,0.0,32768.0,32768.0,2.624,7792.543999999995,8192.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",322,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,4.0,7796.543999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",323,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.688,7799.231999999995,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",324,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.208,7801.439999999995,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",325,262144.0,23535616.0,0,0,0.0,23535616.0,23535616.0,133120.0,256.0,0.9980806142034548,196608.0,65536.0,20.64,7822.079999999995,19841024.0,3170304.0,262144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,326,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73227552.0,196608.0,84.288,7906.367999999995,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2288361.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",327,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.432,7908.799999999995,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",328,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.112,7910.911999999995,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",329,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.048,7912.959999999995,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",330,0.0,20868.0,0,0,0.0,20868.0,20868.0,40.0,132.0,0.23255813953488372,65536.0,32.0,5.696,7918.6559999999945,20864.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",331,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.888,7920.543999999994,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",332,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,7922.591999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",333,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,67584.0,65536.0,2.624,7925.215999999994,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",334,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,131072.0,65536.0,2.656,7927.871999999994,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",335,180355072.0,395231232.0,0,0,0.0,395231232.0,395231232.0,2383232.0,2135552.0,0.5274056029232643,240865792.0,261088.0,196.32,8124.191999999994,11976704.0,22544384.0,180355072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7527056.0,8159.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",336,506368.0,1056768.0,0,0,0.0,1056768.0,1056768.0,0.0,688.0,0.0,176128.0,176128.0,2.528,8126.719999999994,44032.0,0.0,506368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5504.0,5504.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",337,180355072.0,395231232.0,0,0,0.0,395231232.0,395231232.0,2383232.0,2135552.0,0.5274056029232643,244462720.0,266432.0,197.632,8324.351999999993,11976704.0,22544384.0,180355072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7639460.0,8326.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",338,0.0,44032.0,0,0,0.0,44032.0,44032.0,0.0,1032.0,0.0,352256.0,176128.0,2.336,8326.687999999993,0.0,44032.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,11008.0,5504.0
ampere_sgemm_64x32_sliced1x4_tn,339,1447034880.0,2896822272.0,0,0,0.0,2896822272.0,2896822272.0,6451200.0,1502976.0,0.8110456695954427,198367136.0,196608.0,222.432,8549.119999999994,1179648.0,1572864.0,1447034880.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6198973.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",340,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.496,8551.615999999993,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",341,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.112,8553.727999999992,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",342,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.176,8555.903999999991,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",343,0.0,20868.0,0,0,0.0,20868.0,20868.0,40.0,132.0,0.23255813953488372,65536.0,32.0,5.664,8561.567999999992,20864.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",344,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,8563.487999999992,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",345,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,8565.471999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",346,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,67584.0,65536.0,2.624,8568.095999999992,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",347,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,131072.0,65536.0,2.784,8570.879999999992,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,348,4194304000.0,8395776000.0,0,0,0.0,8395776000.0,8395776000.0,18672000.0,4356000.0,0.8108389786347056,550458624.0,512000.0,617.216,9188.095999999992,3072000.0,4096000.0,4194304000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,17201832.0,16000.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",349,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.664,9189.759999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",350,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,64.0,128.0,2.56,9192.319999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",351,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,9194.335999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",352,0.0,128000.0,0,0,0.0,128000.0,128000.0,0.0,2000.0,0.0,512000.0,512000.0,2.528,9196.863999999992,0.0,128000.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,16000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",353,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.664,9198.527999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",354,0.0,0.0,0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,38272.0,3.584,9202.111999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16128.0,1196.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",355,0.0,0.0,0,0,0.0,0.0,0.0,9472.0,34440.0,0.2157041355438149,2109440.0,0.0,4.224,9206.335999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",356,0.0,0.0,0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,37056.0,3.744,9210.079999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16128.0,1158.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",357,0.0,0.0,0,0,0.0,0.0,0.0,9472.0,34696.0,0.2144539032783916,2109440.0,0.0,4.16,9214.239999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",358,0.0,0.0,0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,38144.0,3.616,9217.855999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16128.0,1192.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",359,0.0,0.0,0,0,0.0,0.0,0.0,9472.0,35080.0,0.21260549470281917,2109440.0,0.0,4.192,9222.047999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",360,0.0,0.0,0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,38080.0,3.488,9225.535999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16128.0,1190.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",361,0.0,0.0,0,0,0.0,0.0,0.0,9472.0,34824.0,0.21383420624887123,2109440.0,128.0,4.16,9229.695999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,65920.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",362,0.0,0.0,0,0,0.0,0.0,0.0,0.0,12.0,0.0,4128.0,512.0,2.4,9232.095999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,129.0,16.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",363,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.696,9233.791999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",364,0.0,0.0,0,0,0.0,0.0,0.0,497.0,16.0,0.9688109161793372,512.0,0.0,3.424,9237.215999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",365,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.664,9238.879999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",366,0.0,0.0,0,0,0.0,0.0,0.0,497.0,16.0,0.9688109161793372,512.0,0.0,3.296,9242.175999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",367,0.0,0.0,0,0,0.0,0.0,0.0,27264.0,8432.0,0.7637830569251457,527232.0,7264.0,5.728,9247.903999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16476.0,227.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",368,0.0,0.0,0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,544.0,6.432,9254.335999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,80.0,17.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",369,0.0,0.0,0,0,0.0,0.0,0.0,0.0,12000.0,0.0,520064.0,55136.0,3.648,9257.983999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16252.0,1723.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",370,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3000.0,0.0,640000.0,0.0,2.976,9260.959999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,20000.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",371,0.0,0.0,0,0,0.0,0.0,0.0,0.0,4000.0,0.0,0.0,1024000.0,2.24,9263.199999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,32000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",372,0.0,0.0,0,0,0.0,0.0,0.0,98304.0,4000.0,0.960900844541758,512000.0,0.0,4.096,9267.295999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",373,0.0,0.0,0,0,0.0,0.0,0.0,156.0,64.0,0.7090909090909091,8192.0,0.0,2.144,9269.439999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",374,0.0,0.0,0,0,0.0,0.0,0.0,50958.0,18642.0,0.7321551724137931,1908352.0,1310656.0,9.728,9279.167999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,59636.0,40958.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",375,0.0,0.0,0,0,0.0,0.0,0.0,15054.0,20091.0,0.4283397353819889,1909376.0,1579008.0,7.584,9286.751999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,59668.0,49344.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",376,0.0,0.0,0,0,0.0,0.0,0.0,15858.0,20301.0,0.4385630133576703,1891712.0,1207744.0,8.288,9295.039999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,59116.0,37742.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",377,0.0,0.0,0,0,0.0,0.0,0.0,14958.0,20109.0,0.42655488065702796,1889664.0,1579008.0,8.512,9303.551999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,59052.0,49344.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",378,0.0,0.0,0,0,0.0,0.0,0.0,14336.0,4000.0,0.7818499127399651,1024000.0,0.0,3.904,9307.455999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",379,0.0,0.0,0,0,0.0,0.0,0.0,39.0,16.0,0.7090909090909091,2048.0,0.0,2.176,9309.631999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",380,0.0,0.0,0,0,0.0,0.0,0.0,13650.0,10462.0,0.5661081619110816,1279616.0,886272.0,6.72,9316.351999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,39988.0,27696.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",381,0.0,0.0,0,0,0.0,0.0,0.0,0.0,16000.0,0.0,1548096.0,1536000.0,4.032,9320.383999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48378.0,48000.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",382,1792000.0,4245120.0,0,0,0.0,4245120.0,4245120.0,528.0,5248.0,0.09141274238227147,1008000.0,512000.0,17.216,9337.599999999993,533120.0,128000.0,1792000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,31500.0,16000.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",383,0.0,655488.0,0,0,0.0,655488.0,655488.0,71840.0,8000.0,0.8997995991983968,512000.0,512000.0,46.496,9384.095999999992,655488.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,16000.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",384,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2000.0,0.0,512000.0,128000.0,2.528,9386.623999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,4000.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",385,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,1.888,9388.511999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",386,0.0,0.0,0,0,0.0,0.0,0.0,0.0,12000.0,0.0,1152000.0,54752.0,7.68,9396.191999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,36000.0,1711.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",387,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3000.0,0.0,640000.0,0.0,2.784,9398.975999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,20000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",388,1792000.0,4245120.0,0,0,0.0,4245120.0,4245120.0,528.0,5248.0,0.09141274238227147,1004032.0,512000.0,17.12,9416.095999999994,533120.0,128000.0,1792000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,31376.0,16000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",389,0.0,0.0,0,0,0.0,0.0,0.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,21.888,9437.983999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",390,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.112,9440.095999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",391,0.0,0.0,0,0,0.0,0.0,0.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,21.824,9461.919999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",392,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.112,9464.031999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",393,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.08,9466.111999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",394,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.912,9469.023999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",395,0.0,147456.0,0,0,0.0,147456.0,147456.0,320.0,1004.0,0.24169184290030213,512000.0,128.0,8.192,9477.215999999993,147456.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",396,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,9479.199999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",397,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,9482.431999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",398,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,9484.415999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",399,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.912,9487.327999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",400,1152000.0,2560000.0,0,0,0.0,2560000.0,2560000.0,0.0,4000.0,0.0,0.0,512000.0,3.2,9490.527999999995,0.0,256000.0,1152000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,16000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",401,640000.0,1280000.0,0,0,0.0,1280000.0,1280000.0,0.0,3000.0,0.0,1024000.0,0.0,4.224,9494.751999999995,0.0,0.0,640000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",402,0.0,0.0,0,0,0.0,0.0,0.0,640.0,1004.0,0.38929440389294406,512000.0,128.0,11.936,9506.687999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",403,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,1.952,9508.639999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",404,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,9510.623999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",405,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.208,9512.831999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",406,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,1.984,9514.815999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",407,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,64.0,128.0,2.528,9517.343999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",408,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.664,9519.007999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",409,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,9520.703999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",410,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.016,9522.719999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",411,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.664,9524.383999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",412,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,32.0,2.336,9526.719999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",413,0.0,0.0,0,0,0.0,0.0,0.0,0.0,5.0,0.0,32.0,32.0,4.832,9531.551999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",414,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.016,9533.567999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",415,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.952,9535.519999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",416,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.848,9538.367999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",417,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,9541.663999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",418,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,9543.679999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",419,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.112,9545.791999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",420,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,32.0,3.2,9548.991999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",421,0.0,0.0,0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,64.0,32.0,2.496,9551.487999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",422,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,1.984,9553.471999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",423,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,2.08,9555.551999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",424,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,0.0,2.048,9557.599999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",425,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,2.208,9559.807999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",426,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1536.0,0.0,50176.0,65536.0,5.024,9564.831999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1568.0,2048.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",427,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,2.656,9567.487999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",428,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,9570.783999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",429,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.496,9573.279999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",430,0.0,512.0,0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,2.016,9575.295999999995,0.0,512.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",431,0.0,0.0,0,0,0.0,0.0,0.0,0.0,20.0,0.0,2048.0,2048.0,2.592,9577.887999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",432,4096.0,9216.0,0,0,0.0,9216.0,9216.0,0.0,32.0,0.0,2048.0,2048.0,2.912,9580.799999999996,0.0,1024.0,4096.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",433,0.0,512.0,0,0,0.0,512.0,512.0,0.0,32.0,0.0,2048.0,2048.0,2.016,9582.815999999995,0.0,512.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",434,3600.0,8224.0,0,0,0.0,8224.0,8224.0,0.0,32.0,0.0,2048.0,2048.0,2.88,9585.695999999994,0.0,1024.0,3600.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",435,0.0,512.0,0,0,0.0,512.0,512.0,0.0,32.0,0.0,2048.0,2048.0,1.984,9587.679999999995,0.0,512.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",436,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.016,9589.695999999994,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",437,0.0,20868.0,0,0,0.0,20868.0,20868.0,40.0,132.0,0.23255813953488372,65536.0,32.0,5.664,9595.359999999995,20864.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",438,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.888,9597.247999999996,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",439,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,9599.295999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",440,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,67584.0,65536.0,2.752,9602.047999999997,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",441,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,131072.0,65536.0,2.688,9604.735999999997,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,442,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73237600.0,196608.0,85.504,9690.239999999998,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2288675.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",443,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.432,9692.671999999999,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,444,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73263488.0,196608.0,86.528,9779.199999999999,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2289484.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",445,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.432,9781.632,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,446,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73274848.0,196608.0,85.472,9867.104,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2289839.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",447,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.592,9869.696,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",448,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.688,9872.384,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",449,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,512.0,0.0,32768.0,32768.0,2.56,9874.944,8192.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",450,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,3.968,9878.912,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",451,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.72,9881.632,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",452,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.176,9883.807999999999,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",453,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.688,9886.496,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",454,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,512.0,0.0,32768.0,32768.0,2.592,9889.088,8192.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",455,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,4.0,9893.088,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",456,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.72,9895.807999999999,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",457,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.112,9897.919999999998,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",458,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1280.0,0.0,131072.0,131072.0,2.656,9900.576,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",459,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1280.0,0.0,131072.0,131072.0,2.656,9903.232,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",460,259680.0,23537342.0,0,0,0.0,23537342.0,23537342.0,133193.0,256.0,0.9980816641563444,327680.0,65536.0,20.736,9923.968,19847907.0,3170075.0,259680.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,10240.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,461,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73302496.0,196608.0,85.632,10009.6,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2290703.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",462,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.432,10012.032000000001,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",463,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.176,10014.208,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",464,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,1.984,10016.192000000001,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",465,0.0,20868.0,0,0,0.0,20868.0,20868.0,40.0,132.0,0.23255813953488372,65536.0,32.0,5.696,10021.888,20864.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",466,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,10023.808,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",467,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.432,10026.240000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",468,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,67584.0,65536.0,2.656,10028.896000000002,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",469,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,131072.0,65536.0,2.72,10031.616000000002,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",470,180355072.0,395231232.0,0,0,0.0,395231232.0,395231232.0,2383232.0,2135552.0,0.5274056029232643,239708416.0,263840.0,197.728,10229.344000000001,11976704.0,22544384.0,180355072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7490888.0,8245.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",471,506368.0,1056768.0,0,0,0.0,1056768.0,1056768.0,0.0,688.0,0.0,176128.0,176128.0,2.4,10231.744,44032.0,0.0,506368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5504.0,5504.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",472,180355072.0,395231232.0,0,0,0.0,395231232.0,395231232.0,2383232.0,2135552.0,0.5274056029232643,240293248.0,265792.0,196.032,10427.776,11976704.0,22544384.0,180355072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7509164.0,8306.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",473,0.0,44032.0,0,0,0.0,44032.0,44032.0,0.0,1032.0,0.0,352256.0,176128.0,2.496,10430.271999999999,0.0,44032.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,11008.0,5504.0
ampere_sgemm_64x32_sliced1x4_tn,474,1447034880.0,2896822272.0,0,0,0.0,2896822272.0,2896822272.0,6451200.0,1502976.0,0.8110456695954427,198354784.0,196608.0,223.936,10654.207999999999,1179648.0,1572864.0,1447034880.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6198587.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",475,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.432,10656.64,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",476,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.112,10658.751999999999,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",477,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,1.984,10660.735999999999,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",478,0.0,20868.0,0,0,0.0,20868.0,20868.0,40.0,132.0,0.23255813953488372,65536.0,32.0,5.632,10666.367999999999,20864.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",479,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,10668.319999999998,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",480,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,10670.303999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",481,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,67584.0,65536.0,2.688,10672.991999999998,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",482,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,131072.0,65536.0,2.624,10675.615999999998,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,483,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73216544.0,196608.0,85.504,10761.119999999999,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2288017.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",484,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.592,10763.712,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,485,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73221888.0,196608.0,84.064,10847.776,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2288184.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",486,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.4,10850.176,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,487,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73254592.0,196608.0,86.272,10936.448,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2289206.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",488,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.432,10938.880000000001,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",489,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.688,10941.568000000001,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",490,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,512.0,0.0,32768.0,32768.0,2.592,10944.160000000002,8192.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",491,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,3.968,10948.128000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",492,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.72,10950.848000000002,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",493,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.08,10952.928000000002,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",494,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.688,10955.616000000002,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",495,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,512.0,0.0,32768.0,32768.0,2.784,10958.400000000001,8192.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",496,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,3.936,10962.336000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",497,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.688,10965.024000000001,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",498,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.304,10967.328000000001,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",499,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1280.0,0.0,131072.0,131072.0,2.656,10969.984000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",500,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1280.0,0.0,131072.0,131072.0,2.688,10972.672000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",501,262112.0,23543724.0,0,0,0.0,23543724.0,23543724.0,133123.0,256.0,0.9980806573748491,327680.0,65536.0,20.608,10993.280000000002,19849199.0,3170301.0,262112.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,10240.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,502,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73245856.0,196608.0,85.536,11078.816000000003,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2288933.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",503,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.592,11081.408000000003,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",504,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.304,11083.712000000003,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",505,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.048,11085.760000000004,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",506,0.0,20868.0,0,0,0.0,20868.0,20868.0,40.0,132.0,0.23255813953488372,65536.0,32.0,5.664,11091.424000000005,20864.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",507,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.888,11093.312000000005,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",508,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,11095.296000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",509,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,67584.0,65536.0,2.656,11097.952000000007,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",510,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,131072.0,65536.0,2.624,11100.576000000006,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",511,180355072.0,395231232.0,0,0,0.0,395231232.0,395231232.0,2383232.0,2135552.0,0.5274056029232643,243124480.0,262080.0,197.12,11297.696000000007,11976704.0,22544384.0,180355072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7597640.0,8190.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",512,506368.0,1056768.0,0,0,0.0,1056768.0,1056768.0,0.0,688.0,0.0,176128.0,176128.0,2.4,11300.096000000007,44032.0,0.0,506368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5504.0,5504.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",513,180355072.0,395231232.0,0,0,0.0,395231232.0,395231232.0,2383232.0,2135552.0,0.5274056029232643,241545088.0,262272.0,198.976,11499.072000000007,11976704.0,22544384.0,180355072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7548284.0,8196.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",514,0.0,44032.0,0,0,0.0,44032.0,44032.0,0.0,1032.0,0.0,352256.0,176128.0,2.336,11501.408000000007,0.0,44032.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,11008.0,5504.0
ampere_sgemm_64x32_sliced1x4_tn,515,1447034880.0,2896822272.0,0,0,0.0,2896822272.0,2896822272.0,6451200.0,1502976.0,0.8110456695954427,198377728.0,196608.0,221.312,11722.720000000007,1179648.0,1572864.0,1447034880.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6199304.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",516,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.464,11725.184000000007,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",517,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.208,11727.392000000007,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",518,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.08,11729.472000000007,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",519,0.0,20868.0,0,0,0.0,20868.0,20868.0,40.0,132.0,0.23255813953488372,65536.0,32.0,5.632,11735.104000000007,20864.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",520,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,11737.024000000007,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",521,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,11739.008000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",522,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,67584.0,65536.0,2.688,11741.696000000007,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",523,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,131072.0,65536.0,2.72,11744.416000000007,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,524,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73284128.0,196608.0,85.888,11830.304000000007,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2290129.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",525,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.432,11832.736000000008,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,526,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73267520.0,196608.0,84.608,11917.344000000008,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2289610.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",527,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.656,11920.00000000001,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,528,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73282976.0,196608.0,84.352,12004.35200000001,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2290093.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",529,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.432,12006.78400000001,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",530,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.784,12009.56800000001,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",531,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,512.0,0.0,32768.0,32768.0,2.56,12012.12800000001,8192.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",532,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,4.0,12016.12800000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",533,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.72,12018.848000000009,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",534,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.112,12020.960000000008,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",535,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.72,12023.680000000008,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",536,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,512.0,0.0,32768.0,32768.0,2.592,12026.272000000008,8192.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",537,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,3.968,12030.240000000009,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",538,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.72,12032.960000000008,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",539,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.304,12035.264000000008,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",540,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1280.0,0.0,131072.0,131072.0,2.72,12037.984000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",541,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1280.0,0.0,131072.0,131072.0,2.624,12040.608000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",542,262144.0,23543808.0,0,0,0.0,23543808.0,23543808.0,133120.0,256.0,0.9980806142034548,327680.0,65536.0,20.576,12061.184000000007,19849216.0,3170304.0,262144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,10240.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,543,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73262272.0,196608.0,85.568,12146.752000000006,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2289446.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",544,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.624,12149.376000000006,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",545,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.112,12151.488000000005,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",546,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.016,12153.504000000004,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",547,0.0,20868.0,0,0,0.0,20868.0,20868.0,40.0,132.0,0.23255813953488372,65536.0,32.0,5.76,12159.264000000005,20864.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",548,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,12161.184000000005,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",549,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,12163.168000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",550,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,67584.0,65536.0,2.688,12165.856000000005,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",551,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,131072.0,65536.0,2.88,12168.736000000004,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",552,180355072.0,395231232.0,0,0,0.0,395231232.0,395231232.0,2383232.0,2135552.0,0.5274056029232643,240293248.0,272928.0,198.112,12366.848000000004,11976704.0,22544384.0,180355072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7509164.0,8529.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",553,506368.0,1056768.0,0,0,0.0,1056768.0,1056768.0,0.0,688.0,0.0,176128.0,176128.0,2.4,12369.248000000003,44032.0,0.0,506368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5504.0,5504.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",554,180355072.0,395231232.0,0,0,0.0,395231232.0,395231232.0,2383232.0,2135552.0,0.5274056029232643,242820608.0,263680.0,196.896,12566.144000000004,11976704.0,22544384.0,180355072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7588144.0,8240.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",555,0.0,44032.0,0,0,0.0,44032.0,44032.0,0.0,1032.0,0.0,352256.0,176128.0,2.464,12568.608000000004,0.0,44032.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,11008.0,5504.0
ampere_sgemm_64x32_sliced1x4_tn,556,1447034880.0,2896822272.0,0,0,0.0,2896822272.0,2896822272.0,6451200.0,1502976.0,0.8110456695954427,198379136.0,196608.0,224.832,12793.440000000004,1179648.0,1572864.0,1447034880.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6199348.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",557,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.464,12795.904000000004,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",558,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.08,12797.984000000004,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",559,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.08,12800.064000000004,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",560,0.0,20868.0,0,0,0.0,20868.0,20868.0,40.0,132.0,0.23255813953488372,65536.0,32.0,5.76,12805.824000000004,20864.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",561,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,12807.744000000004,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",562,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,12809.728000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",563,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,67584.0,65536.0,2.656,12812.384000000005,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",564,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,131072.0,65536.0,2.656,12815.040000000006,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,565,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73236096.0,196608.0,84.672,12899.712000000007,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2288628.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",566,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.4,12902.112000000006,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,567,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73236000.0,196608.0,83.232,12985.344000000006,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2288625.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",568,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.432,12987.776000000007,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,569,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73237440.0,196608.0,84.32,13072.096000000007,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2288670.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",570,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.432,13074.528000000008,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",571,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.688,13077.216000000008,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",572,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,512.0,0.0,32768.0,32768.0,2.592,13079.808000000008,8192.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",573,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,4.0,13083.808000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",574,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.688,13086.496000000008,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",575,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.176,13088.672000000008,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",576,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.656,13091.328000000009,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",577,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,512.0,0.0,32768.0,32768.0,2.624,13093.952000000008,8192.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",578,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,4.064,13098.016000000009,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",579,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.88,13100.896000000008,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",580,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.112,13103.008000000007,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",581,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1280.0,0.0,131072.0,131072.0,2.656,13105.664000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",582,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1280.0,0.0,131072.0,131072.0,2.848,13108.512000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",583,262144.0,23543808.0,0,0,0.0,23543808.0,23543808.0,133120.0,256.0,0.9980806142034548,327680.0,65536.0,20.512,13129.024000000009,19849216.0,3170304.0,262144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,10240.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,584,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73231584.0,196608.0,83.872,13212.896000000008,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2288487.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",585,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.496,13215.392000000007,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",586,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.112,13217.504000000006,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",587,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.016,13219.520000000006,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",588,0.0,20868.0,0,0,0.0,20868.0,20868.0,40.0,132.0,0.23255813953488372,65536.0,32.0,5.664,13225.184000000007,20864.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",589,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,13227.104000000007,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",590,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.952,13229.056000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",591,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,67584.0,65536.0,2.752,13231.808000000006,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",592,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,131072.0,65536.0,2.688,13234.496000000006,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",593,180355072.0,395231232.0,0,0,0.0,395231232.0,395231232.0,2383232.0,2135552.0,0.5274056029232643,239176960.0,265472.0,196.096,13430.592000000006,11976704.0,22544384.0,180355072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7474280.0,8296.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",594,506368.0,1056768.0,0,0,0.0,1056768.0,1056768.0,0.0,688.0,0.0,176128.0,176128.0,2.368,13432.960000000006,44032.0,0.0,506368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5504.0,5504.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",595,180355072.0,395231232.0,0,0,0.0,395231232.0,395231232.0,2383232.0,2135552.0,0.5274056029232643,239728640.0,262848.0,197.344,13630.304000000006,11976704.0,22544384.0,180355072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7491520.0,8214.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",596,0.0,44032.0,0,0,0.0,44032.0,44032.0,0.0,1032.0,0.0,352256.0,176128.0,2.528,13632.832000000006,0.0,44032.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,11008.0,5504.0
ampere_sgemm_64x32_sliced1x4_tn,597,1447034880.0,2896822272.0,0,0,0.0,2896822272.0,2896822272.0,6451200.0,1502976.0,0.8110456695954427,198353984.0,196608.0,221.856,13854.688000000006,1179648.0,1572864.0,1447034880.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6198562.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",598,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.432,13857.120000000006,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",599,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.368,13859.488000000007,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",600,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.016,13861.504000000006,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",601,0.0,20868.0,0,0,0.0,20868.0,20868.0,40.0,132.0,0.23255813953488372,65536.0,32.0,5.696,13867.200000000006,20864.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",602,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,13869.120000000006,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",603,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,13871.136000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",604,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,67584.0,65536.0,2.72,13873.856000000005,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",605,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,131072.0,65536.0,2.624,13876.480000000005,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,606,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73293728.0,196608.0,85.312,13961.792000000005,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2290429.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",607,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.496,13964.288000000004,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,608,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73308160.0,196608.0,84.512,14048.800000000005,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2290880.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",609,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.496,14051.296000000004,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,610,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73244032.0,196608.0,84.064,14135.360000000004,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2288876.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",611,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.432,14137.792000000005,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",612,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.656,14140.448000000006,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",613,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,512.0,0.0,32768.0,32768.0,2.688,14143.136000000006,8192.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",614,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,4.032,14147.168000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",615,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.752,14149.920000000006,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",616,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.24,14152.160000000005,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",617,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.656,14154.816000000006,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",618,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,512.0,0.0,32768.0,32768.0,2.592,14157.408000000007,8192.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",619,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,3.936,14161.344000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",620,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.752,14164.096000000007,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",621,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.112,14166.208000000006,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",622,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1280.0,0.0,131072.0,131072.0,2.752,14168.960000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",623,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1280.0,0.0,131072.0,131072.0,2.72,14171.680000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",624,262144.0,23543808.0,0,0,0.0,23543808.0,23543808.0,133120.0,256.0,0.9980806142034548,327680.0,65536.0,20.512,14192.192000000006,19849216.0,3170304.0,262144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,10240.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,625,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73241664.0,196608.0,85.696,14277.888000000006,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2288802.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",626,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.464,14280.352000000006,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",627,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.112,14282.464000000005,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",628,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.048,14284.512000000006,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",629,0.0,20868.0,0,0,0.0,20868.0,20868.0,40.0,132.0,0.23255813953488372,65536.0,32.0,5.696,14290.208000000006,20864.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",630,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,14292.128000000006,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",631,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,14294.176000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",632,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,67584.0,65536.0,2.656,14296.832000000008,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",633,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,131072.0,65536.0,2.656,14299.488000000008,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",634,180355072.0,395231232.0,0,0,0.0,395231232.0,395231232.0,2383232.0,2135552.0,0.5274056029232643,242394624.0,265088.0,196.608,14496.096000000009,11976704.0,22544384.0,180355072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7574832.0,8284.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",635,506368.0,1056768.0,0,0,0.0,1056768.0,1056768.0,0.0,688.0,0.0,176128.0,176128.0,2.432,14498.52800000001,44032.0,0.0,506368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5504.0,5504.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",636,180355072.0,395231232.0,0,0,0.0,395231232.0,395231232.0,2383232.0,2135552.0,0.5274056029232643,241578240.0,268896.0,198.368,14696.89600000001,11976704.0,22544384.0,180355072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7549320.0,8403.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",637,0.0,44032.0,0,0,0.0,44032.0,44032.0,0.0,1032.0,0.0,352256.0,176128.0,2.56,14699.45600000001,0.0,44032.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,11008.0,5504.0
ampere_sgemm_64x32_sliced1x4_tn,638,1447034880.0,2896822272.0,0,0,0.0,2896822272.0,2896822272.0,6451200.0,1502976.0,0.8110456695954427,198317088.0,196608.0,220.064,14919.52000000001,1179648.0,1572864.0,1447034880.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6197409.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",639,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.464,14921.98400000001,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",640,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.304,14924.28800000001,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",641,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.016,14926.30400000001,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",642,0.0,20868.0,0,0,0.0,20868.0,20868.0,40.0,132.0,0.23255813953488372,65536.0,32.0,5.76,14932.06400000001,20864.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",643,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,14933.98400000001,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",644,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,14935.96800000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",645,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,67584.0,65536.0,2.656,14938.62400000001,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",646,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,131072.0,65536.0,2.656,14941.280000000012,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,647,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73318560.0,196608.0,85.536,15026.816000000012,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2291205.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",648,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.592,15029.408000000012,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,649,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73260864.0,196608.0,83.136,15112.544000000013,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2289402.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",650,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.464,15115.008000000013,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,651,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73293536.0,196608.0,84.736,15199.744000000013,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2290423.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",652,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.56,15202.304000000013,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",653,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.688,15204.992000000013,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",654,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,512.0,0.0,32768.0,32768.0,2.56,15207.552000000012,8192.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",655,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,4.096,15211.648000000012,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",656,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.72,15214.368000000011,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",657,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.176,15216.54400000001,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",658,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.688,15219.23200000001,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",659,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,512.0,0.0,32768.0,32768.0,2.592,15221.824000000011,8192.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",660,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,3.968,15225.792000000012,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",661,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.72,15228.512000000012,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",662,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.112,15230.62400000001,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",663,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1280.0,0.0,131072.0,131072.0,2.688,15233.31200000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",664,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1280.0,0.0,131072.0,131072.0,2.624,15235.93600000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",665,262144.0,23543808.0,0,0,0.0,23543808.0,23543808.0,133120.0,256.0,0.9980806142034548,327680.0,65536.0,20.576,15256.51200000001,19849216.0,3170304.0,262144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,10240.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,666,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73248352.0,196608.0,85.28,15341.79200000001,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2289011.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",667,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.464,15344.25600000001,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",668,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.08,15346.33600000001,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",669,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.048,15348.384000000011,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",670,0.0,20868.0,0,0,0.0,20868.0,20868.0,40.0,132.0,0.23255813953488372,65536.0,32.0,5.792,15354.17600000001,20864.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",671,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.952,15356.12800000001,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",672,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,15358.11200000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",673,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,67584.0,65536.0,2.72,15360.83200000001,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",674,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,131072.0,65536.0,2.656,15363.48800000001,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",675,180355072.0,395231232.0,0,0,0.0,395231232.0,395231232.0,2383232.0,2135552.0,0.5274056029232643,240252672.0,263904.0,196.928,15560.41600000001,11976704.0,22544384.0,180355072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7507896.0,8247.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",676,506368.0,1056768.0,0,0,0.0,1056768.0,1056768.0,0.0,688.0,0.0,176128.0,176128.0,2.368,15562.78400000001,44032.0,0.0,506368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5504.0,5504.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",677,180355072.0,395231232.0,0,0,0.0,395231232.0,395231232.0,2383232.0,2135552.0,0.5274056029232643,244628096.0,264672.0,197.152,15759.93600000001,11976704.0,22544384.0,180355072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7644628.0,8271.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",678,0.0,44032.0,0,0,0.0,44032.0,44032.0,0.0,1032.0,0.0,352256.0,176128.0,2.528,15762.46400000001,0.0,44032.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,11008.0,5504.0
ampere_sgemm_64x32_sliced1x4_tn,679,1447034880.0,2896822272.0,0,0,0.0,2896822272.0,2896822272.0,6451200.0,1502976.0,0.8110456695954427,198398432.0,196608.0,226.048,15988.512000000012,1179648.0,1572864.0,1447034880.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6199951.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",680,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.464,15990.976000000011,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",681,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.08,15993.056000000011,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",682,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.016,15995.072000000011,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",683,0.0,20868.0,0,0,0.0,20868.0,20868.0,40.0,132.0,0.23255813953488372,65536.0,32.0,5.856,16000.92800000001,20864.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",684,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.888,16002.816000000012,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",685,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.952,16004.768000000011,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",686,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,67584.0,65536.0,2.688,16007.456000000011,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",687,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,131072.0,65536.0,2.688,16010.144000000011,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,688,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73274432.0,196608.0,85.472,16095.61600000001,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2289826.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",689,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.464,16098.08000000001,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,690,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73279200.0,196608.0,84.0,16182.08000000001,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2289975.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",691,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.496,16184.57600000001,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,692,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73261344.0,196608.0,84.96,16269.53600000001,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2289417.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",693,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.464,16272.00000000001,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",694,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.72,16274.720000000008,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",695,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,512.0,0.0,32768.0,32768.0,2.656,16277.37600000001,8192.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",696,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,3.936,16281.312000000009,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",697,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.816,16284.12800000001,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",698,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.112,16286.240000000009,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",699,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.72,16288.960000000008,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",700,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,512.0,0.0,32768.0,32768.0,2.56,16291.520000000008,8192.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",701,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,3.936,16295.456000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",702,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.72,16298.176000000007,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",703,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.144,16300.320000000007,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",704,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1280.0,0.0,131072.0,131072.0,2.656,16302.976000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",705,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1280.0,0.0,131072.0,131072.0,2.912,16305.888000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",706,262144.0,23543808.0,0,0,0.0,23543808.0,23543808.0,133120.0,256.0,0.9980806142034548,327680.0,65536.0,20.544,16326.432000000008,19849216.0,3170304.0,262144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,10240.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,707,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73240480.0,196608.0,84.416,16410.84800000001,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2288765.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",708,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.496,16413.34400000001,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",709,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.24,16415.58400000001,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",710,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.016,16417.60000000001,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",711,0.0,20868.0,0,0,0.0,20868.0,20868.0,40.0,132.0,0.23255813953488372,65536.0,32.0,5.728,16423.32800000001,20864.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",712,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,16425.248000000007,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",713,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,16427.264000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",714,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,67584.0,65536.0,2.624,16429.888000000006,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",715,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,131072.0,65536.0,2.624,16432.512000000006,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",716,180355072.0,395231232.0,0,0,0.0,395231232.0,395231232.0,2383232.0,2135552.0,0.5274056029232643,243007232.0,266560.0,195.52,16628.032000000007,11976704.0,22544384.0,180355072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7593976.0,8330.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",717,506368.0,1056768.0,0,0,0.0,1056768.0,1056768.0,0.0,688.0,0.0,176128.0,176128.0,2.368,16630.400000000005,44032.0,0.0,506368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5504.0,5504.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",718,180355072.0,395231232.0,0,0,0.0,395231232.0,395231232.0,2383232.0,2135552.0,0.5274056029232643,243472128.0,265856.0,197.696,16828.096000000005,11976704.0,22544384.0,180355072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7608504.0,8308.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",719,0.0,44032.0,0,0,0.0,44032.0,44032.0,0.0,1032.0,0.0,352256.0,176128.0,2.432,16830.528000000006,0.0,44032.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,11008.0,5504.0
ampere_sgemm_64x32_sliced1x4_tn,720,1447034880.0,2896822272.0,0,0,0.0,2896822272.0,2896822272.0,6451200.0,1502976.0,0.8110456695954427,198411840.0,196608.0,223.072,17053.600000000006,1179648.0,1572864.0,1447034880.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6200370.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",721,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.464,17056.064000000006,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",722,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.176,17058.240000000005,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",723,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.016,17060.256000000005,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",724,0.0,20868.0,0,0,0.0,20868.0,20868.0,40.0,132.0,0.23255813953488372,65536.0,32.0,5.664,17065.920000000006,20864.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",725,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.08,17068.000000000007,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",726,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.952,17069.95200000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",727,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,67584.0,65536.0,2.816,17072.768000000007,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",728,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,131072.0,65536.0,2.624,17075.392000000007,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,729,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73193312.0,196608.0,84.64,17160.032000000007,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2287291.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",730,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.464,17162.496000000006,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,731,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73261216.0,196608.0,83.552,17246.048000000006,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2289413.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",732,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.432,17248.480000000007,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,733,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73212896.0,196608.0,84.64,17333.120000000006,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2287903.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",734,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.432,17335.552000000007,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",735,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.752,17338.304000000007,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",736,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,512.0,0.0,32768.0,32768.0,2.56,17340.86400000001,8192.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",737,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,3.968,17344.83200000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",738,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.72,17347.55200000001,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",739,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.08,17349.632000000012,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",740,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.688,17352.32000000001,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",741,0.0,8192.0,0,0,0.0,8192.0,8192.0,0.0,512.0,0.0,32768.0,32768.0,2.624,17354.94400000001,8192.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",742,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1024.0,0.0,65536.0,65536.0,4.064,17359.00800000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",743,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,98304.0,65536.0,2.784,17361.79200000001,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",744,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.112,17363.90400000001,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",745,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1280.0,0.0,131072.0,131072.0,2.88,17366.78400000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",746,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1280.0,0.0,131072.0,131072.0,2.688,17369.47200000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",747,262144.0,23543808.0,0,0,0.0,23543808.0,23543808.0,133120.0,256.0,0.9980806142034548,327680.0,65536.0,20.512,17389.984000000008,19849216.0,3170304.0,262144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,10240.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,748,541065216.0,1084882944.0,0,0,0.0,1084882944.0,1084882944.0,2469888.0,562944.0,0.8143833881995441,73215200.0,196608.0,83.456,17473.440000000006,1179648.0,1572864.0,541065216.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2287975.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",749,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.496,17475.936000000005,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",750,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.336,17478.272000000004,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",751,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.08,17480.352000000006,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",752,0.0,20868.0,0,0,0.0,20868.0,20868.0,40.0,132.0,0.23255813953488372,65536.0,32.0,5.6,17485.952000000005,20864.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",753,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.92,17487.872000000003,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",754,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,17489.888000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",755,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,67584.0,65536.0,2.656,17492.544,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",756,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,131072.0,65536.0,2.688,17495.232,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",757,180355072.0,395231232.0,0,0,0.0,395231232.0,395231232.0,2383232.0,2135552.0,0.5274056029232643,240498560.0,259136.0,196.448,17691.68,11976704.0,22544384.0,180355072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7515580.0,8098.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",758,506368.0,1056768.0,0,0,0.0,1056768.0,1056768.0,0.0,688.0,0.0,176128.0,176128.0,2.336,17694.016,44032.0,0.0,506368.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5504.0,5504.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",759,180355072.0,395231232.0,0,0,0.0,395231232.0,395231232.0,2383232.0,2135552.0,0.5274056029232643,243723904.0,263392.0,198.336,17892.352,11976704.0,22544384.0,180355072.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7616372.0,8231.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",760,0.0,44032.0,0,0,0.0,44032.0,44032.0,0.0,1032.0,0.0,352256.0,176128.0,2.4,17894.752,0.0,44032.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,11008.0,5504.0
ampere_sgemm_64x32_sliced1x4_tn,761,1447034880.0,2896822272.0,0,0,0.0,2896822272.0,2896822272.0,6451200.0,1502976.0,0.8110456695954427,198370432.0,196608.0,221.312,18116.064000000002,1179648.0,1572864.0,1447034880.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6199076.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",762,0.0,65536.0,0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,196608.0,65536.0,2.432,18118.496000000003,49152.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",763,16384.0,32768.0,0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.432,18120.928000000004,0.0,0.0,16384.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",764,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.016,18122.944000000003,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",765,0.0,20868.0,0,0,0.0,20868.0,20868.0,40.0,132.0,0.23255813953488372,65536.0,32.0,5.664,18128.608000000004,20864.0,4.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",766,4.0,8.0,0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,1.888,18130.496000000003,0.0,0.0,4.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",767,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,18132.544,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",768,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,67584.0,65536.0,2.688,18135.232,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",769,0.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,1536.0,0.0,131072.0,65536.0,2.656,18137.888,0.0,16384.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0
ampere_sgemm_64x32_sliced1x4_tn,770,4194304000.0,8395776000.0,0,0,0.0,8395776000.0,8395776000.0,18672000.0,4356000.0,0.8108389786347056,551017600.0,512000.0,615.52,18753.408,3072000.0,4096000.0,4194304000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,17219300.0,16000.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",771,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.664,18755.072,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",772,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,96.0,160.0,2.592,18757.664,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",773,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,18759.648,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",774,0.0,128000.0,0,0,0.0,128000.0,128000.0,0.0,2000.0,0.0,512000.0,512000.0,2.784,18762.432,0.0,128000.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,16000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",775,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.664,18764.096,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",776,0.0,0.0,0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,37632.0,3.744,18767.84,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16128.0,1176.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",777,0.0,0.0,0,0,0.0,0.0,0.0,9472.0,34440.0,0.2157041355438149,2109440.0,0.0,4.192,18772.032,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",778,0.0,0.0,0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,38144.0,3.744,18775.775999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16128.0,1192.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",779,0.0,0.0,0,0,0.0,0.0,0.0,9472.0,34696.0,0.2144539032783916,2109440.0,0.0,4.192,18779.967999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",780,0.0,0.0,0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,37824.0,3.584,18783.551999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16128.0,1182.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",781,0.0,0.0,0,0,0.0,0.0,0.0,9472.0,34760.0,0.21414360643877736,2109440.0,0.0,4.192,18787.743999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",782,0.0,0.0,0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,37888.0,3.648,18791.391999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16128.0,1184.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",783,0.0,0.0,0,0,0.0,0.0,0.0,9472.0,34344.0,0.21617673909074311,2109440.0,128.0,4.384,18795.775999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,65920.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",784,0.0,0.0,0,0,0.0,0.0,0.0,0.0,12.0,0.0,4128.0,512.0,2.4,18798.175999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,129.0,16.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",785,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.664,18799.839999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",786,0.0,0.0,0,0,0.0,0.0,0.0,497.0,16.0,0.9688109161793372,512.0,0.0,3.424,18803.263999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",787,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.632,18804.895999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",788,0.0,0.0,0,0,0.0,0.0,0.0,497.0,16.0,0.9688109161793372,512.0,0.0,3.456,18808.351999999995,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",789,0.0,0.0,0,0,0.0,0.0,0.0,39360.0,8424.0,0.8237066800602713,527232.0,7328.0,5.92,18814.271999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16476.0,229.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",790,0.0,0.0,0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,544.0,6.496,18820.767999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,80.0,17.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",791,0.0,0.0,0,0,0.0,0.0,0.0,0.0,12000.0,0.0,520064.0,58304.0,3.712,18824.479999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16252.0,1822.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",792,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3000.0,0.0,640000.0,0.0,2.912,18827.391999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,20000.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",793,0.0,0.0,0,0,0.0,0.0,0.0,0.0,4000.0,0.0,0.0,1024000.0,2.304,18829.695999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,32000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",794,0.0,0.0,0,0,0.0,0.0,0.0,98304.0,4000.0,0.960900844541758,512000.0,0.0,4.128,18833.823999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",795,0.0,0.0,0,0,0.0,0.0,0.0,156.0,64.0,0.7090909090909091,8192.0,0.0,2.176,18835.999999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",796,0.0,0.0,0,0,0.0,0.0,0.0,50958.0,18903.0,0.7294198479838536,1909504.0,1286880.0,9.728,18845.727999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,59672.0,40215.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",797,0.0,0.0,0,0,0.0,0.0,0.0,15054.0,20097.0,0.42826662114875824,1898112.0,1579008.0,7.488,18853.215999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,59316.0,49344.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",798,0.0,0.0,0,0,0.0,0.0,0.0,15858.0,19899.0,0.44349358167631514,1903360.0,1207488.0,8.352,18861.567999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,59480.0,37734.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",799,0.0,0.0,0,0,0.0,0.0,0.0,14958.0,19741.0,0.43107870543819704,1889536.0,1579008.0,8.448,18870.015999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,59048.0,49344.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",800,0.0,0.0,0,0,0.0,0.0,0.0,14336.0,4000.0,0.7818499127399651,1024000.0,0.0,3.776,18873.791999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",801,0.0,0.0,0,0,0.0,0.0,0.0,39.0,16.0,0.7090909090909091,2048.0,0.0,2.144,18875.935999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",802,0.0,0.0,0,0,0.0,0.0,0.0,13650.0,10438.0,0.5666722019262703,1279744.0,884096.0,6.688,18882.623999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,39992.0,27628.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",803,0.0,0.0,0,0,0.0,0.0,0.0,0.0,16000.0,0.0,1549152.0,1536000.0,4.0,18886.623999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,48411.0,48000.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",804,1792000.0,4245120.0,0,0,0.0,4245120.0,4245120.0,528.0,5248.0,0.09141274238227147,1036928.0,512000.0,17.344,18903.967999999993,533120.0,128000.0,1792000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32404.0,16000.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",805,0.0,655488.0,0,0,0.0,655488.0,655488.0,71840.0,8000.0,0.8997995991983968,512000.0,512000.0,46.624,18950.591999999993,655488.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,16000.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",806,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2000.0,0.0,512000.0,128000.0,2.592,18953.183999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,4000.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",807,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,1.888,18955.071999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",808,0.0,0.0,0,0,0.0,0.0,0.0,0.0,12000.0,0.0,1152000.0,52256.0,7.552,18962.623999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,36000.0,1633.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",809,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3000.0,0.0,640000.0,0.0,2.752,18965.375999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,20000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",810,1792000.0,4245120.0,0,0,0.0,4245120.0,4245120.0,528.0,5248.0,0.09141274238227147,1025920.0,512000.0,17.088,18982.463999999993,533120.0,128000.0,1792000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32060.0,16000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",811,0.0,0.0,0,0,0.0,0.0,0.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,22.016,19004.479999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",812,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,19006.623999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",813,0.0,0.0,0,0,0.0,0.0,0.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,21.76,19028.38399999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",814,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.112,19030.495999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",815,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.176,19032.67199999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",816,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.912,19035.58399999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",817,0.0,147456.0,0,0,0.0,147456.0,147456.0,320.0,1004.0,0.24169184290030213,512000.0,128.0,8.384,19043.96799999999,147456.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",818,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,19045.95199999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",819,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,19049.18399999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",820,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,19051.23199999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",821,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.912,19054.14399999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",822,1152000.0,2560000.0,0,0,0.0,2560000.0,2560000.0,0.0,4000.0,0.0,0.0,512000.0,3.2,19057.34399999999,0.0,256000.0,1152000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,16000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",823,640000.0,1280000.0,0,0,0.0,1280000.0,1280000.0,0.0,3000.0,0.0,1024000.0,0.0,4.32,19061.66399999999,0.0,0.0,640000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",824,0.0,0.0,0,0,0.0,0.0,0.0,640.0,1004.0,0.38929440389294406,512000.0,128.0,11.712,19073.37599999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",825,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,1.984,19075.35999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",826,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.952,19077.31199999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",827,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.176,19079.48799999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",828,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.048,19081.53599999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",829,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,96.0,160.0,2.56,19084.09599999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",830,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.664,19085.75999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",831,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,19087.45599999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",832,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.016,19089.47199999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",833,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.664,19091.13599999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",834,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,128.0,32.0,2.208,19093.34399999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",835,0.0,0.0,0,0,0.0,0.0,0.0,0.0,5.0,0.0,32.0,32.0,4.896,19098.23999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",836,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.048,19100.28799999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",837,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,19102.30399999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",838,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.784,19105.08799999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",839,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.168,19108.25599999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",840,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,19110.23999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
