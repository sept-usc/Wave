Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,64.0,1.856,1.856,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,2.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,64.0,1.696,3.552,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,2.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,5.28,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.016,7.296,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.336,9.632,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",6,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,32.0,2.304,11.936,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",7,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,64.0,3.392,15.328,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,2.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",8,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.264,18.592,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",9,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,21.119999999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",10,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,64.0,1.728,22.848,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,2.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",11,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,24.576,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.728,26.304000000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,0.0,0.0,0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,2.464,28.768,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,30.784,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",15,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.176,32.96,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",16,0.0,0.0,0,0,0.0,0.0,0.0,96.0,8.0,0.9230769230769231,64.0,32.0,2.528,35.488,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",17,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.016,37.504,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",18,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,2.08,39.583999999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",19,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,0.0,2.144,41.727999999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",20,0.0,0.0,0,0,0.0,0.0,0.0,0.0,576.0,0.0,3456.0,24576.0,4.8,46.52799999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,108.0,768.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",21,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,2.496,49.023999999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",22,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,52.44799999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",23,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,2.4,54.84799999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",24,0.0,1024.0,0,0,0.0,1024.0,1024.0,64.0,48.0,0.5714285714285714,2560.0,2048.0,2.016,56.86399999999999,0.0,1024.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,80.0,64.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",25,0.0,0.0,0,0,0.0,0.0,0.0,0.0,40.0,0.0,4096.0,4096.0,2.624,59.48799999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",26,8192.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,16.0,0.0,4096.0,4096.0,2.848,62.33599999999999,0.0,2048.0,8192.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",27,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.016,64.35199999999999,0.0,1024.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",28,7168.0,16384.0,0,0,0.0,16384.0,16384.0,0.0,16.0,0.0,4096.0,4096.0,2.816,67.16799999999999,0.0,2048.0,7168.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",29,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.08,69.24799999999999,0.0,1024.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",30,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.016,71.264,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",31,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.128,75.392,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",32,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,2.016,77.408,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",33,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,79.456,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",34,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.72,82.176,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",35,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.656,84.83200000000001,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,36,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3066880.0,122880.0,7.744,92.57600000000001,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95840.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",37,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.56,95.13600000000001,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,38,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3069568.0,122880.0,7.616,102.75200000000001,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95924.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",39,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.496,105.248,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,40,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3069440.0,122880.0,7.68,112.928,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95920.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",41,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.56,115.488,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",42,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.752,118.24,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",43,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.848,121.088,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",44,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,4.0,125.088,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",45,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.848,127.93599999999999,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",46,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.08,130.016,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",47,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.656,132.672,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",48,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.688,135.35999999999999,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",49,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,4.096,139.456,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",50,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.752,142.208,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",51,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.112,144.32,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",52,98304.0,8825856.0,0,0,0.0,8825856.0,8825856.0,49920.0,96.0,0.9980806142034548,73728.0,24576.0,20.128,164.44799999999998,7440384.0,1188864.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,53,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3067520.0,122880.0,7.776,172.224,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95860.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",54,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.464,174.688,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",55,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.08,176.768,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",56,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.016,178.784,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",57,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.096,182.88,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",58,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,2.016,184.896,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",59,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.112,187.00799999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",60,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.688,189.69599999999997,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",61,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.72,192.41599999999997,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,62,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.36,207.77599999999995,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",63,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.496,210.27199999999996,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",64,282624.0,589824.0,0,0,0.0,589824.0,589824.0,0.0,384.0,0.0,98304.0,98304.0,2.336,212.60799999999998,24576.0,0.0,282624.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,65,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.744,228.35199999999998,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",66,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.56,230.91199999999998,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",67,0.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.208,233.11999999999998,0.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,68,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,84480.0,0.8172757475083057,10616832.0,196608.0,15.584,248.70399999999998,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",69,0.0,55296.0,0,0,0.0,55296.0,55296.0,0.0,1728.0,0.0,196608.0,24576.0,2.496,251.2,49152.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",70,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.08,253.28,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",71,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,1.984,255.264,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",72,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.16,259.42400000000004,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",73,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.984,261.408,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",74,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.112,263.52000000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",75,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.688,266.208,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",76,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.656,268.86400000000003,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,77,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3067424.0,122880.0,8.0,276.86400000000003,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95857.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",78,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.688,279.552,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,79,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3069024.0,122880.0,7.616,287.168,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95907.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",80,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.688,289.856,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,81,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3070080.0,122880.0,7.904,297.76,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95940.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",82,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.592,300.352,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",83,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.72,303.072,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",84,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.624,305.696,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",85,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,4.0,309.696,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",86,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.688,312.384,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",87,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.048,314.432,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",88,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.752,317.184,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",89,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.656,319.84000000000003,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",90,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,4.032,323.872,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",91,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.72,326.59200000000004,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",92,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.24,328.83200000000005,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",93,98304.0,8825856.0,0,0,0.0,8825856.0,8825856.0,49920.0,96.0,0.9980806142034548,73728.0,24576.0,20.224,349.05600000000004,7440384.0,1188864.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,94,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3067648.0,122880.0,7.712,356.76800000000003,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95864.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",95,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.656,359.42400000000004,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",96,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.08,361.504,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",97,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.016,363.52000000000004,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",98,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.224,367.744,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",99,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,2.016,369.76000000000005,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",100,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,371.80800000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",101,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.752,374.56000000000006,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",102,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.592,377.15200000000004,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,103,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.456,392.60800000000006,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",104,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.496,395.10400000000004,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",105,282624.0,589824.0,0,0,0.0,589824.0,589824.0,0.0,384.0,0.0,98304.0,98304.0,2.368,397.47200000000004,24576.0,0.0,282624.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,106,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.68,413.15200000000004,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",107,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.528,415.68000000000006,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",108,0.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.304,417.98400000000004,0.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,109,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,84480.0,0.8172757475083057,10616832.0,196608.0,15.424,433.408,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",110,0.0,55296.0,0,0,0.0,55296.0,55296.0,0.0,1728.0,0.0,196608.0,24576.0,2.336,435.744,49152.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",111,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.048,437.79200000000003,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",112,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.048,439.84000000000003,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",113,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.064,443.90400000000005,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",114,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,2.016,445.9200000000001,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",115,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,447.9680000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",116,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.624,450.5920000000001,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",117,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.656,453.2480000000001,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,118,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3066336.0,122880.0,7.904,461.1520000000001,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95823.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",119,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.528,463.6800000000001,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,120,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3071040.0,122880.0,7.936,471.6160000000001,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95970.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",121,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.624,474.2400000000001,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,122,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3069312.0,122880.0,7.712,481.9520000000001,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95916.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",123,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.656,484.6080000000001,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",124,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.688,487.2960000000001,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",125,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.816,490.1120000000001,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",126,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,4.032,494.14400000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",127,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.656,496.80000000000007,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",128,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.08,498.88000000000005,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",129,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.656,501.53600000000006,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",130,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.688,504.22400000000005,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",131,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,4.032,508.25600000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",132,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.688,510.944,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",133,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.112,513.056,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",134,98304.0,8825856.0,0,0,0.0,8825856.0,8825856.0,49920.0,96.0,0.9980806142034548,73728.0,24576.0,20.128,533.1840000000001,7440384.0,1188864.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,135,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3068064.0,122880.0,7.744,540.9280000000001,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95877.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",136,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.528,543.4560000000001,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",137,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.112,545.5680000000001,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",138,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.048,547.6160000000001,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",139,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.064,551.6800000000001,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",140,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.984,553.6640000000001,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",141,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,555.7440000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",142,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.624,558.3680000000002,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",143,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.656,561.0240000000001,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,144,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.36,576.3840000000001,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",145,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.56,578.9440000000001,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",146,282624.0,589824.0,0,0,0.0,589824.0,589824.0,0.0,384.0,0.0,98304.0,98304.0,2.56,581.504,24576.0,0.0,282624.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,147,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.616,597.12,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",148,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.688,599.808,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",149,0.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.432,602.24,0.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,150,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,84480.0,0.8172757475083057,10616832.0,196608.0,15.744,617.984,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",151,0.0,55296.0,0,0,0.0,55296.0,55296.0,0.0,1728.0,0.0,196608.0,24576.0,2.336,620.32,49152.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",152,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.112,622.432,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",153,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.048,624.48,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",154,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.224,628.7040000000001,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",155,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,2.016,630.72,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",156,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,632.768,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",157,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.656,635.424,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",158,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.624,638.048,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,159,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3066080.0,122880.0,7.648,645.696,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95815.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",160,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.496,648.192,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,161,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3071808.0,122880.0,7.936,656.128,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95994.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",162,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.528,658.6560000000001,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,163,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3070176.0,122880.0,7.808,666.464,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95943.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",164,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.56,669.024,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",165,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.688,671.712,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",166,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.688,674.4,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",167,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,3.968,678.3679999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",168,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.624,680.992,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",169,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.08,683.072,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",170,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.72,685.792,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",171,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.656,688.448,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",172,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,4.0,692.448,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",173,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.688,695.136,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",174,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.08,697.216,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",175,98304.0,8825856.0,0,0,0.0,8825856.0,8825856.0,49920.0,96.0,0.9980806142034548,73728.0,24576.0,20.128,717.344,7440384.0,1188864.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,176,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3069248.0,122880.0,7.872,725.216,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95914.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",177,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.624,727.84,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",178,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.144,729.984,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",179,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.048,732.032,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",180,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.16,736.192,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",181,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.984,738.176,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",182,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,740.2560000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",183,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.752,743.008,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",184,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.688,745.696,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,185,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.328,761.024,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",186,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.752,763.776,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",187,282624.0,589824.0,0,0,0.0,589824.0,589824.0,0.0,384.0,0.0,98304.0,98304.0,2.336,766.112,24576.0,0.0,282624.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,188,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.328,781.4399999999999,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",189,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.592,784.0319999999999,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",190,0.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.272,786.304,0.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,191,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,84480.0,0.8172757475083057,10616832.0,196608.0,15.936,802.24,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",192,0.0,55296.0,0,0,0.0,55296.0,55296.0,0.0,1728.0,0.0,196608.0,24576.0,2.368,804.6080000000001,49152.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",193,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.112,806.72,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",194,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.112,808.832,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",195,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.096,812.928,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",196,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.984,814.912,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",197,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,816.96,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",198,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.752,819.712,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",199,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.592,822.304,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,200,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3067648.0,122880.0,8.064,830.3679999999999,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95864.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",201,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.784,833.1519999999999,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,202,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3071872.0,122880.0,7.68,840.8319999999999,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95996.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",203,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.592,843.4239999999999,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,204,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3070144.0,122880.0,7.68,851.1039999999998,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95942.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",205,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.592,853.6959999999998,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",206,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.688,856.3839999999998,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",207,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.592,858.9759999999998,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",208,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,4.032,863.0079999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",209,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.72,865.7279999999998,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",210,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.144,867.8719999999998,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",211,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.656,870.5279999999998,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",212,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.656,873.1839999999997,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",213,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,4.032,877.2159999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",214,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.688,879.9039999999998,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",215,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.144,882.0479999999998,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",216,98304.0,8825856.0,0,0,0.0,8825856.0,8825856.0,49920.0,96.0,0.9980806142034548,73728.0,24576.0,20.224,902.2719999999998,7440384.0,1188864.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,217,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3066208.0,122880.0,7.744,910.0159999999998,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95819.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",218,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.592,912.6079999999998,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",219,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.08,914.6879999999999,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",220,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.048,916.7359999999999,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",221,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.224,920.9599999999999,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",222,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.952,922.9119999999999,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",223,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,924.896,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",224,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.72,927.616,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",225,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.656,930.2719999999999,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,226,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.552,945.824,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",227,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.592,948.4159999999999,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",228,282624.0,589824.0,0,0,0.0,589824.0,589824.0,0.0,384.0,0.0,98304.0,98304.0,2.304,950.7199999999999,24576.0,0.0,282624.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,229,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.52,966.2399999999999,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",230,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.688,968.9279999999999,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",231,0.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.4,971.3279999999999,0.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,232,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,84480.0,0.8172757475083057,10616832.0,196608.0,15.872,987.1999999999998,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",233,0.0,55296.0,0,0,0.0,55296.0,55296.0,0.0,1728.0,0.0,196608.0,24576.0,2.4,989.5999999999998,49152.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",234,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.144,991.7439999999998,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",235,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.016,993.7599999999998,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",236,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.128,997.8879999999998,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",237,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.984,999.8719999999998,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",238,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,1001.8879999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",239,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.688,1004.5759999999998,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",240,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.656,1007.2319999999997,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,241,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3067392.0,122880.0,7.68,1014.9119999999997,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95856.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",242,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.592,1017.5039999999997,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,243,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3071520.0,122880.0,7.616,1025.1199999999997,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95985.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",244,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.496,1027.6159999999998,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,245,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3073056.0,122880.0,7.968,1035.5839999999998,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96033.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",246,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.592,1038.176,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",247,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.624,1040.8,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",248,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.784,1043.584,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",249,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,4.128,1047.712,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",250,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.72,1050.432,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",251,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.112,1052.544,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",252,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.688,1055.2320000000002,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",253,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.784,1058.0160000000003,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",254,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,3.968,1061.9840000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",255,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.656,1064.6400000000003,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",256,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.048,1066.6880000000003,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",257,98304.0,8825856.0,0,0,0.0,8825856.0,8825856.0,49920.0,96.0,0.9980806142034548,73728.0,24576.0,20.256,1086.9440000000004,7440384.0,1188864.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,258,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3069536.0,122880.0,7.936,1094.8800000000003,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95923.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",259,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.56,1097.4400000000003,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",260,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.112,1099.5520000000004,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",261,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.208,1101.7600000000004,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",262,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.16,1105.9200000000005,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",263,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.952,1107.8720000000005,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",264,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,1109.9200000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",265,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.656,1112.5760000000005,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",266,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.752,1115.3280000000004,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,267,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.36,1130.6880000000003,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",268,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.496,1133.1840000000004,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",269,282624.0,589824.0,0,0,0.0,589824.0,589824.0,0.0,384.0,0.0,98304.0,98304.0,2.368,1135.5520000000004,24576.0,0.0,282624.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,270,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.424,1150.9760000000003,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",271,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.496,1153.4720000000004,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",272,0.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.176,1155.6480000000004,0.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,273,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,84480.0,0.8172757475083057,10616832.0,196608.0,16.128,1171.7760000000003,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",274,0.0,55296.0,0,0,0.0,55296.0,55296.0,0.0,1728.0,0.0,196608.0,24576.0,2.4,1174.1760000000004,49152.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",275,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.176,1176.3520000000003,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",276,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.016,1178.3680000000004,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",277,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.064,1182.4320000000005,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",278,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.984,1184.4160000000004,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",279,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,1186.4960000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",280,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.72,1189.2160000000003,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",281,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.688,1191.9040000000005,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,282,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3068608.0,122880.0,8.128,1200.0320000000004,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95894.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",283,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.624,1202.6560000000004,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,284,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3071200.0,122880.0,7.776,1210.4320000000005,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95975.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",285,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.56,1212.9920000000004,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,286,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3072224.0,122880.0,7.872,1220.8640000000005,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96007.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",287,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.56,1223.4240000000004,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",288,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.656,1226.0800000000004,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",289,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.656,1228.7360000000003,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",290,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,4.032,1232.7680000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",291,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.752,1235.5200000000002,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",292,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.208,1237.7280000000003,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",293,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.72,1240.4480000000003,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",294,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.656,1243.1040000000003,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",295,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,4.032,1247.1360000000002,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",296,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.688,1249.8240000000003,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",297,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.112,1251.9360000000004,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",298,98304.0,8825856.0,0,0,0.0,8825856.0,8825856.0,49920.0,96.0,0.9980806142034548,73728.0,24576.0,20.224,1272.1600000000003,7440384.0,1188864.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,299,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3068288.0,122880.0,7.936,1280.0960000000002,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95884.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",300,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.688,1282.7840000000003,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",301,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.112,1284.8960000000004,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",302,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.048,1286.9440000000004,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",303,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.096,1291.0400000000004,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",304,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.984,1293.0240000000003,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",305,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,1295.0720000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",306,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.848,1297.9200000000003,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",307,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.72,1300.6400000000003,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,308,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.264,1315.9040000000002,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",309,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.56,1318.4640000000002,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",310,282624.0,589824.0,0,0,0.0,589824.0,589824.0,0.0,384.0,0.0,98304.0,98304.0,2.336,1320.8000000000002,24576.0,0.0,282624.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,311,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.232,1336.0320000000002,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",312,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.688,1338.7200000000003,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",313,0.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.4,1341.1200000000003,0.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,314,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,84480.0,0.8172757475083057,10616832.0,196608.0,15.68,1356.8000000000004,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",315,0.0,55296.0,0,0,0.0,55296.0,55296.0,0.0,1728.0,0.0,196608.0,24576.0,2.4,1359.2000000000005,49152.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",316,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.08,1361.2800000000004,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",317,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.048,1363.3280000000004,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",318,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.128,1367.4560000000004,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",319,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.952,1369.4080000000004,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",320,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,1371.4240000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",321,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.688,1374.1120000000005,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",322,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.72,1376.8320000000006,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,323,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3067360.0,122880.0,7.872,1384.7040000000006,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95855.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",324,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.528,1387.2320000000007,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,325,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3070528.0,122880.0,7.744,1394.9760000000006,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95954.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",326,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.528,1397.5040000000006,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,327,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3070464.0,122880.0,7.648,1405.1520000000005,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95952.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",328,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.656,1407.8080000000004,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",329,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.688,1410.4960000000005,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",330,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.72,1413.2160000000006,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",331,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,4.0,1417.2160000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",332,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.688,1419.9040000000007,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",333,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.112,1422.0160000000008,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",334,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.688,1424.7040000000009,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",335,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.592,1427.296000000001,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",336,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,4.032,1431.3280000000009,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",337,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.656,1433.9840000000008,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",338,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.144,1436.1280000000008,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",339,98304.0,8825856.0,0,0,0.0,8825856.0,8825856.0,49920.0,96.0,0.9980806142034548,73728.0,24576.0,20.192,1456.3200000000008,7440384.0,1188864.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2304.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,340,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3066560.0,122880.0,7.712,1464.0320000000008,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95830.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",341,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.56,1466.5920000000008,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",342,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.208,1468.8000000000009,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",343,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,1.984,1470.7840000000008,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",344,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.192,1474.9760000000008,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",345,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.984,1476.9600000000007,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",346,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,1479.1040000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",347,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.752,1481.8560000000007,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",348,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.656,1484.5120000000006,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,349,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.328,1499.8400000000006,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",350,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.528,1502.3680000000006,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",351,282624.0,589824.0,0,0,0.0,589824.0,589824.0,0.0,384.0,0.0,98304.0,98304.0,2.4,1504.7680000000007,24576.0,0.0,282624.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,352,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.264,1520.0320000000006,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",353,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.752,1522.7840000000006,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",354,0.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.24,1525.0240000000006,0.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,355,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,84480.0,0.8172757475083057,10616832.0,196608.0,15.456,1540.4800000000005,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",356,0.0,55296.0,0,0,0.0,55296.0,55296.0,0.0,1728.0,0.0,196608.0,24576.0,2.336,1542.8160000000005,49152.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",357,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.112,1544.9280000000006,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",358,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.016,1546.9440000000006,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",359,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.032,1550.9760000000006,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",360,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,2.048,1553.0240000000006,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",361,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,1555.0720000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",362,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.816,1557.8880000000006,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",363,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.656,1560.5440000000006,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_128x32_tn,364,786432000.0,1573888000.0,0,0,0.0,1573888000.0,1573888000.0,4082000.0,824000.0,0.8320423970648186,103784320.0,1024000.0,112.384,1672.9280000000006,0.0,1024000.0,786432000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3243260.0,32000.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",365,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,64.0,1.728,1674.6560000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,2.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",366,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,128.0,256.0,2.624,1677.2800000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,8.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",367,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,1679.2640000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",368,0.0,256000.0,0,0,0.0,256000.0,256000.0,0.0,4000.0,0.0,1024000.0,1024000.0,3.136,1682.4000000000005,0.0,256000.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32000.0,32000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",369,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,1684.1280000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",370,0.0,0.0,0,0,0.0,0.0,0.0,4096.0,12096.0,0.25296442687747034,1028096.0,74432.0,4.32,1688.4480000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32128.0,2326.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",371,0.0,0.0,0,0,0.0,0.0,0.0,18944.0,68880.0,0.2157041355438149,4210688.0,0.0,4.64,1693.0880000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,131584.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",372,0.0,0.0,0,0,0.0,0.0,0.0,4096.0,12096.0,0.25296442687747034,1028096.0,75840.0,4.096,1697.1840000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32128.0,2370.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",373,0.0,0.0,0,0,0.0,0.0,0.0,18944.0,70416.0,0.21199641897940913,4210688.0,0.0,4.64,1701.8240000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,131584.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",374,0.0,0.0,0,0,0.0,0.0,0.0,4096.0,12096.0,0.25296442687747034,1028096.0,75968.0,3.808,1705.6320000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32128.0,2374.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",375,0.0,0.0,0,0,0.0,0.0,0.0,18944.0,68880.0,0.2157041355438149,4210688.0,0.0,4.64,1710.2720000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,131584.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",376,0.0,0.0,0,0,0.0,0.0,0.0,4096.0,12096.0,0.25296442687747034,1028096.0,74688.0,4.064,1714.336000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32128.0,2334.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",377,0.0,0.0,0,0,0.0,0.0,0.0,18944.0,68624.0,0.216334734149461,4210688.0,128.0,4.736,1719.072000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,131584.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",378,0.0,0.0,0,0,0.0,0.0,0.0,0.0,24.0,0.0,8224.0,1024.0,2.464,1721.536000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,257.0,32.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",379,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.696,1723.2320000000009,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",380,0.0,0.0,0,0,0.0,0.0,0.0,497.0,24.0,0.9539347408829175,1024.0,0.0,3.648,1726.8800000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",381,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.664,1728.5440000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",382,0.0,0.0,0,0,0.0,0.0,0.0,497.0,24.0,0.9539347408829175,1024.0,0.0,3.552,1732.0960000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",383,0.0,0.0,0,0,0.0,0.0,0.0,82944.0,16848.0,0.8311688311688312,1050368.0,14848.0,6.08,1738.1760000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32824.0,464.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",384,0.0,0.0,0,0,0.0,0.0,0.0,3664.0,64.0,0.9828326180257511,5120.0,992.0,6.528,1744.7040000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160.0,31.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",385,0.0,0.0,0,0,0.0,0.0,0.0,0.0,24000.0,0.0,1035008.0,108704.0,3.84,1748.5440000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32344.0,3397.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",386,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6000.0,0.0,1280000.0,0.0,3.616,1752.1600000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,40000.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",387,0.0,0.0,0,0,0.0,0.0,0.0,0.0,8000.0,0.0,0.0,2048000.0,2.816,1754.9760000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,64000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",388,0.0,0.0,0,0,0.0,0.0,0.0,98304.0,8000.0,0.9247441300421433,1024000.0,0.0,4.544,1759.5200000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",389,0.0,0.0,0,0,0.0,0.0,0.0,156.0,64.0,0.7090909090909091,8192.0,0.0,2.176,1761.6960000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",390,0.0,0.0,0,0,0.0,0.0,0.0,103716.0,41417.0,0.7146272729151881,4065920.0,2616864.0,11.104,1772.8000000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,127060.0,81777.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",391,0.0,0.0,0,0,0.0,0.0,0.0,29208.0,59070.0,0.3308638618908448,4079872.0,3158016.0,8.96,1781.7600000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,127496.0,98688.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",392,0.0,0.0,0,0,0.0,0.0,0.0,29916.0,59565.0,0.3343279578905019,4042112.0,3158016.0,9.44,1791.2000000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,126316.0,98688.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",393,0.0,0.0,0,0,0.0,0.0,0.0,29916.0,61167.0,0.32844767958894633,4069760.0,2711360.0,9.6,1800.8000000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,127180.0,84730.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",394,0.0,0.0,0,0,0.0,0.0,0.0,14336.0,8000.0,0.6418338108882522,2048000.0,0.0,5.152,1805.9520000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",395,0.0,0.0,0,0,0.0,0.0,0.0,39.0,16.0,0.7090909090909091,2048.0,0.0,2.368,1808.3200000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",396,0.0,0.0,0,0,0.0,0.0,0.0,27203.0,33109.0,0.45103793606579123,2730752.0,1824032.0,8.672,1816.9920000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,85336.0,57001.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",397,0.0,0.0,0,0,0.0,0.0,0.0,0.0,32000.0,0.0,3094112.0,3072000.0,5.952,1822.9440000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96691.0,96000.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",398,3584000.0,8490240.0,0,0,0.0,8490240.0,8490240.0,1056.0,10496.0,0.09141274238227147,2036608.0,1024000.0,17.376,1840.3200000000006,1066240.0,256000.0,3584000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,63644.0,32000.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",399,0.0,1310976.0,0,0,0.0,1310976.0,1310976.0,143680.0,16000.0,0.8997995991983968,1024000.0,1024000.0,47.04,1887.3600000000006,1310976.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32000.0,32000.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",400,0.0,0.0,0,0,0.0,0.0,0.0,0.0,4000.0,0.0,1024000.0,256000.0,3.328,1890.6880000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32000.0,8000.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",401,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,256.0,1.952,1892.6400000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,8.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",402,0.0,0.0,0,0,0.0,0.0,0.0,0.0,24000.0,0.0,2304000.0,117024.0,7.84,1900.4800000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,72000.0,3657.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",403,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6000.0,0.0,1280000.0,0.0,3.616,1904.0960000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,40000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",404,3584000.0,8490240.0,0,0,0.0,8490240.0,8490240.0,1056.0,10496.0,0.09141274238227147,2039296.0,1024000.0,17.344,1921.4400000000005,1066240.0,256000.0,3584000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,63728.0,32000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",405,0.0,0.0,0,0,0.0,0.0,0.0,2590.0,2034.0,0.5601211072664359,1024128.0,1056.0,6.272,1927.7120000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32004.0,33.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",406,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.208,1929.9200000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",407,0.0,0.0,0,0,0.0,0.0,0.0,2590.0,2034.0,0.5601211072664359,1024128.0,1056.0,6.24,1936.1600000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32004.0,33.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",408,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,1938.3040000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",409,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.048,1940.3520000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",410,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.008,1943.3600000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",411,0.0,294400.0,0,0,0.0,294400.0,294400.0,608.0,2008.0,0.2324159021406728,1024000.0,256.0,8.288,1951.6480000000006,294400.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32000.0,8.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",412,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.952,1953.6000000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",413,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,1956.8960000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",414,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,1958.9440000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",415,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.008,1961.9520000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",416,1769472.0,4050944.0,0,0,0.0,4050944.0,4050944.0,0.0,8000.0,0.0,0.0,1024000.0,4.0,1965.9520000000007,0.0,512000.0,1769472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,32000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",417,1280000.0,2560000.0,0,0,0.0,2560000.0,2560000.0,0.0,6000.0,0.0,2048000.0,0.0,5.376,1971.3280000000007,0.0,0.0,1280000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",418,0.0,0.0,0,0,0.0,0.0,0.0,1216.0,2008.0,0.3771712158808933,1024000.0,256.0,11.648,1982.9760000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32000.0,8.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",419,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,128.0,64.0,2.016,1984.9920000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,2.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",420,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.016,1987.0080000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",421,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,64.0,2.24,1989.2480000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,2.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",422,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,128.0,64.0,2.048,1991.2960000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,2.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",423,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,128.0,256.0,2.656,1993.9520000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,8.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",424,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,1995.6480000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",425,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,1997.3440000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",426,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.048,1999.3920000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",427,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.664,2001.0560000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",428,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,160.0,32.0,2.304,2003.3600000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",429,0.0,0.0,0,0,0.0,0.0,0.0,0.0,5.0,0.0,32.0,32.0,4.864,2008.2240000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",430,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.08,2010.3040000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",431,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,2012.3520000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",432,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,64.0,2.848,2015.2000000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,2.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",433,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.136,2018.3360000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",434,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,2020.3840000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",435,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,2022.5280000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",436,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,160.0,64.0,3.328,2025.8560000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5.0,2.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",437,0.0,0.0,0,0,0.0,0.0,0.0,96.0,8.0,0.9230769230769231,128.0,32.0,2.688,2028.5440000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",438,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,128.0,2.112,2030.6560000000006,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",439,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,32.0,2.112,2032.7680000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",440,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,160.0,0.0,2.144,2034.9120000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,5.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",441,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,64.0,2.336,2037.2480000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,2.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",442,0.0,0.0,0,0,0.0,0.0,0.0,0.0,576.0,0.0,21888.0,24576.0,6.208,2043.4560000000008,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,684.0,768.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",443,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,32.0,2.784,2046.240000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",444,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,2049.568000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",445,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,2.592,2052.160000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",446,0.0,1024.0,0,0,0.0,1024.0,1024.0,64.0,48.0,0.5714285714285714,2560.0,2048.0,2.048,2054.208000000001,0.0,1024.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,80.0,64.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",447,0.0,0.0,0,0,0.0,0.0,0.0,0.0,40.0,0.0,4096.0,4096.0,2.592,2056.800000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",448,8192.0,18432.0,0,0,0.0,18432.0,18432.0,0.0,16.0,0.0,4096.0,4096.0,2.784,2059.584000000001,0.0,2048.0,8192.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",449,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.016,2061.6000000000013,0.0,1024.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",450,7200.0,16448.0,0,0,0.0,16448.0,16448.0,0.0,16.0,0.0,4096.0,4096.0,2.784,2064.3840000000014,0.0,2048.0,7200.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",451,0.0,1024.0,0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.048,2066.432000000001,0.0,1024.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",452,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.176,2068.608000000001,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",453,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.16,2072.768000000001,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",454,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.984,2074.752000000001,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",455,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,2076.736000000001,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",456,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.624,2079.3600000000006,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",457,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.656,2082.0160000000005,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,458,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3066432.0,122880.0,7.904,2089.9200000000005,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95826.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",459,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.496,2092.4160000000006,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,460,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3070944.0,122880.0,7.712,2100.1280000000006,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95967.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",461,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.56,2102.6880000000006,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,462,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3068832.0,122880.0,7.616,2110.3040000000005,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95901.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",463,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.496,2112.8000000000006,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",464,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.72,2115.5200000000004,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",465,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.624,2118.1440000000002,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",466,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,3.968,2122.112,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",467,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.656,2124.768,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",468,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.112,2126.88,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",469,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.784,2129.664,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",470,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.656,2132.32,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",471,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,4.032,2136.3520000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",472,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.72,2139.072,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",473,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.112,2141.184,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",474,0.0,0.0,0,0,0.0,0.0,0.0,0.0,480.0,0.0,49152.0,49152.0,2.592,2143.7760000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",475,0.0,0.0,0,0,0.0,0.0,0.0,0.0,480.0,0.0,49152.0,49152.0,2.688,2146.4640000000004,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",476,98304.0,8828928.0,0,0,0.0,8828928.0,8828928.0,49920.0,96.0,0.9980806142034548,122880.0,24576.0,20.416,2166.8800000000006,7443456.0,1188864.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,477,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3067552.0,122880.0,7.744,2174.6240000000007,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95861.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",478,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.72,2177.3440000000005,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",479,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.08,2179.4240000000004,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",480,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.08,2181.5040000000004,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",481,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.224,2185.7280000000005,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",482,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.92,2187.6480000000006,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",483,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2189.6640000000007,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",484,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.752,2192.4160000000006,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",485,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.656,2195.0720000000006,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,486,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.616,2210.6880000000006,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",487,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.496,2213.1840000000007,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",488,282624.0,589824.0,0,0,0.0,589824.0,589824.0,0.0,384.0,0.0,98304.0,98304.0,2.336,2215.5200000000004,24576.0,0.0,282624.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,489,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.424,2230.9440000000004,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",490,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.624,2233.568,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",491,0.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.304,2235.8720000000003,0.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,492,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,84480.0,0.8172757475083057,10616832.0,196608.0,15.968,2251.84,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",493,0.0,55296.0,0,0,0.0,55296.0,55296.0,0.0,1728.0,0.0,196608.0,24576.0,2.368,2254.208,49152.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",494,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.144,2256.352,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",495,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.016,2258.368,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",496,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.128,2262.496,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",497,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.952,2264.4480000000003,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",498,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.952,2266.4000000000005,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",499,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.656,2269.0560000000005,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",500,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.688,2271.7440000000006,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,501,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3066592.0,122880.0,7.808,2279.5520000000006,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95831.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",502,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.56,2282.1120000000005,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,503,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3070528.0,122880.0,7.648,2289.7600000000007,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95954.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",504,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.624,2292.3840000000005,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,505,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3069472.0,122880.0,7.808,2300.1920000000005,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95921.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",506,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.496,2302.6880000000006,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",507,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.688,2305.3760000000007,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",508,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.72,2308.0960000000005,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",509,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,4.064,2312.1600000000003,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",510,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.688,2314.8480000000004,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",511,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.112,2316.9600000000005,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",512,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.72,2319.6800000000003,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",513,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.624,2322.304,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",514,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,4.0,2326.304,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",515,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.72,2329.024,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",516,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.272,2331.296,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",517,0.0,0.0,0,0,0.0,0.0,0.0,0.0,480.0,0.0,49152.0,49152.0,2.656,2333.9519999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",518,0.0,0.0,0,0,0.0,0.0,0.0,0.0,480.0,0.0,49152.0,49152.0,2.688,2336.64,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",519,98304.0,8828928.0,0,0,0.0,8828928.0,8828928.0,49920.0,96.0,0.9980806142034548,122880.0,24576.0,20.416,2357.056,7443456.0,1188864.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,520,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3067072.0,122880.0,8.0,2365.056,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95846.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",521,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.528,2367.584,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",522,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.08,2369.6639999999998,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",523,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.016,2371.68,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",524,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.096,2375.776,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",525,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.984,2377.7599999999998,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",526,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2379.776,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",527,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.752,2382.528,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",528,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.656,2385.1839999999997,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,529,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.584,2400.7679999999996,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",530,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.688,2403.4559999999997,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",531,282624.0,589824.0,0,0,0.0,589824.0,589824.0,0.0,384.0,0.0,98304.0,98304.0,2.304,2405.7599999999998,24576.0,0.0,282624.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,532,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.456,2421.216,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",533,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.56,2423.776,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",534,0.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.24,2426.0159999999996,0.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,535,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,84480.0,0.8172757475083057,10616832.0,196608.0,15.552,2441.5679999999998,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",536,0.0,55296.0,0,0,0.0,55296.0,55296.0,0.0,1728.0,0.0,196608.0,24576.0,2.592,2444.16,49152.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",537,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.144,2446.3039999999996,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",538,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,1.984,2448.2879999999996,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",539,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.224,2452.5119999999997,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",540,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.984,2454.4959999999996,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",541,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2456.5119999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",542,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.656,2459.1679999999997,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",543,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.688,2461.8559999999998,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,544,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3067232.0,122880.0,7.936,2469.792,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95851.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",545,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.528,2472.3199999999997,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,546,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3070080.0,122880.0,7.904,2480.2239999999997,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95940.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",547,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.496,2482.72,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,548,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3067936.0,122880.0,7.744,2490.464,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95873.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",549,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.56,2493.024,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",550,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.752,2495.776,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",551,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.656,2498.432,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",552,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,4.128,2502.56,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",553,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.656,2505.216,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",554,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.048,2507.2639999999997,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",555,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.688,2509.9519999999998,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",556,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.688,2512.64,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",557,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,4.032,2516.672,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",558,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.72,2519.392,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",559,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.048,2521.4399999999996,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",560,0.0,0.0,0,0,0.0,0.0,0.0,0.0,480.0,0.0,49152.0,49152.0,2.72,2524.1599999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",561,0.0,0.0,0,0,0.0,0.0,0.0,0.0,480.0,0.0,49152.0,49152.0,2.624,2526.783999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",562,98304.0,8828928.0,0,0,0.0,8828928.0,8828928.0,49920.0,96.0,0.9980806142034548,122880.0,24576.0,20.256,2547.039999999999,7443456.0,1188864.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,563,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3069376.0,122880.0,7.744,2554.783999999999,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95918.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",564,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.592,2557.3759999999993,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",565,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.144,2559.519999999999,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",566,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.048,2561.567999999999,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",567,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.16,2565.7279999999987,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",568,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.984,2567.7119999999986,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",569,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,2569.7919999999986,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",570,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.688,2572.4799999999987,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",571,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.592,2575.0719999999988,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,572,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.296,2590.3679999999986,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",573,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.72,2593.0879999999984,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",574,282624.0,589824.0,0,0,0.0,589824.0,589824.0,0.0,384.0,0.0,98304.0,98304.0,2.336,2595.423999999998,24576.0,0.0,282624.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,575,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.36,2610.7839999999983,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",576,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.752,2613.5359999999982,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",577,0.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.176,2615.711999999998,0.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,578,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,84480.0,0.8172757475083057,10616832.0,196608.0,15.744,2631.4559999999983,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",579,0.0,55296.0,0,0,0.0,55296.0,55296.0,0.0,1728.0,0.0,196608.0,24576.0,2.336,2633.791999999998,49152.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",580,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.112,2635.903999999998,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",581,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.08,2637.983999999998,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",582,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.064,2642.047999999998,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",583,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.952,2643.999999999998,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",584,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2646.0159999999983,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",585,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.688,2648.7039999999984,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",586,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.656,2651.3599999999983,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,587,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3068224.0,122880.0,7.68,2659.039999999998,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95882.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",588,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.592,2661.6319999999982,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,589,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3072128.0,122880.0,7.68,2669.311999999998,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96004.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",590,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.624,2671.935999999998,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,591,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3070400.0,122880.0,7.936,2679.871999999998,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95950.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",592,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.56,2682.431999999998,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",593,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.784,2685.215999999998,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",594,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.592,2687.807999999998,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",595,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,3.968,2691.775999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",596,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.688,2694.463999999998,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",597,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.112,2696.575999999998,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",598,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.752,2699.327999999998,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",599,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.656,2701.983999999998,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",600,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,4.0,2705.983999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",601,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.688,2708.671999999998,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",602,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.144,2710.815999999998,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",603,0.0,0.0,0,0,0.0,0.0,0.0,0.0,480.0,0.0,49152.0,49152.0,2.592,2713.407999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",604,0.0,0.0,0,0,0.0,0.0,0.0,0.0,480.0,0.0,49152.0,49152.0,2.688,2716.095999999998,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",605,98304.0,8828928.0,0,0,0.0,8828928.0,8828928.0,49920.0,96.0,0.9980806142034548,122880.0,24576.0,20.128,2736.2239999999983,7443456.0,1188864.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,606,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3067744.0,122880.0,7.936,2744.1599999999985,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95867.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",607,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.656,2746.8159999999984,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",608,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.144,2748.959999999998,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",609,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,1.984,2750.943999999998,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",610,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.096,2755.039999999998,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",611,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.952,2756.9919999999984,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",612,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,2759.0719999999983,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",613,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.816,2761.887999999998,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",614,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.752,2764.639999999998,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,615,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.36,2779.999999999998,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",616,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.56,2782.559999999998,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",617,282624.0,589824.0,0,0,0.0,589824.0,589824.0,0.0,384.0,0.0,98304.0,98304.0,2.304,2784.863999999998,24576.0,0.0,282624.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,618,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.296,2800.159999999998,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",619,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.752,2802.911999999998,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",620,0.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.208,2805.119999999998,0.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,621,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,84480.0,0.8172757475083057,10616832.0,196608.0,15.904,2821.023999999998,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",622,0.0,55296.0,0,0,0.0,55296.0,55296.0,0.0,1728.0,0.0,196608.0,24576.0,2.464,2823.487999999998,49152.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",623,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.048,2825.535999999998,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",624,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.048,2827.5839999999976,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",625,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.192,2831.7759999999976,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",626,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.92,2833.6959999999976,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",627,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2835.7119999999977,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",628,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.624,2838.3359999999975,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",629,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.848,2841.1839999999975,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,630,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3065408.0,122880.0,7.712,2848.8959999999975,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95794.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",631,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.56,2851.4559999999974,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,632,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3069600.0,122880.0,7.936,2859.3919999999976,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95925.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",633,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.528,2861.9199999999973,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,634,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3070976.0,122880.0,7.712,2869.6319999999973,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95968.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",635,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.56,2872.1919999999973,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",636,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.72,2874.911999999997,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",637,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.72,2877.631999999997,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",638,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,4.032,2881.663999999997,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",639,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.72,2884.383999999997,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",640,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.144,2886.5279999999966,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",641,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.816,2889.3439999999964,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",642,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.624,2891.967999999996,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",643,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,4.032,2895.9999999999964,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",644,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.784,2898.7839999999965,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",645,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.144,2900.9279999999962,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",646,0.0,0.0,0,0,0.0,0.0,0.0,0.0,480.0,0.0,49152.0,49152.0,2.656,2903.583999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",647,0.0,0.0,0,0,0.0,0.0,0.0,0.0,480.0,0.0,49152.0,49152.0,2.688,2906.2719999999963,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",648,98304.0,8828928.0,0,0,0.0,8828928.0,8828928.0,49920.0,96.0,0.9980806142034548,122880.0,24576.0,20.288,2926.5599999999963,7443456.0,1188864.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,649,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3066496.0,122880.0,7.872,2934.431999999996,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95828.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",650,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.496,2936.9279999999962,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",651,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.048,2938.975999999996,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",652,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.048,2941.023999999996,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",653,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.192,2945.215999999996,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",654,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.984,2947.1999999999957,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",655,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,2949.215999999996,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",656,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.688,2951.903999999996,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",657,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.656,2954.559999999996,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,658,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.328,2969.887999999996,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",659,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.688,2972.575999999996,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",660,282624.0,589824.0,0,0,0.0,589824.0,589824.0,0.0,384.0,0.0,98304.0,98304.0,2.304,2974.879999999996,24576.0,0.0,282624.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,661,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.424,2990.303999999996,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",662,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.56,2992.863999999996,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",663,0.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.208,2995.071999999996,0.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,664,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,84480.0,0.8172757475083057,10616832.0,196608.0,15.648,3010.719999999996,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",665,0.0,55296.0,0,0,0.0,55296.0,55296.0,0.0,1728.0,0.0,196608.0,24576.0,2.336,3013.055999999996,49152.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",666,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.048,3015.1039999999957,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",667,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,1.984,3017.0879999999956,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",668,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.096,3021.1839999999956,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",669,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,2.016,3023.1999999999957,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",670,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,3025.2479999999955,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",671,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.624,3027.8719999999953,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",672,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.688,3030.5599999999954,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,673,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3065760.0,122880.0,7.968,3038.5279999999952,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95805.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",674,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.528,3041.055999999995,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,675,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3069216.0,122880.0,7.872,3048.927999999995,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95913.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",676,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.56,3051.487999999995,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,677,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3070880.0,122880.0,7.776,3059.2639999999947,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95965.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",678,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.56,3061.8239999999946,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",679,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.72,3064.5439999999944,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",680,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.752,3067.2959999999944,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",681,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,4.032,3071.3279999999945,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",682,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.656,3073.9839999999945,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",683,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.08,3076.0639999999944,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",684,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.72,3078.783999999994,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",685,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.752,3081.535999999994,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",686,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,4.064,3085.599999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",687,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.688,3088.287999999994,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",688,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.368,3090.655999999994,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",689,0.0,0.0,0,0,0.0,0.0,0.0,0.0,480.0,0.0,49152.0,49152.0,2.592,3093.247999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",690,0.0,0.0,0,0,0.0,0.0,0.0,0.0,480.0,0.0,49152.0,49152.0,2.56,3095.807999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",691,98304.0,8828928.0,0,0,0.0,8828928.0,8828928.0,49920.0,96.0,0.9980806142034548,122880.0,24576.0,20.16,3115.967999999994,7443456.0,1188864.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,692,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3067712.0,122880.0,8.128,3124.095999999994,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95866.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",693,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.528,3126.623999999994,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",694,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.144,3128.7679999999937,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",695,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.016,3130.7839999999937,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",696,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.096,3134.8799999999937,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",697,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.952,3136.831999999994,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",698,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,3138.815999999994,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",699,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.656,3141.471999999994,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",700,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.688,3144.159999999994,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,701,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.648,3159.807999999994,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",702,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.592,3162.399999999994,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",703,282624.0,589824.0,0,0,0.0,589824.0,589824.0,0.0,384.0,0.0,98304.0,98304.0,2.304,3164.7039999999943,24576.0,0.0,282624.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,704,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.392,3180.095999999994,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",705,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.496,3182.591999999994,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",706,0.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.176,3184.767999999994,0.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,707,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,84480.0,0.8172757475083057,10616832.0,196608.0,15.488,3200.255999999994,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",708,0.0,55296.0,0,0,0.0,55296.0,55296.0,0.0,1728.0,0.0,196608.0,24576.0,2.592,3202.847999999994,49152.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",709,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.144,3204.991999999994,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",710,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.048,3207.0399999999936,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",711,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.256,3211.2959999999935,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",712,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.952,3213.2479999999937,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",713,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,1.984,3215.2319999999936,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",714,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.624,3217.8559999999934,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",715,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.656,3220.5119999999933,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,716,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3066752.0,122880.0,7.936,3228.4479999999935,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95836.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",717,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.592,3231.0399999999936,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,718,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3070496.0,122880.0,7.808,3238.8479999999936,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95953.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",719,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.528,3241.3759999999934,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,720,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3070048.0,122880.0,7.904,3249.2799999999934,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95939.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",721,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.464,3251.7439999999933,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",722,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.656,3254.3999999999933,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",723,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.752,3257.151999999993,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",724,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,4.064,3261.215999999993,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",725,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.72,3263.935999999993,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",726,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.144,3266.0799999999927,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",727,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.656,3268.7359999999926,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",728,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.656,3271.3919999999925,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",729,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,4.0,3275.3919999999925,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",730,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.688,3278.0799999999927,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",731,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.08,3280.1599999999926,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",732,0.0,0.0,0,0,0.0,0.0,0.0,0.0,480.0,0.0,49152.0,49152.0,2.656,3282.8159999999925,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",733,0.0,0.0,0,0,0.0,0.0,0.0,0.0,480.0,0.0,49152.0,49152.0,2.656,3285.4719999999925,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",734,98304.0,8828928.0,0,0,0.0,8828928.0,8828928.0,49920.0,96.0,0.9980806142034548,122880.0,24576.0,20.352,3305.8239999999923,7443456.0,1188864.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,735,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3068480.0,122880.0,7.84,3313.6639999999925,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95890.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",736,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.592,3316.2559999999926,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",737,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.08,3318.3359999999925,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",738,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.016,3320.3519999999926,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",739,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.16,3324.5119999999924,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",740,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.984,3326.4959999999924,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",741,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.048,3328.543999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",742,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.656,3331.199999999992,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",743,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.656,3333.855999999992,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,744,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.392,3349.247999999992,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",745,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.72,3351.9679999999917,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",746,282624.0,589824.0,0,0,0.0,589824.0,589824.0,0.0,384.0,0.0,98304.0,98304.0,2.368,3354.3359999999916,24576.0,0.0,282624.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,747,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.296,3369.6319999999914,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",748,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.56,3372.1919999999914,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",749,0.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.24,3374.431999999991,0.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,750,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,84480.0,0.8172757475083057,10616832.0,196608.0,15.648,3390.0799999999913,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",751,0.0,55296.0,0,0,0.0,55296.0,55296.0,0.0,1728.0,0.0,196608.0,24576.0,2.304,3392.3839999999914,49152.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",752,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.112,3394.4959999999915,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",753,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.016,3396.5119999999915,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",754,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.192,3400.7039999999915,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",755,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.952,3402.6559999999918,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",756,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,3404.671999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",757,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.752,3407.423999999992,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",758,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.656,3410.0799999999917,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,759,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3068352.0,122880.0,7.616,3417.6959999999917,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95886.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",760,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.56,3420.2559999999917,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,761,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3070048.0,122880.0,7.744,3427.999999999992,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95939.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",762,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.496,3430.495999999992,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,763,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3069056.0,122880.0,8.0,3438.495999999992,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95908.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",764,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.56,3441.055999999992,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",765,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.784,3443.839999999992,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",766,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.688,3446.527999999992,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",767,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,4.0,3450.527999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",768,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.688,3453.215999999992,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",769,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.08,3455.295999999992,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",770,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.656,3457.951999999992,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",771,0.0,3072.0,0,0,0.0,3072.0,3072.0,0.0,192.0,0.0,12288.0,12288.0,2.592,3460.543999999992,3072.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",772,0.0,0.0,0,0,0.0,0.0,0.0,0.0,384.0,0.0,24576.0,24576.0,4.032,3464.5759999999923,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",773,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,36864.0,24576.0,2.72,3467.295999999992,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",774,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.112,3469.407999999992,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",775,0.0,0.0,0,0,0.0,0.0,0.0,0.0,480.0,0.0,49152.0,49152.0,2.656,3472.063999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",776,0.0,0.0,0,0,0.0,0.0,0.0,0.0,480.0,0.0,49152.0,49152.0,2.816,3474.879999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",777,98304.0,8828928.0,0,0,0.0,8828928.0,8828928.0,49920.0,96.0,0.9980806142034548,122880.0,24576.0,20.128,3495.007999999992,7443456.0,1188864.0,98304.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
ampere_sgemm_32x32_sliced1x4_tn,778,19660800.0,40181760.0,0,0,0.0,40181760.0,40181760.0,126720.0,24960.0,0.8354430379746836,3067328.0,122880.0,7.904,3502.911999999992,368640.0,491520.0,19660800.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,95854.0,3840.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",779,0.0,36864.0,0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,122880.0,24576.0,2.528,3505.439999999992,30720.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3840.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",780,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.04,3508.479999999992,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",781,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.08,3510.5599999999918,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",782,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.064,3514.6239999999916,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",783,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.952,3516.575999999992,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",784,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,3518.591999999992,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",785,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.656,3521.247999999992,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",786,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.656,3523.903999999992,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_64x32_sliced1x4_tn,787,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.488,3539.3919999999916,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",788,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.56,3541.9519999999916,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",789,282624.0,589824.0,0,0,0.0,589824.0,589824.0,0.0,384.0,0.0,98304.0,98304.0,2.368,3544.3199999999915,24576.0,0.0,282624.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3072.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,790,75497472.0,153747456.0,0,0,0.0,153747456.0,153747456.0,423936.0,86016.0,0.8313253012048193,10616832.0,393216.0,15.488,3559.8079999999914,1179648.0,1572864.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",791,0.0,122880.0,0,0,0.0,122880.0,122880.0,0.0,3840.0,0.0,393216.0,98304.0,2.624,3562.431999999991,98304.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,12288.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",792,0.0,24576.0,0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.208,3564.6399999999912,0.0,24576.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,3072.0
ampere_sgemm_64x32_sliced1x4_tn,793,75497472.0,152371200.0,0,0,0.0,152371200.0,152371200.0,377856.0,84480.0,0.8172757475083057,10616832.0,196608.0,15.488,3580.127999999991,589824.0,786432.0,75497472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,331776.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",794,0.0,55296.0,0,0,0.0,55296.0,55296.0,0.0,1728.0,0.0,196608.0,24576.0,2.336,3582.463999999991,49152.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6144.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",795,6144.0,12288.0,0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.08,3584.543999999991,0.0,0.0,6144.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",796,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.048,3586.5919999999905,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",797,0.0,10504.0,0,0,0.0,10504.0,10504.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.16,3590.7519999999904,10496.0,8.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",798,8.0,16.0,0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,1.984,3592.7359999999903,0.0,0.0,8.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",799,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,3594.7519999999904,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",800,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,25344.0,24576.0,2.688,3597.4399999999905,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",801,0.0,6144.0,0,0,0.0,6144.0,6144.0,0.0,576.0,0.0,49152.0,24576.0,2.72,3600.1599999999903,0.0,6144.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1536.0,768.0
ampere_sgemm_128x32_tn,802,786432000.0,1573888000.0,0,0,0.0,1573888000.0,1573888000.0,4082000.0,824000.0,0.8320423970648186,103849248.0,1024000.0,112.128,3712.2879999999905,0.0,1024000.0,786432000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3245289.0,32000.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",803,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,64.0,1.696,3713.9839999999904,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,2.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",804,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,192.0,320.0,2.688,3716.6719999999905,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6.0,10.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",805,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,3718.7519999999904,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",806,0.0,256000.0,0,0,0.0,256000.0,256000.0,0.0,4000.0,0.0,1024000.0,1024000.0,3.488,3722.2399999999902,0.0,256000.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32000.0,32000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",807,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,3723.93599999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",808,0.0,0.0,0,0,0.0,0.0,0.0,4096.0,12096.0,0.25296442687747034,1028096.0,75584.0,3.872,3727.80799999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32128.0,2362.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",809,0.0,0.0,0,0,0.0,0.0,0.0,18944.0,68880.0,0.2157041355438149,4210688.0,0.0,4.448,3732.25599999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,131584.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",810,0.0,0.0,0,0,0.0,0.0,0.0,4096.0,12096.0,0.25296442687747034,1028096.0,74752.0,3.968,3736.2239999999897,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32128.0,2336.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",811,0.0,0.0,0,0,0.0,0.0,0.0,18944.0,70416.0,0.21199641897940913,4210688.0,0.0,4.64,3740.8639999999896,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,131584.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",812,0.0,0.0,0,0,0.0,0.0,0.0,4096.0,12096.0,0.25296442687747034,1028096.0,75520.0,4.032,3744.8959999999897,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32128.0,2360.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",813,0.0,0.0,0,0,0.0,0.0,0.0,18944.0,69040.0,0.21531187488634296,4210688.0,0.0,4.672,3749.5679999999898,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,131584.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",814,0.0,0.0,0,0,0.0,0.0,0.0,4096.0,12096.0,0.25296442687747034,1028096.0,75456.0,4.0,3753.5679999999898,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32128.0,2358.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",815,0.0,0.0,0,0,0.0,0.0,0.0,18944.0,69808.0,0.21344871101496304,4210688.0,128.0,4.544,3758.1119999999896,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,131584.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",816,0.0,0.0,0,0,0.0,0.0,0.0,0.0,24.0,0.0,8224.0,1024.0,2.592,3760.7039999999897,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,257.0,32.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",817,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.664,3762.36799999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",818,0.0,0.0,0,0,0.0,0.0,0.0,497.0,24.0,0.9539347408829175,1024.0,0.0,3.68,3766.0479999999898,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",819,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.696,3767.7439999999897,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",820,0.0,0.0,0,0,0.0,0.0,0.0,497.0,24.0,0.9539347408829175,1024.0,0.0,3.616,3771.3599999999897,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",821,0.0,0.0,0,0,0.0,0.0,0.0,65328.0,16848.0,0.7949766355140186,1050368.0,14272.0,6.08,3777.4399999999896,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32824.0,446.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",822,0.0,0.0,0,0,0.0,0.0,0.0,3664.0,64.0,0.9828326180257511,5120.0,992.0,6.56,3783.9999999999895,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,160.0,31.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",823,0.0,0.0,0,0,0.0,0.0,0.0,0.0,24000.0,0.0,1035008.0,108352.0,4.064,3788.0639999999894,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32344.0,3386.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",824,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6000.0,0.0,1280000.0,0.0,3.488,3791.551999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,40000.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",825,0.0,0.0,0,0,0.0,0.0,0.0,0.0,8000.0,0.0,0.0,2048000.0,2.848,3794.399999999989,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,64000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",826,0.0,0.0,0,0,0.0,0.0,0.0,98304.0,8000.0,0.9247441300421433,1024000.0,0.0,4.416,3798.8159999999893,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",827,0.0,0.0,0,0,0.0,0.0,0.0,156.0,64.0,0.7090909090909091,8192.0,0.0,2.176,3800.9919999999893,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",828,0.0,0.0,0,0,0.0,0.0,0.0,102108.0,39989.0,0.7185795618485964,4043392.0,2611904.0,11.168,3812.1599999999894,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,126356.0,81622.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",829,0.0,0.0,0,0,0.0,0.0,0.0,30108.0,57202.0,0.3448402244874585,4089600.0,2103904.0,9.664,3821.8239999999896,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,127800.0,65747.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",830,0.0,0.0,0,0,0.0,0.0,0.0,29916.0,58731.0,0.3374733493519239,4054144.0,3158016.0,9.632,3831.4559999999897,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,126692.0,98688.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",831,0.0,0.0,0,0,0.0,0.0,0.0,29916.0,58138.0,0.33974606491471143,4075904.0,2712192.0,9.888,3841.3439999999896,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,127372.0,84756.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",832,0.0,0.0,0,0,0.0,0.0,0.0,14336.0,8000.0,0.6418338108882522,2048000.0,0.0,5.024,3846.3679999999895,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",833,0.0,0.0,0,0,0.0,0.0,0.0,39.0,16.0,0.7090909090909091,2048.0,0.0,2.176,3848.5439999999894,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",834,0.0,0.0,0,0,0.0,0.0,0.0,27203.0,29349.0,0.4810263120667704,2729344.0,1827040.0,8.768,3857.3119999999894,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,85292.0,57095.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",835,0.0,0.0,0,0,0.0,0.0,0.0,0.0,32000.0,0.0,3094656.0,3072000.0,6.016,3863.3279999999895,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,96708.0,96000.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",836,3584000.0,8490240.0,0,0,0.0,8490240.0,8490240.0,1056.0,10496.0,0.09141274238227147,2041088.0,1024000.0,17.376,3880.7039999999897,1066240.0,256000.0,3584000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,63784.0,32000.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",837,0.0,1310976.0,0,0,0.0,1310976.0,1310976.0,143680.0,16000.0,0.8997995991983968,1024000.0,1024000.0,46.976,3927.67999999999,1310976.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32000.0,32000.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",838,0.0,0.0,0,0,0.0,0.0,0.0,0.0,4000.0,0.0,1024000.0,256000.0,3.168,3930.84799999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32000.0,8000.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",839,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,256.0,1.952,3932.79999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,8.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",840,0.0,0.0,0,0,0.0,0.0,0.0,0.0,24000.0,0.0,2304000.0,116896.0,7.968,3940.76799999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,72000.0,3653.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",841,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6000.0,0.0,1280000.0,0.0,3.456,3944.22399999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,40000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",842,3584000.0,8490240.0,0,0,0.0,8490240.0,8490240.0,1056.0,10496.0,0.09141274238227147,2065536.0,1024000.0,17.312,3961.53599999999,1066240.0,256000.0,3584000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64548.0,32000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",843,0.0,0.0,0,0,0.0,0.0,0.0,2590.0,2034.0,0.5601211072664359,1024128.0,1056.0,6.048,3967.58399999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32004.0,33.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",844,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,3969.7279999999896,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",845,0.0,0.0,0,0,0.0,0.0,0.0,2590.0,2034.0,0.5601211072664359,1024128.0,1056.0,5.952,3975.67999999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32004.0,33.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",846,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.144,3977.8239999999896,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",847,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.112,3979.9359999999897,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",848,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.944,3982.8799999999896,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",849,0.0,294400.0,0,0,0.0,294400.0,294400.0,608.0,2008.0,0.2324159021406728,1024000.0,256.0,8.192,3991.0719999999897,294400.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32000.0,8.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",850,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.08,3993.1519999999896,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",851,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.168,3996.3199999999897,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",852,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,3998.33599999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",853,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,2.976,4001.31199999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",854,1769472.0,4050944.0,0,0,0.0,4050944.0,4050944.0,0.0,8000.0,0.0,0.0,1024000.0,3.968,4005.2799999999897,0.0,512000.0,1769472.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,32000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",855,1280000.0,2560000.0,0,0,0.0,2560000.0,2560000.0,0.0,6000.0,0.0,2048000.0,0.0,5.344,4010.62399999999,0.0,0.0,1280000.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,64000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",856,0.0,0.0,0,0,0.0,0.0,0.0,1216.0,2008.0,0.3771712158808933,1024000.0,256.0,11.552,4022.17599999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,32000.0,8.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",857,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,128.0,64.0,2.016,4024.19199999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,2.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",858,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.08,4026.27199999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",859,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,64.0,2.272,4028.54399999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,2.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",860,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,128.0,64.0,2.048,4030.5919999999896,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,4.0,2.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",861,0.0,0.0,0,0,0.0,0.0,0.0,0.0,6.0,0.0,192.0,320.0,2.784,4033.3759999999897,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,6.0,10.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",862,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,4035.10399999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",863,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.632,4036.73599999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",864,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.08,4038.81599999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",865,0.0,0.0,0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,4040.54399999999,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",866,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,224.0,32.0,2.336,4042.8799999999896,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,7.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",867,0.0,0.0,0,0,0.0,0.0,0.0,0.0,5.0,0.0,32.0,32.0,4.864,4047.7439999999897,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",868,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.144,4049.8879999999895,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",869,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,4051.9039999999895,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",870,0.0,0.0,0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,64.0,2.688,4054.5919999999896,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,3.0,2.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",871,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.296,4057.8879999999895,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",872,0.0,0.0,0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.112,4059.9999999999895,0.0,0.0,0.0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,0.0,1.0,1.0
