Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum,flops_log,flops_threshold,is_matmul_candidate,is_attention_candidate,elementwise_add_fma_ops,role
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",528.0,17104896.0,36831232.0,655360.0,0.0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102784.0,45788.0,15.872,4635.199999999999,1179648.0,2097152.0,16777216.0,327680.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,659462.0,1430.875,17.439493907015127,13.845364684353797,True,False,0,Q
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",529.0,17104896.0,36831232.0,655360.0,0.0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102848.0,45600.0,16.343999999999998,4651.543999999999,1179648.0,2097152.0,16777216.0,327680.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,659464.0,1425.0,17.439493907015127,13.845364684353797,True,False,0,K
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",530.0,17104896.0,36831232.0,655360.0,0.0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102656.0,45584.0,16.308,4667.851999999999,1179648.0,2097152.0,16777216.0,327680.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,659458.0,1424.5,17.439493907015127,13.845364684353797,True,False,0,V
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",531.0,16384.0,8192.0,32768.0,0.0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.66,4672.511999999999,0.0,8192.0,0.0,16384.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1536.0,1024.0,10.620375673477872,13.845364684353797,False,False,0,other
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",532.0,6144.0,4096.0,12288.0,0.0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.324,4676.835999999998,4096.0,0.0,0.0,6144.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,512.0,512.0,9.704121561132915,13.845364684353797,False,False,0,other
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",533.0,16384.0,0.0,32768.0,0.0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.364,4682.199999999999,0.0,0.0,0.0,16384.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0,10.397238225511654,13.845364684353797,False,False,0,add
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",534.0,16384.0,8192.0,32768.0,0.0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.572,4686.771999999999,0.0,8192.0,0.0,16384.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1536.0,1024.0,10.620375673477872,13.845364684353797,False,False,0,other
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",535.0,8192.0,16384.0,0.0,0.0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.452,4690.223999999998,0.0,0.0,8192.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0,9.704121561132915,13.845364684353797,False,False,0,add
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",536.0,16384.0,8192.0,32768.0,0.0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.692,4694.915999999998,0.0,8192.0,0.0,16384.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1536.0,1024.0,10.620375673477872,13.845364684353797,False,False,0,other
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",537.0,6144.0,4096.0,12288.0,0.0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.396000000000001,4699.311999999998,4096.0,0.0,0.0,6144.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,512.0,512.0,9.704121561132915,13.845364684353797,False,False,0,other
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",538.0,16384.0,0.0,32768.0,0.0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.332,4704.643999999998,0.0,0.0,0.0,16384.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0,10.397238225511654,13.845364684353797,False,False,0,add
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",539.0,16384.0,8192.0,32768.0,0.0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.588,4709.231999999998,0.0,8192.0,0.0,16384.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1536.0,1024.0,10.620375673477872,13.845364684353797,False,False,0,other
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",540.0,8192.0,16384.0,0.0,0.0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.448,4712.6799999999985,0.0,0.0,8192.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0,9.704121561132915,13.845364684353797,False,False,0,add
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",541.0,8192.0,0.0,16384.0,0.0,0.0,16384.0,16384.0,0.0,640.0,0.0,65536.0,65536.0,4.603999999999999,4717.283999999999,0.0,0.0,0.0,8192.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0,9.704121561132915,13.845364684353797,False,False,0,add
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",542.0,8192.0,0.0,16384.0,0.0,0.0,16384.0,16384.0,0.0,640.0,0.0,65536.0,65536.0,4.584,4721.867999999999,0.0,0.0,0.0,8192.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0,9.704121561132915,13.845364684353797,False,False,0,add
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",543.0,131036.0,11771809.5,0.0,0.0,128849018880.0,11771809.5,128860790689.5,66562.25,128.0,0.9980806789445282,163840.0,32768.0,15.98,4737.847999999998,9924588.875,1585148.625,131036.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,503316480.0,5120.0,1024.0,25.581998516681075,13.845364684353797,True,True,0,Attention
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",544.0,17104896.0,36831232.0,655360.0,0.0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102720.0,45108.0,16.072000000000003,4753.919999999998,1179648.0,2097152.0,16777216.0,327680.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,659460.0,1409.625,17.439493907015127,13.845364684353797,True,False,0,Wo
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",545.0,8192.0,16384.0,0.0,0.0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.388,4757.307999999998,0.0,0.0,8192.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0,9.704121561132915,13.845364684353797,False,False,8192,elementwise_add
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",546.0,0.0,8192.0,0.0,0.0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.224,4760.531999999999,0.0,8192.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0,9.011035410141815,13.845364684353797,False,False,0,other
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",547.0,2048.0,12676.0,4096.0,0.0,0.0,16772.0,16772.0,40.0,68.0,0.3703703703703703,32768.0,32.0,6.816,4767.347999999998,12672.0,4.0,0.0,2048.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1024.0,1.0,9.727525729694754,13.845364684353797,False,False,0,other
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",548.0,1152.0,2048.0,256.0,0.0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.2760000000000002,4770.623999999998,0.0,0.0,1024.0,128.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,7.742835955430749,13.845364684353797,False,False,0,add
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",549.0,128.0,0.0,256.0,0.0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.212,4773.8359999999975,0.0,0.0,0.0,128.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,5.54907608489522,13.845364684353797,False,False,0,add
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",550.0,8192.0,8192.0,16384.0,0.0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.508000000000001,4778.343999999999,0.0,8192.0,0.0,8192.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1056.0,1024.0,10.109566325223746,13.845364684353797,False,False,0,other
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",551.0,8192.0,8192.0,16384.0,0.0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.5,4782.843999999998,0.0,8192.0,0.0,8192.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0,10.109566325223746,13.845364684353797,False,False,0,other
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",552.0,68419584.0,147324928.0,2621440.0,0.0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75303136.0,188324.0,40.128,4822.971999999999,4718592.0,8388608.0,67108864.0,1310720.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2353223.0,5885.125,18.825788248127864,13.845364684353797,True,False,0,FFN1
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",553.0,409600.0,786432.0,65536.0,0.0,0.0,851968.0,851968.0,0.0,512.0,0.0,131072.0,131072.0,3.7079999999999997,4826.6799999999985,32768.0,0.0,376832.0,32768.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,4096.0,4096.0,13.655305420172978,13.845364684353797,False,False,0,other
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",554.0,68419584.0,147324928.0,2621440.0,0.0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75308000.0,189576.0,39.879999999999995,4866.5599999999995,4718592.0,8388608.0,67108864.0,1310720.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2353375.0,5924.25,18.825788248127864,13.845364684353797,True,False,0,FFN2
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",555.0,0.0,32768.0,0.0,0.0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.436,4869.995999999999,0.0,32768.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,8192.0,4096.0,10.397238225511654,13.845364684353797,False,False,0,other
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",556.0,68222976.0,146931712.0,2228224.0,0.0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,84439456.0,45028.0,50.46,4920.455999999998,4325376.0,8388608.0,67108864.0,1114112.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2638733.0,1407.125,18.82052969090956,13.845364684353797,True,False,0,FFN3
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",557.0,8192.0,16384.0,0.0,0.0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.3880000000000003,4923.843999999998,0.0,0.0,8192.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0,9.704121561132915,13.845364684353797,False,False,8192,elementwise_add
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",558.0,0.0,8192.0,0.0,0.0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.224,4927.067999999998,0.0,8192.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0,9.011035410141815,13.845364684353797,False,False,0,other
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",559.0,2048.0,12676.0,4096.0,0.0,0.0,16772.0,16772.0,40.0,68.0,0.3703703703703703,32768.0,32.0,6.792,4933.859999999999,12672.0,4.0,0.0,2048.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1024.0,1.0,9.727525729694754,13.845364684353797,False,False,0,other
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",560.0,1152.0,2048.0,256.0,0.0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.2,4937.059999999999,0.0,0.0,1024.0,128.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,7.742835955430749,13.845364684353797,False,False,0,add
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",561.0,128.0,0.0,256.0,0.0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.196,4940.255999999999,0.0,0.0,0.0,128.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,5.54907608489522,13.845364684353797,False,False,0,add
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",562.0,8192.0,8192.0,16384.0,0.0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.492000000000001,4944.747999999999,0.0,8192.0,0.0,8192.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1056.0,1024.0,10.109566325223746,13.845364684353797,False,False,0,other
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",563.0,8192.0,8192.0,16384.0,0.0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.508000000000001,4949.2559999999985,0.0,8192.0,0.0,8192.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2048.0,1024.0,10.109566325223746,13.845364684353797,False,False,0,other
