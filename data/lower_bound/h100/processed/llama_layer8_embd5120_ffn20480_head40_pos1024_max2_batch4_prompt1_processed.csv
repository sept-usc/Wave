Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum,flops_log,flops_threshold,is_matmul_candidate,is_attention_candidate,elementwise_add_fma_ops,role
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",528.0,106659840.0,229703680.0,3604480.0,0.0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115802144.0,117620.0,51.412000000000006,11405.600000000002,6881280.0,13107200.0,104857600.0,1802240.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,3618817.0,3675.625,19.267870717091377,15.018339843011587,True,False,0,Q
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",529.0,106659840.0,229703680.0,3604480.0,0.0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115808304.0,117704.0,51.664,11457.264000000003,6881280.0,13107200.0,104857600.0,1802240.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,3619009.5,3678.25,19.267870717091377,15.018339843011587,True,False,0,K
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",530.0,106659840.0,229703680.0,3604480.0,0.0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115803008.0,118488.0,51.152,11508.416000000001,6881280.0,13107200.0,104857600.0,1802240.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,3618844.0,3702.75,19.267870717091377,15.018339843011587,True,False,0,V
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",531.0,40960.0,20480.0,81920.0,0.0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.68,11513.096000000001,0.0,20480.0,0.0,40960.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,3840.0,2560.0,11.536651757164861,15.018339843011587,False,False,0,other
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",532.0,15360.0,10240.0,30720.0,0.0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,4.476000000000001,11517.572000000002,10240.0,0.0,0.0,15360.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1280.0,1280.0,10.620375673477872,15.018339843011587,False,False,0,other
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",533.0,40960.0,0.0,81920.0,0.0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,5.9239999999999995,11523.496000000003,0.0,0.0,0.0,40960.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2560.0,2560.0,11.31351064723008,15.018339843011587,False,False,0,add
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",534.0,40960.0,20480.0,81920.0,0.0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.715999999999999,11528.212000000003,0.0,20480.0,0.0,40960.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,3840.0,2560.0,11.536651757164861,15.018339843011587,False,False,0,other
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",535.0,20480.0,40960.0,0.0,0.0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.44,11531.652000000002,0.0,0.0,20480.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,5120.0,2560.0,10.620375673477872,15.018339843011587,False,False,0,add
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",536.0,40960.0,20480.0,81920.0,0.0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.704,11536.356000000002,0.0,20480.0,0.0,40960.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,3840.0,2560.0,11.536651757164861,15.018339843011587,False,False,0,other
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",537.0,15360.0,10240.0,30720.0,0.0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,4.556,11540.912000000002,10240.0,0.0,0.0,15360.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1280.0,1280.0,10.620375673477872,15.018339843011587,False,False,0,other
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",538.0,40960.0,0.0,81920.0,0.0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,5.827999999999999,11546.740000000002,0.0,0.0,0.0,40960.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2560.0,2560.0,11.31351064723008,15.018339843011587,False,False,0,add
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",539.0,40960.0,20480.0,81920.0,0.0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.644,11551.384000000002,0.0,20480.0,0.0,40960.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,3840.0,2560.0,11.536651757164861,15.018339843011587,False,False,0,other
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",540.0,20480.0,40960.0,0.0,0.0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.436,11554.820000000003,0.0,0.0,20480.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,5120.0,2560.0,10.620375673477872,15.018339843011587,False,False,0,add
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",541.0,20480.0,0.0,40960.0,0.0,0.0,40960.0,40960.0,0.0,1600.0,0.0,163840.0,163840.0,4.715999999999999,11559.536000000004,0.0,0.0,0.0,20480.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,5120.0,5120.0,10.620375673477872,15.018339843011587,False,False,0,add
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",542.0,20480.0,0.0,40960.0,0.0,0.0,40960.0,40960.0,0.0,1600.0,0.0,163840.0,163840.0,4.74,11564.276000000002,0.0,0.0,0.0,20480.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,5120.0,5120.0,10.620375673477872,15.018339843011587,False,False,0,add
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",543.0,327592.0,29429529.0,0.0,0.0,322122547200.0,29429529.0,322151976729.0,166404.125,320.0,0.9980806616887845,409600.0,81920.0,28.032000000000004,11592.308,24811473.25,3962871.75,327592.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1258291200.0,12800.0,2560.0,26.49828924856687,15.018339843011587,True,True,0,Attention
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",544.0,106659840.0,229703680.0,3604480.0,0.0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115811600.0,118840.0,49.78,11642.088000000002,6881280.0,13107200.0,104857600.0,1802240.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,3619112.5,3713.75,19.267870717091377,15.018339843011587,True,False,0,Wo
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",545.0,20480.0,40960.0,0.0,0.0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.4,11645.488000000003,0.0,0.0,20480.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,5120.0,2560.0,10.620375673477872,15.018339843011587,False,False,20480,elementwise_add
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",546.0,0.0,20480.0,0.0,0.0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,3.3160000000000003,11648.804000000002,0.0,20480.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2560.0,2560.0,9.92725290608639,15.018339843011587,False,False,0,other
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",547.0,2048.0,24964.0,4096.0,0.0,0.0,29060.0,29060.0,40.0,164.0,0.196078431372549,81920.0,32.0,9.568,11658.372000000001,24960.0,4.0,0.0,2048.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2560.0,1.0,10.277152348094495,15.018339843011587,False,False,0,other
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",548.0,1152.0,2048.0,256.0,0.0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.36,11661.732000000002,0.0,0.0,1024.0,128.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,7.742835955430749,15.018339843011587,False,False,0,add
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",549.0,128.0,0.0,256.0,0.0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.284,11665.016,0.0,0.0,0.0,128.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,5.54907608489522,15.018339843011587,False,False,0,add
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",550.0,20480.0,20480.0,40960.0,0.0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,4.58,11669.596000000001,0.0,20480.0,0.0,20480.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2640.0,2560.0,11.025832643730768,15.018339843011587,False,False,0,other
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",551.0,20480.0,20480.0,40960.0,0.0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,4.603999999999999,11674.2,0.0,20480.0,0.0,20480.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,5120.0,2560.0,11.025832643730768,15.018339843011587,False,False,0,other
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",552.0,426639360.0,918814720.0,14417920.0,0.0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463246272.0,470932.0,182.60399999999998,11856.804000000002,27525120.0,52428800.0,419430400.0,7208960.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,14476446.0,14716.625,20.654165074996637,15.018339843011587,True,False,0,FFN1
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",553.0,1024000.0,1966080.0,163840.0,0.0,0.0,2129920.0,2129920.0,0.0,1280.0,0.0,327680.0,327680.0,3.864,11860.668000000001,81920.0,0.0,942080.0,81920.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,10240.0,10240.0,14.571595447795909,15.018339843011587,False,False,0,other
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",554.0,426639360.0,918814720.0,14417920.0,0.0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463251104.0,468104.0,183.808,12044.476000000002,27525120.0,52428800.0,419430400.0,7208960.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,14476597.0,14628.25,20.654165074996637,15.018339843011587,True,False,0,FFN2
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",555.0,0.0,81920.0,0.0,0.0,0.0,81920.0,81920.0,0.0,1920.0,0.0,655360.0,327680.0,3.564,12048.04,0.0,81920.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,20480.0,10240.0,11.31351064723008,15.018339843011587,False,False,0,other
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",556.0,426147840.0,917831680.0,13434880.0,0.0,0.0,931266560.0,931266560.0,5368320.0,4925440.0,0.5215120616761999,463770128.0,118048.0,176.828,12224.868,26542080.0,52428800.0,419430400.0,6717440.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,14492816.5,3689.0,20.65205611112408,15.018339843011587,True,False,0,FFN3
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",557.0,20480.0,40960.0,0.0,0.0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.416,12228.284000000001,0.0,0.0,20480.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,5120.0,2560.0,10.620375673477872,15.018339843011587,False,False,20480,elementwise_add
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",558.0,0.0,20480.0,0.0,0.0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,3.372,12231.656,0.0,20480.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2560.0,2560.0,9.92725290608639,15.018339843011587,False,False,0,other
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",559.0,2048.0,24964.0,4096.0,0.0,0.0,29060.0,29060.0,40.0,164.0,0.196078431372549,81920.0,32.0,9.604,12241.260000000002,24960.0,4.0,0.0,2048.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2560.0,1.0,10.277152348094495,15.018339843011587,False,False,0,other
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",560.0,1152.0,2048.0,256.0,0.0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.4,12244.660000000002,0.0,0.0,1024.0,128.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,7.742835955430749,15.018339843011587,False,False,0,add
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",561.0,128.0,0.0,256.0,0.0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.312,12247.972000000002,0.0,0.0,0.0,128.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,5.54907608489522,15.018339843011587,False,False,0,add
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",562.0,20480.0,20480.0,40960.0,0.0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,4.676,12252.648,0.0,20480.0,0.0,20480.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2640.0,2560.0,11.025832643730768,15.018339843011587,False,False,0,other
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",563.0,20480.0,20480.0,40960.0,0.0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,4.656,12257.304000000002,0.0,20480.0,0.0,20480.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,5120.0,2560.0,11.025832643730768,15.018339843011587,False,False,0,other
