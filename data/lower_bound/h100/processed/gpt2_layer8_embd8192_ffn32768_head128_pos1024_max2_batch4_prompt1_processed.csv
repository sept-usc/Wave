Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum,flops_log,flops_threshold,is_matmul_candidate,is_attention_candidate,elementwise_add_fma_ops,role
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",386.0,178244.0,568564.0,8192.0,0.0,0.0,576756.0,576756.0,80.0,2824.0,0.0275482093663911,393216.0,131328.0,21.880000000000003,17931.196000000014,174640.0,45628.0,174148.0,4096.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,12288.0,4104.0,13.265176312936774,16.14977720831756,False,False,0,other
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",387.0,808550400.0,1629880320.0,6488064.0,0.0,0.0,1636368384.0,1636368384.0,7093248.0,6690816.0,0.5145977267662135,824164128.0,393216.0,276.0,18207.19600000001,6684672.0,12582912.0,805306368.0,3244032.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,25755129.0,12288.0,21.215745223984438,16.14977720831756,True,False,0,QKV
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",388.0,131072.0,0.0,262144.0,0.0,0.0,262144.0,262144.0,0.0,4096.0,0.0,262144.0,262144.0,6.208,18213.404000000013,0.0,0.0,0.0,131072.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0,12.476653064769005,16.14977720831756,False,False,0,add
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",389.0,131072.0,0.0,262144.0,0.0,0.0,262144.0,262144.0,0.0,4096.0,0.0,262144.0,262144.0,6.2,18219.604000000014,0.0,0.0,0.0,131072.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0,12.476653064769005,16.14977720831756,False,False,0,add
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",390.0,32768.0,0.0,65536.0,0.0,0.0,65536.0,65536.0,0.0,2048.0,0.0,131072.0,131072.0,4.667999999999999,18224.272000000015,0.0,0.0,0.0,32768.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,4096.0,4096.0,11.090370147631774,16.14977720831756,False,False,0,add
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",391.0,1048576.0,34865152.0,0.0,0.0,309237645312.0,34865152.0,309272510464.0,272384.0,512.0,0.99812382739212,655360.0,131072.0,29.716,18253.988000000012,26378240.0,6389760.0,1048576.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1207959552.0,20480.0,4096.0,26.457488636079205,16.14977720831756,True,True,0,Attention
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",392.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,8192.0,0.0,0.0,157488.0,3.092,18257.080000000016,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,4921.5,0.0,16.14977720831756,False,False,0,other
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",393.0,537920512.0,1075314688.0,1050624.0,0.0,0.0,1076365312.0,1076365312.0,10753024.0,3360692.125,0.7619690726782073,281122416.0,2127424.0,148.88,18405.960000000014,0.0,524288.0,537395200.0,525312.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,8785075.5,66482.0,20.796855751288497,16.14977720831756,True,True,0,Wo
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",394.0,0.0,32768.0,0.0,0.0,0.0,32768.0,32768.0,0.0,10240.0,0.0,163840.0,0.0,4.58,18410.540000000015,32768.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,5120.0,0.0,10.397238225511654,16.14977720831756,False,False,0,other
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",395.0,32768.0,65536.0,0.0,0.0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.564,18414.104000000014,0.0,0.0,32768.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,8192.0,4096.0,11.090370147631774,16.14977720831756,False,False,32768,elementwise_add
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",396.0,178244.0,568564.0,8192.0,0.0,0.0,576756.0,576756.0,80.0,2824.0,0.0275482093663911,393216.0,131328.0,22.156,18436.260000000013,174640.0,45628.0,174148.0,4096.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,12288.0,4104.0,13.265176312936774,16.14977720831756,False,False,0,other
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",397.0,1078067200.0,2173173760.0,8650752.0,0.0,0.0,2181824512.0,2181824512.0,9457664.0,8921088.0,0.5145977267662135,1091805168.0,524288.0,356.768,18793.028000000013,8912896.0,16777216.0,1073741824.0,4325376.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,34118911.5,16384.0,21.503427296283444,16.14977720831756,True,False,0,FFN1
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",398.0,0.0,131072.0,0.0,0.0,0.0,131072.0,131072.0,0.0,2048.0,0.0,524288.0,524288.0,3.548,18796.576000000012,0.0,131072.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,16384.0,16384.0,11.783509698884497,16.14977720831756,False,False,0,other
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",399.0,0.0,262144.0,0.0,0.0,0.0,262144.0,262144.0,0.0,2048.0,0.0,524288.0,524288.0,3.572,18800.148000000016,0.0,262144.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,16384.0,16384.0,12.476653064769005,16.14977720831756,False,False,0,other
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",400.0,0.0,131072.0,0.0,0.0,0.0,131072.0,131072.0,0.0,2048.0,0.0,524288.0,524288.0,3.536,18803.684000000012,0.0,131072.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,16384.0,16384.0,11.783509698884497,16.14977720831756,False,False,0,other
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",401.0,131072.0,262144.0,0.0,0.0,0.0,262144.0,262144.0,0.0,3072.0,0.0,1048576.0,524288.0,3.7119999999999997,18807.396000000015,0.0,0.0,131072.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,32768.0,16384.0,12.476653064769005,16.14977720831756,False,False,0,add
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",402.0,0.0,131072.0,0.0,0.0,0.0,131072.0,131072.0,0.0,2048.0,0.0,524288.0,524288.0,3.532,18810.928000000014,0.0,131072.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,16384.0,16384.0,11.783509698884497,16.14977720831756,False,False,0,other
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",403.0,729282.0,1819012.0,65536.0,0.0,0.0,1884548.0,1884548.0,0.0,2048.0,0.0,524288.0,524288.0,3.6799999999999997,18814.608000000015,131072.0,294912.0,696514.0,32768.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,16384.0,16384.0,14.449199092943227,16.14977720831756,False,False,0,other
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",404.0,131072.0,262144.0,0.0,0.0,0.0,262144.0,262144.0,0.0,2048.0,0.0,524288.0,524288.0,3.612,18818.220000000016,0.0,0.0,131072.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,16384.0,16384.0,12.476653064769005,16.14977720831756,False,False,0,add
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",405.0,0.0,131072.0,0.0,0.0,0.0,131072.0,131072.0,0.0,3072.0,0.0,1048576.0,524288.0,3.788,18822.008000000016,0.0,131072.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,32768.0,16384.0,11.783509698884497,16.14977720831756,False,False,0,other
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",406.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,8192.0,0.0,0.0,157456.0,3.044,18825.052000000014,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,4920.5,0.0,16.14977720831756,False,False,0,other
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",407.0,2155880448.0,4307550208.0,8404992.0,0.0,0.0,4315955200.0,4315955200.0,43032576.0,14245746.75,0.7513285765081223,1158997916.0,17030444.0,515.912,19340.964000000014,0.0,4194304.0,2151677952.0,4202496.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,36218684.875,532201.375,22.18558450453866,16.14977720831756,True,True,0,FFN2
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",408.0,0.0,32768.0,0.0,0.0,0.0,32768.0,32768.0,0.0,10240.0,0.0,163840.0,0.0,4.596,19345.560000000012,32768.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,5120.0,0.0,10.397238225511654,16.14977720831756,False,False,0,other
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",409.0,32768.0,65536.0,0.0,0.0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.428,19348.988000000012,0.0,0.0,32768.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,8192.0,4096.0,11.090370147631774,16.14977720831756,False,False,32768,elementwise_add
