Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum,flops_log,flops_threshold,is_matmul_candidate,is_attention_candidate,elementwise_add_fma_ops,role
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",517.0,106659840.0,229703680.0,3604480.0,0.0,0.0,233308160.0,233308160.0,1374720.0,1241600.0,0.525440313111546,115841568.0,105464.0,0.049472,12.633959999999991,6881280.0,13107200.0,104857600.0,1802240.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,3620049.0,3295.75,19.267870717091377,15.018339842922684,True,False,0,Q
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",518.0,106659840.0,229703680.0,3604480.0,0.0,0.0,233308160.0,233308160.0,1374720.0,1241600.0,0.525440313111546,115840080.0,105648.0,0.049420000000000006,12.68337999999999,6881280.0,13107200.0,104857600.0,1802240.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,3620002.5,3301.5,19.267870717091377,15.018339842922684,True,False,0,K
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",519.0,106659840.0,229703680.0,3604480.0,0.0,0.0,233308160.0,233308160.0,1374720.0,1241600.0,0.525440313111546,115842688.0,105572.0,0.050159999999999996,12.73353999999999,6881280.0,13107200.0,104857600.0,1802240.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,3620084.0,3299.125,19.267870717091377,15.018339842922684,True,False,0,V
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",520.0,40960.0,20480.0,81920.0,0.0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.004588,12.738127999999993,0.0,20480.0,0.0,40960.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,3840.0,2560.0,11.536651757164861,15.018339842922684,False,False,0,other
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",521.0,15360.0,10240.0,30720.0,0.0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,0.004472,12.74259999999999,10240.0,0.0,0.0,15360.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1280.0,1280.0,10.620375673477872,15.018339842922684,False,False,0,other
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",522.0,40960.0,0.0,81920.0,0.0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,0.005868,12.748467999999992,0.0,0.0,0.0,40960.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2560.0,2560.0,11.31351064723008,15.018339842922684,False,False,0,add
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",523.0,40960.0,20480.0,81920.0,0.0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.004688,12.75315599999999,0.0,20480.0,0.0,40960.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,3840.0,2560.0,11.536651757164861,15.018339842922684,False,False,0,other
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",524.0,20480.0,40960.0,0.0,0.0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.00342,12.756575999999992,0.0,0.0,20480.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,5120.0,2560.0,10.620375673477872,15.018339842922684,False,False,0,add
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",525.0,40960.0,20480.0,81920.0,0.0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.004616,12.76119199999999,0.0,20480.0,0.0,40960.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,3840.0,2560.0,11.536651757164861,15.018339842922684,False,False,0,other
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",526.0,15360.0,10240.0,30720.0,0.0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,0.0045000000000000005,12.76569199999999,10240.0,0.0,0.0,15360.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1280.0,1280.0,10.620375673477872,15.018339842922684,False,False,0,other
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",527.0,40960.0,0.0,81920.0,0.0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,0.005808,12.77149999999999,0.0,0.0,0.0,40960.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2560.0,2560.0,11.31351064723008,15.018339842922684,False,False,0,add
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",528.0,40960.0,20480.0,81920.0,0.0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.004656,12.77615599999999,0.0,20480.0,0.0,40960.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,3840.0,2560.0,11.536651757164861,15.018339842922684,False,False,0,other
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",529.0,20480.0,40960.0,0.0,0.0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.003472,12.77962799999999,0.0,0.0,20480.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,5120.0,2560.0,10.620375673477872,15.018339842922684,False,False,0,add
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",530.0,20480.0,0.0,40960.0,0.0,0.0,40960.0,40960.0,0.0,1600.0,0.0,163840.0,163840.0,0.004752,12.78437999999999,0.0,0.0,0.0,20480.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,5120.0,5120.0,10.620375673477872,15.018339842922684,False,False,0,add
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",531.0,20480.0,0.0,40960.0,0.0,0.0,40960.0,40960.0,0.0,1600.0,0.0,163840.0,163840.0,0.0047,12.78907999999999,0.0,0.0,0.0,20480.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,5120.0,5120.0,10.620375673477872,15.018339842922684,False,False,0,add
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",532.0,327432.0,29429112.25,0.0,0.0,322122547200.0,29429112.25,322151976312.25,166412.0,320.0,0.9980807523359172,409600.0,81920.0,0.02802,12.81709999999999,24811388.25,3962860.0,327432.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1258291200.0,12800.0,2560.0,26.498289247273227,15.018339842922684,True,True,0,Attention
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",533.0,106659840.0,229703680.0,3604480.0,0.0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115814576.0,117080.0,0.051404,12.868503999999989,6881280.0,13107200.0,104857600.0,1802240.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,3619205.5,3658.75,19.267870717091377,15.018339842922684,True,False,0,Wo
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",534.0,20480.0,40960.0,0.0,0.0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.003424,12.87192799999999,0.0,0.0,20480.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,5120.0,2560.0,10.620375673477872,15.018339842922684,False,False,20480,elementwise_add
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",535.0,0.0,20480.0,0.0,0.0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,0.003352,12.87527999999999,0.0,20480.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2560.0,2560.0,9.92725290608639,15.018339842922684,False,False,0,other
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",536.0,2048.0,24964.0,4096.0,0.0,0.0,29060.0,29060.0,40.0,164.0,0.196078431372549,81920.0,32.0,0.00954,12.88481999999999,24960.0,4.0,0.0,2048.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2560.0,1.0,10.277152348094495,15.018339842922684,False,False,0,other
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",537.0,1152.0,2048.0,256.0,0.0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003264,12.888083999999989,0.0,0.0,1024.0,128.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,7.742835955430749,15.018339842922684,False,False,0,add
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",538.0,128.0,0.0,256.0,0.0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003336,12.89141999999999,0.0,0.0,0.0,128.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,5.54907608489522,15.018339842922684,False,False,0,add
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",539.0,20480.0,20480.0,40960.0,0.0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,0.004632,12.89605199999999,0.0,20480.0,0.0,20480.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2640.0,2560.0,11.025832643730768,15.018339842922684,False,False,0,other
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",540.0,20480.0,20480.0,40960.0,0.0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,0.004596,12.90064799999999,0.0,20480.0,0.0,20480.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,5120.0,2560.0,11.025832643730768,15.018339842922684,False,False,0,other
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",541.0,426639360.0,918814720.0,14417920.0,0.0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463214672.0,470992.0,0.181948,13.082595999999988,27525120.0,52428800.0,419430400.0,7208960.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,14475458.5,14718.5,20.654165074996637,15.018339842922684,True,False,0,FFN1
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",542.0,1024000.0,1966080.0,163840.0,0.0,0.0,2129920.0,2129920.0,0.0,1280.0,0.0,327680.0,327680.0,0.003844,13.086439999999989,81920.0,0.0,942080.0,81920.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,10240.0,10240.0,14.571595447795909,15.018339842922684,False,False,0,other
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",543.0,426639360.0,918814720.0,14417920.0,0.0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463252448.0,468416.0,0.181964,13.26840399999999,27525120.0,52428800.0,419430400.0,7208960.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,14476639.0,14638.0,20.654165074996637,15.018339842922684,True,False,0,FFN2
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",544.0,0.0,81920.0,0.0,0.0,0.0,81920.0,81920.0,0.0,1920.0,0.0,655360.0,327680.0,0.0036360000000000003,13.272039999999988,0.0,81920.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,20480.0,10240.0,11.31351064723008,15.018339842922684,False,False,0,other
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",545.0,426147840.0,917831680.0,13434880.0,0.0,0.0,931266560.0,931266560.0,5368320.0,4925440.0,0.5215120616761999,463838464.0,118032.0,0.174624,13.446663999999988,26542080.0,52428800.0,419430400.0,6717440.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,14494952.0,3688.5,20.65205611112408,15.018339842922684,True,False,0,FFN3
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",546.0,20480.0,40960.0,0.0,0.0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.00348,13.45014399999999,0.0,0.0,20480.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,5120.0,2560.0,10.620375673477872,15.018339842922684,False,False,20480,elementwise_add
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",547.0,0.0,20480.0,0.0,0.0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,0.0033959999999999997,13.453539999999988,0.0,20480.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2560.0,2560.0,9.92725290608639,15.018339842922684,False,False,0,other
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",548.0,2048.0,24964.0,4096.0,0.0,0.0,29060.0,29060.0,40.0,164.0,0.196078431372549,81920.0,32.0,0.009592,13.46313199999999,24960.0,4.0,0.0,2048.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2560.0,1.0,10.277152348094495,15.018339842922684,False,False,0,other
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",549.0,1152.0,2048.0,256.0,0.0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003284,13.46641599999999,0.0,0.0,1024.0,128.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,7.742835955430749,15.018339842922684,False,False,0,add
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",550.0,128.0,0.0,256.0,0.0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003364,13.46977999999999,0.0,0.0,0.0,128.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,5.54907608489522,15.018339842922684,False,False,0,add
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",551.0,20480.0,20480.0,40960.0,0.0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,0.004592,13.474371999999988,0.0,20480.0,0.0,20480.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2640.0,2560.0,11.025832643730768,15.018339842922684,False,False,0,other
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",552.0,20480.0,20480.0,40960.0,0.0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,0.004572,13.478943999999988,0.0,20480.0,0.0,20480.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,5120.0,2560.0,11.025832643730768,15.018339842922684,False,False,0,other
