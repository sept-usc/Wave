Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum,flops_log,flops_threshold,is_matmul_candidate,is_attention_candidate,elementwise_add_fma_ops,role
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",566.0,272891904.0,587726848.0,8912896.0,0.0,0.0,596639744.0,596639744.0,3477504.0,3166208.0,0.5234278668310728,299918992.0,171840.0,0.14156400000000002,33.278648000000004,17301504.0,33554432.0,268435456.0,4456448.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,9372468.5,5370.0,20.20682404700129,15.039384953804394,True,False,0,Q
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",567.0,272891904.0,587726848.0,8912896.0,0.0,0.0,596639744.0,596639744.0,3477504.0,3166208.0,0.5234278668310728,299382880.0,171508.0,0.14095600000000003,33.41960399999999,17301504.0,33554432.0,268435456.0,4456448.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,9355715.0,5359.625,20.20682404700129,15.039384953804394,True,False,0,K
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",568.0,272891904.0,587726848.0,8912896.0,0.0,0.0,596639744.0,596639744.0,3477504.0,3166208.0,0.5234278668310728,298988064.0,171348.0,0.14133600000000002,33.56094,17301504.0,33554432.0,268435456.0,4456448.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,9343377.0,5354.625,20.20682404700129,15.039384953804394,True,False,0,V
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",569.0,65536.0,32768.0,131072.0,0.0,0.0,163840.0,163840.0,0.0,3072.0,0.0,196608.0,131072.0,0.004724,33.565664,0.0,32768.0,0.0,65536.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,6144.0,4096.0,12.006651724330279,15.039384953804394,False,False,0,other
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",570.0,24576.0,16384.0,49152.0,0.0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.004532,33.570195999999996,16384.0,0.0,0.0,24576.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0,11.090370147631774,15.039384953804394,False,False,0,other
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",571.0,65536.0,0.0,131072.0,0.0,0.0,131072.0,131072.0,0.0,2048.0,0.0,131072.0,131072.0,0.006056,33.576252,0.0,0.0,0.0,65536.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,4096.0,4096.0,11.783509698884497,15.039384953804394,False,False,0,add
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",572.0,65536.0,32768.0,131072.0,0.0,0.0,163840.0,163840.0,0.0,3072.0,0.0,196608.0,131072.0,0.004848,33.5811,0.0,32768.0,0.0,65536.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,6144.0,4096.0,12.006651724330279,15.039384953804394,False,False,0,other
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",573.0,32768.0,65536.0,0.0,0.0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,0.00352,33.58462,0.0,0.0,32768.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,8192.0,4096.0,11.090370147631774,15.039384953804394,False,False,0,add
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",574.0,65536.0,32768.0,131072.0,0.0,0.0,163840.0,163840.0,0.0,3072.0,0.0,196608.0,131072.0,0.004784,33.589403999999995,0.0,32768.0,0.0,65536.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,6144.0,4096.0,12.006651724330279,15.039384953804394,False,False,0,other
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",575.0,24576.0,16384.0,49152.0,0.0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.0045839999999999995,33.593987999999996,16384.0,0.0,0.0,24576.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0,11.090370147631774,15.039384953804394,False,False,0,other
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",576.0,65536.0,0.0,131072.0,0.0,0.0,131072.0,131072.0,0.0,2048.0,0.0,131072.0,131072.0,0.006,33.599988,0.0,0.0,0.0,65536.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,4096.0,4096.0,11.783509698884497,15.039384953804394,False,False,0,add
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",577.0,65536.0,32768.0,131072.0,0.0,0.0,163840.0,163840.0,0.0,3072.0,0.0,196608.0,131072.0,0.00476,33.604748,0.0,32768.0,0.0,65536.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,6144.0,4096.0,12.006651724330279,15.039384953804394,False,False,0,other
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",578.0,32768.0,65536.0,0.0,0.0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,0.003468,33.608216,0.0,0.0,32768.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,8192.0,4096.0,11.090370147631774,15.039384953804394,False,False,0,add
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",579.0,32768.0,0.0,65536.0,0.0,0.0,65536.0,65536.0,0.0,2560.0,0.0,262144.0,262144.0,0.004884,33.613099999999996,0.0,0.0,0.0,32768.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0,11.090370147631774,15.039384953804394,False,False,0,add
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",580.0,32768.0,0.0,65536.0,0.0,0.0,65536.0,65536.0,0.0,2560.0,0.0,262144.0,262144.0,0.004868,33.617968000000005,0.0,0.0,0.0,32768.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0,11.090370147631774,15.039384953804394,False,False,0,add
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",581.0,524272.0,47087574.0,0.0,0.0,515396075520.0,47087574.0,515443163094.0,266240.75,512.0,0.9980806195998791,655360.0,131072.0,0.0286,33.646568,39698423.5,6340606.5,524272.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2013265920.0,20480.0,4096.0,26.968292878447013,15.039384953804394,True,True,0,Attention
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",582.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,8192.0,0.0,0.0,158464.0,0.003108,33.649676,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,4952.0,0.0,15.039384953804394,False,False,0,other
"void sgemm_largek_lds64<1, 0, 6, 3, 4, 5, 2, 66>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",583.0,537920512.0,1075314688.0,1050624.0,0.0,0.0,1076365312.0,1076365312.0,10753024.0,3606150.25,0.7488911250866159,282558860.0,2128400.0,0.161992,33.811668,0.0,524288.0,537395200.0,525312.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,8829964.375,66512.5,20.796855751288497,15.039384953804394,True,True,0,Wo
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",584.0,32768.0,65536.0,0.0,0.0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,0.003464,33.815132,0.0,0.0,32768.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,8192.0,4096.0,11.090370147631774,15.039384953804394,False,False,32768,elementwise_add
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",585.0,0.0,32768.0,0.0,0.0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,0.003396,33.81852800000001,0.0,32768.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,4096.0,4096.0,10.397238225511654,15.039384953804394,False,False,0,other
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",586.0,8192.0,52228.0,16384.0,0.0,0.0,68612.0,68612.0,320.0,260.0,0.5517241379310345,131072.0,128.0,0.006836,33.825364,52224.0,4.0,0.0,8192.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,4096.0,4.0,11.13623730013347,15.039384953804394,False,False,0,other
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",587.0,1152.0,2048.0,256.0,0.0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.0032359999999999997,33.82860000000001,0.0,0.0,1024.0,128.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,7.742835955430749,15.039384953804394,False,False,0,add
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",588.0,128.0,0.0,256.0,0.0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003236,33.831836,0.0,0.0,0.0,128.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,5.54907608489522,15.039384953804394,False,False,0,add
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",589.0,32768.0,32768.0,65536.0,0.0,0.0,98304.0,98304.0,0.0,3072.0,0.0,135168.0,131072.0,0.004788,33.836624,0.0,32768.0,0.0,32768.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,4224.0,4096.0,11.495830169541591,15.039384953804394,False,False,0,other
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",590.0,32768.0,32768.0,65536.0,0.0,0.0,98304.0,98304.0,0.0,3072.0,0.0,262144.0,131072.0,0.0047279999999999996,33.841352,0.0,32768.0,0.0,32768.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,8192.0,4096.0,11.495830169541591,15.039384953804394,False,False,0,other
"void scal_64addr_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",591.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,32768.0,0.0,0.0,1179872.0,0.003568,33.84492,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,36871.0,0.0,15.039384953804394,False,False,0,other
"void sgemm_largek_lds64<1, 0, 6, 3, 4, 5, 2, 66>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",592.0,2164277248.0,4320133120.0,16809984.0,0.0,0.0,4336943104.0,4336943104.0,43073536.0,9768083.625,0.8151442530878699,1149777060.0,34070768.0,0.580084,34.425004,0.0,8388608.0,2155872256.0,8404992.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,35930533.125,1064711.5,22.19043558319849,15.039384953804394,True,True,0,FFN1
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",593.0,1638400.0,3145728.0,262144.0,0.0,0.0,3407872.0,3407872.0,0.0,2048.0,0.0,524288.0,524288.0,0.0038480000000000003,34.428852,131072.0,0.0,1507328.0,131072.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,16384.0,16384.0,15.04159890097876,15.039384953804394,True,False,0,other
"void scal_64addr_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",594.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,32768.0,0.0,0.0,1177296.0,0.003448,34.4323,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,36790.5,0.0,15.039384953804394,False,False,0,other
"void sgemm_largek_lds64<1, 0, 6, 3, 4, 5, 2, 66>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",595.0,2164277248.0,4320133120.0,16809984.0,0.0,0.0,4336943104.0,4336943104.0,43073536.0,9776937.875,0.8150077221001457,1150113220.0,34070460.0,0.578776,35.011076,0.0,8388608.0,2155872256.0,8404992.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,35941038.125,1064701.875,22.19043558319849,15.039384953804394,True,True,0,FFN2
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",596.0,0.0,131072.0,0.0,0.0,0.0,131072.0,131072.0,0.0,3072.0,0.0,1048576.0,524288.0,0.00384,35.014916,0.0,131072.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,32768.0,16384.0,11.783509698884497,15.039384953804394,False,False,0,other
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",597.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,8192.0,0.0,0.0,157008.0,0.003144,35.018060000000006,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,4906.5,0.0,15.039384953804394,False,False,0,other
"void sgemm_largek_lds64<1, 0, 6, 3, 4, 5, 2, 66>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",598.0,2151682048.0,4301258752.0,4202496.0,0.0,0.0,4305461248.0,4305461248.0,43012096.0,13710059.875,0.7583178011412854,1142851396.0,8516224.0,0.6466160000000001,35.664676,0.0,2097152.0,2149580800.0,2101248.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,35714106.125,266132.0,22.183150111711598,15.039384953804394,True,True,0,FFN3
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",599.0,32768.0,65536.0,0.0,0.0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,0.003556,35.668232,0.0,0.0,32768.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,8192.0,4096.0,11.090370147631774,15.039384953804394,False,False,32768,elementwise_add
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",600.0,0.0,32768.0,0.0,0.0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,0.003356,35.671588,0.0,32768.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,4096.0,4096.0,10.397238225511654,15.039384953804394,False,False,0,other
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",601.0,8192.0,52228.0,16384.0,0.0,0.0,68612.0,68612.0,320.0,260.0,0.5517241379310345,131072.0,128.0,0.00676,35.678348,52224.0,4.0,0.0,8192.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,4096.0,4.0,11.13623730013347,15.039384953804394,False,False,0,other
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",602.0,1152.0,2048.0,256.0,0.0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003252,35.6816,0.0,0.0,1024.0,128.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,7.742835955430749,15.039384953804394,False,False,0,add
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",603.0,128.0,0.0,256.0,0.0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003212,35.684812,0.0,0.0,0.0,128.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,5.54907608489522,15.039384953804394,False,False,0,add
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",604.0,32768.0,32768.0,65536.0,0.0,0.0,98304.0,98304.0,0.0,3072.0,0.0,135168.0,131072.0,0.004763999999999999,35.689576,0.0,32768.0,0.0,32768.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,4224.0,4096.0,11.495830169541591,15.039384953804394,False,False,0,other
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",605.0,32768.0,32768.0,65536.0,0.0,0.0,98304.0,98304.0,0.0,3072.0,0.0,262144.0,131072.0,0.004739999999999999,35.694316,0.0,32768.0,0.0,32768.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,8192.0,4096.0,11.495830169541591,15.039384953804394,False,False,0,other
