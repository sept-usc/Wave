Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.784,2.784,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.72,5.504,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.72,8.224,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.264,11.488,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.552,15.04,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",6,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,3.744,18.784,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",7,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.192,22.976,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",8,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,5.312,28.288,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",9,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.68,31.968,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",10,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.784,34.752,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.72,37.472,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.008,40.480000000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,0.0,0.0,0.0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,3.84,44.32000000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,47.74400000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",15,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.064,51.80800000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",16,0.0,0.0,0.0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,32.0,32.0,4.128,55.93600000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",17,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,59.168000000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",18,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,62.49600000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",19,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,3.36,65.85600000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",20,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,768.0,0.0,8704.0,32768.0,5.792,71.64800000000001,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,272.0,1024.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",21,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.552,75.20000000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",22,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,5.44,80.64000000000001,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",23,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.616,84.25600000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",24,0.0,512.0,0.0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,3.456,87.71200000000002,0.0,512.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",25,384.0,0.0,768.0,0,0.0,768.0,768.0,0.0,20.0,0.0,2048.0,2048.0,4.32,92.03200000000001,0.0,0.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",26,4096.0,9216.0,0.0,0,0.0,9216.0,9216.0,0.0,32.0,0.0,2048.0,2048.0,4.192,96.22400000000002,0.0,1024.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",27,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,3.328,99.55200000000002,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",28,3584.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,32.0,0.0,2048.0,2048.0,4.192,103.74400000000003,0.0,1024.0,3584.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",29,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,3.168,106.91200000000003,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",30,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.616,110.52800000000003,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",31,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,7.072,117.60000000000004,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",32,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,120.86400000000003,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",33,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.2,124.06400000000004,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",34,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.48,128.54400000000004,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",35,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.512,133.05600000000004,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",36,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,44320.0,15.968,149.02400000000003,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1385.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",37,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,44704.0,16.192,165.21600000000004,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1397.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",38,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,45504.0,16.992,182.20800000000003,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1422.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",39,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.48,186.68800000000002,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",40,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.416,191.104,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",41,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.472,196.57600000000002,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",42,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.672,201.24800000000002,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",43,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.456,204.704,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",44,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.64,209.344,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",45,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.384,213.728,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",46,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.568,219.29600000000002,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",47,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.864,224.16000000000003,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",48,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.424,227.58400000000003,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",49,131072.0,11767808.0,0.0,0,128849018880.0,11767808.0,128860786688.0,66560.0,128.0,0.9980806142034548,98304.0,32768.0,15.872,243.45600000000002,9920512.0,1585152.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,503316480.0,3072.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",50,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,46720.0,15.936,259.392,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1460.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",51,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.36,262.752,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",52,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.136,265.88800000000003,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",53,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,6.368,272.25600000000003,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",54,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.168,275.42400000000004,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",55,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,278.752,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",56,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.48,283.232,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",57,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.32,287.552,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",58,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75237760.0,191264.0,40.512,328.064,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2351180.0,5977.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",59,409600.0,786432.0,65536.0,0,0.0,851968.0,851968.0,0.0,512.0,0.0,131072.0,131072.0,3.68,331.744,32768.0,0.0,376832.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",60,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75359360.0,189280.0,40.32,372.064,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2354980.0,5915.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",61,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.456,375.52000000000004,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",62,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,84434304.0,43200.0,51.04,426.56000000000006,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2638572.0,1350.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",63,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.712,430.27200000000005,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",64,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.52,433.79200000000003,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",65,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,6.496,440.288,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",66,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,443.552,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",67,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,446.78400000000005,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",68,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.48,451.26400000000007,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",69,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.352,455.61600000000004,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",70,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,46848.0,16.352,471.968,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1464.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",71,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,42976.0,16.064,488.03200000000004,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1343.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",72,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,43968.0,16.224,504.25600000000003,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1374.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",73,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.32,508.576,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",74,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.448,513.024,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",75,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.856,518.88,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",76,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.672,523.552,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",77,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.392,526.9440000000001,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",78,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.64,531.5840000000001,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",79,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.48,536.0640000000001,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",80,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.184,541.248,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",81,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.608,545.856,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",82,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.488,549.344,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",83,131072.0,11767808.0,0.0,0,128849018880.0,11767808.0,128860786688.0,66560.0,128.0,0.9980806142034548,98304.0,32768.0,15.84,565.1840000000001,9920512.0,1585152.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,503316480.0,3072.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",84,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21103616.0,45120.0,16.0,581.1840000000001,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659488.0,1410.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",85,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.264,584.4480000000001,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",86,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.328,587.7760000000001,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",87,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,6.944,594.72,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",88,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.072,597.792,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",89,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.136,600.928,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",90,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.512,605.4399999999999,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",91,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.608,610.0479999999999,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",92,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75172992.0,190176.0,41.952,651.9999999999999,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2349156.0,5943.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",93,409600.0,786432.0,65536.0,0,0.0,851968.0,851968.0,0.0,512.0,0.0,131072.0,131072.0,3.872,655.8719999999998,32768.0,0.0,376832.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",94,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75313024.0,191136.0,40.48,696.3519999999999,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2353532.0,5973.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",95,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.456,699.8079999999999,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",96,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,84438912.0,45280.0,51.392,751.1999999999999,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2638716.0,1415.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",97,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.36,754.56,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",98,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.392,757.952,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",99,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,6.752,764.704,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",100,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.008,767.712,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",101,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,770.944,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",102,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.448,775.3919999999999,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",103,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.416,779.808,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",104,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,46208.0,16.704,796.512,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1444.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",105,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,44288.0,16.352,812.8639999999999,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",106,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,44960.0,16.768,829.632,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1405.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",107,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.48,834.112,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",108,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.288,838.4,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",109,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.28,843.68,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",110,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.8,848.4799999999999,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",111,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.552,852.0319999999999,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",112,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.544,856.5759999999999,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",113,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.32,860.896,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",114,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.6,866.496,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",115,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.448,870.944,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",116,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.264,874.208,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",117,131072.0,11767808.0,0.0,0,128849018880.0,11767808.0,128860786688.0,66560.0,128.0,0.9980806142034548,98304.0,32768.0,15.744,889.952,9920512.0,1585152.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,503316480.0,3072.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",118,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21108096.0,45504.0,16.448,906.4,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659628.0,1422.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",119,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.584,909.9839999999999,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",120,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.584,913.5679999999999,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",121,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,6.304,919.8719999999998,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",122,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.104,922.9759999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",123,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,926.3039999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",124,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.416,930.7199999999999,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",125,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.576,935.2959999999999,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",126,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75281408.0,187584.0,40.288,975.584,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2352544.0,5862.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",127,409600.0,786432.0,65536.0,0,0.0,851968.0,851968.0,0.0,512.0,0.0,131072.0,131072.0,3.68,979.2639999999999,32768.0,0.0,376832.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",128,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75315328.0,189792.0,41.12,1020.3839999999999,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2353604.0,5931.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",129,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.36,1023.7439999999999,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",130,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,84427520.0,45952.0,50.688,1074.432,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2638360.0,1436.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",131,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.488,1077.92,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",132,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.36,1081.28,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",133,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,6.848,1088.128,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",134,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.36,1091.4879999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",135,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,1094.7839999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",136,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.672,1099.456,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",137,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.288,1103.744,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",138,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,43456.0,16.256,1120.0,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1358.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",139,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,46464.0,16.064,1136.064,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1452.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",140,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,45120.0,16.256,1152.3200000000002,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1410.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",141,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.512,1156.832,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",142,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.416,1161.248,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",143,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.632,1166.88,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",144,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.512,1171.392,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",145,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.328,1174.72,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",146,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.544,1179.2640000000001,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",147,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.448,1183.7120000000002,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",148,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.6,1189.3120000000001,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",149,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.416,1193.728,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",150,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.552,1197.28,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",151,131072.0,11767808.0,0.0,0,128849018880.0,11767808.0,128860786688.0,66560.0,128.0,0.9980806142034548,98304.0,32768.0,15.872,1213.152,9920512.0,1585152.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,503316480.0,3072.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",152,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21107200.0,43200.0,16.352,1229.5040000000001,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659600.0,1350.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",153,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.264,1232.768,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",154,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.296,1236.064,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",155,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,6.816,1242.88,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",156,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,2.976,1245.8560000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",157,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.2,1249.0560000000003,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",158,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.672,1253.7280000000003,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",159,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.416,1258.1440000000002,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",160,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,74996096.0,189376.0,39.392,1297.5360000000003,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2343628.0,5918.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",161,409600.0,786432.0,65536.0,0,0.0,851968.0,851968.0,0.0,512.0,0.0,131072.0,131072.0,3.584,1301.1200000000003,32768.0,0.0,376832.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",162,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75307648.0,187104.0,39.84,1340.9600000000003,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2353364.0,5847.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",163,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.296,1344.2560000000003,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",164,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,84431488.0,45664.0,51.328,1395.5840000000003,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2638484.0,1427.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",165,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.424,1399.0080000000003,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",166,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.328,1402.3360000000002,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",167,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,7.008,1409.3440000000003,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",168,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.104,1412.4480000000003,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",169,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.136,1415.5840000000003,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",170,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.384,1419.9680000000003,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",171,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.608,1424.5760000000002,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",172,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,44960.0,16.288,1440.8640000000003,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1405.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",173,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,47616.0,16.704,1457.5680000000002,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1488.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",174,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,46304.0,16.544,1474.1120000000003,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1447.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",175,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.512,1478.6240000000003,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",176,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.32,1482.9440000000002,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",177,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.024,1487.968,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",178,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.416,1492.384,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",179,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.36,1495.744,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",180,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.544,1500.288,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",181,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.448,1504.736,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",182,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.696,1510.432,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",183,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.576,1515.008,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",184,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.232,1518.24,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",185,131072.0,11767808.0,0.0,0,128849018880.0,11767808.0,128860786688.0,66560.0,128.0,0.9980806142034548,98304.0,32768.0,15.648,1533.888,9920512.0,1585152.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,503316480.0,3072.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",186,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,43616.0,15.808,1549.696,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1363.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",187,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.392,1553.088,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",188,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.488,1556.576,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",189,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,6.56,1563.136,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",190,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,1566.368,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",191,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,1569.664,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",192,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.544,1574.208,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",193,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.512,1578.72,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",194,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75378560.0,191008.0,40.288,1619.008,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2355580.0,5969.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",195,409600.0,786432.0,65536.0,0,0.0,851968.0,851968.0,0.0,512.0,0.0,131072.0,131072.0,3.712,1622.72,32768.0,0.0,376832.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",196,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75343616.0,192800.0,40.96,1663.68,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2354488.0,6025.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",197,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.712,1667.392,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",198,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,84420992.0,42592.0,50.56,1717.952,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2638156.0,1331.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",199,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.776,1721.728,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",200,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.328,1725.056,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",201,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,6.304,1731.3600000000001,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",202,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.104,1734.4640000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",203,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,1737.7600000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",204,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.416,1742.1760000000002,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",205,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.384,1746.5600000000002,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",206,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,45472.0,16.32,1762.88,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1421.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",207,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,44704.0,15.968,1778.8480000000002,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1397.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",208,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,45664.0,16.544,1795.3920000000003,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1427.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",209,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.512,1799.9040000000002,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",210,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.224,1804.1280000000002,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",211,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.728,1809.8560000000002,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",212,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.416,1814.2720000000002,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",213,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.296,1817.5680000000002,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",214,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.544,1822.1120000000003,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",215,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.288,1826.4000000000003,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",216,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.248,1831.6480000000004,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",217,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.608,1836.2560000000003,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",218,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.552,1839.8080000000002,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",219,131072.0,11767808.0,0.0,0,128849018880.0,11767808.0,128860786688.0,66560.0,128.0,0.9980806142034548,98304.0,32768.0,15.84,1855.6480000000001,9920512.0,1585152.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,503316480.0,3072.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",220,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,45056.0,15.968,1871.6160000000002,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1408.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",221,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.392,1875.0080000000003,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",222,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.424,1878.4320000000002,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",223,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,6.976,1885.4080000000004,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",224,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.2,1888.6080000000004,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",225,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.104,1891.7120000000004,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",226,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.512,1896.2240000000004,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",227,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.416,1900.6400000000003,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",228,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75404032.0,189248.0,39.84,1940.4800000000002,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2356376.0,5914.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",229,409600.0,786432.0,65536.0,0,0.0,851968.0,851968.0,0.0,512.0,0.0,131072.0,131072.0,3.744,1944.2240000000002,32768.0,0.0,376832.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",230,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75308032.0,188992.0,39.936,1984.16,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2353376.0,5906.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",231,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.552,1987.712,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",232,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,84436096.0,44320.0,51.712,2039.424,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2638628.0,1385.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",233,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.232,2042.656,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",234,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.424,2046.08,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",235,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,6.784,2052.864,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",236,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,2.976,2055.84,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",237,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.36,2059.2000000000003,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",238,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.512,2063.7120000000004,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",239,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.512,2068.2240000000006,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",240,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,45408.0,16.224,2084.448000000001,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1419.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",241,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,44256.0,16.416,2100.864000000001,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1383.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",242,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,44544.0,16.32,2117.184000000001,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1392.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",243,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.64,2121.824000000001,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",244,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.256,2126.080000000001,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",245,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.024,2131.1040000000007,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",246,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.704,2135.808000000001,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",247,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.584,2139.3920000000007,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",248,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.512,2143.904000000001,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",249,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.288,2148.192000000001,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",250,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.568,2153.760000000001,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",251,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.512,2158.2720000000013,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",252,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.168,2161.4400000000014,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",253,131072.0,11767808.0,0.0,0,128849018880.0,11767808.0,128860786688.0,66560.0,128.0,0.9980806142034548,98304.0,32768.0,15.712,2177.1520000000014,9920512.0,1585152.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,503316480.0,3072.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",254,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,45536.0,15.904,2193.0560000000014,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1423.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",255,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.68,2196.7360000000012,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",256,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.584,2200.320000000001,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",257,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,6.24,2206.560000000001,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",258,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.2,2209.7600000000007,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",259,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,2212.9920000000006,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",260,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.416,2217.408000000001,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",261,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.48,2221.888000000001,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",262,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75172096.0,188832.0,40.96,2262.848000000001,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2349128.0,5901.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",263,409600.0,786432.0,65536.0,0,0.0,851968.0,851968.0,0.0,512.0,0.0,131072.0,131072.0,3.68,2266.5280000000007,32768.0,0.0,376832.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",264,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75334912.0,187456.0,40.96,2307.4880000000007,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2354216.0,5858.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",265,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.296,2310.7840000000006,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",266,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,84441216.0,45888.0,50.24,2361.0240000000003,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2638788.0,1434.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",267,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.328,2364.3520000000003,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",268,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.2,2367.552,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",269,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,6.656,2374.208,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",270,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.36,2377.568,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",271,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,2380.864,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",272,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.448,2385.312,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",273,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.448,2389.7599999999998,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",274,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,45152.0,16.256,2406.0159999999996,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1411.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",275,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,48608.0,16.48,2422.4959999999996,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1519.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",276,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,47168.0,16.352,2438.8479999999995,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1474.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",277,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.512,2443.3599999999997,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",278,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.544,2447.9039999999995,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",279,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.376,2453.2799999999997,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",280,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.416,2457.696,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",281,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.2,2460.8959999999997,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",282,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.576,2465.4719999999998,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",283,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.384,2469.8559999999998,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",284,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.408,2475.2639999999997,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",285,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.768,2480.0319999999997,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",286,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.424,2483.4559999999997,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",287,131072.0,11767808.0,0.0,0,128849018880.0,11767808.0,128860786688.0,66560.0,128.0,0.9980806142034548,98304.0,32768.0,15.776,2499.2319999999995,9920512.0,1585152.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,503316480.0,3072.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",288,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21105664.0,45856.0,16.256,2515.4879999999994,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659552.0,1433.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",289,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.2,2518.687999999999,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",290,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.36,2522.0479999999993,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",291,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,6.88,2528.9279999999994,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",292,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.04,2531.9679999999994,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",293,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.36,2535.3279999999995,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",294,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.672,2539.9999999999995,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",295,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.48,2544.4799999999996,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",296,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75307008.0,187712.0,40.992,2585.4719999999998,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2353344.0,5866.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",297,409600.0,786432.0,65536.0,0,0.0,851968.0,851968.0,0.0,512.0,0.0,131072.0,131072.0,3.552,2589.024,32768.0,0.0,376832.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",298,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75337984.0,187872.0,40.576,2629.6,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2354312.0,5871.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",299,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.648,2633.248,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",300,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,84434560.0,45664.0,51.104,2684.352,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2638580.0,1427.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",301,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.52,2687.872,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",302,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.52,2691.392,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",303,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,7.008,2698.3999999999996,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",304,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.04,2701.4399999999996,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",305,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.2,2704.6399999999994,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",306,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.672,2709.3119999999994,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",307,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.448,2713.7599999999993,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",308,267264000.0,575488000.0,10240000.0,0,0.0,585728000.0,585728000.0,3600000.0,3136000.0,0.5344418052256532,288924544.0,735680.0,125.952,2839.7119999999995,18432000.0,32768000.0,262144000.0,5120000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9028892.0,22990.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",309,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.752,2842.4639999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",310,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,128.0,4.256,2846.7199999999993,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",311,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,2849.9519999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",312,0.0,128000.0,0.0,0,0.0,128000.0,128000.0,0.0,2000.0,0.0,512000.0,512000.0,3.84,2853.7919999999995,0.0,128000.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,16000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",313,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,3.104,2856.8959999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",314,0.0,0.0,0.0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,34624.0,5.792,2862.687999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16128.0,1082.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",315,61440.0,0.0,122880.0,0,0.0,122880.0,122880.0,8448.0,34440.0,0.1969781757134863,2109440.0,0.0,6.304,2868.9919999999993,0.0,0.0,0.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",316,0.0,0.0,0.0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,35520.0,5.856,2874.8479999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16128.0,1110.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",317,45056.0,0.0,90112.0,0,0.0,90112.0,90112.0,8448.0,34952.0,0.19465437788018433,2109440.0,0.0,6.688,2881.5359999999996,0.0,0.0,0.0,45056.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",318,0.0,0.0,0.0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,34688.0,5.856,2887.392,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16128.0,1084.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",319,36864.0,0.0,73728.0,0,0.0,73728.0,73728.0,8448.0,35208.0,0.19351291918636612,2109440.0,0.0,6.4,2893.792,0.0,0.0,0.0,36864.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",320,0.0,0.0,0.0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,34368.0,5.856,2899.648,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16128.0,1074.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",321,61440.0,0.0,122880.0,0,0.0,122880.0,122880.0,8448.0,34440.0,0.1969781757134863,2109440.0,128.0,6.624,2906.272,0.0,0.0,0.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65920.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",322,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,12.0,0.0,4128.0,512.0,3.776,2910.048,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,129.0,16.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",323,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.848,2912.8959999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",324,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,17.0,0.974124809741248,512.0,0.0,5.376,2918.272,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",325,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.104,2921.3759999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",326,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,17.0,0.974124809741248,512.0,0.0,5.728,2927.104,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",327,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,25748.0,8424.0,0.7534823832377385,527232.0,6944.0,8.8,2935.904,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16476.0,217.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",328,0.0,0.0,0.0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,8.224,2944.128,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",329,256000.0,0.0,512000.0,0,0.0,512000.0,512000.0,0.0,12000.0,0.0,520064.0,43200.0,5.888,2950.016,0.0,0.0,0.0,256000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16252.0,1350.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",330,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3000.0,0.0,640000.0,0.0,3.424,2953.44,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20000.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",331,128000.0,0.0,256000.0,0,0.0,256000.0,256000.0,0.0,4000.0,0.0,0.0,1024000.0,3.68,2957.12,0.0,0.0,0.0,128000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,32000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",332,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,4000.0,0.9712577604046907,512000.0,0.0,5.856,2962.976,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",333,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.456,2966.4320000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",334,0.0,0.0,0.0,0,0.0,0.0,0.0,41688.0,17669.0,0.7023266000640194,1703040.0,1290944.0,15.072,2981.5040000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,53220.0,40342.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",335,0.0,0.0,0.0,0,0.0,0.0,0.0,15108.0,17577.0,0.4622303809086737,1686912.0,1122272.0,12.288,2993.7920000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,52716.0,35071.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",336,0.0,0.0,0.0,0,0.0,0.0,0.0,10800.0,17604.0,0.38022813688212925,1701888.0,1277536.0,13.6,3007.3920000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,53184.0,39923.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",337,0.0,0.0,0.0,0,0.0,0.0,0.0,10800.0,17619.0,0.3800274464266864,1693568.0,1278400.0,13.632,3021.0240000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,52924.0,39950.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",338,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,4000.0,0.787052810902896,1024000.0,0.0,4.736,3025.76,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",339,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.328,3029.088,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",340,0.0,0.0,0.0,0,0.0,0.0,0.0,10543.0,9448.0,0.5273873242959332,1172992.0,857376.0,9.344,3038.4320000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36656.0,26793.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",341,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,16000.0,0.0,1549248.0,1536000.0,4.736,3043.168,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48414.0,48000.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",342,1994552.0,4245120.0,405104.0,0,0.0,4650224.0,4650224.0,528.0,5248.0,0.09141274238227147,512000.0,512000.0,22.688,3065.856,533120.0,128000.0,1792000.0,202552.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,16000.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",343,0.0,655488.0,0.0,0,0.0,655488.0,655488.0,71840.0,8000.0,0.8997995991983968,512000.0,512000.0,63.488,3129.344,655488.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,16000.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",344,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2000.0,0.0,512000.0,128000.0,3.552,3132.896,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,4000.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",345,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,3.2,3136.096,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",346,256000.0,0.0,512000.0,0,0.0,512000.0,512000.0,0.0,12000.0,0.0,1152000.0,59232.0,11.584,3147.68,0.0,0.0,0.0,256000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36000.0,1851.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",347,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3000.0,0.0,640000.0,0.0,3.552,3151.232,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",348,1994564.0,4245120.0,405128.0,0,0.0,4650248.0,4650248.0,528.0,5248.0,0.09141274238227147,512000.0,512000.0,22.976,3174.208,533120.0,128000.0,1792000.0,202564.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,16000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",349,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,32.992,3207.2000000000003,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",350,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.488,3210.688,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",351,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,32.832,3243.52,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",352,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.552,3247.072,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",353,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.296,3250.368,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",354,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.608,3254.976,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",355,4096.0,147456.0,8192.0,0,0.0,155648.0,155648.0,320.0,1004.0,0.24169184290030213,512000.0,128.0,11.936,3266.9120000000003,147456.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",356,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,3270.1440000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",357,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,5.088,3275.2320000000004,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",358,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,3278.5600000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",359,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.64,3283.2000000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",360,1408000.0,2560000.0,512000.0,0,0.0,3072000.0,3072000.0,0.0,4000.0,0.0,0.0,512000.0,5.12,3288.32,0.0,256000.0,1152000.0,256000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,16000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",361,799812.0,1280000.0,319624.0,0,0.0,1599624.0,1599624.0,0.0,3000.0,0.0,1024000.0,0.0,5.28,3293.6000000000004,0.0,0.0,640000.0,159812.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",362,2560.0,0.0,5120.0,0,0.0,5120.0,5120.0,640.0,1004.0,0.38929440389294406,512000.0,128.0,17.024,3310.6240000000003,0.0,0.0,0.0,2560.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",363,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.328,3313.952,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",364,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.616,3317.568,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",365,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,3.552,3321.1200000000003,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",366,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.168,3324.2880000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",367,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,128.0,4.512,3328.8000000000006,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",368,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.88,3331.6800000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",369,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.816,3334.4960000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",370,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.264,3337.7600000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",371,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.848,3340.6080000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",372,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,96.0,32.0,3.904,3344.5120000000006,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",373,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,5.0,0.0,32.0,32.0,7.04,3351.5520000000006,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",374,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.424,3354.9760000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",375,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,3358.2400000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",376,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,4.224,3362.464000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",377,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.864,3367.328000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",378,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,3370.688000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",379,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.584,3374.272000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",380,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,3.0,0.0,96.0,32.0,4.48,3378.752000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",381,0.0,0.0,0.0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,64.0,32.0,3.872,3382.6240000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",382,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,3.136,3385.7600000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",383,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.136,3388.8960000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",384,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,0.0,3.264,3392.1600000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",385,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,64.0,32.0,3.712,3395.8720000000008,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",386,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,768.0,0.0,33280.0,32768.0,7.168,3403.040000000001,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1040.0,1024.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",387,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.584,3406.6240000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",388,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,4.928,3411.5520000000006,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",389,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,3414.8800000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",390,0.0,512.0,0.0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,3.584,3418.4640000000004,0.0,512.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",391,384.0,0.0,768.0,0,0.0,768.0,768.0,0.0,20.0,0.0,2048.0,2048.0,3.872,3422.3360000000002,0.0,0.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",392,4096.0,9216.0,0.0,0,0.0,9216.0,9216.0,0.0,32.0,0.0,2048.0,2048.0,4.352,3426.688,0.0,1024.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",393,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,3.36,3430.0480000000002,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",394,3600.0,8224.0,0.0,0,0.0,8224.0,8224.0,0.0,32.0,0.0,2048.0,2048.0,4.512,3434.5600000000004,0.0,1024.0,3600.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",395,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,3.488,3438.0480000000002,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",396,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.168,3441.2160000000003,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",397,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,6.784,3448.0000000000005,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",398,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.104,3451.1040000000003,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",399,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.136,3454.2400000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",400,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.384,3458.6240000000003,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",401,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.576,3463.2000000000003,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",402,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,45920.0,15.84,3479.0400000000004,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1435.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",403,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21103872.0,45056.0,15.872,3494.9120000000003,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659496.0,1408.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",404,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102976.0,44800.0,16.928,3511.84,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659468.0,1400.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",405,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.608,3516.4480000000003,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",406,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.224,3520.6720000000005,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",407,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,4.96,3525.6320000000005,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",408,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.768,3530.4000000000005,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",409,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.744,3534.1440000000007,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",410,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.608,3538.752000000001,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",411,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.512,3543.264000000001,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",412,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,4.928,3548.192000000001,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",413,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.448,3552.640000000001,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",414,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.52,3556.1600000000008,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",415,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,640.0,0.0,65536.0,65536.0,4.576,3560.736000000001,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",416,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,640.0,0.0,65536.0,65536.0,4.512,3565.248000000001,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",417,130784.0,11771148.0,0.0,0,128849018880.0,11771148.0,128860790028.0,66578.0,128.0,0.9980811321320421,163840.0,32768.0,15.968,3581.216000000001,9924455.0,1585125.0,130784.0,0.0,0,0,0,0,0,0,0,0.0,0.0,503316480.0,5120.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",418,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,44288.0,15.936,3597.152000000001,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",419,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.296,3600.448000000001,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",420,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.168,3603.616000000001,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",421,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,7.072,3610.688000000001,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",422,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.104,3613.792000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",423,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.2,3616.9920000000006,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",424,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.8,3621.792000000001,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",425,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.64,3626.4320000000007,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",426,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75331840.0,190976.0,40.544,3666.9760000000006,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2354120.0,5968.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",427,409600.0,786432.0,65536.0,0,0.0,851968.0,851968.0,0.0,512.0,0.0,131072.0,131072.0,3.616,3670.5920000000006,32768.0,0.0,376832.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",428,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75249792.0,195328.0,40.096,3710.6880000000006,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2351556.0,6104.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",429,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.328,3714.0160000000005,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",430,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,84436864.0,43072.0,51.168,3765.1840000000007,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2638652.0,1346.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",431,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.552,3768.736000000001,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",432,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.296,3772.0320000000006,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",433,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,6.848,3778.8800000000006,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",434,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,3782.1440000000007,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",435,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,3785.3760000000007,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",436,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.384,3789.7600000000007,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",437,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.512,3794.272000000001,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",438,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,46368.0,15.904,3810.176000000001,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1449.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",439,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,43424.0,16.192,3826.368000000001,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1357.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",440,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,44960.0,16.096,3842.464000000001,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1405.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",441,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.864,3847.328000000001,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",442,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.416,3851.744000000001,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",443,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.12,3856.864000000001,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",444,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.352,3861.216000000001,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",445,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.52,3864.736000000001,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",446,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.512,3869.248000000001,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",447,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.448,3873.696000000001,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",448,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.088,3878.784000000001,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",449,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.64,3883.424000000001,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",450,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.52,3886.944000000001,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",451,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,640.0,0.0,65536.0,65536.0,4.608,3891.552000000001,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",452,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,640.0,0.0,65536.0,65536.0,4.48,3896.032000000001,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",453,131072.0,11771904.0,0.0,0,128849018880.0,11771904.0,128860790784.0,66560.0,128.0,0.9980806142034548,163840.0,32768.0,15.936,3911.968000000001,9924608.0,1585152.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,503316480.0,5120.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",454,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,44672.0,15.904,3927.872000000001,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1396.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",455,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.2,3931.072000000001,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",456,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.2,3934.272000000001,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",457,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,6.784,3941.056000000001,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",458,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.456,3944.512000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",459,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.392,3947.904000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",460,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.48,3952.384000000001,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",461,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.352,3956.736000000001,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",462,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75284096.0,191200.0,39.968,3996.7040000000006,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2352628.0,5975.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",463,409600.0,786432.0,65536.0,0,0.0,851968.0,851968.0,0.0,512.0,0.0,131072.0,131072.0,3.808,4000.5120000000006,32768.0,0.0,376832.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",464,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75275136.0,192704.0,39.872,4040.3840000000005,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2352348.0,6022.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",465,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.36,4043.7440000000006,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",466,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,84442880.0,45088.0,52.064,4095.8080000000004,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2638840.0,1409.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",467,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.232,4099.040000000001,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",468,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.168,4102.2080000000005,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",469,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,6.752,4108.960000000001,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",470,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.168,4112.128000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",471,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.136,4115.264000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",472,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.672,4119.936000000001,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",473,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.48,4124.416,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",474,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,46752.0,16.192,4140.608,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1461.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",475,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,48960.0,16.48,4157.088,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1530.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",476,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,48416.0,16.192,4173.28,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1513.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",477,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.48,4177.759999999999,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",478,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.32,4182.079999999999,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",479,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.344,4187.423999999999,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",480,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.672,4192.095999999999,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",481,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.616,4195.711999999999,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",482,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.864,4200.575999999998,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",483,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.32,4204.895999999998,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",484,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.6,4210.495999999998,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",485,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.48,4214.975999999998,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",486,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.328,4218.303999999998,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",487,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,640.0,0.0,65536.0,65536.0,4.512,4222.815999999998,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",488,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,640.0,0.0,65536.0,65536.0,4.736,4227.551999999998,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",489,131072.0,11771904.0,0.0,0,128849018880.0,11771904.0,128860790784.0,66560.0,128.0,0.9980806142034548,163840.0,32768.0,15.968,4243.519999999998,9924608.0,1585152.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,503316480.0,5120.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",490,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21103616.0,45888.0,15.936,4259.455999999997,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659488.0,1434.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",491,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.424,4262.879999999997,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",492,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.136,4266.015999999998,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",493,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,6.816,4272.831999999998,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",494,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.36,4276.191999999997,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",495,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.136,4279.327999999998,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",496,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.608,4283.935999999998,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",497,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.608,4288.543999999998,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",498,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75251456.0,186368.0,41.408,4329.951999999998,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2351608.0,5824.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",499,409600.0,786432.0,65536.0,0,0.0,851968.0,851968.0,0.0,512.0,0.0,131072.0,131072.0,3.616,4333.567999999998,32768.0,0.0,376832.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",500,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75266176.0,186976.0,39.232,4372.799999999998,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2352068.0,5843.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",501,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.488,4376.287999999999,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",502,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,84440192.0,45632.0,50.048,4426.335999999998,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2638756.0,1426.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",503,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.52,4429.855999999999,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",504,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.2,4433.055999999999,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",505,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,6.88,4439.935999999999,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",506,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.168,4443.103999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",507,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.2,4446.303999999998,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",508,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.544,4450.847999999998,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",509,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.608,4455.455999999998,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",510,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21104128.0,44960.0,15.936,4471.391999999998,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659504.0,1405.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",511,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21103104.0,46368.0,16.192,4487.583999999998,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659472.0,1449.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",512,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102720.0,44096.0,16.0,4503.583999999998,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659460.0,1378.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",513,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.896,4508.479999999998,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",514,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.256,4512.735999999998,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",515,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.6,4518.335999999998,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",516,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.608,4522.943999999999,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",517,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.328,4526.271999999999,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",518,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.96,4531.231999999999,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",519,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.48,4535.711999999999,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",520,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.344,4541.055999999999,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",521,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.64,4545.695999999999,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",522,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.424,4549.119999999999,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",523,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,640.0,0.0,65536.0,65536.0,4.608,4553.727999999999,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",524,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,640.0,0.0,65536.0,65536.0,4.64,4558.3679999999995,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",525,131072.0,11771904.0,0.0,0,128849018880.0,11771904.0,128860790784.0,66560.0,128.0,0.9980806142034548,163840.0,32768.0,15.744,4574.111999999999,9924608.0,1585152.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,503316480.0,5120.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",526,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,44352.0,16.96,4591.071999999999,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1386.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",527,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.2,4594.271999999999,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",528,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.2,4597.471999999999,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",529,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,6.848,4604.319999999999,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",530,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,4607.551999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",531,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.168,4610.719999999998,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",532,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.48,4615.199999999998,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",533,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.416,4619.615999999998,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",534,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75352576.0,186016.0,40.0,4659.615999999998,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2354768.0,5813.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",535,409600.0,786432.0,65536.0,0,0.0,851968.0,851968.0,0.0,512.0,0.0,131072.0,131072.0,3.712,4663.327999999999,32768.0,0.0,376832.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",536,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75447424.0,188416.0,40.416,4703.743999999999,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2357732.0,5888.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",537,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.392,4707.135999999999,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",538,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,84437248.0,47136.0,50.08,4757.2159999999985,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2638664.0,1473.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",539,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.392,4760.607999999998,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",540,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.232,4763.839999999998,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",541,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,6.752,4770.591999999999,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",542,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.104,4773.695999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",543,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,4777.023999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",544,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.768,4781.7919999999995,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",545,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.48,4786.271999999999,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",546,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,46016.0,15.872,4802.143999999999,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1438.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",547,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102720.0,45984.0,16.864,4819.007999999999,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659460.0,1437.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",548,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,44224.0,16.224,4835.231999999999,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1382.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",549,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.48,4839.711999999999,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",550,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.224,4843.935999999999,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",551,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.376,4849.311999999999,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",552,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.608,4853.919999999999,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",553,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.392,4857.311999999999,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",554,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.704,4862.015999999999,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",555,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.32,4866.335999999998,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",556,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.312,4871.647999999998,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",557,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.64,4876.287999999999,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",558,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.392,4879.6799999999985,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",559,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,640.0,0.0,65536.0,65536.0,4.512,4884.191999999998,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",560,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,640.0,0.0,65536.0,65536.0,4.544,4888.735999999998,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",561,131072.0,11771904.0,0.0,0,128849018880.0,11771904.0,128860790784.0,66560.0,128.0,0.9980806142034548,163840.0,32768.0,16.16,4904.895999999998,9924608.0,1585152.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,503316480.0,5120.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",562,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,47136.0,15.808,4920.703999999998,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1473.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",563,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.392,4924.095999999998,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",564,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.328,4927.423999999998,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",565,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,6.624,4934.047999999998,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",566,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.136,4937.183999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",567,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,4940.511999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",568,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.384,4944.895999999999,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",569,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.448,4949.343999999999,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",570,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75521024.0,186560.0,39.072,4988.415999999999,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2360032.0,5830.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",571,409600.0,786432.0,65536.0,0,0.0,851968.0,851968.0,0.0,512.0,0.0,131072.0,131072.0,3.808,4992.223999999999,32768.0,0.0,376832.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",572,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75355776.0,188736.0,39.008,5031.231999999999,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2354868.0,5898.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",573,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.52,5034.7519999999995,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",574,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,84448384.0,46560.0,51.584,5086.335999999999,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2639012.0,1455.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",575,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.392,5089.727999999999,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",576,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.2,5092.927999999999,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",577,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,6.72,5099.647999999999,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",578,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,5102.911999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",579,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,5106.143999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",580,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.288,5110.431999999999,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",581,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.544,5114.975999999999,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",582,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,45504.0,15.744,5130.719999999998,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1422.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",583,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102720.0,44224.0,16.832,5147.551999999999,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659460.0,1382.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",584,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,45440.0,16.416,5163.967999999999,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1420.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",585,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.736,5168.703999999999,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",586,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.32,5173.0239999999985,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",587,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.632,5178.655999999998,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",588,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.544,5183.199999999998,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",589,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.296,5186.495999999998,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",590,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.736,5191.231999999998,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",591,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.288,5195.519999999998,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",592,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.632,5201.151999999997,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",593,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.736,5205.887999999997,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",594,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.392,5209.279999999997,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",595,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,640.0,0.0,65536.0,65536.0,4.768,5214.047999999997,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",596,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,640.0,0.0,65536.0,65536.0,4.64,5218.687999999997,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",597,131072.0,11771904.0,0.0,0,128849018880.0,11771904.0,128860790784.0,66560.0,128.0,0.9980806142034548,163840.0,32768.0,15.968,5234.655999999997,9924608.0,1585152.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,503316480.0,5120.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",598,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,45664.0,15.936,5250.591999999997,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1427.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",599,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.392,5253.983999999997,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",600,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.424,5257.407999999997,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",601,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,6.816,5264.2239999999965,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",602,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.52,5267.743999999997,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",603,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.2,5270.943999999997,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",604,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.448,5275.391999999997,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",605,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.544,5279.935999999997,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",606,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75222144.0,189664.0,39.424,5319.359999999997,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2350692.0,5927.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",607,409600.0,786432.0,65536.0,0,0.0,851968.0,851968.0,0.0,512.0,0.0,131072.0,131072.0,3.552,5322.911999999997,32768.0,0.0,376832.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",608,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75323008.0,188288.0,40.16,5363.0719999999965,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2353844.0,5884.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",609,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.424,5366.4959999999965,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",610,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,84438272.0,44000.0,49.376,5415.871999999997,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2638696.0,1375.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",611,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.392,5419.2639999999965,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",612,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.136,5422.399999999997,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",613,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,6.624,5429.023999999997,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",614,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,5432.255999999997,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",615,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.104,5435.359999999997,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",616,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.48,5439.8399999999965,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",617,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.544,5444.383999999996,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",618,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,45024.0,15.648,5460.0319999999965,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1407.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",619,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,45248.0,16.224,5476.255999999997,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1414.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",620,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,46368.0,16.032,5492.287999999997,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1449.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",621,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.48,5496.767999999996,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",622,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.576,5501.343999999996,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",623,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.44,5506.783999999996,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",624,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.416,5511.199999999996,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",625,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.424,5514.623999999996,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",626,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.512,5519.135999999996,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",627,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.544,5523.679999999996,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",628,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.344,5529.023999999996,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",629,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.608,5533.631999999996,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",630,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.424,5537.055999999996,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",631,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,640.0,0.0,65536.0,65536.0,4.64,5541.695999999996,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",632,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,640.0,0.0,65536.0,65536.0,4.512,5546.207999999996,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",633,131072.0,11771904.0,0.0,0,128849018880.0,11771904.0,128860790784.0,66560.0,128.0,0.9980806142034548,163840.0,32768.0,15.968,5562.175999999996,9924608.0,1585152.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,503316480.0,5120.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",634,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,44608.0,16.032,5578.207999999996,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1394.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",635,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.424,5581.631999999996,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",636,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.136,5584.767999999996,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",637,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,6.816,5591.583999999996,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",638,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.136,5594.719999999997,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",639,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.104,5597.823999999997,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",640,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.448,5602.271999999997,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",641,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.48,5606.751999999997,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",642,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75121152.0,188992.0,39.296,5646.047999999997,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2347536.0,5906.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",643,409600.0,786432.0,65536.0,0,0.0,851968.0,851968.0,0.0,512.0,0.0,131072.0,131072.0,3.616,5649.663999999997,32768.0,0.0,376832.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",644,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75412480.0,186688.0,41.024,5690.687999999997,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2356640.0,5834.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",645,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.424,5694.111999999997,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",646,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,84427776.0,45472.0,49.12,5743.231999999997,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2638368.0,1421.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",647,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.232,5746.463999999997,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",648,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.2,5749.663999999997,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",649,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,6.752,5756.415999999997,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",650,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.2,5759.615999999997,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",651,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.2,5762.815999999997,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",652,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.352,5767.167999999997,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",653,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.48,5771.6479999999965,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",654,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,45760.0,15.84,5787.487999999997,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1430.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",655,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,45536.0,16.096,5803.583999999996,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1423.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",656,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,46368.0,16.576,5820.159999999996,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1449.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",657,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.736,5824.895999999996,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",658,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.256,5829.151999999996,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",659,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.44,5834.591999999996,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",660,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.608,5839.199999999996,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",661,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.296,5842.4959999999965,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",662,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.64,5847.135999999997,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",663,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.256,5851.391999999997,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",664,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.408,5856.799999999997,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",665,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.512,5861.311999999997,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",666,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.584,5864.895999999997,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",667,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,640.0,0.0,65536.0,65536.0,4.608,5869.503999999997,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",668,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,640.0,0.0,65536.0,65536.0,4.608,5874.111999999997,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",669,131072.0,11771904.0,0.0,0,128849018880.0,11771904.0,128860790784.0,66560.0,128.0,0.9980806142034548,163840.0,32768.0,16.128,5890.239999999997,9924608.0,1585152.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,503316480.0,5120.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",670,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,44256.0,16.064,5906.303999999997,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1383.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",671,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.776,5910.079999999997,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",672,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.2,5913.279999999997,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",673,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,6.752,5920.031999999997,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",674,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,5923.295999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",675,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.168,5926.463999999997,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",676,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.416,5930.879999999997,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",677,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.512,5935.391999999997,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",678,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75340800.0,186816.0,41.312,5976.703999999997,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2354400.0,5838.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",679,409600.0,786432.0,65536.0,0,0.0,851968.0,851968.0,0.0,512.0,0.0,131072.0,131072.0,3.936,5980.639999999997,32768.0,0.0,376832.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",680,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75134208.0,189472.0,39.232,6019.871999999997,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2347944.0,5921.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",681,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.552,6023.423999999996,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",682,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,84444032.0,43264.0,50.24,6073.663999999996,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2638876.0,1352.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",683,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.392,6077.055999999996,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",684,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.36,6080.415999999996,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",685,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,7.008,6087.423999999995,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",686,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.2,6090.623999999995,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",687,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.136,6093.759999999996,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",688,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.448,6098.207999999996,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",689,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.416,6102.623999999996,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",690,267264000.0,575488000.0,10240000.0,0,0.0,585728000.0,585728000.0,3600000.0,3136000.0,0.5344418052256532,288826240.0,738368.0,123.84,6226.463999999996,18432000.0,32768000.0,262144000.0,5120000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9025820.0,23074.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",691,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.784,6229.247999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",692,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,96.0,160.0,3.776,6233.023999999996,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",693,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.104,6236.127999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",694,0.0,128000.0,0.0,0,0.0,128000.0,128000.0,0.0,2000.0,0.0,512000.0,512000.0,3.52,6239.6479999999965,0.0,128000.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,16000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",695,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.976,6242.623999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",696,0.0,0.0,0.0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,33344.0,5.824,6248.447999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16128.0,1042.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",697,61440.0,0.0,122880.0,0,0.0,122880.0,122880.0,8448.0,34440.0,0.1969781757134863,2109440.0,0.0,6.656,6255.103999999996,0.0,0.0,0.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",698,0.0,0.0,0.0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,33728.0,5.984,6261.087999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16128.0,1054.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",699,45056.0,0.0,90112.0,0,0.0,90112.0,90112.0,8448.0,34952.0,0.19465437788018433,2109440.0,0.0,6.528,6267.615999999996,0.0,0.0,0.0,45056.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",700,0.0,0.0,0.0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,33408.0,5.696,6273.311999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16128.0,1044.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",701,56320.0,0.0,112640.0,0,0.0,112640.0,112640.0,8448.0,34600.0,0.19624605091990335,2109440.0,0.0,6.432,6279.743999999996,0.0,0.0,0.0,56320.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",702,0.0,0.0,0.0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,33408.0,5.792,6285.535999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16128.0,1044.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",703,55296.0,0.0,110592.0,0,0.0,110592.0,110592.0,8448.0,34632.0,0.19610027855153203,2109440.0,128.0,6.688,6292.2239999999965,0.0,0.0,0.0,55296.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65920.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",704,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,12.0,0.0,4128.0,512.0,3.872,6296.095999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,129.0,16.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",705,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.136,6299.231999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",706,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,17.0,0.974124809741248,512.0,0.0,5.44,6304.671999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",707,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.912,6307.583999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",708,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,17.0,0.974124809741248,512.0,0.0,5.696,6313.279999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",709,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,30627.0,8424.0,0.7842820926480756,527232.0,7104.0,8.8,6322.079999999997,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16476.0,222.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",710,0.0,0.0,0.0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,8.48,6330.559999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",711,256000.0,0.0,512000.0,0,0.0,512000.0,512000.0,0.0,12000.0,0.0,520064.0,42976.0,5.984,6336.543999999997,0.0,0.0,0.0,256000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16252.0,1343.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",712,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3000.0,0.0,640000.0,0.0,3.84,6340.383999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20000.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",713,128000.0,0.0,256000.0,0,0.0,256000.0,256000.0,0.0,4000.0,0.0,0.0,1024000.0,3.584,6343.967999999997,0.0,0.0,0.0,128000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,32000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",714,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,4000.0,0.9712577604046907,512000.0,0.0,5.632,6349.599999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",715,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.424,6353.023999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",716,0.0,0.0,0.0,0,0.0,0.0,0.0,41688.0,17660.0,0.7024331064231314,1699712.0,1271904.0,14.656,6367.679999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,53116.0,39747.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",717,0.0,0.0,0.0,0,0.0,0.0,0.0,10896.0,17682.0,0.38127230736930506,1710720.0,1472928.0,11.808,6379.487999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,53460.0,46029.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",718,0.0,0.0,0.0,0,0.0,0.0,0.0,10800.0,17600.0,0.38028169014084506,1704064.0,1011712.0,13.152,6392.639999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,53252.0,31616.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",719,0.0,0.0,0.0,0,0.0,0.0,0.0,10800.0,17623.0,0.37997396474685996,1689600.0,1264448.0,12.992,6405.631999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,52800.0,39514.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",720,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,4000.0,0.787052810902896,1024000.0,0.0,4.768,6410.399999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",721,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.488,6413.887999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",722,0.0,0.0,0.0,0,0.0,0.0,0.0,10543.0,9395.0,0.5287892466646604,1163392.0,856896.0,9.248,6423.135999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36356.0,26778.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",723,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,16000.0,0.0,1549184.0,1536000.0,4.736,6427.871999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48412.0,48000.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",724,1994552.0,4245120.0,405104.0,0,0.0,4650224.0,4650224.0,528.0,5248.0,0.09141274238227147,513536.0,512000.0,22.912,6450.783999999997,533120.0,128000.0,1792000.0,202552.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16048.0,16000.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",725,0.0,655488.0,0.0,0,0.0,655488.0,655488.0,71840.0,8000.0,0.8997995991983968,512000.0,512000.0,63.392,6514.175999999997,655488.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,16000.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",726,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2000.0,0.0,512000.0,128000.0,3.552,6517.727999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,4000.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",727,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,3.168,6520.895999999996,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",728,256000.0,0.0,512000.0,0,0.0,512000.0,512000.0,0.0,12000.0,0.0,1152000.0,58368.0,11.616,6532.511999999996,0.0,0.0,0.0,256000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36000.0,1824.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",729,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3000.0,0.0,640000.0,0.0,3.52,6536.0319999999965,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",730,1994565.0,4245120.0,405130.0,0,0.0,4650250.0,4650250.0,528.0,5248.0,0.09141274238227147,519296.0,512000.0,22.912,6558.943999999997,533120.0,128000.0,1792000.0,202565.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16228.0,16000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",731,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,32.64,6591.583999999997,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",732,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,6594.975999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",733,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,31.776,6626.751999999997,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",734,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,6630.143999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",735,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.488,6633.631999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",736,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.608,6638.239999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",737,4096.0,147456.0,8192.0,0,0.0,155648.0,155648.0,320.0,1004.0,0.24169184290030213,512000.0,128.0,11.392,6649.631999999997,147456.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",738,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.456,6653.087999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",739,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,5.216,6658.303999999997,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",740,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,6661.599999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",741,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.544,6666.1439999999975,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",742,1408000.0,2560000.0,512000.0,0,0.0,3072000.0,3072000.0,0.0,4000.0,0.0,0.0,512000.0,5.088,6671.231999999997,0.0,256000.0,1152000.0,256000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,16000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",743,799813.0,1280000.0,319626.0,0,0.0,1599626.0,1599626.0,0.0,3000.0,0.0,1024000.0,0.0,5.344,6676.575999999997,0.0,0.0,640000.0,159813.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",744,2560.0,0.0,5120.0,0,0.0,5120.0,5120.0,640.0,1004.0,0.38929440389294406,512000.0,128.0,16.384,6692.959999999997,0.0,0.0,0.0,2560.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",745,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.104,6696.063999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",746,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.2,6699.263999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",747,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,4.064,6703.327999999998,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",748,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.232,6706.559999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",749,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,96.0,160.0,3.84,6710.399999999998,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",750,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.976,6713.3759999999975,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",751,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.88,6716.255999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",752,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.296,6719.551999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",753,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.688,6722.239999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",754,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,128.0,32.0,3.84,6726.079999999998,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",755,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,5.0,0.0,32.0,32.0,7.264,6733.343999999998,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",756,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.392,6736.735999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",757,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,6740.127999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",758,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,4.096,6744.223999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",759,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.8,6749.023999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",760,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.168,6752.191999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
