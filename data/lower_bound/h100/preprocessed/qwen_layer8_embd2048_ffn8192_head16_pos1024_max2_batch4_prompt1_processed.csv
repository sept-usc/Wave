Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.816,2.816,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.592,5.4079999999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",3,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,4.064,9.472,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",4,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.32,13.792,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",5,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,4.832,18.624,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",6,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,21.951999999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",7,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.72,24.671999999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",8,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.816,27.487999999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",9,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.168,30.655999999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",10,0.0,0.0,0.0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,4.032,34.687999999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,37.952,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",12,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.648,41.6,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",13,0.0,0.0,0.0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,32.0,32.0,4.16,45.760000000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.104,48.864000000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",15,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.616,52.480000000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",16,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,3.488,55.968,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",17,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,768.0,0.0,8704.0,32768.0,5.76,61.728,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,272.0,1024.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",18,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.456,65.184,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",19,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,5.184,70.368,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",20,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.488,73.856,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",21,0.0,512.0,0.0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,4.224,78.08,0.0,512.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",22,384.0,0.0,768.0,0,0.0,768.0,768.0,0.0,20.0,0.0,2048.0,2048.0,4.448,82.52799999999999,0.0,0.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",23,4096.0,9216.0,0.0,0,0.0,9216.0,9216.0,0.0,32.0,0.0,2048.0,2048.0,4.32,86.84799999999998,0.0,1024.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",24,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,3.392,90.23999999999998,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",25,3584.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,32.0,0.0,2048.0,2048.0,4.224,94.46399999999998,0.0,1024.0,3584.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",26,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,3.328,97.79199999999999,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",27,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.456,101.24799999999999,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",28,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,6.592,107.83999999999999,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",29,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,111.07199999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",30,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,114.33599999999998,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",31,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.672,119.00799999999998,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",32,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.672,123.67999999999998,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",33,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,21111296.0,37408.0,16.192,139.87199999999999,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659728.0,1169.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",34,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,21110784.0,35616.0,16.064,155.93599999999998,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659712.0,1113.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",35,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,21111680.0,35936.0,16.192,172.128,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659740.0,1123.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",36,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.608,176.736,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",37,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.448,181.184,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",38,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.664,186.84799999999998,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",39,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.576,191.42399999999998,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",40,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.328,194.75199999999998,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",41,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.704,199.456,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",42,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.416,203.87199999999999,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",43,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.568,209.44,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",44,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.672,214.112,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",45,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.392,217.504,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",46,131072.0,11767808.0,0.0,0,128849018880.0,11767808.0,128860786688.0,66560.0,128.0,0.9980806142034548,98304.0,32768.0,15.808,233.31199999999998,9920512.0,1585152.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,503316480.0,3072.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",47,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,44864.0,16.128,249.44,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1402.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",48,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.424,252.864,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",49,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.2,256.064,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",50,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,64.0,6.848,262.91200000000003,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,2.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",51,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,266.17600000000004,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",52,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.136,269.31200000000007,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",53,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.48,273.7920000000001,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",54,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.448,278.24000000000007,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",55,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75254144.0,193696.0,41.152,319.39200000000005,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2351692.0,6053.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",56,409600.0,786432.0,65536.0,0,0.0,851968.0,851968.0,0.0,512.0,0.0,131072.0,131072.0,3.744,323.1360000000001,32768.0,0.0,376832.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",57,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75235328.0,188064.0,40.576,363.7120000000001,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2351104.0,5877.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",58,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.424,367.1360000000001,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",59,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,84432000.0,44736.0,49.696,416.8320000000001,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2638500.0,1398.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",60,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.36,420.1920000000001,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",61,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.168,423.3600000000001,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",62,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,6.752,430.11200000000014,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",63,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.2,433.3120000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",64,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.2,436.5120000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",65,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.448,440.9600000000001,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",66,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.736,445.6960000000001,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",67,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,21110784.0,36832.0,15.808,461.5040000000001,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659712.0,1151.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",68,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,21110784.0,35744.0,16.608,478.1120000000001,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659712.0,1117.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",69,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,21111680.0,38272.0,16.256,494.36800000000005,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659740.0,1196.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",70,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.608,498.97600000000006,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",71,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.352,503.32800000000003,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",72,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.376,508.704,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",73,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.48,513.184,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",74,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.456,516.64,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",75,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.768,521.408,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",76,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.416,525.8240000000001,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",77,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.568,531.392,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",78,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.48,535.8720000000001,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",79,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.456,539.3280000000001,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",80,131072.0,11767808.0,0.0,0,128849018880.0,11767808.0,128860786688.0,66560.0,128.0,0.9980806142034548,98304.0,32768.0,15.68,555.008,9920512.0,1585152.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,503316480.0,3072.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",81,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,47008.0,16.64,571.648,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1469.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",82,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.776,575.424,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",83,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.584,579.0079999999999,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",84,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,7.136,586.1439999999999,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",85,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.104,589.2479999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",86,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,592.512,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",87,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.416,596.928,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",88,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.352,601.28,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",89,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75288448.0,190816.0,41.472,642.752,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2352764.0,5963.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",90,409600.0,786432.0,65536.0,0,0.0,851968.0,851968.0,0.0,512.0,0.0,131072.0,131072.0,3.68,646.4319999999999,32768.0,0.0,376832.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",91,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75219200.0,189696.0,40.576,687.0079999999999,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2350600.0,5928.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",92,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.488,690.496,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",93,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,84432256.0,44512.0,51.136,741.632,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2638508.0,1391.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",94,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.52,745.1519999999999,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",95,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.296,748.448,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",96,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,6.72,755.168,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",97,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,758.4,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",98,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.168,761.568,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",99,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.48,766.048,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",100,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.416,770.464,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",101,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,21110784.0,37760.0,16.256,786.72,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659712.0,1180.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",102,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,21110784.0,36768.0,16.224,802.9440000000001,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659712.0,1149.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",103,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,21110784.0,36800.0,16.256,819.2,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659712.0,1150.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",104,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.736,823.936,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",105,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.544,828.48,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",106,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.952,834.432,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",107,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.512,838.944,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",108,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.488,842.432,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",109,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.384,846.816,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",110,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.416,851.2320000000001,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",111,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.76,856.9920000000001,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",112,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.576,861.5680000000001,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",113,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.456,865.0240000000001,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",114,131072.0,11767808.0,0.0,0,128849018880.0,11767808.0,128860786688.0,66560.0,128.0,0.9980806142034548,98304.0,32768.0,15.968,880.9920000000001,9920512.0,1585152.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,503316480.0,3072.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",115,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,43360.0,16.16,897.152,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1355.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",116,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.52,900.672,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",117,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.328,904.0,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",118,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,6.912,910.912,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",119,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.168,914.08,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",120,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.168,917.248,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",121,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.416,921.6640000000001,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",122,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.544,926.2080000000001,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",123,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75268352.0,187776.0,40.832,967.0400000000001,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2352136.0,5868.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",124,409600.0,786432.0,65536.0,0,0.0,851968.0,851968.0,0.0,512.0,0.0,131072.0,131072.0,3.712,970.7520000000001,32768.0,0.0,376832.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",125,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75163904.0,187168.0,40.608,1011.36,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2348872.0,5849.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",126,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.264,1014.624,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",127,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,84438528.0,47264.0,50.144,1064.768,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2638704.0,1477.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",128,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.488,1068.256,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",129,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.424,1071.68,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",130,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,6.72,1078.4,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",131,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,1081.664,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",132,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.136,1084.8,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",133,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.416,1089.216,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",134,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.544,1093.76,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",135,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,21111040.0,36256.0,15.84,1109.6,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659720.0,1133.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",136,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,21110784.0,37824.0,16.32,1125.9199999999998,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659712.0,1182.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",137,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,21111168.0,36352.0,16.352,1142.272,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659724.0,1136.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",138,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.64,1146.912,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",139,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.448,1151.3600000000001,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",140,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.632,1156.9920000000002,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",141,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.544,1161.5360000000003,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",142,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.456,1164.9920000000002,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",143,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.64,1169.6320000000003,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",144,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.32,1173.9520000000002,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",145,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.632,1179.5840000000003,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",146,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.768,1184.3520000000003,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",147,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.456,1187.8080000000002,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",148,131072.0,11767808.0,0.0,0,128849018880.0,11767808.0,128860786688.0,66560.0,128.0,0.9980806142034548,98304.0,32768.0,15.616,1203.4240000000002,9920512.0,1585152.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,503316480.0,3072.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",149,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,44928.0,16.288,1219.7120000000002,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1404.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",150,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.52,1223.2320000000002,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",151,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.488,1226.7200000000003,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",152,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,6.528,1233.2480000000003,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",153,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.136,1236.3840000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",154,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,1239.6160000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",155,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.608,1244.2240000000002,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",156,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.384,1248.6080000000002,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",157,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75331968.0,190656.0,39.968,1288.5760000000002,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2354124.0,5958.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",158,409600.0,786432.0,65536.0,0,0.0,851968.0,851968.0,0.0,512.0,0.0,131072.0,131072.0,3.84,1292.4160000000002,32768.0,0.0,376832.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",159,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75397376.0,191360.0,40.992,1333.4080000000001,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2356168.0,5980.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",160,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.36,1336.768,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",161,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,84428032.0,45088.0,50.656,1387.424,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2638376.0,1409.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",162,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.616,1391.04,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",163,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.36,1394.3999999999999,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",164,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,6.656,1401.0559999999998,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",165,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.072,1404.1279999999997,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",166,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,1407.4559999999997,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",167,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.512,1411.9679999999996,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",168,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.384,1416.3519999999996,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",169,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,21110784.0,36928.0,15.936,1432.2879999999996,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659712.0,1154.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",170,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,21110784.0,37536.0,16.384,1448.6719999999996,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659712.0,1173.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",171,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,21111680.0,37728.0,16.16,1464.8319999999997,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659740.0,1179.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",172,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.512,1469.3439999999996,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",173,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.352,1473.6959999999997,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",174,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.76,1479.4559999999997,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",175,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.576,1484.0319999999997,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",176,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.392,1487.4239999999998,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",177,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.576,1491.9999999999998,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",178,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.384,1496.3839999999998,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",179,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.696,1502.0799999999997,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",180,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.576,1506.6559999999997,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",181,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.392,1510.0479999999998,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",182,131072.0,11767808.0,0.0,0,128849018880.0,11767808.0,128860786688.0,66560.0,128.0,0.9980806142034548,98304.0,32768.0,15.808,1525.8559999999998,9920512.0,1585152.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,503316480.0,3072.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",183,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,45824.0,16.16,1542.0159999999998,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1432.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",184,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.488,1545.504,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",185,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.424,1548.9279999999999,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",186,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,7.008,1555.936,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",187,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,1559.168,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",188,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.136,1562.3039999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",189,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.576,1566.8799999999999,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",190,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.544,1571.424,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",191,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75214848.0,192000.0,40.864,1612.288,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2350464.0,6000.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",192,409600.0,786432.0,65536.0,0,0.0,851968.0,851968.0,0.0,512.0,0.0,131072.0,131072.0,3.712,1616.0,32768.0,0.0,376832.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",193,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75349760.0,186816.0,40.736,1656.736,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2354680.0,5838.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",194,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.36,1660.096,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",195,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,84426496.0,45792.0,50.944,1711.04,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2638328.0,1431.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",196,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.328,1714.368,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",197,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.328,1717.696,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",198,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,6.848,1724.5439999999999,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",199,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.168,1727.7119999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",200,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.072,1730.7839999999997,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",201,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.448,1735.2319999999997,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",202,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.672,1739.9039999999998,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",203,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,21110784.0,38336.0,15.808,1755.7119999999998,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659712.0,1198.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",204,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,21110784.0,35488.0,17.056,1772.7679999999998,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659712.0,1109.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",205,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,21111168.0,37376.0,16.064,1788.8319999999999,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659724.0,1168.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",206,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.64,1793.472,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",207,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.416,1797.888,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",208,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.472,1803.36,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",209,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.608,1807.9679999999998,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",210,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.648,1811.6159999999998,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",211,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.608,1816.2239999999997,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",212,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.416,1820.6399999999996,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",213,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.376,1826.0159999999996,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",214,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.672,1830.6879999999996,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",215,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.36,1834.0479999999995,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",216,131072.0,11767808.0,0.0,0,128849018880.0,11767808.0,128860786688.0,66560.0,128.0,0.9980806142034548,98304.0,32768.0,16.096,1850.1439999999996,9920512.0,1585152.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,503316480.0,3072.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",217,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,45664.0,16.48,1866.6239999999996,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1427.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",218,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.616,1870.2399999999996,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",219,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.456,1873.6959999999995,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",220,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,6.528,1880.2239999999995,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",221,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.072,1883.2959999999994,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",222,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.168,1886.4639999999993,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",223,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.64,1891.1039999999994,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",224,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.48,1895.5839999999994,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",225,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75335168.0,191744.0,39.712,1935.2959999999994,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2354224.0,5992.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",226,409600.0,786432.0,65536.0,0,0.0,851968.0,851968.0,0.0,512.0,0.0,131072.0,131072.0,3.68,1938.9759999999994,32768.0,0.0,376832.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",227,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75098368.0,191872.0,40.544,1979.5199999999995,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2346824.0,5996.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",228,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.424,1982.9439999999995,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",229,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,84426624.0,46400.0,49.92,2032.8639999999996,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2638332.0,1450.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",230,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.392,2036.2559999999996,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",231,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.456,2039.7119999999995,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",232,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,6.496,2046.2079999999996,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",233,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,2049.4399999999996,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",234,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.2,2052.6399999999994,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",235,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.576,2057.2159999999994,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",236,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.416,2061.6319999999996,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",237,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,21111808.0,37824.0,16.288,2077.9199999999996,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659744.0,1182.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",238,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,21110784.0,38112.0,16.192,2094.1119999999996,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659712.0,1191.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",239,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,21110784.0,37152.0,16.0,2110.1119999999996,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659712.0,1161.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",240,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.512,2114.624,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",241,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.416,2119.04,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",242,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.792,2124.832,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",243,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.704,2129.536,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",244,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.328,2132.864,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",245,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.608,2137.472,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",246,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.224,2141.6960000000004,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",247,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.664,2147.3600000000006,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",248,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.48,2151.8400000000006,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",249,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.52,2155.3600000000006,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",250,131072.0,11767808.0,0.0,0,128849018880.0,11767808.0,128860786688.0,66560.0,128.0,0.9980806142034548,98304.0,32768.0,15.904,2171.2640000000006,9920512.0,1585152.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,503316480.0,3072.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",251,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,44256.0,16.16,2187.4240000000004,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1383.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",252,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.488,2190.9120000000003,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",253,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.36,2194.2720000000004,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",254,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,6.656,2200.9280000000003,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",255,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.296,2204.224,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",256,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.168,2207.3920000000003,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",257,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.576,2211.9680000000003,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",258,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.576,2216.5440000000003,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",259,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75239808.0,190720.0,40.864,2257.4080000000004,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2351244.0,5960.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",260,409600.0,786432.0,65536.0,0,0.0,851968.0,851968.0,0.0,512.0,0.0,131072.0,131072.0,3.744,2261.1520000000005,32768.0,0.0,376832.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",261,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75307904.0,189184.0,39.872,2301.0240000000003,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2353372.0,5912.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",262,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.296,2304.32,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",263,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,84454528.0,45440.0,51.424,2355.744,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2639204.0,1420.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",264,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.296,2359.04,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",265,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.424,2362.464,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",266,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,6.752,2369.216,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",267,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,2372.48,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",268,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.104,2375.584,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",269,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.608,2380.192,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",270,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.384,2384.576,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",271,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,21111296.0,36032.0,16.128,2400.704,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659728.0,1126.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",272,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,21110784.0,37760.0,16.448,2417.152,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659712.0,1180.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",273,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,21110784.0,36192.0,16.416,2433.568,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659712.0,1131.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",274,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.8,2438.3680000000004,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",275,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.288,2442.6560000000004,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",276,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,4.992,2447.6480000000006,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",277,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.448,2452.0960000000005,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",278,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.456,2455.5520000000006,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",279,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.448,2460.0000000000005,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",280,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.352,2464.3520000000003,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",281,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.312,2469.664,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",282,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.64,2474.304,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",283,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.488,2477.792,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",284,131072.0,11767808.0,0.0,0,128849018880.0,11767808.0,128860786688.0,66560.0,128.0,0.9980806142034548,98304.0,32768.0,15.712,2493.504,9920512.0,1585152.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,503316480.0,3072.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",285,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,44256.0,16.0,2509.504,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1383.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",286,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.616,2513.12,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",287,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.424,2516.544,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",288,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,6.72,2523.2639999999997,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",289,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.104,2526.3679999999995,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",290,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.2,2529.5679999999993,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",291,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.64,2534.207999999999,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",292,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.576,2538.783999999999,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",293,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75446016.0,192288.0,41.088,2579.8719999999994,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2357688.0,6009.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",294,409600.0,786432.0,65536.0,0,0.0,851968.0,851968.0,0.0,512.0,0.0,131072.0,131072.0,3.712,2583.5839999999994,32768.0,0.0,376832.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",295,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75365632.0,191808.0,40.288,2623.8719999999994,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2355176.0,5994.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",296,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.296,2627.167999999999,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",297,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,84440576.0,44640.0,49.92,2677.0879999999993,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2638768.0,1395.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",298,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.616,2680.7039999999993,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",299,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.36,2684.0639999999994,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",300,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,6.4,2690.4639999999995,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",301,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.328,2693.7919999999995,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",302,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.2,2696.9919999999993,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",303,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.512,2701.5039999999995,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",304,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.48,2705.9839999999995,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",305,1268969472.0,2732417024.0,48619520.0,0,0.0,2781036544.0,2781036544.0,17092800.0,14889728.0,0.5344418052256532,1370044288.0,3513568.0,510.528,3216.5119999999997,87515136.0,155582464.0,1244659712.0,24309760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,42813884.0,109799.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",306,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.88,3219.392,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",307,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,128.0,4.416,3223.808,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",308,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.2,3227.008,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",309,128.0,608256.0,256.0,0,0.0,608512.0,608512.0,0.0,9520.0,0.0,2430976.0,2430976.0,4.704,3231.712,0.0,608256.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,75968.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",310,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.848,3234.56,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",311,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,171136.0,6.368,3240.928,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5348.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",312,286080.0,0.0,572160.0,0,0.0,572160.0,572160.0,39336.0,718188.0,0.05192706765726234,38124032.0,64.0,14.624,3255.5519999999997,0.0,0.0,0.0,286080.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1191376.0,2.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",313,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,172736.0,6.528,3262.0799999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5398.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",314,228864.0,0.0,457728.0,0,0.0,457728.0,457728.0,39336.0,719976.0,0.05180479170617612,38153888.0,0.0,14.432,3276.5119999999993,0.0,0.0,0.0,228864.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1192309.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",315,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,171520.0,6.176,3282.687999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5360.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",316,247936.0,0.0,495872.0,0,0.0,495872.0,495872.0,39336.0,719380.0,0.05184548632162759,38148416.0,32.0,14.944,3297.631999999999,0.0,0.0,0.0,247936.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1192138.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",317,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,169536.0,6.208,3303.8399999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5298.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",318,305152.0,0.0,610304.0,0,0.0,610304.0,610304.0,39336.0,717592.0,0.051967954679969564,38103424.0,128.0,15.264,3319.1039999999994,0.0,0.0,0.0,305152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1190732.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",319,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,57.0,0.0,19104.0,2400.0,4.832,3323.9359999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,597.0,75.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",320,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.04,3326.975999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",321,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,47.0,0.9315866084425036,2400.0,0.0,5.952,3332.9279999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",322,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.88,3335.8079999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",323,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,47.0,0.9315866084425036,2400.0,0.0,5.696,3341.5039999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",324,152576.0,0.0,305152.0,0,0.0,305152.0,305152.0,174332.0,38400.0,0.8194911907940508,2488288.0,11008.0,9.984,3351.4879999999994,0.0,0.0,0.0,152576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,77759.0,344.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",325,0.0,0.0,0.0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,8.768,3360.2559999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",326,1215488.0,0.0,2430976.0,0,0.0,2430976.0,2430976.0,0.0,56976.0,0.0,2447872.0,196608.0,6.336,3366.591999999999,0.0,0.0,0.0,1215488.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76496.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",327,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,14280.0,0.0,3038720.0,0.0,5.792,3372.383999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,94960.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",328,607744.0,0.0,1215488.0,0,0.0,1215488.0,1215488.0,0.0,18992.0,0.0,0.0,4861952.0,5.568,3377.9519999999993,0.0,0.0,0.0,607744.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,151936.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",329,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,18992.0,0.8768033212247016,2430976.0,0.0,7.008,3384.959999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",330,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.456,3388.4159999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",331,0.0,0.0,0.0,0,0.0,0.0,0.0,174114.0,83597.0,0.6756172611956804,8648192.0,5955392.0,17.184,3405.5999999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,270256.0,186106.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",332,0.0,0.0,0.0,0,0.0,0.0,0.0,45438.0,91105.0,0.3327742908827256,8843904.0,4953504.0,15.296,3420.8959999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,276372.0,154797.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",333,0.0,0.0,0.0,0,0.0,0.0,0.0,40734.0,91219.0,0.3087008252938546,8847232.0,5371840.0,14.56,3435.455999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,276476.0,167870.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",334,0.0,0.0,0.0,0,0.0,0.0,0.0,40734.0,91839.0,0.307257133805526,8872320.0,4606112.0,14.784,3450.2399999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,277260.0,143941.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",335,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,18992.0,0.43770724774988157,4861952.0,0.0,6.08,3456.3199999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,151936.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",336,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.808,3460.1279999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",337,0.0,0.0,0.0,0,0.0,0.0,0.0,38618.0,51423.0,0.42889350407036797,6184960.0,4015744.0,12.448,3472.575999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,193280.0,125492.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",338,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,75968.0,0.0,7333120.0,7292928.0,8.448,3481.023999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,229160.0,227904.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",339,9424696.0,20076672.0,1832560.0,0,0.0,21909232.0,21909232.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,86.304,3567.327999999999,2452096.0,607744.0,8508416.0,916280.0,0,0,0,0,0,0,0,0.0,0.0,0.0,227904.0,75968.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",340,0.0,3052116.0,0.0,0,0.0,3052116.0,3052116.0,334872.0,37984.0,0.8981268908103933,2430976.0,2430976.0,285.856,3853.1839999999993,3052116.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,75968.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",341,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,9520.0,0.0,2430976.0,607360.0,4.32,3857.5039999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,18980.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",342,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,3.232,3860.7359999999994,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",343,1215488.0,0.0,2430976.0,0,0.0,2430976.0,2430976.0,0.0,56976.0,0.0,5469696.0,289760.0,11.584,3872.3199999999993,0.0,0.0,0.0,1215488.0,0,0,0,0,0,0,0,0.0,0.0,0.0,170928.0,9055.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",344,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,14280.0,0.0,3038720.0,0.0,5.376,3877.6959999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,94960.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",345,9424708.0,20076672.0,1832584.0,0,0.0,21909256.0,21909256.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,86.336,3964.0319999999992,2452096.0,607744.0,8508416.0,916292.0,0,0,0,0,0,0,0,0.0,0.0,0.0,227904.0,75968.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",346,115712.0,0.0,231424.0,0,0.0,231424.0,231424.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,9.504,3973.535999999999,0.0,0.0,0.0,115712.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",347,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,3976.863999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",348,115712.0,0.0,231424.0,0,0.0,231424.0,231424.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,9.44,3986.303999999999,0.0,0.0,0.0,115712.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",349,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,3989.535999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",350,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.392,3992.927999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",351,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.544,3997.471999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",352,119088.0,990796.0,238176.0,0,0.0,1228972.0,1228972.0,7692.0,4832.0,0.6141807729160013,2431392.0,2560.0,9.6,4007.0719999999988,990796.0,0.0,0.0,119088.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75981.0,80.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",353,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,4010.4959999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",354,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,4.928,4015.4239999999986,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",355,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,4018.8479999999986,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",356,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.544,4023.3919999999985,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",357,2973696.0,6081536.0,1081344.0,0,0.0,7162880.0,7162880.0,0.0,18992.0,0.0,0.0,2430976.0,7.2,4030.5919999999983,0.0,1215488.0,2433024.0,540672.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,75968.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",358,3798340.0,6077440.0,1519240.0,0,0.0,7596680.0,7596680.0,0.0,14280.0,0.0,4861952.0,5120.0,6.88,4037.4719999999984,0.0,0.0,3038720.0,759620.0,0,0,0,0,0,0,0,0.0,0.0,0.0,151936.0,160.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",359,89600.0,0.0,179200.0,0,0.0,179200.0,179200.0,14092.0,4912.0,0.7415280993475057,2432256.0,2784.0,13.184,4050.6559999999986,0.0,0.0,0.0,89600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76008.0,87.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",360,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,128.0,4.32,4054.9759999999987,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",361,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.656,4057.6319999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",362,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.752,4060.3839999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",363,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.488,4063.8719999999985,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",364,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.456,4067.3279999999986,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",365,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,4.032,4071.3599999999988,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",366,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.768,4076.127999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",367,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,4079.4239999999986,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",368,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.52,4082.9439999999986,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",369,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,3.0,0.0,96.0,32.0,4.512,4087.4559999999988,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",370,0.0,0.0,0.0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,64.0,32.0,4.224,4091.679999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",371,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,3.296,4094.9759999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",372,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.232,4098.207999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",373,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,0.0,3.264,4101.471999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",374,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,64.0,32.0,4.0,4105.471999999999,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",375,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,768.0,0.0,33280.0,32768.0,7.52,4112.991999999999,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1040.0,1024.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",376,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.36,4116.351999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",377,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,4.96,4121.311999999999,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",378,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.712,4125.023999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",379,0.0,512.0,0.0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,3.616,4128.639999999999,0.0,512.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",380,384.0,0.0,768.0,0,0.0,768.0,768.0,0.0,20.0,0.0,2048.0,2048.0,4.0,4132.639999999999,0.0,0.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",381,4096.0,9216.0,0.0,0,0.0,9216.0,9216.0,0.0,32.0,0.0,2048.0,2048.0,4.448,4137.088,0.0,1024.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",382,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,3.328,4140.416,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",383,3600.0,8224.0,0.0,0,0.0,8224.0,8224.0,0.0,32.0,0.0,2048.0,2048.0,4.32,4144.736,0.0,1024.0,3600.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",384,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,3.232,4147.968,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",385,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.36,4151.3279999999995,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",386,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,7.008,4158.335999999999,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",387,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.328,4161.664,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",388,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.392,4165.056,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",389,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.384,4169.44,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",390,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.544,4173.9839999999995,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",391,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,21110784.0,36096.0,15.936,4189.919999999999,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659712.0,1128.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",392,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,21110784.0,37856.0,16.064,4205.9839999999995,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659712.0,1183.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",393,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,21113216.0,35936.0,16.736,4222.719999999999,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659788.0,1123.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",394,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.576,4227.295999999999,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",395,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.544,4231.839999999999,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",396,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.6,4237.44,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",397,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.448,4241.888,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",398,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.584,4245.472,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",399,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.608,4250.08,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",400,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.384,4254.464,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",401,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.376,4259.84,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",402,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.768,4264.608,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",403,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.488,4268.0960000000005,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",404,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,640.0,0.0,65536.0,65536.0,4.608,4272.704000000001,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",405,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,640.0,0.0,65536.0,65536.0,4.512,4277.216,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",406,131072.0,11771904.0,0.0,0,128849018880.0,11771904.0,128860790784.0,66560.0,128.0,0.9980806142034548,163840.0,32768.0,16.224,4293.4400000000005,9924608.0,1585152.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,503316480.0,5120.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",407,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,46688.0,16.224,4309.664000000001,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1459.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",408,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.296,4312.960000000001,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",409,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.392,4316.352000000001,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",410,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,6.816,4323.168000000001,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",411,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.328,4326.496000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",412,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.392,4329.888000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",413,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.416,4334.304000000001,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",414,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.48,4338.784000000001,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",415,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75244672.0,190976.0,40.16,4378.944,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2351396.0,5968.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",416,409600.0,786432.0,65536.0,0,0.0,851968.0,851968.0,0.0,512.0,0.0,131072.0,131072.0,3.744,4382.688,32768.0,0.0,376832.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",417,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75292800.0,190656.0,40.032,4422.72,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2352900.0,5958.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",418,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.648,4426.368,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",419,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,84443904.0,45472.0,50.944,4477.312000000001,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2638872.0,1421.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",420,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.392,4480.704000000001,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",421,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.36,4484.064,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",422,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,7.008,4491.072,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",423,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.424,4494.496,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",424,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.136,4497.6320000000005,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",425,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.384,4502.0160000000005,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",426,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.576,4506.592000000001,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",427,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,21110784.0,36608.0,15.712,4522.304000000001,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659712.0,1144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",428,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,21110784.0,37536.0,16.064,4538.368000000001,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659712.0,1173.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",429,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,21112192.0,37216.0,16.448,4554.816000000002,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659756.0,1163.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",430,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.48,4559.296000000001,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",431,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.48,4563.776000000001,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",432,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,4.896,4568.6720000000005,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",433,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.736,4573.408,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",434,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.456,4576.8640000000005,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",435,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.672,4581.536,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",436,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.32,4585.856,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",437,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,4.96,4590.816,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",438,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.64,4595.456,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",439,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.616,4599.072,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",440,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,640.0,0.0,65536.0,65536.0,4.576,4603.648,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",441,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,640.0,0.0,65536.0,65536.0,4.48,4608.128,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",442,131072.0,11771904.0,0.0,0,128849018880.0,11771904.0,128860790784.0,66560.0,128.0,0.9980806142034548,163840.0,32768.0,16.16,4624.288,9924608.0,1585152.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,503316480.0,5120.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",443,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21103104.0,46272.0,16.288,4640.575999999999,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659472.0,1446.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",444,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.36,4643.935999999999,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",445,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.136,4647.071999999999,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",446,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,6.816,4653.887999999999,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",447,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,4657.119999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",448,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.392,4660.511999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",449,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.704,4665.2159999999985,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",450,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.672,4669.887999999998,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",451,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75245952.0,187776.0,39.424,4709.311999999998,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2351436.0,5868.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",452,409600.0,786432.0,65536.0,0,0.0,851968.0,851968.0,0.0,512.0,0.0,131072.0,131072.0,3.616,4712.927999999998,32768.0,0.0,376832.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",453,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75111552.0,190560.0,40.512,4753.439999999998,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2347236.0,5955.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",454,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.424,4756.863999999998,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",455,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,84440192.0,46016.0,50.336,4807.199999999998,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2638756.0,1438.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",456,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.424,4810.623999999998,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",457,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.36,4813.983999999998,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",458,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,6.848,4820.831999999998,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",459,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.328,4824.159999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",460,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.2,4827.359999999998,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",461,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.384,4831.743999999998,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",462,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.608,4836.351999999998,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",463,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,21110784.0,36416.0,16.096,4852.447999999998,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659712.0,1138.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",464,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,21110784.0,36800.0,16.256,4868.703999999998,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659712.0,1150.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",465,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,21111680.0,37408.0,16.16,4884.863999999998,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659740.0,1169.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",466,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.672,4889.535999999997,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",467,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.32,4893.855999999997,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",468,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.408,4899.263999999997,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",469,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.672,4903.935999999997,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",470,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.712,4907.647999999997,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",471,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.768,4912.415999999997,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",472,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.352,4916.767999999997,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",473,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.536,4922.303999999997,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",474,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.768,4927.071999999997,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",475,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.552,4930.623999999997,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",476,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,640.0,0.0,65536.0,65536.0,4.608,4935.231999999997,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",477,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,640.0,0.0,65536.0,65536.0,4.48,4939.711999999997,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",478,131072.0,11771904.0,0.0,0,128849018880.0,11771904.0,128860790784.0,66560.0,128.0,0.9980806142034548,163840.0,32768.0,15.968,4955.679999999997,9924608.0,1585152.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,503316480.0,5120.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",479,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,46496.0,15.808,4971.487999999997,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1453.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",480,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.296,4974.783999999997,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",481,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.392,4978.175999999997,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",482,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,6.816,4984.991999999997,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",483,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.328,4988.319999999997,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",484,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.36,4991.679999999997,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",485,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.512,4996.191999999996,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",486,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.608,5000.7999999999965,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",487,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75209856.0,186912.0,39.392,5040.191999999996,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2350308.0,5841.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",488,409600.0,786432.0,65536.0,0,0.0,851968.0,851968.0,0.0,512.0,0.0,131072.0,131072.0,3.872,5044.063999999997,32768.0,0.0,376832.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",489,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75327104.0,190080.0,39.904,5083.967999999997,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2353972.0,5940.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",490,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.456,5087.423999999997,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",491,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,84449920.0,43936.0,50.272,5137.695999999997,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2639060.0,1373.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",492,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.488,5141.1839999999975,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",493,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.296,5144.479999999998,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",494,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,6.848,5151.327999999998,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",495,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,5154.591999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",496,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.168,5157.7599999999975,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",497,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.544,5162.303999999997,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",498,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.576,5166.879999999997,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",499,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,21110784.0,36800.0,15.936,5182.815999999997,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659712.0,1150.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",500,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,21110784.0,36416.0,16.544,5199.359999999997,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659712.0,1138.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",501,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,21111040.0,37632.0,16.096,5215.4559999999965,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659720.0,1176.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",502,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.608,5220.063999999997,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",503,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.448,5224.511999999997,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",504,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.376,5229.887999999997,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",505,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.512,5234.399999999997,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",506,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.424,5237.823999999997,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",507,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.576,5242.399999999997,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",508,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.416,5246.815999999997,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",509,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.376,5252.191999999997,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",510,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.608,5256.799999999997,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",511,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.552,5260.351999999997,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",512,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,640.0,0.0,65536.0,65536.0,4.544,5264.895999999997,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",513,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,640.0,0.0,65536.0,65536.0,4.544,5269.439999999997,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",514,131072.0,11771904.0,0.0,0,128849018880.0,11771904.0,128860790784.0,66560.0,128.0,0.9980806142034548,163840.0,32768.0,16.032,5285.471999999997,9924608.0,1585152.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,503316480.0,5120.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",515,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,48096.0,15.744,5301.215999999997,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1503.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",516,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.488,5304.703999999997,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",517,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.296,5307.999999999997,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",518,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,6.848,5314.847999999997,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",519,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.296,5318.1439999999975,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",520,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.104,5321.247999999998,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",521,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.512,5325.7599999999975,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",522,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.512,5330.271999999997,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",523,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75306880.0,187328.0,39.744,5370.015999999997,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2353340.0,5854.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",524,409600.0,786432.0,65536.0,0,0.0,851968.0,851968.0,0.0,512.0,0.0,131072.0,131072.0,3.776,5373.791999999997,32768.0,0.0,376832.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",525,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75173760.0,188416.0,40.192,5413.983999999997,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2349180.0,5888.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",526,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.328,5417.311999999997,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",527,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,84431360.0,45344.0,51.68,5468.9919999999975,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2638480.0,1417.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",528,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.328,5472.319999999998,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",529,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.264,5475.583999999998,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",530,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,6.848,5482.431999999998,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",531,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.36,5485.791999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",532,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.136,5488.927999999998,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",533,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.48,5493.407999999998,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",534,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.576,5497.983999999998,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",535,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,21111680.0,38688.0,15.904,5513.887999999998,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659740.0,1209.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",536,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,21110784.0,35808.0,16.416,5530.303999999998,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659712.0,1119.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",537,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,21110784.0,37536.0,16.64,5546.943999999999,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659712.0,1173.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",538,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.8,5551.743999999999,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",539,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.64,5556.383999999999,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",540,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.44,5561.823999999999,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",541,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.48,5566.303999999998,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",542,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.552,5569.855999999998,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",543,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.64,5574.495999999998,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",544,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.416,5578.911999999998,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",545,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.44,5584.351999999998,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",546,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.64,5588.991999999998,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",547,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.456,5592.4479999999985,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",548,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,640.0,0.0,65536.0,65536.0,4.64,5597.087999999999,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",549,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,640.0,0.0,65536.0,65536.0,4.64,5601.727999999999,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",550,131072.0,11771904.0,0.0,0,128849018880.0,11771904.0,128860790784.0,66560.0,128.0,0.9980806142034548,163840.0,32768.0,15.872,5617.599999999999,9924608.0,1585152.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,503316480.0,5120.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",551,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,47936.0,15.872,5633.472,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1498.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",552,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.392,5636.864,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",553,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.36,5640.223999999999,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",554,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,6.944,5647.168,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",555,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.36,5650.527999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",556,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.168,5653.695999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",557,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.48,5658.175999999999,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",558,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.608,5662.783999999999,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",559,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75324928.0,191616.0,39.584,5702.367999999999,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2353904.0,5988.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",560,409600.0,786432.0,65536.0,0,0.0,851968.0,851968.0,0.0,512.0,0.0,131072.0,131072.0,3.552,5705.919999999998,32768.0,0.0,376832.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",561,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75276288.0,191904.0,39.904,5745.823999999999,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2352384.0,5997.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",562,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.712,5749.535999999999,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",563,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,84430592.0,45824.0,50.368,5799.9039999999995,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2638456.0,1432.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",564,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.488,5803.392,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",565,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.264,5806.656,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",566,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,7.168,5813.824,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",567,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,5817.056,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",568,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.168,5820.223999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",569,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.544,5824.767999999999,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",570,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.608,5829.375999999999,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",571,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,21112192.0,40096.0,15.84,5845.215999999999,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659756.0,1253.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",572,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,21110784.0,36576.0,16.256,5861.472,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659712.0,1143.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",573,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,21110784.0,35296.0,16.192,5877.664,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659712.0,1103.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",574,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.48,5882.143999999999,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",575,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.576,5886.719999999999,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",576,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.6,5892.32,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",577,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.608,5896.928,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",578,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.616,5900.544,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",579,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.64,5905.184,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",580,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.48,5909.664,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",581,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.504,5915.168,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",582,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.704,5919.871999999999,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",583,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.488,5923.36,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",584,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,640.0,0.0,65536.0,65536.0,4.448,5927.808,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",585,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,640.0,0.0,65536.0,65536.0,4.544,5932.352,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",586,131072.0,11771904.0,0.0,0,128849018880.0,11771904.0,128860790784.0,66560.0,128.0,0.9980806142034548,163840.0,32768.0,16.128,5948.48,9924608.0,1585152.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,503316480.0,5120.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",587,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,45472.0,16.128,5964.607999999999,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1421.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",588,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.36,5967.967999999999,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",589,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.168,5971.135999999999,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",590,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,6.848,5977.983999999999,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",591,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,5981.2159999999985,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",592,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.136,5984.351999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",593,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.48,5988.8319999999985,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",594,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.448,5993.279999999999,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",595,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75427968.0,192544.0,40.288,6033.567999999998,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2357124.0,6017.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",596,409600.0,786432.0,65536.0,0,0.0,851968.0,851968.0,0.0,512.0,0.0,131072.0,131072.0,3.648,6037.2159999999985,32768.0,0.0,376832.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",597,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75164800.0,188672.0,39.808,6077.0239999999985,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2348900.0,5896.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",598,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.392,6080.415999999998,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",599,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,84436608.0,45152.0,49.6,6130.015999999999,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2638644.0,1411.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",600,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.296,6133.311999999999,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",601,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.36,6136.671999999999,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",602,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,7.2,6143.8719999999985,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",603,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.328,6147.199999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",604,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.168,6150.367999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",605,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.352,6154.719999999998,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",606,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.512,6159.231999999998,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",607,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,21110784.0,36192.0,16.0,6175.231999999998,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659712.0,1131.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",608,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,21112448.0,38560.0,16.16,6191.391999999998,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659764.0,1205.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",609,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,21110784.0,36832.0,16.288,6207.679999999998,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659712.0,1151.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",610,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.704,6212.383999999997,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",611,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.48,6216.863999999997,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",612,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.504,6222.367999999997,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",613,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.48,6226.847999999996,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",614,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.392,6230.239999999996,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",615,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.48,6234.719999999996,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",616,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.224,6238.943999999996,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",617,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.472,6244.415999999996,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",618,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.608,6249.023999999996,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",619,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.584,6252.607999999996,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",620,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,640.0,0.0,65536.0,65536.0,4.512,6257.119999999995,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",621,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,640.0,0.0,65536.0,65536.0,4.544,6261.663999999995,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",622,131072.0,11771904.0,0.0,0,128849018880.0,11771904.0,128860790784.0,66560.0,128.0,0.9980806142034548,163840.0,32768.0,16.0,6277.663999999995,9924608.0,1585152.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,503316480.0,5120.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",623,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,45600.0,15.552,6293.215999999995,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1425.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",624,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.328,6296.543999999995,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",625,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.36,6299.903999999995,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",626,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,7.04,6306.943999999995,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",627,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,6310.207999999995,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",628,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.36,6313.567999999995,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",629,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.512,6318.0799999999945,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",630,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.608,6322.687999999995,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",631,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75216000.0,189408.0,40.064,6362.751999999995,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2350500.0,5919.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",632,409600.0,786432.0,65536.0,0,0.0,851968.0,851968.0,0.0,512.0,0.0,131072.0,131072.0,3.68,6366.431999999995,32768.0,0.0,376832.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",633,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75236480.0,191680.0,38.304,6404.735999999995,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2351140.0,5990.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",634,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.36,6408.095999999995,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",635,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,84439552.0,43808.0,51.872,6459.967999999995,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2638736.0,1369.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",636,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.296,6463.263999999996,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",637,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.168,6466.431999999995,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",638,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,6.72,6473.1519999999955,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",639,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,6476.3839999999955,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",640,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.136,6479.519999999996,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",641,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.512,6484.031999999996,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",642,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.768,6488.799999999996,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",643,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,21110784.0,36384.0,15.904,6504.703999999996,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659712.0,1137.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",644,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,21110784.0,36864.0,16.384,6521.087999999996,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659712.0,1152.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",645,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,21110784.0,38176.0,16.352,6537.439999999996,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659712.0,1193.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",646,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.544,6541.983999999996,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",647,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.608,6546.591999999996,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",648,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.536,6552.127999999996,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",649,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.8,6556.927999999996,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",650,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.584,6560.511999999996,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",651,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.672,6565.183999999996,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",652,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,4.32,6569.503999999995,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",653,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.472,6574.975999999995,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",654,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,49152.0,32768.0,4.48,6579.455999999995,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",655,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.552,6583.007999999994,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",656,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,640.0,0.0,65536.0,65536.0,4.64,6587.647999999995,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",657,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,640.0,0.0,65536.0,65536.0,4.832,6592.479999999995,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",658,131072.0,11771904.0,0.0,0,128849018880.0,11771904.0,128860790784.0,66560.0,128.0,0.9980806142034548,163840.0,32768.0,16.128,6608.607999999995,9924608.0,1585152.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,503316480.0,5120.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",659,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,21102592.0,46496.0,16.064,6624.671999999995,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,659456.0,1453.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",660,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.68,6628.351999999995,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",661,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.2,6631.551999999995,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",662,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,6.88,6638.431999999995,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",663,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,6641.695999999995,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",664,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.104,6644.799999999996,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",665,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.448,6649.247999999996,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",666,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.704,6653.951999999996,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",667,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75225600.0,189376.0,40.384,6694.335999999996,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2350800.0,5918.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",668,409600.0,786432.0,65536.0,0,0.0,851968.0,851968.0,0.0,512.0,0.0,131072.0,131072.0,3.584,6697.9199999999955,32768.0,0.0,376832.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",669,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,75296384.0,192320.0,39.52,6737.439999999996,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2353012.0,6010.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",670,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.456,6740.895999999996,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",671,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,84452992.0,44672.0,50.72,6791.615999999996,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2639156.0,1396.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",672,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.232,6794.847999999996,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",673,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.2,6798.047999999996,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",674,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,6.688,6804.735999999996,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",675,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.36,6808.095999999996,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",676,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.168,6811.263999999996,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",677,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,33792.0,32768.0,4.352,6815.615999999995,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",678,8192.0,8192.0,16384.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,65536.0,32768.0,4.608,6820.223999999996,0.0,8192.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",679,1268969472.0,2732417024.0,48619520.0,0,0.0,2781036544.0,2781036544.0,17092800.0,14889728.0,0.5344418052256532,1369974656.0,3515136.0,509.312,7329.5359999999955,87515136.0,155582464.0,1244659712.0,24309760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,42811708.0,109848.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",680,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.752,7332.287999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",681,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,96.0,160.0,3.936,7336.223999999996,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",682,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,7339.487999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",683,128.0,608256.0,256.0,0,0.0,608512.0,608512.0,0.0,9520.0,0.0,2430976.0,2430976.0,4.64,7344.127999999996,0.0,608256.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,75968.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",684,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,3.04,7347.167999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",685,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,173248.0,6.272,7353.439999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5414.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",686,286080.0,0.0,572160.0,0,0.0,572160.0,572160.0,39336.0,718188.0,0.05192706765726234,38126400.0,0.0,14.976,7368.415999999996,0.0,0.0,0.0,286080.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1191450.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",687,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,174656.0,6.336,7374.751999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5458.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",688,228864.0,0.0,457728.0,0,0.0,457728.0,457728.0,39336.0,719976.0,0.05180479170617612,38156800.0,0.0,14.88,7389.631999999996,0.0,0.0,0.0,228864.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1192400.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",689,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,172096.0,6.24,7395.871999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5378.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",690,233632.0,0.0,467264.0,0,0.0,467264.0,467264.0,39336.0,719827.0,0.05181495936972692,38152864.0,0.0,14.912,7410.783999999996,0.0,0.0,0.0,233632.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1192277.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",691,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,171712.0,6.304,7417.087999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5366.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",692,252704.0,0.0,505408.0,0,0.0,505408.0,505408.0,39336.0,719231.0,0.051855669967188135,38139168.0,128.0,15.328,7432.4159999999965,0.0,0.0,0.0,252704.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1191849.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",693,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,57.0,0.0,19104.0,2400.0,4.96,7437.375999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,597.0,75.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",694,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.04,7440.4159999999965,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",695,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,47.0,0.9315866084425036,2400.0,0.0,5.76,7446.175999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",696,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.072,7449.247999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",697,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,47.0,0.9315866084425036,2400.0,0.0,6.08,7455.327999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",698,152576.0,0.0,305152.0,0,0.0,305152.0,305152.0,149363.0,38398.0,0.7954953371573437,2488288.0,11040.0,9.568,7464.895999999997,0.0,0.0,0.0,152576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,77759.0,345.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",699,0.0,0.0,0.0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,8.288,7473.183999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",700,1215488.0,0.0,2430976.0,0,0.0,2430976.0,2430976.0,0.0,56976.0,0.0,2447872.0,198080.0,6.432,7479.615999999996,0.0,0.0,0.0,1215488.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76496.0,6190.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",701,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,14280.0,0.0,3038720.0,0.0,5.376,7484.991999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,94960.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",702,607744.0,0.0,1215488.0,0,0.0,1215488.0,1215488.0,0.0,18992.0,0.0,0.0,4861952.0,5.504,7490.4959999999965,0.0,0.0,0.0,607744.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,151936.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",703,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,18992.0,0.8768033212247016,2430976.0,0.0,6.944,7497.439999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",704,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.68,7501.119999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",705,0.0,0.0,0.0,0,0.0,0.0,0.0,167586.0,86247.0,0.6602214842041815,8855296.0,5939936.0,17.792,7518.9119999999975,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,276728.0,185623.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",706,0.0,0.0,0.0,0,0.0,0.0,0.0,39822.0,91599.0,0.3030109343255644,8878976.0,7409664.0,14.272,7533.1839999999975,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,277468.0,231552.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",707,0.0,0.0,0.0,0,0.0,0.0,0.0,40734.0,91450.0,0.30816135084427765,8827008.0,7358624.0,14.656,7547.839999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,275844.0,229957.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",708,0.0,0.0,0.0,0,0.0,0.0,0.0,40734.0,91890.0,0.30713897937024975,8842624.0,6846464.0,14.464,7562.303999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,276332.0,213952.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",709,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,18992.0,0.43770724774988157,4861952.0,0.0,5.92,7568.223999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,151936.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",710,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.648,7571.871999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",711,0.0,0.0,0.0,0,0.0,0.0,0.0,38618.0,51402.0,0.42899355698733616,6210176.0,4024384.0,12.448,7584.319999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,194068.0,125762.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",712,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,75968.0,0.0,7332128.0,7292928.0,8.416,7592.735999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,229129.0,227904.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",713,9424696.0,20076672.0,1832560.0,0,0.0,21909232.0,21909232.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,86.368,7679.103999999998,2452096.0,607744.0,8508416.0,916280.0,0,0,0,0,0,0,0,0.0,0.0,0.0,227904.0,75968.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",714,0.0,3052116.0,0.0,0,0.0,3052116.0,3052116.0,334872.0,37984.0,0.8981268908103933,2430976.0,2430976.0,284.576,7963.6799999999985,3052116.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,75968.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",715,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,9520.0,0.0,2430976.0,607584.0,4.288,7967.967999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,18987.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",716,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,3.232,7971.199999999998,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",717,1215488.0,0.0,2430976.0,0,0.0,2430976.0,2430976.0,0.0,56976.0,0.0,5469696.0,281536.0,11.616,7982.815999999998,0.0,0.0,0.0,1215488.0,0,0,0,0,0,0,0,0.0,0.0,0.0,170928.0,8798.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",718,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,14280.0,0.0,3038720.0,0.0,5.184,7987.999999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,94960.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",719,9424708.0,20076672.0,1832584.0,0,0.0,21909256.0,21909256.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,86.624,8074.623999999998,2452096.0,607744.0,8508416.0,916292.0,0,0,0,0,0,0,0,0.0,0.0,0.0,227904.0,75968.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",720,115712.0,0.0,231424.0,0,0.0,231424.0,231424.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,9.216,8083.839999999998,0.0,0.0,0.0,115712.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",721,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,8087.231999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",722,115712.0,0.0,231424.0,0,0.0,231424.0,231424.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,9.504,8096.735999999998,0.0,0.0,0.0,115712.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",723,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.552,8100.287999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",724,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.68,8103.967999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",725,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.448,8108.415999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",726,119088.0,990796.0,238176.0,0,0.0,1228972.0,1228972.0,7692.0,4832.0,0.6141807729160013,2431392.0,2560.0,9.824,8118.239999999998,990796.0,0.0,0.0,119088.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75981.0,80.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",727,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,8121.599999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",728,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,4.96,8126.559999999998,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",729,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.136,8129.695999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",730,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.384,8134.079999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",731,2973696.0,6081536.0,1081344.0,0,0.0,7162880.0,7162880.0,0.0,18992.0,0.0,0.0,2430976.0,7.264,8141.343999999998,0.0,1215488.0,2433024.0,540672.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,75968.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",732,3798340.0,6077440.0,1519240.0,0,0.0,7596680.0,7596680.0,0.0,14280.0,0.0,4861952.0,1536.0,6.848,8148.191999999998,0.0,0.0,3038720.0,759620.0,0,0,0,0,0,0,0,0.0,0.0,0.0,151936.0,48.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",733,89600.0,0.0,179200.0,0,0.0,179200.0,179200.0,14092.0,4912.0,0.7415280993475057,2432256.0,2720.0,12.896,8161.087999999998,0.0,0.0,0.0,89600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76008.0,85.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",734,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,96.0,160.0,3.872,8164.959999999998,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",735,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.784,8167.743999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",736,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.816,8170.559999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",737,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.456,8174.015999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",738,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.168,8177.1839999999975,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",739,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,4.352,8181.535999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",740,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,5.184,8186.7199999999975,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",741,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,8190.015999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
