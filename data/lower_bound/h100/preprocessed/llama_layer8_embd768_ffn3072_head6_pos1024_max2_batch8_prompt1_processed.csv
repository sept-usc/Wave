Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,64.0,2.816,2.816,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,2.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,64.0,2.592,5.4079999999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,2.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.752,8.16,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.168,11.328,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.872,15.2,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",6,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,3.0,0.0,96.0,32.0,3.776,18.976,0.0,0.0,0.0,16.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",7,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,64.0,4.48,23.456,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,2.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",8,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,32.0,5.024,28.48,0.0,0.0,0.0,16.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",9,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.776,32.256,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",10,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,64.0,2.816,35.072,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,2.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.72,37.792,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.232,41.024,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,0.0,0.0,0.0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,3.648,44.672000000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.584,48.25600000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",15,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.488,51.74400000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",16,0.0,0.0,0.0,0,0.0,0.0,0.0,96.0,8.0,0.9230769230769231,64.0,32.0,4.192,55.93600000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",17,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,3.2,59.13600000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",18,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.424,62.56000000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",19,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,0.0,3.456,66.016,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",20,768.0,0.0,1536.0,0,0.0,1536.0,1536.0,0.0,576.0,0.0,3456.0,24576.0,7.136,73.152,0.0,0.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,108.0,768.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",21,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.584,76.736,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",22,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,5.344,82.08,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",23,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.36,85.44,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",24,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,64.0,48.0,0.5714285714285714,2560.0,2048.0,3.52,88.96,0.0,1024.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80.0,64.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",25,512.0,0.0,1024.0,0,0.0,1024.0,1024.0,0.0,40.0,0.0,4096.0,4096.0,3.872,92.832,0.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",26,8192.0,18432.0,0.0,0,0.0,18432.0,18432.0,0.0,16.0,0.0,4096.0,4096.0,4.096,96.928,0.0,2048.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",27,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,3.296,100.224,0.0,1024.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",28,7168.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,16.0,0.0,4096.0,4096.0,4.064,104.28800000000001,0.0,2048.0,7168.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",29,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,3.168,107.45600000000002,0.0,1024.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",30,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.52,110.97600000000001,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",31,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,64.0,6.912,117.88800000000002,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,2.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",32,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,121.15200000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",33,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,124.38400000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",34,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.416,128.8,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",35,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.384,133.18400000000003,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,36,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1109664.0,8.48,141.66400000000002,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34677.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,37,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.368,152.032,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,38,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1103872.0,7.808,159.84,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34496.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,39,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.496,170.336,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,40,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1103424.0,7.84,178.17600000000002,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34482.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,41,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.272,188.448,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",42,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.672,193.12,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",43,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.512,197.632,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",44,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.376,203.008,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",45,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.768,207.776,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",46,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.456,211.232,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",47,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.544,215.776,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",48,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.448,220.22400000000002,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",49,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.44,225.66400000000002,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",50,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.384,230.048,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",51,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.36,233.40800000000002,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",52,98304.0,8825856.0,0.0,0,96636764160.0,8825856.0,96645590016.0,49920.0,96.0,0.9980806142034548,73728.0,24576.0,15.648,249.056,7440384.0,1188864.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,377487360.0,2304.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,53,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1108960.0,7.776,256.832,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34655.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,54,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.4,267.23199999999997,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",55,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.584,270.816,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",56,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.36,274.176,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",57,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,6.464,280.64,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",58,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.36,284.0,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",59,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,287.232,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",60,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.352,291.584,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",61,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.608,296.192,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",62,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681216.0,152384.0,13.6,309.79200000000003,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396288.0,4762.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",63,307200.0,589824.0,49152.0,0,0.0,638976.0,638976.0,0.0,384.0,0.0,98304.0,98304.0,3.776,313.56800000000004,24576.0,0.0,282624.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",64,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681216.0,150368.0,13.44,327.00800000000004,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396288.0,4699.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",65,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,3.424,330.432,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,66,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,11796480.0,3063072.0,12.608,343.04,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,95721.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,67,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6528.0,0.1282051282051282,3244032.0,24576.0,21.312,364.35200000000003,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",68,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.488,367.84000000000003,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",69,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.2,371.04,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",70,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,6.496,377.536,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",71,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.296,380.832,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",72,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.36,384.192,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",73,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.384,388.576,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",74,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.416,392.992,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,75,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1110912.0,8.32,401.312,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34716.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,76,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.464,411.776,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,77,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1097408.0,8.0,419.776,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34294.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,78,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.272,430.048,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,79,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1111968.0,7.776,437.824,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34749.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,80,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.592,448.416,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",81,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.416,452.832,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",82,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.448,457.28,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",83,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.216,462.496,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",84,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.448,466.94399999999996,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",85,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.488,470.43199999999996,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",86,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.608,475.03999999999996,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",87,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.32,479.35999999999996,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",88,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.472,484.83199999999994,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",89,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.576,489.40799999999996,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",90,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.392,492.79999999999995,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",91,98304.0,8825856.0,0.0,0,96636764160.0,8825856.0,96645590016.0,49920.0,96.0,0.9980806142034548,73728.0,24576.0,15.52,508.31999999999994,7440384.0,1188864.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,377487360.0,2304.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,92,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1106720.0,7.968,516.2879999999999,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34585.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,93,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.72,527.0079999999999,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",94,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.616,530.6239999999999,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",95,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.36,533.9839999999999,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",96,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,64.0,6.24,540.2239999999999,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,2.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",97,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.136,543.3599999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",98,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.488,546.848,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",99,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.448,551.2959999999999,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",100,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.576,555.872,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",101,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681216.0,149344.0,13.216,569.088,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396288.0,4667.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",102,307200.0,589824.0,49152.0,0,0.0,638976.0,638976.0,0.0,384.0,0.0,98304.0,98304.0,3.808,572.896,24576.0,0.0,282624.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",103,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681600.0,148992.0,14.048,586.944,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396300.0,4656.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",104,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,3.456,590.4,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,105,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,11796480.0,3067264.0,12.736,603.136,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,95852.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,106,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6528.0,0.1282051282051282,3244032.0,24576.0,21.6,624.736,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",107,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.392,628.128,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",108,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.264,631.392,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",109,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,64.0,5.984,637.3760000000001,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,2.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",110,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,640.6400000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",111,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,643.9680000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",112,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.416,648.3840000000001,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",113,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.512,652.8960000000001,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,114,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1101856.0,7.776,660.672,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34433.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,115,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.336,671.008,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,116,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1103008.0,7.968,678.976,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34469.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,117,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.432,689.408,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,118,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1108160.0,7.84,697.248,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34630.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,119,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.4,707.648,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",120,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.672,712.32,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",121,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.16,716.48,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",122,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.248,721.7280000000001,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",123,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.48,726.2080000000001,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",124,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.328,729.5360000000001,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",125,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.512,734.048,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",126,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.352,738.4,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",127,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.344,743.744,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",128,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.448,748.192,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",129,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.264,751.456,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",130,98304.0,8825856.0,0.0,0,96636764160.0,8825856.0,96645590016.0,49920.0,96.0,0.9980806142034548,73728.0,24576.0,15.712,767.168,7440384.0,1188864.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,377487360.0,2304.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,131,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1105760.0,7.712,774.88,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34555.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,132,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.56,785.4399999999999,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",133,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.328,788.7679999999999,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",134,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.52,792.2879999999999,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",135,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,6.752,799.0399999999998,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",136,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.2,802.2399999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",137,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.136,805.3759999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",138,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.288,809.6639999999999,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",139,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.448,814.1119999999999,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",140,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681216.0,151424.0,13.088,827.1999999999998,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396288.0,4732.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",141,307200.0,589824.0,49152.0,0,0.0,638976.0,638976.0,0.0,384.0,0.0,98304.0,98304.0,3.744,830.9439999999998,24576.0,0.0,282624.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",142,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681216.0,149248.0,13.088,844.0319999999998,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396288.0,4664.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",143,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,3.52,847.5519999999998,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,144,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,11796480.0,3055616.0,12.928,860.4799999999998,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,95488.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,145,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6528.0,0.1282051282051282,3244032.0,24576.0,21.44,881.9199999999998,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",146,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.392,885.3119999999999,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",147,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.392,888.704,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",148,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,6.176,894.88,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",149,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.168,898.048,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",150,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.392,901.44,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",151,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.32,905.7600000000001,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",152,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.608,910.368,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,153,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1105600.0,7.872,918.24,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34550.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,154,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.24,928.48,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,155,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1103232.0,7.808,936.288,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34476.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,156,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.56,946.848,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,157,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1103168.0,8.16,955.0079999999999,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34474.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,158,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.336,965.3439999999999,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",159,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.704,970.0479999999999,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",160,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.352,974.3999999999999,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",161,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.504,979.9039999999999,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",162,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.512,984.4159999999998,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",163,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.52,987.9359999999998,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",164,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.512,992.4479999999998,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",165,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.48,996.9279999999998,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",166,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.28,1002.2079999999997,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",167,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.608,1006.8159999999997,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",168,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.392,1010.2079999999997,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",169,98304.0,8825856.0,0.0,0,96636764160.0,8825856.0,96645590016.0,49920.0,96.0,0.9980806142034548,73728.0,24576.0,15.456,1025.6639999999998,7440384.0,1188864.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,377487360.0,2304.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,170,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1108608.0,7.84,1033.5039999999997,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34644.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,171,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.432,1043.9359999999997,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",172,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.488,1047.4239999999998,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",173,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.232,1050.6559999999997,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",174,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,6.592,1057.2479999999998,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",175,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.296,1060.5439999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",176,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.2,1063.744,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",177,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.352,1068.096,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",178,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.384,1072.48,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",179,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681216.0,151936.0,13.12,1085.6,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396288.0,4748.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",180,307200.0,589824.0,49152.0,0,0.0,638976.0,638976.0,0.0,384.0,0.0,98304.0,98304.0,3.808,1089.408,24576.0,0.0,282624.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",181,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681216.0,148800.0,13.248,1102.656,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396288.0,4650.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",182,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,3.392,1106.048,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,183,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,11796480.0,3072224.0,12.768,1118.816,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,96007.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,184,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6528.0,0.1282051282051282,3244032.0,24576.0,21.152,1139.968,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",185,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.424,1143.392,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",186,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.296,1146.688,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",187,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,64.0,6.208,1152.8960000000002,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,2.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",188,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.136,1156.0320000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",189,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.392,1159.4240000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",190,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.448,1163.8720000000003,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",191,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.736,1168.6080000000004,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,192,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1107328.0,8.032,1176.6400000000003,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34604.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,193,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.272,1186.9120000000003,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,194,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1108896.0,7.872,1194.7840000000003,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34653.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,195,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.144,1204.9280000000003,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,196,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1103680.0,7.936,1212.8640000000003,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34490.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,197,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.528,1223.3920000000003,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",198,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.608,1228.0000000000002,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",199,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.64,1232.6400000000003,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",200,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.536,1238.1760000000004,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",201,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.416,1242.5920000000003,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",202,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.584,1246.1760000000004,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",203,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.352,1250.5280000000005,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",204,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.32,1254.8480000000004,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",205,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.44,1260.2880000000005,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",206,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.576,1264.8640000000005,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",207,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.456,1268.3200000000004,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",208,98304.0,8825856.0,0.0,0,96636764160.0,8825856.0,96645590016.0,49920.0,96.0,0.9980806142034548,73728.0,24576.0,15.616,1283.9360000000004,7440384.0,1188864.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,377487360.0,2304.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,209,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1105216.0,8.0,1291.9360000000004,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34538.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,210,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.336,1302.2720000000004,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",211,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.392,1305.6640000000004,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",212,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.168,1308.8320000000003,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",213,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,64.0,6.4,1315.2320000000004,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,2.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",214,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,1318.4960000000003,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",215,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,1321.8240000000003,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",216,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.608,1326.4320000000002,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",217,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.32,1330.7520000000002,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",218,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681472.0,147872.0,13.152,1343.9040000000002,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396296.0,4621.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",219,307200.0,589824.0,49152.0,0,0.0,638976.0,638976.0,0.0,384.0,0.0,98304.0,98304.0,3.776,1347.6800000000003,24576.0,0.0,282624.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",220,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681216.0,146944.0,13.184,1360.8640000000003,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396288.0,4592.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",221,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,3.552,1364.4160000000002,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,222,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,11796480.0,3062432.0,12.768,1377.1840000000002,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,95701.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,223,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6528.0,0.1282051282051282,3244032.0,24576.0,21.312,1398.496,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",224,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.456,1401.952,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",225,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.36,1405.312,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",226,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,6.72,1412.032,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",227,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.424,1415.456,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",228,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.168,1418.6239999999998,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",229,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.448,1423.072,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",230,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.416,1427.4879999999998,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,231,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1103808.0,7.904,1435.3919999999998,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34494.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,232,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.368,1445.7599999999998,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,233,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1104256.0,7.904,1453.6639999999998,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34508.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,234,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.336,1463.9999999999998,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,235,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1106304.0,7.712,1471.7119999999998,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34572.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,236,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.56,1482.2719999999997,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",237,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.48,1486.7519999999997,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",238,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.512,1491.2639999999997,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",239,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.696,1496.9599999999996,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",240,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.8,1501.7599999999995,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",241,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.456,1505.2159999999994,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",242,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.416,1509.6319999999994,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",243,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.416,1514.0479999999993,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",244,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.344,1519.3919999999994,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",245,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.608,1523.9999999999993,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",246,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.648,1527.6479999999992,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",247,98304.0,8825856.0,0.0,0,96636764160.0,8825856.0,96645590016.0,49920.0,96.0,0.9980806142034548,73728.0,24576.0,15.648,1543.2959999999991,7440384.0,1188864.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,377487360.0,2304.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,248,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1107296.0,7.872,1551.1679999999992,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34603.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,249,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.432,1561.5999999999992,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",250,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.488,1565.0879999999993,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",251,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.296,1568.3839999999993,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",252,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,64.0,6.208,1574.5919999999994,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,2.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",253,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.168,1577.7599999999993,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",254,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,1581.0559999999994,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",255,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.416,1585.4719999999993,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",256,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.576,1590.0479999999993,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",257,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681600.0,147328.0,13.024,1603.0719999999992,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396300.0,4604.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",258,307200.0,589824.0,49152.0,0,0.0,638976.0,638976.0,0.0,384.0,0.0,98304.0,98304.0,3.776,1606.8479999999993,24576.0,0.0,282624.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",259,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681472.0,147648.0,13.12,1619.9679999999992,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396296.0,4614.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",260,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,3.456,1623.423999999999,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,261,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,11796480.0,3049312.0,12.8,1636.223999999999,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,95291.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,262,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6528.0,0.1282051282051282,3244032.0,24576.0,21.152,1657.375999999999,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",263,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.648,1661.023999999999,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",264,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.488,1664.511999999999,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",265,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,6.24,1670.751999999999,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",266,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.392,1674.143999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",267,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.2,1677.3439999999991,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",268,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.416,1681.759999999999,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",269,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.416,1686.175999999999,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,270,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1105184.0,7.872,1694.047999999999,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34537.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,271,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.304,1704.3519999999992,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,272,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1108992.0,8.0,1712.3519999999992,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34656.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,273,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.56,1722.9119999999991,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,274,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1106080.0,7.744,1730.655999999999,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34565.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,275,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.208,1740.8639999999991,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",276,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.64,1745.5039999999992,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",277,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.224,1749.7279999999992,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",278,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.344,1755.0719999999992,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",279,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.576,1759.6479999999992,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",280,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.52,1763.1679999999992,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",281,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.512,1767.6799999999992,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",282,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.32,1771.999999999999,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",283,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.216,1777.215999999999,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",284,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.416,1781.631999999999,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",285,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.296,1784.927999999999,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",286,98304.0,8825856.0,0.0,0,96636764160.0,8825856.0,96645590016.0,49920.0,96.0,0.9980806142034548,73728.0,24576.0,15.68,1800.607999999999,7440384.0,1188864.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,377487360.0,2304.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,287,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1097696.0,7.84,1808.447999999999,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34303.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,288,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.4,1818.847999999999,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",289,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.264,1822.111999999999,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",290,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.424,1825.535999999999,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",291,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,64.0,6.656,1832.1919999999989,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,2.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",292,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,1835.4239999999988,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",293,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.2,1838.623999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",294,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.448,1843.071999999999,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",295,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.448,1847.519999999999,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",296,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681984.0,146688.0,13.12,1860.639999999999,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396312.0,4584.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",297,307200.0,589824.0,49152.0,0,0.0,638976.0,638976.0,0.0,384.0,0.0,98304.0,98304.0,3.968,1864.607999999999,24576.0,0.0,282624.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",298,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681216.0,149024.0,13.152,1877.759999999999,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396288.0,4657.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",299,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,3.392,1881.1519999999991,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,300,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,11796480.0,3063200.0,12.704,1893.855999999999,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,95725.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,301,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6528.0,0.1282051282051282,3244032.0,24576.0,21.248,1915.1039999999991,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",302,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.648,1918.751999999999,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",303,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.36,1922.111999999999,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",304,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,6.496,1928.607999999999,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",305,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.168,1931.775999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",306,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,1935.071999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",307,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.384,1939.455999999999,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",308,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.512,1943.967999999999,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,309,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1102976.0,7.872,1951.839999999999,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34468.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,310,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.56,1962.399999999999,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,311,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1108928.0,7.808,1970.207999999999,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34654.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,312,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.592,1980.799999999999,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,313,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1108448.0,7.84,1988.639999999999,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34639.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,314,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.272,1998.911999999999,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",315,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.448,2003.359999999999,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",316,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.288,2007.647999999999,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",317,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.504,2013.151999999999,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",318,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.8,2017.9519999999989,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",319,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.616,2021.5679999999988,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",320,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.448,2026.015999999999,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",321,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.288,2030.303999999999,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",322,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.312,2035.6159999999988,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",323,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.512,2040.1279999999988,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",324,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.456,2043.5839999999987,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",325,98304.0,8825856.0,0.0,0,96636764160.0,8825856.0,96645590016.0,49920.0,96.0,0.9980806142034548,73728.0,24576.0,15.552,2059.1359999999986,7440384.0,1188864.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,377487360.0,2304.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,326,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1104352.0,7.84,2066.9759999999987,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34511.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,327,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.272,2077.2479999999987,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",328,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.392,2080.6399999999985,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",329,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.168,2083.8079999999986,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",330,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,64.0,6.624,2090.4319999999984,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,2.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",331,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.392,2093.8239999999983,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",332,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.168,2096.9919999999984,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",333,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.416,2101.4079999999985,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",334,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.64,2106.0479999999984,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",335,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681216.0,147360.0,13.12,2119.1679999999983,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396288.0,4605.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",336,307200.0,589824.0,49152.0,0,0.0,638976.0,638976.0,0.0,384.0,0.0,98304.0,98304.0,3.776,2122.943999999998,24576.0,0.0,282624.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",337,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681216.0,145632.0,12.992,2135.9359999999983,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396288.0,4551.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",338,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,3.552,2139.4879999999985,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,339,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,11796480.0,3057632.0,12.704,2152.1919999999986,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,95551.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,340,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6528.0,0.1282051282051282,3244032.0,24576.0,21.344,2173.5359999999987,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",341,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.328,2176.8639999999987,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",342,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.328,2180.1919999999986,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",343,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,6.464,2186.6559999999986,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",344,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.2,2189.8559999999984,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",345,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,2193.1839999999984,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",346,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.288,2197.4719999999984,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",347,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.64,2202.1119999999983,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",348,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,32000.0,0.0,0.0,1287680.0,3.328,2205.4399999999982,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,40240.0
"void sgemm_largek_lds64<1, 0, 6, 3, 4, 5, 2, 66>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",349,197633000.0,394752000.0,1026000.0,0,0.0,395778000.0,395778000.0,3941000.0,1052781.0,0.7891815840542467,105973184.0,4127744.0,61.056,2266.4959999999983,0.0,512000.0,197120000.0,513000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3311662.0,128992.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",350,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,64.0,2.88,2269.3759999999984,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,2.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",351,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,128.0,256.0,4.608,2273.9839999999986,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,8.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",352,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.168,2277.1519999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",353,0.0,256000.0,0.0,0,0.0,256000.0,256000.0,0.0,4000.0,0.0,1024000.0,1024000.0,3.84,2280.991999999999,0.0,256000.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32000.0,32000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",354,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,3.072,2284.063999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",355,0.0,0.0,0.0,0,0.0,0.0,0.0,4096.0,12096.0,0.25296442687747034,1028224.0,70976.0,6.016,2290.079999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32132.0,2218.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",356,122880.0,0.0,245760.0,0,0.0,245760.0,245760.0,16896.0,68880.0,0.1969781757134863,4210944.0,0.0,6.592,2296.671999999999,0.0,0.0,0.0,122880.0,0,0,0,0,0,0,0,0.0,0.0,0.0,131592.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",357,0.0,0.0,0.0,0,0.0,0.0,0.0,4096.0,12096.0,0.25296442687747034,1028224.0,72256.0,6.176,2302.847999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32132.0,2258.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",358,73728.0,0.0,147456.0,0,0.0,147456.0,147456.0,16896.0,70416.0,0.19351291918636612,4210944.0,0.0,6.72,2309.567999999999,0.0,0.0,0.0,73728.0,0,0,0,0,0,0,0,0.0,0.0,0.0,131592.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",359,0.0,0.0,0.0,0,0.0,0.0,0.0,4096.0,12096.0,0.25296442687747034,1028224.0,70336.0,6.048,2315.6159999999986,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32132.0,2198.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",360,131072.0,0.0,262144.0,0,0.0,262144.0,262144.0,16896.0,68624.0,0.19756782039289056,4210944.0,0.0,6.688,2322.3039999999987,0.0,0.0,0.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,131592.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",361,0.0,0.0,0.0,0,0.0,0.0,0.0,4096.0,12096.0,0.25296442687747034,1028224.0,72192.0,5.92,2328.223999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32132.0,2256.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",362,122880.0,0.0,245760.0,0,0.0,245760.0,245760.0,16896.0,68880.0,0.1969781757134863,4210944.0,224.0,6.72,2334.9439999999986,0.0,0.0,0.0,122880.0,0,0,0,0,0,0,0,0.0,0.0,0.0,131592.0,7.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",363,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,24.0,0.0,8224.0,1024.0,4.032,2338.9759999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,257.0,32.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",364,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.912,2341.8879999999986,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",365,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,25.0,0.9624060150375939,1024.0,0.0,5.92,2347.8079999999986,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",366,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.296,2351.1039999999985,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",367,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,25.0,0.9624060150375939,1024.0,0.0,5.632,2356.7359999999985,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",368,65536.0,0.0,131072.0,0,0.0,131072.0,131072.0,51168.0,16832.0,0.7524705882352941,1050496.0,15232.0,9.216,2365.9519999999984,0.0,0.0,0.0,65536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32828.0,476.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",369,0.0,0.0,0.0,0,0.0,0.0,0.0,3664.0,64.0,0.9828326180257511,5120.0,0.0,9.216,2375.1679999999983,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",370,512000.0,0.0,1024000.0,0,0.0,1024000.0,1024000.0,0.0,24000.0,0.0,1040128.0,85632.0,5.92,2381.0879999999984,0.0,0.0,0.0,512000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32504.0,2676.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",371,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,6000.0,0.0,1280000.0,0.0,3.872,2384.959999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,40000.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",372,256000.0,0.0,512000.0,0,0.0,512000.0,512000.0,0.0,8000.0,0.0,0.0,2048000.0,4.064,2389.023999999998,0.0,0.0,0.0,256000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,64000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",373,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,8000.0,0.9441215914170764,1024000.0,0.0,6.048,2395.071999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",374,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.52,2398.591999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",375,0.0,0.0,0.0,0,0.0,0.0,0.0,83376.0,36471.0,0.6956870009261809,3518848.0,2558112.0,15.68,2414.2719999999977,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,109964.0,79941.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",376,0.0,0.0,0.0,0,0.0,0.0,0.0,17580.0,36498.0,0.32508598690779983,3518464.0,3121152.0,11.84,2426.111999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,109952.0,97536.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",377,0.0,0.0,0.0,0,0.0,0.0,0.0,18792.0,36308.0,0.3410526315789474,3500160.0,3121152.0,13.664,2439.775999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,109380.0,97536.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",378,0.0,0.0,0.0,0,0.0,0.0,0.0,18792.0,36363.0,0.34071253739461516,3505536.0,2740160.0,13.568,2453.3439999999982,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,109548.0,85630.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",379,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,8000.0,0.648876404494382,2048000.0,0.0,5.12,2458.463999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",380,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.392,2461.855999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",381,0.0,0.0,0.0,0,0.0,0.0,0.0,21109.0,19492.0,0.519913302628014,2409088.0,1761024.0,10.048,2471.9039999999977,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75284.0,55032.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",382,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,32000.0,0.0,3098880.0,3072000.0,5.632,2477.535999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96840.0,96000.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",383,3989104.0,8490240.0,810208.0,0,0.0,9300448.0,9300448.0,1056.0,10496.0,0.09141274238227147,1024640.0,1024000.0,22.816,2500.3519999999976,1066240.0,256000.0,3584000.0,405104.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32020.0,32000.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",384,0.0,1310976.0,0.0,0,0.0,1310976.0,1310976.0,143680.0,16000.0,0.8997995991983968,1024000.0,1024000.0,63.488,2563.8399999999974,1310976.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32000.0,32000.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",385,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4000.0,0.0,1024000.0,256000.0,3.776,2567.6159999999973,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32000.0,8000.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",386,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,1.0,0.0,0.0,256.0,3.264,2570.8799999999974,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,8.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",387,512000.0,0.0,1024000.0,0,0.0,1024000.0,1024000.0,0.0,24000.0,0.0,2304000.0,123552.0,11.68,2582.559999999997,0.0,0.0,0.0,512000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,72000.0,3861.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",388,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,6000.0,0.0,1280000.0,0.0,3.904,2586.463999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,40000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",389,3989128.0,8490240.0,810256.0,0,0.0,9300496.0,9300496.0,1056.0,10496.0,0.09141274238227147,1046016.0,1024000.0,22.976,2609.4399999999973,1066240.0,256000.0,3584000.0,405128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32688.0,32000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",390,49664.0,0.0,99328.0,0,0.0,99328.0,99328.0,2590.0,2034.0,0.5601211072664359,1024128.0,1056.0,9.184,2618.6239999999975,0.0,0.0,0.0,49664.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32004.0,33.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",391,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.552,2622.1759999999977,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",392,49664.0,0.0,99328.0,0,0.0,99328.0,99328.0,2590.0,2034.0,0.5601211072664359,1024128.0,1056.0,9.6,2631.7759999999976,0.0,0.0,0.0,49664.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32004.0,33.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",393,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,2635.1039999999975,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",394,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.456,2638.5599999999977,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",395,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.736,2643.2959999999975,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",396,8192.0,294400.0,16384.0,0,0.0,310784.0,310784.0,608.0,2008.0,0.2324159021406728,1024000.0,256.0,12.128,2655.4239999999977,294400.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32000.0,8.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",397,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.2,2658.6239999999975,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",398,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,4.896,2663.5199999999977,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",399,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,2666.9119999999975,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",400,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.672,2671.5839999999976,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",401,2816000.0,5120000.0,1024000.0,0,0.0,6144000.0,6144000.0,0.0,8000.0,0.0,0.0,1024000.0,7.04,2678.6239999999975,0.0,512000.0,2304000.0,512000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,32000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",402,1599624.0,2560000.0,639248.0,0,0.0,3199248.0,3199248.0,0.0,6000.0,0.0,2048000.0,0.0,5.664,2684.2879999999977,0.0,0.0,1280000.0,319624.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",403,4608.0,0.0,9216.0,0,0.0,9216.0,9216.0,1216.0,2008.0,0.3771712158808933,1024000.0,256.0,17.856,2702.143999999998,0.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32000.0,8.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",404,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,128.0,64.0,3.488,2705.631999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,2.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",405,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,3.168,2708.799999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",406,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,96.0,64.0,3.744,2712.543999999998,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,2.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",407,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,128.0,64.0,3.392,2715.935999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,2.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",408,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,128.0,256.0,4.32,2720.255999999998,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,8.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",409,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.72,2722.975999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",410,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.752,2725.727999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",411,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.68,2729.4079999999976,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",412,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,3.008,2732.4159999999974,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",413,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,3.0,0.0,160.0,32.0,3.744,2736.1599999999976,0.0,0.0,0.0,16.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",414,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,5.0,0.0,32.0,32.0,6.976,2743.1359999999977,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",415,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.424,2746.5599999999977,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",416,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,2749.823999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",417,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,64.0,4.032,2753.855999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,2.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",418,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,5.184,2759.039999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",419,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,2762.367999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",420,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,2765.759999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",421,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,3.0,0.0,160.0,64.0,4.48,2770.239999999998,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5.0,2.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",422,0.0,0.0,0.0,0,0.0,0.0,0.0,96.0,8.0,0.9230769230769231,128.0,32.0,4.096,2774.335999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",423,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,128.0,3.296,2777.631999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",424,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,32.0,3.36,2780.991999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",425,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,160.0,0.0,3.488,2784.4799999999977,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",426,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,128.0,64.0,3.84,2788.319999999998,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,2.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",427,768.0,0.0,1536.0,0,0.0,1536.0,1536.0,0.0,576.0,0.0,21888.0,24576.0,9.216,2797.535999999998,0.0,0.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,684.0,768.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",428,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,32.0,3.584,2801.1199999999976,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",429,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,2.0,0.0,32.0,32.0,5.28,2806.399999999998,0.0,0.0,0.0,16.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",430,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.456,2809.855999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",431,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,64.0,48.0,0.5714285714285714,2560.0,2048.0,3.616,2813.471999999998,0.0,1024.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80.0,64.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",432,512.0,0.0,1024.0,0,0.0,1024.0,1024.0,0.0,40.0,0.0,4096.0,4096.0,4.064,2817.535999999998,0.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",433,8192.0,18432.0,0.0,0,0.0,18432.0,18432.0,0.0,16.0,0.0,4096.0,4096.0,4.32,2821.855999999998,0.0,2048.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",434,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,3.2,2825.0559999999978,0.0,1024.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",435,7200.0,16448.0,0.0,0,0.0,16448.0,16448.0,0.0,16.0,0.0,4096.0,4096.0,4.064,2829.1199999999976,0.0,2048.0,7200.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",436,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,3.04,2832.1599999999976,0.0,1024.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",437,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.552,2835.7119999999977,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",438,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,6.304,2842.015999999998,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",439,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.296,2845.3119999999976,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",440,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,2848.6079999999974,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",441,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.384,2852.9919999999975,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",442,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.352,2857.3439999999973,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,443,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1109056.0,7.776,2865.119999999997,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34658.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,444,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.432,2875.551999999997,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,445,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1105184.0,7.648,2883.199999999997,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34537.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,446,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.368,2893.567999999997,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,447,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1105472.0,7.904,2901.471999999997,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34546.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,448,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.208,2911.679999999997,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",449,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.576,2916.255999999997,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",450,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.48,2920.735999999997,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",451,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.632,2926.367999999997,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",452,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.608,2930.9759999999974,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",453,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.552,2934.5279999999975,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",454,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.352,2938.8799999999974,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",455,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.352,2943.2319999999972,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",456,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.76,2948.9919999999975,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",457,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.448,2953.4399999999973,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",458,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.456,2956.8959999999975,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",459,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,480.0,0.0,49152.0,49152.0,4.576,2961.4719999999975,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",460,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,480.0,0.0,49152.0,49152.0,4.64,2966.1119999999974,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",461,98304.0,8828928.0,0.0,0,96636764160.0,8828928.0,96645593088.0,49920.0,96.0,0.9980806142034548,122880.0,24576.0,15.584,2981.695999999997,7443456.0,1188864.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,377487360.0,3840.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,462,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1100928.0,8.032,2989.7279999999973,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34404.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,463,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.496,3000.2239999999974,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",464,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.52,3003.7439999999974,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",465,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.36,3007.1039999999975,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",466,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,64.0,6.624,3013.7279999999973,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,2.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",467,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,3016.9919999999975,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",468,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,3020.2559999999976,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",469,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.448,3024.7039999999974,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",470,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.32,3029.0239999999976,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",471,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681216.0,144896.0,13.088,3042.111999999998,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396288.0,4528.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",472,307200.0,589824.0,49152.0,0,0.0,638976.0,638976.0,0.0,384.0,0.0,98304.0,98304.0,3.68,3045.7919999999976,24576.0,0.0,282624.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",473,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681216.0,144032.0,13.184,3058.975999999998,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396288.0,4501.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",474,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,3.552,3062.527999999998,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,475,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,11796480.0,3079360.0,12.704,3075.231999999998,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,96230.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,476,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6528.0,0.1282051282051282,3244032.0,24576.0,21.536,3096.767999999998,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",477,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.424,3100.191999999998,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",478,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.264,3103.4559999999983,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",479,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,64.0,6.208,3109.6639999999984,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,2.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",480,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.296,3112.959999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",481,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.36,3116.3199999999983,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",482,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.672,3120.9919999999984,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",483,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.384,3125.3759999999984,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,484,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1108672.0,7.744,3133.1199999999985,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34646.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,485,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.176,3143.2959999999985,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,486,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1108512.0,7.744,3151.0399999999986,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34641.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,487,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.56,3161.5999999999985,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,488,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1107968.0,7.84,3169.4399999999987,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34624.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,489,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.336,3179.7759999999985,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",490,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.512,3184.2879999999986,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",491,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.416,3188.703999999999,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",492,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.6,3194.3039999999987,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",493,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.448,3198.7519999999986,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",494,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.36,3202.1119999999987,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",495,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.48,3206.5919999999987,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",496,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.544,3211.1359999999986,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",497,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.376,3216.511999999999,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",498,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.416,3220.927999999999,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",499,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.52,3224.447999999999,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",500,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,480.0,0.0,49152.0,49152.0,4.672,3229.119999999999,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",501,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,480.0,0.0,49152.0,49152.0,4.608,3233.727999999999,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",502,98304.0,8828928.0,0.0,0,96636764160.0,8828928.0,96645593088.0,49920.0,96.0,0.9980806142034548,122880.0,24576.0,15.552,3249.2799999999993,7443456.0,1188864.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,377487360.0,3840.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,503,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1100128.0,7.936,3257.2159999999994,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34379.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,504,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.336,3267.551999999999,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",505,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.552,3271.1039999999994,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",506,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.36,3274.4639999999995,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",507,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,64.0,6.304,3280.7679999999996,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,2.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",508,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.392,3284.1599999999994,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",509,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.456,3287.6159999999995,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",510,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.512,3292.1279999999997,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",511,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.384,3296.5119999999997,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",512,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681216.0,150976.0,13.248,3309.7599999999998,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396288.0,4718.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",513,307200.0,589824.0,49152.0,0,0.0,638976.0,638976.0,0.0,384.0,0.0,98304.0,98304.0,3.872,3313.6319999999996,24576.0,0.0,282624.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",514,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681216.0,150464.0,13.12,3326.7519999999995,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396288.0,4702.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",515,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,3.52,3330.2719999999995,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,516,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,11796480.0,3057920.0,12.768,3343.0399999999995,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,95560.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,517,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6528.0,0.1282051282051282,3244032.0,24576.0,21.376,3364.4159999999997,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",518,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.456,3367.872,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",519,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.2,3371.0719999999997,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",520,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,64.0,6.208,3377.2799999999997,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,2.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",521,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.392,3380.6719999999996,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",522,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.456,3384.1279999999997,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",523,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.608,3388.736,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",524,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.576,3393.312,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,525,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1106752.0,7.808,3401.12,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34586.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,526,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.176,3411.296,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,527,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1110080.0,8.096,3419.392,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34690.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,528,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.112,3429.504,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,529,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1101824.0,7.872,3437.3759999999997,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34432.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,530,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.176,3447.5519999999997,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",531,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.576,3452.1279999999997,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",532,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.608,3456.736,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",533,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.472,3462.208,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",534,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.608,3466.8160000000003,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",535,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.488,3470.304,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",536,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.672,3474.976,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",537,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.512,3479.4880000000003,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",538,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.824,3485.3120000000004,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",539,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.48,3489.7920000000004,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",540,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.36,3493.1520000000005,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",541,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,480.0,0.0,49152.0,49152.0,4.576,3497.7280000000005,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",542,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,480.0,0.0,49152.0,49152.0,4.736,3502.4640000000004,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",543,98304.0,8828928.0,0.0,0,96636764160.0,8828928.0,96645593088.0,49920.0,96.0,0.9980806142034548,122880.0,24576.0,15.648,3518.1120000000005,7443456.0,1188864.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,377487360.0,3840.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,544,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1102496.0,7.84,3525.9520000000007,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34453.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,545,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.272,3536.2240000000006,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",546,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.424,3539.6480000000006,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",547,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.648,3543.2960000000007,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",548,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,64.0,6.112,3549.408000000001,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,2.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",549,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.744,3553.152000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",550,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.712,3556.864000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",551,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.448,3561.312000000001,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",552,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.48,3565.792000000001,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",553,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681216.0,147392.0,13.024,3578.8160000000007,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396288.0,4606.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",554,307200.0,589824.0,49152.0,0,0.0,638976.0,638976.0,0.0,384.0,0.0,98304.0,98304.0,3.808,3582.6240000000007,24576.0,0.0,282624.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",555,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681216.0,152064.0,13.088,3595.712000000001,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396288.0,4752.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",556,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,3.36,3599.072000000001,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,557,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,11796480.0,3062016.0,12.704,3611.776000000001,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,95688.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,558,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6528.0,0.1282051282051282,3244032.0,24576.0,21.376,3633.1520000000014,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",559,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.456,3636.6080000000015,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",560,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.232,3639.8400000000015,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",561,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,6.368,3646.2080000000014,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",562,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.584,3649.7920000000013,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",563,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,3653.1200000000013,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",564,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.352,3657.472000000001,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",565,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.288,3661.760000000001,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,566,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1103520.0,7.776,3669.536000000001,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34485.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,567,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.368,3679.904000000001,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,568,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1103136.0,7.84,3687.744000000001,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34473.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,569,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.24,3697.984000000001,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,570,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1102272.0,7.84,3705.824000000001,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34446.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,571,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.496,3716.320000000001,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",572,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.544,3720.864000000001,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",573,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.448,3725.312000000001,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",574,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.248,3730.560000000001,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",575,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.448,3735.0080000000007,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",576,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.36,3738.368000000001,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",577,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.544,3742.9120000000007,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",578,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.352,3747.2640000000006,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",579,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.504,3752.7680000000005,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",580,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.384,3757.1520000000005,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",581,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.68,3760.8320000000003,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",582,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,480.0,0.0,49152.0,49152.0,4.416,3765.2480000000005,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",583,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,480.0,0.0,49152.0,49152.0,4.576,3769.8240000000005,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",584,98304.0,8828928.0,0.0,0,96636764160.0,8828928.0,96645593088.0,49920.0,96.0,0.9980806142034548,122880.0,24576.0,15.616,3785.4400000000005,7443456.0,1188864.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,377487360.0,3840.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,585,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1109888.0,7.776,3793.2160000000003,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34684.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,586,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.336,3803.552,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",587,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.424,3806.976,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",588,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.456,3810.4320000000002,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",589,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,64.0,6.496,3816.9280000000003,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,2.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",590,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.296,3820.224,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",591,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,3823.552,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",592,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.704,3828.2560000000003,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",593,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.416,3832.6720000000005,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",594,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681216.0,146304.0,13.152,3845.8240000000005,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396288.0,4572.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",595,307200.0,589824.0,49152.0,0,0.0,638976.0,638976.0,0.0,384.0,0.0,98304.0,98304.0,3.648,3849.4720000000007,24576.0,0.0,282624.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",596,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681216.0,150592.0,13.024,3862.4960000000005,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396288.0,4706.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",597,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,3.296,3865.7920000000004,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,598,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,11796480.0,3064416.0,12.64,3878.4320000000002,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,95763.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,599,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6528.0,0.1282051282051282,3244032.0,24576.0,20.864,3899.2960000000003,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",600,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.744,3903.0400000000004,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",601,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.328,3906.3680000000004,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",602,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,6.624,3912.992,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",603,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,3916.2560000000003,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",604,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,3919.5200000000004,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",605,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.544,3924.0640000000003,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",606,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.448,3928.512,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,607,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1105472.0,7.872,3936.384,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34546.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,608,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.56,3946.944,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,609,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1099808.0,7.808,3954.752,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34369.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,610,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.336,3965.0879999999997,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,611,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1106656.0,8.096,3973.1839999999997,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34583.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,612,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.24,3983.4239999999995,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",613,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.384,3987.8079999999995,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",614,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.352,3992.1599999999994,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",615,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.376,3997.5359999999996,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",616,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.448,4001.9839999999995,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",617,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.584,4005.5679999999993,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",618,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.576,4010.1439999999993,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",619,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.416,4014.5599999999995,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",620,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.376,4019.9359999999997,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",621,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.384,4024.3199999999997,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",622,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.552,4027.872,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",623,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,480.0,0.0,49152.0,49152.0,4.832,4032.7039999999997,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",624,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,480.0,0.0,49152.0,49152.0,4.544,4037.2479999999996,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",625,98304.0,8828928.0,0.0,0,96636764160.0,8828928.0,96645593088.0,49920.0,96.0,0.9980806142034548,122880.0,24576.0,15.52,4052.7679999999996,7443456.0,1188864.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,377487360.0,3840.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,626,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1106784.0,7.936,4060.7039999999997,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34587.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,627,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.304,4071.008,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",628,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.52,4074.528,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",629,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.36,4077.888,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",630,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,64.0,6.4,4084.288,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,2.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",631,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,4087.552,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",632,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,4090.88,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",633,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.576,4095.456,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",634,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.608,4100.064,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",635,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681344.0,152096.0,13.44,4113.504,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396292.0,4753.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",636,307200.0,589824.0,49152.0,0,0.0,638976.0,638976.0,0.0,384.0,0.0,98304.0,98304.0,3.584,4117.088,24576.0,0.0,282624.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",637,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681216.0,149120.0,13.152,4130.24,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396288.0,4660.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",638,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,3.424,4133.664,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,639,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,11796480.0,3072416.0,12.704,4146.3679999999995,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,96013.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,640,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6528.0,0.1282051282051282,3244032.0,24576.0,21.408,4167.776,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",641,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.456,4171.232,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",642,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.328,4174.56,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",643,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,6.176,4180.736000000001,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",644,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,4183.968000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",645,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.584,4187.552000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",646,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.448,4192.000000000001,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",647,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.352,4196.352000000001,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,648,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1109920.0,7.872,4204.224000000001,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34685.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,649,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.272,4214.496000000001,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,650,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1098528.0,7.808,4222.304000000001,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34329.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,651,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.464,4232.768000000001,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,652,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1108064.0,7.808,4240.576000000001,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34627.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,653,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.176,4250.752000000001,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",654,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.512,4255.264000000001,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",655,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.48,4259.744000000001,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",656,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.408,4265.152000000001,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",657,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.608,4269.760000000001,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",658,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.488,4273.248000000001,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",659,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.448,4277.696000000002,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",660,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.288,4281.984000000001,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",661,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.28,4287.264000000001,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",662,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.768,4292.032000000001,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",663,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.328,4295.3600000000015,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",664,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,480.0,0.0,49152.0,49152.0,4.64,4300.000000000002,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",665,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,480.0,0.0,49152.0,49152.0,4.64,4304.640000000002,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",666,98304.0,8828928.0,0.0,0,96636764160.0,8828928.0,96645593088.0,49920.0,96.0,0.9980806142034548,122880.0,24576.0,15.488,4320.128000000002,7443456.0,1188864.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,377487360.0,3840.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,667,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1102624.0,7.872,4328.000000000003,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34457.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,668,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.432,4338.4320000000025,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",669,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.584,4342.016000000002,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",670,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.456,4345.4720000000025,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",671,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,6.048,4351.520000000002,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",672,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,4354.784000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",673,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.424,4358.208000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",674,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.544,4362.752000000002,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",675,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.576,4367.328000000002,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",676,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681216.0,149984.0,13.12,4380.448000000002,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396288.0,4687.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",677,307200.0,589824.0,49152.0,0,0.0,638976.0,638976.0,0.0,384.0,0.0,98304.0,98304.0,3.712,4384.160000000003,24576.0,0.0,282624.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",678,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681216.0,144544.0,13.056,4397.216000000002,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396288.0,4517.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",679,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,3.424,4400.640000000002,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,680,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,11796480.0,3066752.0,12.8,4413.440000000002,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,95836.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,681,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6528.0,0.1282051282051282,3244032.0,24576.0,21.024,4434.464000000003,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",682,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.648,4438.112000000003,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",683,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.456,4441.568000000003,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",684,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,64.0,5.952,4447.520000000003,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,2.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",685,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.36,4450.880000000003,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",686,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,4454.208000000003,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",687,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.448,4458.656000000004,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",688,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.352,4463.008000000003,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,689,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1107776.0,7.776,4470.784000000003,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34618.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,690,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.08,4480.864000000003,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,691,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1108064.0,7.968,4488.832000000003,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34627.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,692,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.24,4499.072000000003,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,693,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1103136.0,7.776,4506.848000000003,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34473.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,694,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.24,4517.0880000000025,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",695,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.416,4521.504000000003,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",696,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.352,4525.8560000000025,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",697,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.312,4531.168000000002,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",698,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.544,4535.712000000002,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",699,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.52,4539.232000000003,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",700,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.416,4543.648000000003,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",701,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.256,4547.904000000003,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",702,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.344,4553.248000000003,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",703,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.416,4557.664000000003,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",704,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.456,4561.1200000000035,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",705,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,480.0,0.0,49152.0,49152.0,4.672,4565.792000000003,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",706,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,480.0,0.0,49152.0,49152.0,4.576,4570.368000000003,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",707,98304.0,8828928.0,0.0,0,96636764160.0,8828928.0,96645593088.0,49920.0,96.0,0.9980806142034548,122880.0,24576.0,15.552,4585.920000000003,7443456.0,1188864.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,377487360.0,3840.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,708,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1108480.0,7.776,4593.696000000003,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34640.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,709,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.368,4604.064000000003,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",710,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.552,4607.616000000003,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",711,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.36,4610.976000000002,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",712,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,6.08,4617.056000000002,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",713,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.36,4620.416000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",714,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.456,4623.872000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",715,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.416,4628.288000000002,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",716,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.448,4632.736000000003,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",717,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681216.0,152416.0,13.248,4645.984000000002,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396288.0,4763.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",718,307200.0,589824.0,49152.0,0,0.0,638976.0,638976.0,0.0,384.0,0.0,98304.0,98304.0,3.744,4649.728000000002,24576.0,0.0,282624.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",719,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681216.0,145600.0,13.312,4663.040000000002,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396288.0,4550.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",720,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,3.488,4666.528000000002,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,721,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,11796480.0,3069632.0,12.736,4679.264000000002,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,95926.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,722,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6528.0,0.1282051282051282,3244032.0,24576.0,21.376,4700.640000000002,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",723,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.328,4703.968000000003,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",724,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.168,4707.136000000002,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",725,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,6.624,4713.760000000002,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",726,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.296,4717.056000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",727,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,4720.352000000003,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",728,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.512,4724.864000000002,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",729,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.416,4729.2800000000025,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,730,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1105696.0,7.936,4737.216000000002,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34553.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,731,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.656,4747.872000000002,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,732,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1105792.0,7.808,4755.680000000002,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34556.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,733,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.304,4765.984000000002,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,734,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1101728.0,7.776,4773.760000000002,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34429.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,735,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.336,4784.096000000002,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",736,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.448,4788.544000000003,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",737,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.352,4792.8960000000025,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",738,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.312,4798.208000000002,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",739,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.608,4802.8160000000025,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",740,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.456,4806.272000000003,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",741,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.544,4810.8160000000025,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",742,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.448,4815.264000000003,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",743,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.376,4820.640000000003,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",744,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.704,4825.344000000003,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",745,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.616,4828.960000000003,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",746,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,480.0,0.0,49152.0,49152.0,4.704,4833.6640000000025,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",747,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,480.0,0.0,49152.0,49152.0,4.736,4838.400000000002,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",748,98304.0,8828928.0,0.0,0,96636764160.0,8828928.0,96645593088.0,49920.0,96.0,0.9980806142034548,122880.0,24576.0,15.552,4853.952000000002,7443456.0,1188864.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,377487360.0,3840.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,749,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1108064.0,7.808,4861.760000000002,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34627.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,750,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.272,4872.032000000002,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",751,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.296,4875.328000000002,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",752,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.392,4878.720000000002,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",753,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,64.0,6.72,4885.440000000002,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,2.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",754,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.36,4888.800000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",755,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,4892.096000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",756,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.32,4896.416000000002,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",757,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.448,4900.864000000002,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",758,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681344.0,151616.0,13.504,4914.368000000002,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396292.0,4738.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",759,307200.0,589824.0,49152.0,0,0.0,638976.0,638976.0,0.0,384.0,0.0,98304.0,98304.0,3.84,4918.208000000002,24576.0,0.0,282624.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",760,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681216.0,150944.0,13.024,4931.232000000003,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396288.0,4717.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",761,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,3.584,4934.8160000000025,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,762,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,11796480.0,3062496.0,12.704,4947.520000000002,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,95703.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,763,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6528.0,0.1282051282051282,3244032.0,24576.0,22.08,4969.600000000002,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",764,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.264,4972.864000000002,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",765,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.488,4976.352000000003,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",766,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,64.0,6.592,4982.944000000002,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,2.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",767,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,4986.176000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",768,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,4989.504000000003,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",769,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.608,4994.112000000003,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",770,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.64,4998.752000000003,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",771,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,32000.0,0.0,0.0,1285504.0,3.328,5002.080000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,40172.0
"void sgemm_largek_lds64<1, 0, 6, 3, 4, 5, 2, 66>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",772,197633000.0,394752000.0,1026000.0,0,0.0,395778000.0,395778000.0,3941000.0,1047449.0,0.7900251160230364,105993600.0,4127904.0,61.024,5063.104000000004,0.0,512000.0,197120000.0,513000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3312300.0,128997.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",773,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,64.0,2.784,5065.888000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,2.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",774,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,192.0,320.0,4.256,5070.144000000004,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6.0,10.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",775,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.2,5073.344000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",776,0.0,256000.0,0.0,0,0.0,256000.0,256000.0,0.0,4000.0,0.0,1024000.0,1024000.0,3.808,5077.152000000004,0.0,256000.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32000.0,32000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",777,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,3.104,5080.256000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",778,0.0,0.0,0.0,0,0.0,0.0,0.0,4096.0,12096.0,0.25296442687747034,1028224.0,72256.0,6.016,5086.272000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32132.0,2258.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",779,122880.0,0.0,245760.0,0,0.0,245760.0,245760.0,16896.0,68880.0,0.1969781757134863,4210944.0,0.0,6.592,5092.864000000003,0.0,0.0,0.0,122880.0,0,0,0,0,0,0,0,0.0,0.0,0.0,131592.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",780,0.0,0.0,0.0,0,0.0,0.0,0.0,4096.0,12096.0,0.25296442687747034,1028224.0,72448.0,5.76,5098.624000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32132.0,2264.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",781,73728.0,0.0,147456.0,0,0.0,147456.0,147456.0,16896.0,70416.0,0.19351291918636612,4210944.0,0.0,6.848,5105.472000000003,0.0,0.0,0.0,73728.0,0,0,0,0,0,0,0,0.0,0.0,0.0,131592.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",782,0.0,0.0,0.0,0,0.0,0.0,0.0,4096.0,12096.0,0.25296442687747034,1028224.0,71552.0,5.92,5111.3920000000035,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32132.0,2236.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",783,107520.0,0.0,215040.0,0,0.0,215040.0,215040.0,16896.0,69360.0,0.19588202559821927,4210944.0,0.0,6.656,5118.048000000003,0.0,0.0,0.0,107520.0,0,0,0,0,0,0,0,0.0,0.0,0.0,131592.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",784,0.0,0.0,0.0,0,0.0,0.0,0.0,4096.0,12096.0,0.25296442687747034,1028224.0,71488.0,5.856,5123.904000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32132.0,2234.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",785,101376.0,0.0,202752.0,0,0.0,202752.0,202752.0,16896.0,69552.0,0.195446973903387,4210944.0,224.0,6.944,5130.848000000004,0.0,0.0,0.0,101376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,131592.0,7.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",786,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,24.0,0.0,8224.0,1024.0,4.032,5134.880000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,257.0,32.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",787,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.912,5137.792000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",788,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,25.0,0.9624060150375939,1024.0,0.0,5.92,5143.712000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",789,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.072,5146.784000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",790,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,25.0,0.9624060150375939,1024.0,0.0,5.792,5152.576000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",791,65536.0,0.0,131072.0,0,0.0,131072.0,131072.0,59122.0,16844.0,0.778269225706237,1050496.0,13568.0,9.024,5161.600000000005,0.0,0.0,0.0,65536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32828.0,424.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",792,0.0,0.0,0.0,0,0.0,0.0,0.0,3664.0,64.0,0.9828326180257511,5120.0,0.0,8.608,5170.208000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",793,512000.0,0.0,1024000.0,0,0.0,1024000.0,1024000.0,0.0,24000.0,0.0,1040128.0,87808.0,6.08,5176.288000000005,0.0,0.0,0.0,512000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32504.0,2744.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",794,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,6000.0,0.0,1280000.0,0.0,4.064,5180.352000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,40000.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",795,256000.0,0.0,512000.0,0,0.0,512000.0,512000.0,0.0,8000.0,0.0,0.0,2048000.0,3.904,5184.256000000006,0.0,0.0,0.0,256000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,64000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",796,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,8000.0,0.9441215914170764,1024000.0,0.0,6.112,5190.368000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",797,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.648,5194.016000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",798,0.0,0.0,0.0,0,0.0,0.0,0.0,83376.0,36389.0,0.6961633198346763,3523072.0,2534720.0,16.064,5210.080000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110096.0,79210.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",799,0.0,0.0,0.0,0,0.0,0.0,0.0,17580.0,36434.0,0.3254711741400378,3518592.0,3121152.0,11.584,5221.664000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,109956.0,97536.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",800,0.0,0.0,0.0,0,0.0,0.0,0.0,18792.0,36342.0,0.34084231145935356,3512960.0,3121152.0,14.208,5235.872000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,109780.0,97536.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",801,0.0,0.0,0.0,0,0.0,0.0,0.0,18792.0,36342.0,0.34084231145935356,3497344.0,2737472.0,13.888,5249.760000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,109292.0,85546.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",802,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,8000.0,0.648876404494382,2048000.0,0.0,5.056,5254.816000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",803,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.552,5258.368000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",804,0.0,0.0,0.0,0,0.0,0.0,0.0,21109.0,19574.0,0.5188653737433326,2430976.0,1765792.0,10.56,5268.928000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,55181.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",805,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,32000.0,0.0,3097760.0,3072000.0,5.728,5274.656000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96805.0,96000.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",806,3989104.0,8490240.0,810208.0,0,0.0,9300448.0,9300448.0,1056.0,10496.0,0.09141274238227147,1025152.0,1024000.0,22.624,5297.280000000005,1066240.0,256000.0,3584000.0,405104.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32036.0,32000.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",807,0.0,1310976.0,0.0,0,0.0,1310976.0,1310976.0,143680.0,16000.0,0.8997995991983968,1024000.0,1024000.0,63.776,5361.056000000005,1310976.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32000.0,32000.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",808,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4000.0,0.0,1024000.0,256000.0,3.68,5364.736000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32000.0,8000.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",809,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,1.0,0.0,0.0,256.0,3.296,5368.032000000006,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,8.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",810,512000.0,0.0,1024000.0,0,0.0,1024000.0,1024000.0,0.0,24000.0,0.0,2304000.0,124544.0,11.456,5379.488000000006,0.0,0.0,0.0,512000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,72000.0,3892.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",811,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,6000.0,0.0,1280000.0,0.0,3.744,5383.232000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,40000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",812,3989128.0,8490240.0,810256.0,0,0.0,9300496.0,9300496.0,1056.0,10496.0,0.09141274238227147,1025152.0,1024000.0,22.72,5405.952000000006,1066240.0,256000.0,3584000.0,405128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32036.0,32000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",813,49664.0,0.0,99328.0,0,0.0,99328.0,99328.0,2590.0,2034.0,0.5601211072664359,1024128.0,1056.0,9.184,5415.136000000006,0.0,0.0,0.0,49664.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32004.0,33.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",814,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,5418.560000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",815,49664.0,0.0,99328.0,0,0.0,99328.0,99328.0,2590.0,2034.0,0.5601211072664359,1024128.0,1056.0,9.28,5427.840000000006,0.0,0.0,0.0,49664.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32004.0,33.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",816,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,5431.168000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",817,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.264,5434.432000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",818,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.64,5439.0720000000065,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",819,8192.0,294400.0,16384.0,0,0.0,310784.0,310784.0,608.0,2008.0,0.2324159021406728,1024000.0,256.0,11.936,5451.008000000006,294400.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32000.0,8.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",820,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,5454.336000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",821,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,4.96,5459.296000000007,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",822,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,5462.624000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",823,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.64,5467.264000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",824,2816000.0,5120000.0,1024000.0,0,0.0,6144000.0,6144000.0,0.0,8000.0,0.0,0.0,1024000.0,6.976,5474.240000000007,0.0,512000.0,2304000.0,512000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,32000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",825,1599624.0,2560000.0,639248.0,0,0.0,3199248.0,3199248.0,0.0,6000.0,0.0,2048000.0,0.0,5.696,5479.936000000007,0.0,0.0,1280000.0,319624.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",826,4608.0,0.0,9216.0,0,0.0,9216.0,9216.0,1216.0,2008.0,0.3771712158808933,1024000.0,256.0,16.96,5496.896000000007,0.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32000.0,8.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",827,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,128.0,64.0,3.392,5500.288000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,2.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",828,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,3.232,5503.520000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",829,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,96.0,64.0,3.616,5507.136000000007,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,2.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",830,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,128.0,64.0,3.36,5510.4960000000065,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,2.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",831,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,192.0,320.0,4.32,5514.816000000006,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6.0,10.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",832,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.752,5517.568000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",833,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.784,5520.352000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",834,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.36,5523.712000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",835,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.784,5526.496000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",836,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,3.0,0.0,224.0,32.0,4.032,5530.528000000006,0.0,0.0,0.0,16.0,0,0,0,0,0,0,0,0.0,0.0,0.0,7.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",837,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,5.0,0.0,32.0,32.0,7.168,5537.696000000005,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",838,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.456,5541.1520000000055,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",839,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,5544.416000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",840,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,64.0,3.872,5548.288000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,2.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",841,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,5.184,5553.472000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",842,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.488,5556.960000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
