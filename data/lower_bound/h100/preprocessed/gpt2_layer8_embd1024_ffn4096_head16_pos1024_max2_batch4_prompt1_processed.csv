Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.816,2.816,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.656,5.4719999999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.72,8.192,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.232,11.424,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.52,14.943999999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",6,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,3.808,18.752,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",7,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.512,23.264,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",8,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,5.248,28.512,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",9,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.936,32.448,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",10,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.752,35.2,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.72,37.92,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.168,41.088,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,0.0,0.0,0.0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,4.096,45.184,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.104,48.288,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",15,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,51.647999999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",16,0.0,0.0,0.0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,32.0,32.0,4.256,55.903999999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",17,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.168,59.071999999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",18,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,62.303999999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",19,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,3.488,65.792,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",20,1024.0,0.0,2048.0,0,0.0,2048.0,2048.0,0.0,384.0,0.0,4352.0,16384.0,5.696,71.488,0.0,0.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,136.0,512.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",21,1024.0,0.0,2048.0,0,0.0,2048.0,2048.0,0.0,384.0,0.0,4352.0,16384.0,5.568,77.056,0.0,0.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,136.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",22,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.52,80.576,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",23,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,84.0,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",24,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,5.152,89.152,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",25,35396.0,109812.0,9216.0,0,0.0,119028.0,119028.0,80.0,360.0,0.18181818181818182,49152.0,16640.0,6.624,95.776,31280.0,16956.0,30788.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",26,12644352.0,25509888.0,122880.0,0,0.0,25632768.0,25632768.0,112512.0,105216.0,0.5167548500881834,13381632.0,49152.0,25.216,120.99199999999999,147456.0,196608.0,12582912.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,418176.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",27,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,256.0,0.0,16384.0,16384.0,4.576,125.56799999999998,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",28,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,256.0,0.0,16384.0,16384.0,4.256,129.82399999999998,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",29,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,256.0,0.0,16384.0,16384.0,4.64,134.46399999999997,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",30,131072.0,4354048.0,0.0,0,38654705664.0,4354048.0,38659059712.0,34048.0,64.0,0.99812382739212,49152.0,16384.0,13.92,148.38399999999996,3293184.0,798720.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,150994944.0,1536.0,512.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),31,67108864.0,134742016.0,0.0,0,0.0,134742016.0,134742016.0,230912.0,1024.0,0.9955849889624724,4456448.0,131072.0,10.496,158.87999999999997,0.0,524288.0,67108864.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,139264.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",32,20480.0,40960.0,40960.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,135168.0,16384.0,4.16,163.03999999999996,36864.0,4096.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4224.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",33,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.776,166.81599999999997,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",34,35396.0,109812.0,9216.0,0,0.0,119028.0,119028.0,80.0,360.0,0.18181818181818182,49152.0,16640.0,7.328,174.14399999999998,31280.0,16956.0,30788.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",35,16859136.0,34013184.0,163840.0,0,0.0,34177024.0,34177024.0,150016.0,140288.0,0.5167548500881834,17842176.0,65536.0,23.68,197.82399999999998,196608.0,262144.0,16777216.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,557568.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",36,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.328,201.152,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",37,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,3.648,204.79999999999998,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",38,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.52,208.32,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",39,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.456,211.77599999999998,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",40,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.264,215.04,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",41,98280.0,241616.0,8192.0,0,0.0,249808.0,249808.0,0.0,256.0,0.0,65536.0,65536.0,3.584,218.624,16384.0,36864.0,94184.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",42,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,3.52,222.144,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",43,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,3.328,225.472,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),44,268435456.0,537722880.0,0.0,0,0.0,537722880.0,537722880.0,842176.0,1664.0,0.9980280621918847,17825792.0,212992.0,27.36,252.832,0.0,851968.0,268435456.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,557056.0,6656.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",45,20480.0,61440.0,40960.0,0,0.0,102400.0,102400.0,0.0,2560.0,0.0,217088.0,16384.0,5.056,257.888,57344.0,4096.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6784.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",46,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.488,261.376,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",47,35396.0,109812.0,9216.0,0,0.0,119028.0,119028.0,80.0,360.0,0.18181818181818182,49152.0,16640.0,6.656,268.032,31280.0,16956.0,30788.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",48,12644352.0,25509888.0,122880.0,0,0.0,25632768.0,25632768.0,112512.0,105216.0,0.5167548500881834,13381632.0,49152.0,24.448,292.47999999999996,147456.0,196608.0,12582912.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,418176.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",49,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,256.0,0.0,16384.0,16384.0,4.288,296.768,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",50,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,256.0,0.0,16384.0,16384.0,4.224,300.99199999999996,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",51,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,256.0,0.0,16384.0,16384.0,4.416,305.40799999999996,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",52,131072.0,4354048.0,0.0,0,38654705664.0,4354048.0,38659059712.0,34048.0,64.0,0.99812382739212,49152.0,16384.0,12.576,317.984,3293184.0,798720.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,150994944.0,1536.0,512.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),53,67108864.0,134742016.0,0.0,0,0.0,134742016.0,134742016.0,230912.0,1024.0,0.9955849889624724,4456448.0,131072.0,10.4,328.38399999999996,0.0,524288.0,67108864.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,139264.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",54,20480.0,40960.0,40960.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,135168.0,16384.0,4.128,332.51199999999994,36864.0,4096.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4224.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",55,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.616,336.12799999999993,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",56,35396.0,109812.0,9216.0,0,0.0,119028.0,119028.0,80.0,360.0,0.18181818181818182,49152.0,16640.0,6.624,342.75199999999995,31280.0,16956.0,30788.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",57,16859136.0,34013184.0,163840.0,0,0.0,34177024.0,34177024.0,150016.0,140288.0,0.5167548500881834,17842176.0,65536.0,23.648,366.4,196608.0,262144.0,16777216.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,557568.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",58,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.36,369.76,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",59,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,3.232,372.992,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",60,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.264,376.25600000000003,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",61,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.488,379.744,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",62,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.52,383.264,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",63,98336.0,241728.0,8192.0,0,0.0,249920.0,249920.0,0.0,256.0,0.0,65536.0,65536.0,3.52,386.784,16384.0,36864.0,94240.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",64,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,3.232,390.016,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",65,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,3.264,393.28000000000003,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),66,268435456.0,537722880.0,0.0,0,0.0,537722880.0,537722880.0,842176.0,1664.0,0.9980280621918847,17825792.0,212992.0,27.552,420.83200000000005,0.0,851968.0,268435456.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,557056.0,6656.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",67,20480.0,61440.0,40960.0,0,0.0,102400.0,102400.0,0.0,2560.0,0.0,217088.0,16384.0,5.152,425.98400000000004,57344.0,4096.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6784.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",68,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.36,429.34400000000005,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",69,35396.0,109812.0,9216.0,0,0.0,119028.0,119028.0,80.0,360.0,0.18181818181818182,49152.0,16640.0,6.816,436.16,31280.0,16956.0,30788.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",70,12644352.0,25509888.0,122880.0,0,0.0,25632768.0,25632768.0,112512.0,105216.0,0.5167548500881834,13381632.0,49152.0,23.904,460.064,147456.0,196608.0,12582912.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,418176.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",71,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,256.0,0.0,16384.0,16384.0,4.384,464.44800000000004,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",72,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,256.0,0.0,16384.0,16384.0,4.32,468.76800000000003,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",73,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,256.0,0.0,16384.0,16384.0,4.32,473.088,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",74,131072.0,4354048.0,0.0,0,38654705664.0,4354048.0,38659059712.0,34048.0,64.0,0.99812382739212,49152.0,16384.0,12.608,485.696,3293184.0,798720.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,150994944.0,1536.0,512.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),75,67108864.0,134742016.0,0.0,0,0.0,134742016.0,134742016.0,230912.0,1024.0,0.9955849889624724,4456448.0,131072.0,10.4,496.096,0.0,524288.0,67108864.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,139264.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",76,20480.0,40960.0,40960.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,135168.0,16384.0,4.096,500.192,36864.0,4096.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4224.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",77,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.36,503.552,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",78,35396.0,109812.0,9216.0,0,0.0,119028.0,119028.0,80.0,360.0,0.18181818181818182,49152.0,16640.0,6.688,510.24,31280.0,16956.0,30788.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",79,16859136.0,34013184.0,163840.0,0,0.0,34177024.0,34177024.0,150016.0,140288.0,0.5167548500881834,17842176.0,65536.0,24.288,534.528,196608.0,262144.0,16777216.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,557568.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",80,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.456,537.984,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",81,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,3.424,541.408,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",82,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.264,544.672,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",83,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.296,547.9680000000001,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",84,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.264,551.2320000000001,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",85,98248.0,241552.0,8192.0,0,0.0,249744.0,249744.0,0.0,256.0,0.0,65536.0,65536.0,3.712,554.9440000000001,16384.0,36864.0,94152.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",86,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,3.52,558.464,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",87,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,3.488,561.9520000000001,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),88,268435456.0,537722880.0,0.0,0,0.0,537722880.0,537722880.0,842176.0,1664.0,0.9980280621918847,17825792.0,212992.0,27.936,589.8880000000001,0.0,851968.0,268435456.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,557056.0,6656.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",89,20480.0,61440.0,40960.0,0,0.0,102400.0,102400.0,0.0,2560.0,0.0,217088.0,16384.0,5.472,595.3600000000001,57344.0,4096.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6784.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",90,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.296,598.6560000000002,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",91,35396.0,109812.0,9216.0,0,0.0,119028.0,119028.0,80.0,360.0,0.18181818181818182,49152.0,16640.0,6.496,605.1520000000002,31280.0,16956.0,30788.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",92,12644352.0,25509888.0,122880.0,0,0.0,25632768.0,25632768.0,112512.0,105216.0,0.5167548500881834,13381632.0,49152.0,23.808,628.9600000000002,147456.0,196608.0,12582912.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,418176.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",93,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,256.0,0.0,16384.0,16384.0,4.48,633.4400000000002,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",94,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,256.0,0.0,16384.0,16384.0,4.416,637.8560000000002,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",95,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,256.0,0.0,16384.0,16384.0,4.352,642.2080000000002,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",96,131072.0,4354048.0,0.0,0,38654705664.0,4354048.0,38659059712.0,34048.0,64.0,0.99812382739212,49152.0,16384.0,12.768,654.9760000000002,3293184.0,798720.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,150994944.0,1536.0,512.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),97,67108864.0,134742016.0,0.0,0,0.0,134742016.0,134742016.0,230912.0,1024.0,0.9955849889624724,4456448.0,131072.0,10.432,665.4080000000002,0.0,524288.0,67108864.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,139264.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",98,20480.0,40960.0,40960.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,135168.0,16384.0,4.096,669.5040000000002,36864.0,4096.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4224.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",99,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.264,672.7680000000003,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",100,35396.0,109812.0,9216.0,0,0.0,119028.0,119028.0,80.0,360.0,0.18181818181818182,49152.0,16640.0,6.528,679.2960000000003,31280.0,16956.0,30788.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",101,16859136.0,34013184.0,163840.0,0,0.0,34177024.0,34177024.0,150016.0,140288.0,0.5167548500881834,17842176.0,65536.0,23.872,703.1680000000002,196608.0,262144.0,16777216.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,557568.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",102,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.328,706.4960000000002,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",103,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,3.424,709.9200000000002,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",104,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.232,713.1520000000002,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",105,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.488,716.6400000000002,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",106,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.456,720.0960000000002,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",107,97992.0,241040.0,8192.0,0,0.0,249232.0,249232.0,0.0,256.0,0.0,65536.0,65536.0,3.392,723.4880000000003,16384.0,36864.0,93896.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",108,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,3.264,726.7520000000003,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",109,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,3.584,730.3360000000002,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),110,268435456.0,537722880.0,0.0,0,0.0,537722880.0,537722880.0,842176.0,1664.0,0.9980280621918847,17825792.0,212992.0,27.584,757.9200000000002,0.0,851968.0,268435456.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,557056.0,6656.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",111,20480.0,61440.0,40960.0,0,0.0,102400.0,102400.0,0.0,2560.0,0.0,217088.0,16384.0,5.184,763.1040000000002,57344.0,4096.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6784.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",112,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.456,766.5600000000002,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",113,35396.0,109812.0,9216.0,0,0.0,119028.0,119028.0,80.0,360.0,0.18181818181818182,49152.0,16640.0,6.624,773.1840000000002,31280.0,16956.0,30788.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",114,12644352.0,25509888.0,122880.0,0,0.0,25632768.0,25632768.0,112512.0,105216.0,0.5167548500881834,13381632.0,49152.0,24.064,797.2480000000002,147456.0,196608.0,12582912.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,418176.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",115,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,256.0,0.0,16384.0,16384.0,4.352,801.6000000000001,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",116,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,256.0,0.0,16384.0,16384.0,4.48,806.0800000000002,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",117,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,256.0,0.0,16384.0,16384.0,4.32,810.4000000000002,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",118,131072.0,4354048.0,0.0,0,38654705664.0,4354048.0,38659059712.0,34048.0,64.0,0.99812382739212,49152.0,16384.0,12.832,823.2320000000002,3293184.0,798720.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,150994944.0,1536.0,512.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),119,67108864.0,134742016.0,0.0,0,0.0,134742016.0,134742016.0,230912.0,1024.0,0.9955849889624724,4456448.0,131072.0,10.688,833.9200000000002,0.0,524288.0,67108864.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,139264.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",120,20480.0,40960.0,40960.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,135168.0,16384.0,4.128,838.0480000000002,36864.0,4096.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4224.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",121,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.296,841.3440000000003,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",122,35396.0,109812.0,9216.0,0,0.0,119028.0,119028.0,80.0,360.0,0.18181818181818182,49152.0,16640.0,6.624,847.9680000000003,31280.0,16956.0,30788.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",123,16859136.0,34013184.0,163840.0,0,0.0,34177024.0,34177024.0,150016.0,140288.0,0.5167548500881834,17842176.0,65536.0,23.712,871.6800000000003,196608.0,262144.0,16777216.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,557568.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",124,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.264,874.9440000000003,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",125,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,3.52,878.4640000000003,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",126,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.488,881.9520000000003,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",127,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.616,885.5680000000003,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",128,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.392,888.9600000000004,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",129,98248.0,241552.0,8192.0,0,0.0,249744.0,249744.0,0.0,256.0,0.0,65536.0,65536.0,3.584,892.5440000000003,16384.0,36864.0,94152.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",130,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,3.424,895.9680000000003,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",131,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,3.296,899.2640000000004,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),132,268435456.0,537722880.0,0.0,0,0.0,537722880.0,537722880.0,842176.0,1664.0,0.9980280621918847,17825792.0,212992.0,28.16,927.4240000000003,0.0,851968.0,268435456.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,557056.0,6656.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",133,20480.0,61440.0,40960.0,0,0.0,102400.0,102400.0,0.0,2560.0,0.0,217088.0,16384.0,5.056,932.4800000000004,57344.0,4096.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6784.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",134,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.36,935.8400000000004,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",135,35396.0,109812.0,9216.0,0,0.0,119028.0,119028.0,80.0,360.0,0.18181818181818182,49152.0,16640.0,6.656,942.4960000000003,31280.0,16956.0,30788.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",136,12644352.0,25509888.0,122880.0,0,0.0,25632768.0,25632768.0,112512.0,105216.0,0.5167548500881834,13381632.0,49152.0,23.488,965.9840000000004,147456.0,196608.0,12582912.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,418176.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",137,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,256.0,0.0,16384.0,16384.0,4.384,970.3680000000004,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",138,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,256.0,0.0,16384.0,16384.0,4.576,974.9440000000004,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",139,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,256.0,0.0,16384.0,16384.0,4.16,979.1040000000004,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",140,131072.0,4354048.0,0.0,0,38654705664.0,4354048.0,38659059712.0,34048.0,64.0,0.99812382739212,49152.0,16384.0,12.736,991.8400000000004,3293184.0,798720.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,150994944.0,1536.0,512.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),141,67108864.0,134742016.0,0.0,0,0.0,134742016.0,134742016.0,230912.0,1024.0,0.9955849889624724,4456448.0,131072.0,10.368,1002.2080000000004,0.0,524288.0,67108864.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,139264.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",142,20480.0,40960.0,40960.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,135168.0,16384.0,4.096,1006.3040000000004,36864.0,4096.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4224.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",143,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.36,1009.6640000000004,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",144,35396.0,109812.0,9216.0,0,0.0,119028.0,119028.0,80.0,360.0,0.18181818181818182,49152.0,16640.0,6.784,1016.4480000000004,31280.0,16956.0,30788.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",145,16859136.0,34013184.0,163840.0,0,0.0,34177024.0,34177024.0,150016.0,140288.0,0.5167548500881834,17842176.0,65536.0,23.712,1040.1600000000005,196608.0,262144.0,16777216.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,557568.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",146,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.424,1043.5840000000005,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",147,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,3.232,1046.8160000000005,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",148,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.392,1050.2080000000005,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",149,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.328,1053.5360000000005,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",150,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.328,1056.8640000000005,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",151,98192.0,241440.0,8192.0,0,0.0,249632.0,249632.0,0.0,256.0,0.0,65536.0,65536.0,3.616,1060.4800000000005,16384.0,36864.0,94096.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",152,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,3.424,1063.9040000000005,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",153,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,3.488,1067.3920000000005,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),154,268435456.0,537722880.0,0.0,0,0.0,537722880.0,537722880.0,842176.0,1664.0,0.9980280621918847,17825792.0,212992.0,27.52,1094.9120000000005,0.0,851968.0,268435456.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,557056.0,6656.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",155,20480.0,61440.0,40960.0,0,0.0,102400.0,102400.0,0.0,2560.0,0.0,217088.0,16384.0,4.96,1099.8720000000005,57344.0,4096.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6784.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",156,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.232,1103.1040000000005,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",157,35396.0,109812.0,9216.0,0,0.0,119028.0,119028.0,80.0,360.0,0.18181818181818182,49152.0,16640.0,6.56,1109.6640000000004,31280.0,16956.0,30788.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",158,12644352.0,25509888.0,122880.0,0,0.0,25632768.0,25632768.0,112512.0,105216.0,0.5167548500881834,13381632.0,49152.0,24.16,1133.8240000000005,147456.0,196608.0,12582912.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,418176.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",159,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,256.0,0.0,16384.0,16384.0,4.256,1138.0800000000006,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",160,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,256.0,0.0,16384.0,16384.0,4.416,1142.4960000000005,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",161,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,256.0,0.0,16384.0,16384.0,4.256,1146.7520000000006,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",162,131072.0,4354048.0,0.0,0,38654705664.0,4354048.0,38659059712.0,34048.0,64.0,0.99812382739212,49152.0,16384.0,12.448,1159.2000000000007,3293184.0,798720.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,150994944.0,1536.0,512.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),163,67108864.0,134742016.0,0.0,0,0.0,134742016.0,134742016.0,230912.0,1024.0,0.9955849889624724,4456448.0,131072.0,10.656,1169.8560000000007,0.0,524288.0,67108864.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,139264.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",164,20480.0,40960.0,40960.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,135168.0,16384.0,4.128,1173.9840000000006,36864.0,4096.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4224.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",165,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.424,1177.4080000000006,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",166,35396.0,109812.0,9216.0,0,0.0,119028.0,119028.0,80.0,360.0,0.18181818181818182,49152.0,16640.0,6.688,1184.0960000000007,31280.0,16956.0,30788.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",167,16859136.0,34013184.0,163840.0,0,0.0,34177024.0,34177024.0,150016.0,140288.0,0.5167548500881834,17842176.0,65536.0,23.648,1207.7440000000006,196608.0,262144.0,16777216.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,557568.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",168,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.232,1210.9760000000006,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",169,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,3.456,1214.4320000000005,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",170,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.488,1217.9200000000005,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",171,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.392,1221.3120000000006,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",172,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.232,1224.5440000000006,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",173,98320.0,241696.0,8192.0,0,0.0,249888.0,249888.0,0.0,256.0,0.0,65536.0,65536.0,3.616,1228.1600000000005,16384.0,36864.0,94224.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",174,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,3.488,1231.6480000000006,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",175,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,3.52,1235.1680000000006,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),176,268435456.0,537722880.0,0.0,0,0.0,537722880.0,537722880.0,842176.0,1664.0,0.9980280621918847,17825792.0,212992.0,27.872,1263.0400000000006,0.0,851968.0,268435456.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,557056.0,6656.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",177,20480.0,61440.0,40960.0,0,0.0,102400.0,102400.0,0.0,2560.0,0.0,217088.0,16384.0,5.024,1268.0640000000005,57344.0,4096.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6784.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",178,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.488,1271.5520000000006,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",179,35396.0,109812.0,9216.0,0,0.0,119028.0,119028.0,80.0,360.0,0.18181818181818182,49152.0,16640.0,6.592,1278.1440000000007,31280.0,16956.0,30788.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",180,12644352.0,25509888.0,122880.0,0,0.0,25632768.0,25632768.0,112512.0,105216.0,0.5167548500881834,13381632.0,49152.0,24.128,1302.2720000000006,147456.0,196608.0,12582912.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,418176.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",181,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,256.0,0.0,16384.0,16384.0,4.384,1306.6560000000006,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",182,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,256.0,0.0,16384.0,16384.0,4.32,1310.9760000000006,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",183,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,256.0,0.0,16384.0,16384.0,4.352,1315.3280000000007,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",184,131072.0,4354048.0,0.0,0,38654705664.0,4354048.0,38659059712.0,34048.0,64.0,0.99812382739212,49152.0,16384.0,12.672,1328.0000000000007,3293184.0,798720.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,150994944.0,1536.0,512.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),185,67108864.0,134742016.0,0.0,0,0.0,134742016.0,134742016.0,230912.0,1024.0,0.9955849889624724,4456448.0,131072.0,10.432,1338.4320000000007,0.0,524288.0,67108864.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,139264.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",186,20480.0,40960.0,40960.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,135168.0,16384.0,4.16,1342.5920000000008,36864.0,4096.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4224.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",187,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.296,1345.8880000000008,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",188,35396.0,109812.0,9216.0,0,0.0,119028.0,119028.0,80.0,360.0,0.18181818181818182,49152.0,16640.0,6.592,1352.480000000001,31280.0,16956.0,30788.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",189,16859136.0,34013184.0,163840.0,0,0.0,34177024.0,34177024.0,150016.0,140288.0,0.5167548500881834,17842176.0,65536.0,23.584,1376.064000000001,196608.0,262144.0,16777216.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,557568.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",190,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.328,1379.392000000001,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",191,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,3.36,1382.7520000000009,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",192,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.392,1386.144000000001,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",193,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.264,1389.4080000000008,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",194,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.392,1392.8000000000009,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",195,98148.0,241352.0,8192.0,0,0.0,249544.0,249544.0,0.0,256.0,0.0,65536.0,65536.0,3.424,1396.2240000000008,16384.0,36864.0,94052.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",196,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,3.232,1399.4560000000008,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",197,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,3.52,1402.9760000000008,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),198,268435456.0,537722880.0,0.0,0,0.0,537722880.0,537722880.0,842176.0,1664.0,0.9980280621918847,17825792.0,212992.0,27.52,1430.4960000000008,0.0,851968.0,268435456.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,557056.0,6656.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",199,20480.0,61440.0,40960.0,0,0.0,102400.0,102400.0,0.0,2560.0,0.0,217088.0,16384.0,5.056,1435.5520000000008,57344.0,4096.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6784.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",200,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.296,1438.8480000000009,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",201,35396.0,109812.0,9216.0,0,0.0,119028.0,119028.0,80.0,360.0,0.18181818181818182,49152.0,16640.0,6.496,1445.344000000001,31280.0,16956.0,30788.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,520.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",202,210677456.0,453522752.0,9649568.0,0,0.0,463172320.0,463172320.0,3040636.0,2512996.0,0.5475040478015107,215428096.0,1365824.0,94.4,1539.744000000001,16082240.0,25735168.0,205852672.0,4824784.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6732128.0,42682.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",203,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.784,1542.5280000000012,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",204,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,128.0,3.84,1546.368000000001,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",205,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.2,1549.5680000000011,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",206,128.0,201728.0,256.0,0,0.0,201984.0,201984.0,0.0,3158.0,0.0,804128.0,804128.0,3.808,1553.376000000001,0.0,201728.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25129.0,25129.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",207,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.976,1556.3520000000012,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",208,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,55296.0,5.92,1562.2720000000013,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1728.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",209,96000.0,0.0,192000.0,0,0.0,192000.0,192000.0,13200.0,82608.0,0.1377755511022044,5134848.0,0.0,8.544,1570.8160000000014,0.0,0.0,0.0,96000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",210,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,54400.0,5.824,1576.6400000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1700.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",211,57600.0,0.0,115200.0,0,0.0,115200.0,115200.0,13200.0,83808.0,0.13607125185551708,5134848.0,0.0,8.448,1585.0880000000016,0.0,0.0,0.0,57600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",212,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,53312.0,5.856,1590.9440000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1666.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",213,83200.0,0.0,166400.0,0,0.0,166400.0,166400.0,13200.0,83008.0,0.13720272742391484,5134848.0,0.0,8.192,1599.1360000000016,0.0,0.0,0.0,83200.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",214,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,54016.0,5.984,1605.1200000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1688.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",215,70400.0,0.0,140800.0,0,0.0,140800.0,140800.0,13200.0,83408.0,0.1366346472341835,5134848.0,128.0,8.352,1613.4720000000016,0.0,0.0,0.0,70400.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",216,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,21.0,0.0,6432.0,800.0,3.712,1617.1840000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,201.0,25.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",217,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.04,1620.2240000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",218,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,23.0,0.9653092006033183,800.0,0.0,5.568,1625.7920000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",219,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.88,1628.6720000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",220,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,23.0,0.9653092006033183,800.0,0.0,5.6,1634.2720000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",221,51200.0,0.0,102400.0,0,0.0,102400.0,102400.0,41328.0,13020.0,0.7604327666151468,831584.0,7904.0,9.12,1643.3920000000014,0.0,0.0,0.0,51200.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25987.0,247.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",222,0.0,0.0,0.0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,8.832,1652.2240000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",223,402056.0,0.0,804112.0,0,0.0,804112.0,804112.0,0.0,18849.0,0.0,816544.0,68992.0,6.112,1658.3360000000016,0.0,0.0,0.0,402056.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25517.0,2156.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",224,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4737.0,0.0,1005184.0,0.0,4.448,1662.7840000000017,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,31412.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",225,201028.0,0.0,402056.0,0,0.0,402056.0,402056.0,0.0,6283.0,0.0,0.0,1608224.0,4.256,1667.0400000000018,0.0,0.0,0.0,201028.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,50257.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",226,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,6283.0,0.9555817915744674,804128.0,0.0,6.24,1673.2800000000018,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25129.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",227,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.52,1676.8000000000018,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",228,0.0,0.0,0.0,0,0.0,0.0,0.0,65855.0,28366.0,0.698941849481538,2727744.0,1989696.0,15.072,1691.8720000000017,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85242.0,62178.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",229,0.0,0.0,0.0,0,0.0,0.0,0.0,14210.0,28362.0,0.3337874659400545,2736576.0,2451264.0,11.872,1703.7440000000017,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85518.0,76602.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",230,0.0,0.0,0.0,0,0.0,0.0,0.0,15311.0,28157.0,0.3522361277261434,2721088.0,2451264.0,12.512,1716.2560000000017,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85034.0,76602.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",231,0.0,0.0,0.0,0,0.0,0.0,0.0,15311.0,28249.0,0.3514921946740129,2728768.0,1904608.0,13.312,1729.5680000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85274.0,59519.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",232,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,6283.0,0.7017610480846822,1608224.0,0.0,4.896,1734.4640000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50257.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",233,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.232,1737.6960000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",234,0.0,0.0,0.0,0,0.0,0.0,0.0,14833.0,15196.0,0.4939558426854041,1869344.0,1342880.0,9.792,1747.4880000000014,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,58417.0,41965.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",235,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,25132.0,0.0,2428992.0,2412352.0,5.152,1752.6400000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75906.0,75386.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",236,3122040.0,6655044.0,615296.0,0,0.0,7270340.0,7270340.0,528.0,6704.0,0.07300884955752213,1069984.0,753216.0,32.032,1784.6720000000014,825232.0,201028.0,2814392.0,307648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33437.0,23538.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",237,0.0,1024200.0,0.0,0,0.0,1024200.0,1024200.0,112284.0,12568.0,0.8993368147887099,804224.0,613856.0,97.92,1882.5920000000015,1024200.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25132.0,19183.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",238,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3158.0,0.0,804128.0,200864.0,3.808,1886.4000000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25129.0,6277.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",239,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,3.2,1889.6000000000015,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",240,402056.0,0.0,804112.0,0,0.0,804112.0,804112.0,0.0,18849.0,0.0,1809280.0,90208.0,11.744,1901.3440000000014,0.0,0.0,0.0,402056.0,0,0,0,0,0,0,0,0.0,0.0,0.0,56540.0,2819.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",241,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4737.0,0.0,1005184.0,0.0,4.384,1905.7280000000014,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,31412.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",242,3122052.0,6655044.0,615320.0,0,0.0,7270364.0,7270364.0,528.0,6704.0,0.07300884955752213,1085376.0,753024.0,32.256,1937.9840000000015,825232.0,201028.0,2814392.0,307660.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33918.0,23532.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",243,38912.0,0.0,77824.0,0,0.0,77824.0,77824.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,9.312,1947.2960000000014,0.0,0.0,0.0,38912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",244,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.488,1950.7840000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",245,38912.0,0.0,77824.0,0,0.0,77824.0,77824.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,9.632,1960.4160000000015,0.0,0.0,0.0,38912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",246,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,1963.7120000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",247,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.488,1967.2000000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",248,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.608,1971.8080000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",249,4096.0,220484.0,8192.0,0,0.0,228676.0,228676.0,320.0,1582.0,0.16824395373291273,804224.0,128.0,16.192,1988.0000000000016,220484.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25132.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",250,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.2,1991.2000000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",251,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,5.152,1996.3520000000017,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",252,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.456,1999.8080000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",253,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.448,2004.2560000000017,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",254,2213376.0,4023944.0,804864.0,0,0.0,4828808.0,4828808.0,0.0,6283.0,0.0,0.0,804128.0,6.016,2010.2720000000018,0.0,402056.0,1810944.0,402432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,25129.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",255,1256412.0,2010280.0,502544.0,0,0.0,2512824.0,2512824.0,0.0,4737.0,0.0,1608256.0,0.0,5.408,2015.6800000000017,0.0,0.0,1005140.0,251272.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50258.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",256,2560.0,0.0,5120.0,0,0.0,5120.0,5120.0,640.0,1582.0,0.28802880288028804,804288.0,128.0,22.912,2038.5920000000017,0.0,0.0,0.0,2560.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25134.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",257,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.072,2041.6640000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",258,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.136,2044.8000000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",259,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,3.936,2048.7360000000017,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",260,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.296,2052.0320000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",261,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,128.0,3.808,2055.8400000000015,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",262,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.656,2058.4960000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",263,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.816,2061.3120000000013,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",264,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.584,2064.896000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",265,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.72,2067.616000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",266,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,96.0,32.0,3.712,2071.328000000001,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",267,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,5.0,0.0,32.0,32.0,7.04,2078.368000000001,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",268,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.392,2081.7600000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",269,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,2085.120000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",270,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,4.064,2089.1840000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",271,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.8,2093.984000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",272,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,2097.216000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",273,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,2100.5120000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",274,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,3.0,0.0,96.0,32.0,4.8,2105.312000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",275,0.0,0.0,0.0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,64.0,32.0,4.096,2109.408000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",276,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,3.264,2112.672000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",277,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.296,2115.9680000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",278,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,0.0,3.424,2119.3920000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",279,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,64.0,32.0,3.616,2123.0080000000007,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",280,1024.0,0.0,2048.0,0,0.0,2048.0,2048.0,0.0,384.0,0.0,16640.0,16384.0,6.336,2129.3440000000005,0.0,0.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,520.0,512.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",281,1024.0,0.0,2048.0,0,0.0,2048.0,2048.0,0.0,384.0,0.0,4352.0,16384.0,5.792,2135.1360000000004,0.0,0.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,136.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",282,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.456,2138.5920000000006,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",283,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.232,2141.8240000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",284,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,4.992,2146.8160000000007,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",285,35396.0,109812.0,9216.0,0,0.0,119028.0,119028.0,80.0,360.0,0.18181818181818182,49152.0,16640.0,6.688,2153.504000000001,31280.0,16956.0,30788.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",286,12644352.0,25509888.0,122880.0,0,0.0,25632768.0,25632768.0,112512.0,105216.0,0.5167548500881834,13381632.0,49152.0,24.32,2177.824000000001,147456.0,196608.0,12582912.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,418176.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",287,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.472,2183.296000000001,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",288,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.568,2188.8640000000014,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",289,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,256.0,0.0,16384.0,16384.0,4.416,2193.2800000000016,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",290,131072.0,4358144.0,0.0,0,38654705664.0,4358144.0,38659063808.0,34048.0,64.0,0.99812382739212,81920.0,16384.0,12.8,2206.0800000000017,3297280.0,798720.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,150994944.0,2560.0,512.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),291,67108864.0,134742016.0,0.0,0,0.0,134742016.0,134742016.0,230912.0,1024.0,0.9955849889624724,4456448.0,131072.0,10.304,2216.384000000002,0.0,524288.0,67108864.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,139264.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",292,20480.0,40960.0,40960.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,135168.0,16384.0,4.192,2220.576000000002,36864.0,4096.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4224.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",293,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.296,2223.8720000000017,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",294,35396.0,109812.0,9216.0,0,0.0,119028.0,119028.0,80.0,360.0,0.18181818181818182,49152.0,16640.0,6.752,2230.6240000000016,31280.0,16956.0,30788.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",295,16859136.0,34013184.0,163840.0,0,0.0,34177024.0,34177024.0,150016.0,140288.0,0.5167548500881834,17842176.0,65536.0,23.68,2254.3040000000015,196608.0,262144.0,16777216.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,557568.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",296,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.424,2257.7280000000014,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",297,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,3.36,2261.0880000000016,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",298,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.456,2264.5440000000017,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",299,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.52,2268.0640000000017,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",300,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.2,2271.2640000000015,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",301,98316.0,241688.0,8192.0,0,0.0,249880.0,249880.0,0.0,256.0,0.0,65536.0,65536.0,3.392,2274.6560000000013,16384.0,36864.0,94220.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",302,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,3.328,2277.9840000000013,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",303,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,3.392,2281.376000000001,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),304,268435456.0,537722880.0,0.0,0,0.0,537722880.0,537722880.0,842176.0,1664.0,0.9980280621918847,17825792.0,212992.0,27.776,2309.152000000001,0.0,851968.0,268435456.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,557056.0,6656.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",305,20480.0,61440.0,40960.0,0,0.0,102400.0,102400.0,0.0,2560.0,0.0,217088.0,16384.0,4.896,2314.048000000001,57344.0,4096.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6784.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",306,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.36,2317.4080000000013,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",307,35396.0,109812.0,9216.0,0,0.0,119028.0,119028.0,80.0,360.0,0.18181818181818182,49152.0,16640.0,6.496,2323.9040000000014,31280.0,16956.0,30788.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",308,12644352.0,25509888.0,122880.0,0,0.0,25632768.0,25632768.0,112512.0,105216.0,0.5167548500881834,13381632.0,49152.0,24.0,2347.9040000000014,147456.0,196608.0,12582912.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,418176.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",309,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.408,2353.3120000000013,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",310,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.408,2358.720000000001,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",311,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,256.0,0.0,16384.0,16384.0,4.32,2363.0400000000013,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",312,131072.0,4358144.0,0.0,0,38654705664.0,4358144.0,38659063808.0,34048.0,64.0,0.99812382739212,81920.0,16384.0,12.672,2375.7120000000014,3297280.0,798720.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,150994944.0,2560.0,512.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),313,67108864.0,134742016.0,0.0,0,0.0,134742016.0,134742016.0,230912.0,1024.0,0.9955849889624724,4456448.0,131072.0,10.336,2386.048000000001,0.0,524288.0,67108864.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,139264.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",314,20480.0,40960.0,40960.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,135168.0,16384.0,4.128,2390.1760000000013,36864.0,4096.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4224.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",315,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.232,2393.4080000000013,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",316,35396.0,109812.0,9216.0,0,0.0,119028.0,119028.0,80.0,360.0,0.18181818181818182,49152.0,16640.0,6.752,2400.160000000001,31280.0,16956.0,30788.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",317,16859136.0,34013184.0,163840.0,0,0.0,34177024.0,34177024.0,150016.0,140288.0,0.5167548500881834,17842176.0,65536.0,23.744,2423.9040000000014,196608.0,262144.0,16777216.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,557568.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",318,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.392,2427.296000000001,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",319,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,3.488,2430.784000000001,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",320,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.328,2434.112000000001,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",321,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.392,2437.504000000001,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",322,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.328,2440.832000000001,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",323,98243.0,241542.0,8192.0,0,0.0,249734.0,249734.0,0.0,256.0,0.0,65536.0,65536.0,3.456,2444.288000000001,16384.0,36864.0,94147.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",324,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,3.168,2447.456000000001,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",325,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,3.424,2450.880000000001,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),326,268435456.0,537722880.0,0.0,0,0.0,537722880.0,537722880.0,842176.0,1664.0,0.9980280621918847,17825792.0,212992.0,27.584,2478.464000000001,0.0,851968.0,268435456.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,557056.0,6656.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",327,20480.0,61440.0,40960.0,0,0.0,102400.0,102400.0,0.0,2560.0,0.0,217088.0,16384.0,4.864,2483.328000000001,57344.0,4096.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6784.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",328,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.296,2486.6240000000007,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",329,35396.0,109812.0,9216.0,0,0.0,119028.0,119028.0,80.0,360.0,0.18181818181818182,49152.0,16640.0,6.624,2493.2480000000005,31280.0,16956.0,30788.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",330,12644352.0,25509888.0,122880.0,0,0.0,25632768.0,25632768.0,112512.0,105216.0,0.5167548500881834,13381632.0,49152.0,24.16,2517.4080000000004,147456.0,196608.0,12582912.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,418176.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",331,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.696,2523.1040000000003,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",332,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.536,2528.6400000000003,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",333,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,256.0,0.0,16384.0,16384.0,4.224,2532.8640000000005,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",334,131072.0,4358144.0,0.0,0,38654705664.0,4358144.0,38659063808.0,34048.0,64.0,0.99812382739212,81920.0,16384.0,12.576,2545.4400000000005,3297280.0,798720.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,150994944.0,2560.0,512.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),335,67108864.0,134742016.0,0.0,0,0.0,134742016.0,134742016.0,230912.0,1024.0,0.9955849889624724,4456448.0,131072.0,10.4,2555.8400000000006,0.0,524288.0,67108864.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,139264.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",336,20480.0,40960.0,40960.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,135168.0,16384.0,4.16,2560.0000000000005,36864.0,4096.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4224.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",337,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.328,2563.3280000000004,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",338,35396.0,109812.0,9216.0,0,0.0,119028.0,119028.0,80.0,360.0,0.18181818181818182,49152.0,16640.0,6.88,2570.2080000000005,31280.0,16956.0,30788.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",339,16859136.0,34013184.0,163840.0,0,0.0,34177024.0,34177024.0,150016.0,140288.0,0.5167548500881834,17842176.0,65536.0,24.032,2594.2400000000007,196608.0,262144.0,16777216.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,557568.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",340,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.264,2597.504000000001,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",341,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,3.264,2600.768000000001,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",342,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.264,2604.032000000001,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",343,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.424,2607.456000000001,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",344,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.392,2610.848000000001,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",345,98306.0,241668.0,8192.0,0,0.0,249860.0,249860.0,0.0,256.0,0.0,65536.0,65536.0,3.424,2614.272000000001,16384.0,36864.0,94210.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",346,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,3.36,2617.632000000001,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",347,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,3.36,2620.992000000001,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),348,268435456.0,537722880.0,0.0,0,0.0,537722880.0,537722880.0,842176.0,1664.0,0.9980280621918847,17825792.0,212992.0,27.392,2648.384000000001,0.0,851968.0,268435456.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,557056.0,6656.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",349,20480.0,61440.0,40960.0,0,0.0,102400.0,102400.0,0.0,2560.0,0.0,217088.0,16384.0,5.152,2653.536000000001,57344.0,4096.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6784.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",350,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.296,2656.832000000001,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",351,35396.0,109812.0,9216.0,0,0.0,119028.0,119028.0,80.0,360.0,0.18181818181818182,49152.0,16640.0,6.56,2663.3920000000007,31280.0,16956.0,30788.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",352,12644352.0,25509888.0,122880.0,0,0.0,25632768.0,25632768.0,112512.0,105216.0,0.5167548500881834,13381632.0,49152.0,23.936,2687.328000000001,147456.0,196608.0,12582912.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,418176.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",353,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.6,2692.928000000001,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",354,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.376,2698.304000000001,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",355,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,256.0,0.0,16384.0,16384.0,4.384,2702.688000000001,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",356,131072.0,4358144.0,0.0,0,38654705664.0,4358144.0,38659063808.0,34048.0,64.0,0.99812382739212,81920.0,16384.0,12.64,2715.328000000001,3297280.0,798720.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,150994944.0,2560.0,512.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),357,67108864.0,134742016.0,0.0,0,0.0,134742016.0,134742016.0,230912.0,1024.0,0.9955849889624724,4456448.0,131072.0,10.336,2725.6640000000007,0.0,524288.0,67108864.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,139264.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",358,20480.0,40960.0,40960.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,135168.0,16384.0,4.032,2729.696000000001,36864.0,4096.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4224.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",359,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.2,2732.8960000000006,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",360,35396.0,109812.0,9216.0,0,0.0,119028.0,119028.0,80.0,360.0,0.18181818181818182,49152.0,16640.0,6.656,2739.5520000000006,31280.0,16956.0,30788.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",361,16859136.0,34013184.0,163840.0,0,0.0,34177024.0,34177024.0,150016.0,140288.0,0.5167548500881834,17842176.0,65536.0,23.552,2763.1040000000007,196608.0,262144.0,16777216.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,557568.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",362,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.392,2766.4960000000005,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",363,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,3.488,2769.9840000000004,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",364,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.2,2773.184,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",365,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.456,2776.6400000000003,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",366,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.552,2780.1920000000005,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",367,98206.0,241468.0,8192.0,0,0.0,249660.0,249660.0,0.0,256.0,0.0,65536.0,65536.0,3.584,2783.7760000000003,16384.0,36864.0,94110.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",368,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,3.264,2787.0400000000004,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",369,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,3.488,2790.5280000000002,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),370,268435456.0,537722880.0,0.0,0,0.0,537722880.0,537722880.0,842176.0,1664.0,0.9980280621918847,17825792.0,212992.0,27.68,2818.208,0.0,851968.0,268435456.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,557056.0,6656.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",371,20480.0,61440.0,40960.0,0,0.0,102400.0,102400.0,0.0,2560.0,0.0,217088.0,16384.0,4.96,2823.168,57344.0,4096.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6784.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",372,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.392,2826.56,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",373,35396.0,109812.0,9216.0,0,0.0,119028.0,119028.0,80.0,360.0,0.18181818181818182,49152.0,16640.0,6.56,2833.12,31280.0,16956.0,30788.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",374,12644352.0,25509888.0,122880.0,0,0.0,25632768.0,25632768.0,112512.0,105216.0,0.5167548500881834,13381632.0,49152.0,23.968,2857.0879999999997,147456.0,196608.0,12582912.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,418176.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",375,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.536,2862.624,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",376,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.632,2868.256,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",377,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,256.0,0.0,16384.0,16384.0,4.384,2872.64,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",378,131072.0,4358144.0,0.0,0,38654705664.0,4358144.0,38659063808.0,34048.0,64.0,0.99812382739212,81920.0,16384.0,12.608,2885.248,3297280.0,798720.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,150994944.0,2560.0,512.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),379,67108864.0,134742016.0,0.0,0,0.0,134742016.0,134742016.0,230912.0,1024.0,0.9955849889624724,4456448.0,131072.0,10.432,2895.68,0.0,524288.0,67108864.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,139264.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",380,20480.0,40960.0,40960.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,135168.0,16384.0,4.384,2900.064,36864.0,4096.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4224.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",381,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.296,2903.3599999999997,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",382,35396.0,109812.0,9216.0,0,0.0,119028.0,119028.0,80.0,360.0,0.18181818181818182,49152.0,16640.0,6.784,2910.144,31280.0,16956.0,30788.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",383,16859136.0,34013184.0,163840.0,0,0.0,34177024.0,34177024.0,150016.0,140288.0,0.5167548500881834,17842176.0,65536.0,23.584,2933.7279999999996,196608.0,262144.0,16777216.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,557568.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",384,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.648,2937.3759999999997,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",385,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,3.392,2940.7679999999996,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",386,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.456,2944.2239999999997,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",387,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.296,2947.5199999999995,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",388,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.36,2950.8799999999997,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",389,98303.0,241662.0,8192.0,0,0.0,249854.0,249854.0,0.0,256.0,0.0,65536.0,65536.0,3.52,2954.3999999999996,16384.0,36864.0,94207.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",390,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,3.264,2957.6639999999998,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",391,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,3.52,2961.1839999999997,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),392,268435456.0,537722880.0,0.0,0,0.0,537722880.0,537722880.0,842176.0,1664.0,0.9980280621918847,17825792.0,212992.0,27.648,2988.832,0.0,851968.0,268435456.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,557056.0,6656.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",393,20480.0,61440.0,40960.0,0,0.0,102400.0,102400.0,0.0,2560.0,0.0,217088.0,16384.0,5.024,2993.8559999999998,57344.0,4096.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6784.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",394,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.392,2997.2479999999996,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",395,35396.0,109812.0,9216.0,0,0.0,119028.0,119028.0,80.0,360.0,0.18181818181818182,49152.0,16640.0,6.624,3003.8719999999994,31280.0,16956.0,30788.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",396,12644352.0,25509888.0,122880.0,0,0.0,25632768.0,25632768.0,112512.0,105216.0,0.5167548500881834,13381632.0,49152.0,23.68,3027.551999999999,147456.0,196608.0,12582912.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,418176.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",397,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.44,3032.9919999999993,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",398,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.408,3038.399999999999,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",399,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,256.0,0.0,16384.0,16384.0,4.352,3042.751999999999,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",400,131072.0,4358144.0,0.0,0,38654705664.0,4358144.0,38659063808.0,34048.0,64.0,0.99812382739212,81920.0,16384.0,12.512,3055.263999999999,3297280.0,798720.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,150994944.0,2560.0,512.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),401,67108864.0,134742016.0,0.0,0,0.0,134742016.0,134742016.0,230912.0,1024.0,0.9955849889624724,4456448.0,131072.0,10.4,3065.6639999999993,0.0,524288.0,67108864.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,139264.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",402,20480.0,40960.0,40960.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,135168.0,16384.0,4.224,3069.8879999999995,36864.0,4096.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4224.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",403,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.424,3073.3119999999994,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",404,35396.0,109812.0,9216.0,0,0.0,119028.0,119028.0,80.0,360.0,0.18181818181818182,49152.0,16640.0,6.72,3080.0319999999992,31280.0,16956.0,30788.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",405,16859136.0,34013184.0,163840.0,0,0.0,34177024.0,34177024.0,150016.0,140288.0,0.5167548500881834,17842176.0,65536.0,23.808,3103.8399999999992,196608.0,262144.0,16777216.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,557568.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",406,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.392,3107.231999999999,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",407,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,3.456,3110.687999999999,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",408,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.264,3113.9519999999993,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",409,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.488,3117.439999999999,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",410,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.52,3120.959999999999,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",411,98309.0,241674.0,8192.0,0,0.0,249866.0,249866.0,0.0,256.0,0.0,65536.0,65536.0,3.456,3124.4159999999993,16384.0,36864.0,94213.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",412,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,3.552,3127.9679999999994,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",413,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,3.328,3131.2959999999994,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),414,268435456.0,537722880.0,0.0,0,0.0,537722880.0,537722880.0,842176.0,1664.0,0.9980280621918847,17825792.0,212992.0,27.616,3158.9119999999994,0.0,851968.0,268435456.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,557056.0,6656.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",415,20480.0,61440.0,40960.0,0,0.0,102400.0,102400.0,0.0,2560.0,0.0,217088.0,16384.0,5.056,3163.9679999999994,57344.0,4096.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6784.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",416,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.456,3167.4239999999995,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",417,35396.0,109812.0,9216.0,0,0.0,119028.0,119028.0,80.0,360.0,0.18181818181818182,49152.0,16640.0,6.56,3173.9839999999995,31280.0,16956.0,30788.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",418,12644352.0,25509888.0,122880.0,0,0.0,25632768.0,25632768.0,112512.0,105216.0,0.5167548500881834,13381632.0,49152.0,24.032,3198.0159999999996,147456.0,196608.0,12582912.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,418176.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",419,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.504,3203.5199999999995,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",420,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.44,3208.9599999999996,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",421,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,256.0,0.0,16384.0,16384.0,4.448,3213.4079999999994,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",422,131072.0,4358144.0,0.0,0,38654705664.0,4358144.0,38659063808.0,34048.0,64.0,0.99812382739212,81920.0,16384.0,12.544,3225.9519999999993,3297280.0,798720.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,150994944.0,2560.0,512.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),423,67108864.0,134742016.0,0.0,0,0.0,134742016.0,134742016.0,230912.0,1024.0,0.9955849889624724,4456448.0,131072.0,10.432,3236.383999999999,0.0,524288.0,67108864.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,139264.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",424,20480.0,40960.0,40960.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,135168.0,16384.0,4.352,3240.735999999999,36864.0,4096.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4224.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",425,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.488,3244.223999999999,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",426,35396.0,109812.0,9216.0,0,0.0,119028.0,119028.0,80.0,360.0,0.18181818181818182,49152.0,16640.0,6.656,3250.8799999999987,31280.0,16956.0,30788.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",427,16859136.0,34013184.0,163840.0,0,0.0,34177024.0,34177024.0,150016.0,140288.0,0.5167548500881834,17842176.0,65536.0,23.904,3274.7839999999987,196608.0,262144.0,16777216.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,557568.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",428,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.2,3277.9839999999986,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",429,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,3.264,3281.2479999999987,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",430,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.424,3284.6719999999987,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",431,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.68,3288.3519999999985,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",432,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.456,3291.8079999999986,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",433,98322.0,241700.0,8192.0,0,0.0,249892.0,249892.0,0.0,256.0,0.0,65536.0,65536.0,3.424,3295.2319999999986,16384.0,36864.0,94226.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",434,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,3.744,3298.9759999999987,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",435,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,3.52,3302.4959999999987,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),436,268435456.0,537722880.0,0.0,0,0.0,537722880.0,537722880.0,842176.0,1664.0,0.9980280621918847,17825792.0,212992.0,27.456,3329.951999999999,0.0,851968.0,268435456.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,557056.0,6656.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",437,20480.0,61440.0,40960.0,0,0.0,102400.0,102400.0,0.0,2560.0,0.0,217088.0,16384.0,5.024,3334.9759999999987,57344.0,4096.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6784.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",438,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.296,3338.2719999999986,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",439,35396.0,109812.0,9216.0,0,0.0,119028.0,119028.0,80.0,360.0,0.18181818181818182,49152.0,16640.0,6.528,3344.7999999999984,31280.0,16956.0,30788.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",440,12644352.0,25509888.0,122880.0,0,0.0,25632768.0,25632768.0,112512.0,105216.0,0.5167548500881834,13381632.0,49152.0,24.8,3369.5999999999985,147456.0,196608.0,12582912.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,418176.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",441,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.472,3375.0719999999988,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",442,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,5.344,3380.415999999999,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",443,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,256.0,0.0,16384.0,16384.0,4.192,3384.607999999999,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",444,131072.0,4358144.0,0.0,0,38654705664.0,4358144.0,38659063808.0,34048.0,64.0,0.99812382739212,81920.0,16384.0,12.608,3397.215999999999,3297280.0,798720.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,150994944.0,2560.0,512.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),445,67108864.0,134742016.0,0.0,0,0.0,134742016.0,134742016.0,230912.0,1024.0,0.9955849889624724,4456448.0,131072.0,10.304,3407.519999999999,0.0,524288.0,67108864.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,139264.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",446,20480.0,40960.0,40960.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,135168.0,16384.0,4.0,3411.519999999999,36864.0,4096.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4224.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",447,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.296,3414.815999999999,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",448,35396.0,109812.0,9216.0,0,0.0,119028.0,119028.0,80.0,360.0,0.18181818181818182,49152.0,16640.0,6.592,3421.407999999999,31280.0,16956.0,30788.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",449,16859136.0,34013184.0,163840.0,0,0.0,34177024.0,34177024.0,150016.0,140288.0,0.5167548500881834,17842176.0,65536.0,23.968,3445.375999999999,196608.0,262144.0,16777216.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,557568.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",450,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.328,3448.703999999999,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",451,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,3.52,3452.223999999999,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",452,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.2,3455.4239999999986,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",453,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.488,3458.9119999999984,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",454,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.296,3462.2079999999983,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",455,98200.0,241456.0,8192.0,0,0.0,249648.0,249648.0,0.0,256.0,0.0,65536.0,65536.0,3.424,3465.6319999999982,16384.0,36864.0,94104.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",456,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,3.392,3469.023999999998,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",457,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,3.552,3472.575999999998,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),458,268435456.0,537722880.0,0.0,0,0.0,537722880.0,537722880.0,842176.0,1664.0,0.9980280621918847,17825792.0,212992.0,27.84,3500.4159999999983,0.0,851968.0,268435456.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,557056.0,6656.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",459,20480.0,61440.0,40960.0,0,0.0,102400.0,102400.0,0.0,2560.0,0.0,217088.0,16384.0,5.12,3505.5359999999982,57344.0,4096.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6784.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",460,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.296,3508.831999999998,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",461,35396.0,109812.0,9216.0,0,0.0,119028.0,119028.0,80.0,360.0,0.18181818181818182,49152.0,16640.0,6.656,3515.487999999998,31280.0,16956.0,30788.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,520.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",462,210677456.0,453522752.0,9649568.0,0,0.0,463172320.0,463172320.0,3040636.0,2512996.0,0.5475040478015107,216692480.0,1402016.0,94.688,3610.175999999998,16082240.0,25735168.0,205852672.0,4824784.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6771640.0,43813.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",463,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.912,3613.087999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",464,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,96.0,160.0,3.808,3616.895999999998,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",465,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.2,3620.0959999999977,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",466,128.0,201728.0,256.0,0,0.0,201984.0,201984.0,0.0,3158.0,0.0,804128.0,804128.0,3.808,3623.9039999999977,0.0,201728.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25129.0,25129.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",467,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.848,3626.7519999999977,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",468,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,54976.0,5.952,3632.703999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1718.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",469,96000.0,0.0,192000.0,0,0.0,192000.0,192000.0,13200.0,82608.0,0.1377755511022044,5134848.0,0.0,8.448,3641.1519999999978,0.0,0.0,0.0,96000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",470,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,54976.0,5.984,3647.1359999999977,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1718.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",471,64000.0,0.0,128000.0,0,0.0,128000.0,128000.0,13200.0,83608.0,0.13635236757292785,5134848.0,0.0,8.288,3655.4239999999977,0.0,0.0,0.0,64000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",472,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,53952.0,5.888,3661.3119999999976,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1686.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",473,80000.0,0.0,160000.0,0,0.0,160000.0,160000.0,13200.0,83108.0,0.13706026498317897,5134848.0,0.0,8.352,3669.6639999999975,0.0,0.0,0.0,80000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",474,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,54080.0,5.856,3675.5199999999977,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1690.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",475,78400.0,0.0,156800.0,0,0.0,156800.0,156800.0,13200.0,83158.0,0.13698914464808318,5134848.0,128.0,8.064,3683.5839999999976,0.0,0.0,0.0,78400.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",476,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,21.0,0.0,6432.0,800.0,4.032,3687.6159999999977,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,201.0,25.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",477,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.008,3690.6239999999975,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",478,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,23.0,0.9653092006033183,800.0,0.0,5.728,3696.3519999999976,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",479,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.88,3699.2319999999977,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",480,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,23.0,0.9653092006033183,800.0,0.0,5.792,3705.0239999999976,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",481,51200.0,0.0,102400.0,0,0.0,102400.0,102400.0,45715.0,13014.0,0.7784058982785336,831584.0,8832.0,9.088,3714.111999999998,0.0,0.0,0.0,51200.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25987.0,276.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",482,0.0,0.0,0.0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,8.608,3722.719999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",483,402056.0,0.0,804112.0,0,0.0,804112.0,804112.0,0.0,18849.0,0.0,816544.0,68512.0,5.952,3728.671999999998,0.0,0.0,0.0,402056.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25517.0,2141.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",484,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4737.0,0.0,1005184.0,0.0,4.064,3732.735999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,31412.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",485,201028.0,0.0,402056.0,0,0.0,402056.0,402056.0,0.0,6283.0,0.0,0.0,1608224.0,4.032,3736.767999999998,0.0,0.0,0.0,201028.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,50257.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",486,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,6283.0,0.9555817915744674,804128.0,0.0,6.272,3743.039999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25129.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",487,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.424,3746.463999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",488,0.0,0.0,0.0,0,0.0,0.0,0.0,65855.0,28336.0,0.6991644636961069,2750912.0,2005536.0,15.392,3761.855999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85966.0,62673.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",489,0.0,0.0,0.0,0,0.0,0.0,0.0,14210.0,28345.0,0.3339208083656445,2720832.0,2451264.0,11.392,3773.247999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85026.0,76602.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",490,0.0,0.0,0.0,0,0.0,0.0,0.0,15311.0,28312.0,0.3509845723586182,2719040.0,2429472.0,13.28,3786.527999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,84970.0,75921.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",491,0.0,0.0,0.0,0,0.0,0.0,0.0,15311.0,28243.0,0.35154061624649857,2717632.0,2264032.0,12.8,3799.327999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,84926.0,70751.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",492,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,6283.0,0.7017610480846822,1608224.0,0.0,5.024,3804.351999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50257.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",493,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.456,3807.807999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",494,0.0,0.0,0.0,0,0.0,0.0,0.0,14833.0,15233.0,0.4933479678041642,1882272.0,1340608.0,9.792,3817.599999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,58821.0,41894.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",495,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,25132.0,0.0,2428640.0,2412352.0,5.024,3822.623999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75895.0,75386.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",496,3122040.0,6655044.0,615296.0,0,0.0,7270340.0,7270340.0,528.0,6704.0,0.07300884955752213,1061056.0,752320.0,31.968,3854.591999999998,825232.0,201028.0,2814392.0,307648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33158.0,23510.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",497,0.0,1024200.0,0.0,0,0.0,1024200.0,1024200.0,112284.0,12568.0,0.8993368147887099,804320.0,615840.0,98.432,3953.0239999999976,1024200.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25135.0,19245.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",498,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3158.0,0.0,804128.0,200800.0,3.648,3956.6719999999978,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25129.0,6275.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",499,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,3.008,3959.6799999999976,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",500,402056.0,0.0,804112.0,0,0.0,804112.0,804112.0,0.0,18849.0,0.0,1809280.0,89600.0,11.744,3971.4239999999977,0.0,0.0,0.0,402056.0,0,0,0,0,0,0,0,0.0,0.0,0.0,56540.0,2800.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",501,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4737.0,0.0,1005184.0,0.0,4.192,3975.6159999999977,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,31412.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",502,3122052.0,6655044.0,615320.0,0,0.0,7270364.0,7270364.0,528.0,6704.0,0.07300884955752213,1081024.0,753280.0,32.608,4008.223999999998,825232.0,201028.0,2814392.0,307660.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33782.0,23540.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",503,38912.0,0.0,77824.0,0,0.0,77824.0,77824.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,9.408,4017.631999999998,0.0,0.0,0.0,38912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",504,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.488,4021.1199999999976,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",505,38912.0,0.0,77824.0,0,0.0,77824.0,77824.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,9.344,4030.4639999999977,0.0,0.0,0.0,38912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",506,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,4033.8559999999975,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",507,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.584,4037.4399999999973,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",508,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.512,4041.9519999999975,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",509,4096.0,220484.0,8192.0,0,0.0,228676.0,228676.0,320.0,1582.0,0.16824395373291273,804224.0,128.0,16.288,4058.2399999999975,220484.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25132.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",510,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,4061.5999999999976,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",511,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,5.312,4066.9119999999975,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",512,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,4070.3039999999974,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",513,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.352,4074.655999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",514,2213376.0,4023944.0,804864.0,0,0.0,4828808.0,4828808.0,0.0,6283.0,0.0,0.0,804128.0,6.048,4080.703999999997,0.0,402056.0,1810944.0,402432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,25129.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",515,1256412.0,2010280.0,502544.0,0,0.0,2512824.0,2512824.0,0.0,4737.0,0.0,1608256.0,0.0,5.44,4086.143999999997,0.0,0.0,1005140.0,251272.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50258.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",516,2560.0,0.0,5120.0,0,0.0,5120.0,5120.0,640.0,1582.0,0.28802880288028804,804224.0,128.0,22.688,4108.831999999997,0.0,0.0,0.0,2560.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25132.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",517,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.36,4112.191999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",518,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,4115.4559999999965,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",519,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,3.968,4119.423999999996,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",520,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.232,4122.655999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",521,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,96.0,160.0,3.808,4126.463999999996,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",522,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,3.008,4129.471999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",523,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.816,4132.287999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",524,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.328,4135.615999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",525,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.752,4138.367999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",526,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,128.0,32.0,3.904,4142.271999999997,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",527,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,5.0,0.0,32.0,32.0,7.424,4149.695999999997,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",528,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.264,4152.959999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",529,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,4156.383999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",530,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.936,4160.319999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",531,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.832,4165.151999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",532,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,4168.479999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
